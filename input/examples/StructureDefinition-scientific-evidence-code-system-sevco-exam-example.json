{"id": "181513", "url": "https://fevir.net/resources/CodeSystem/181513", "date": "2024-12-13", "meta": {"versionId": "37", "lastUpdated": "2024-12-13T10:23:35.919Z"}, "name": "Sevco_example_for_ebmonfhir_ig", "title": "Scientific Evidence Code System (SEVCO) -- EXAMPLE VERSION for EBMonFHIR Implementation Guide", "status": "active", "concept": [{"code": "SEVCO:01000", "display": "study design", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Harold Lehmann, Asiyah Lin, Mario Tristan, Neeraj Ojha"}, {"code": "approval", "valueString": "9/9 as of 4/26/2021: Eric Harvey, Bhagvan Kommadi, KM Saif-Ur-Rahman, Paola Rosati, Jes\u00fas L\u00f3pez-Alcalde, Tatyana Shamliyan, Sorana D. Bolboaca, Asiyah Lin, Eric Au"}, {"code": "negative-vote", "valueString": "2021-04-12 Vote 9-2 on \"Study design=A plan specification for how and what kinds of data are gathered or used to generate or test a hypothesis\", Bhagvan Kommadi, Jes\u00fas L\u00f3pez-Alcalde, Sorana D. Bolboaca, Tatyana Shamliyan, Asiyah Lin, Philippe Rocca-Serra, Eric Au, Alejandro Piscoya, Harold Lehmann, KM Saif-Ur-Rahman, Eric Harvey\n2021-04-06 vote 8-1 on \"Study Design = A plan specification for how and what kinds of data will be gathered as part of an investigation to generate or test a hypothesis\" by Tatyana Shamliyan, Paola Rosati, Mario Tristan, Bhagvan Kommadi, Jes\u00fas L\u00f3pez-Alcalde, Eric Harvey, KM Saif-Ur-Rahman, Asiyah Lin, Brian S. Alper"}], "definition": "A plan specification for how and what kinds of data will be gathered as part of an investigation which may produce testable explanations, conclusions and predictions or test a hypothesis.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "research design"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "experimental design"}], "concept": [{"code": "SEVCO:01001", "concept": [{"code": "SEVCO:01003", "display": "randomized assignment", "definition": "An interventional study design in which an independent variable (an exposure or intervention) is prospectively assigned or modified by random chance to separate groups.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "interventional research with randomized assignment"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "randomized trial"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "randomized controlled trial"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "RCT"}], "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Mario Tristan, Kenneth Wilkins, Erfan Shamsoddin, Ellen Jepson"}, {"code": "approval", "valueString": "8/8 as of 7/19/2021: Alejandro Piscoya, Harold Lehmann, Paola Rosati, Eric Harvey, Bhagvan Kommadi, Jesus Lopez-Alcalde, Sorana d. Bolboaca, Janice Tufte"}], "concept": [{"code": "SEVCO:01006", "display": "simple randomization", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Mario Tristan, Kenneth Wilkins, Erfan Shamsoddin, Ellen Jepson"}, {"code": "approval", "valueString": "8/8 as of 7/19/2021: Alejandro Piscoya, Harold Lehmann, Paola Rosati, Eric Harvey, Bhagvan Kommadi, Jesus Lopez-Alcalde, Sorana d. Bolboaca, Janice Tufte"}], "definition": "A randomized assignment in which each participant has the same prespecified likelihood of being assigned to a group as all other participants, independent of the assignment of any other participant.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "unrestricted randomization"}]}, {"code": "SEVCO:01007", "display": "stratified randomization", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Khalid Shahin"}, {"code": "approval", "valueString": "8/8 as of 7/19/2021: Alejandro Piscoya, Harold Lehmann, Paola Rosati, Eric Harvey, Bhagvan Kommadi, Jesus Lopez-Alcalde, Sorana d. Bolboaca, Janice Tufte"}], "definition": "A randomized assignment in which participants are stratified into groups based on prognostic variables and then randomized into balanced treatment groups"}, {"code": "SEVCO:01008", "display": "block randomization", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Khalid Shahin"}, {"code": "approval", "valueString": "7/7 as of 7/26/2021: Mario Tristan, Paola Rosati, Eric Harvey, Bhagvan Kommadi, Jesus Lopez-Alcalde, Leo Orozco, Janice Tufte"}, {"code": "negative-vote", "valueString": "2021-07-19 vote 7-1 on \"A randomized assignment in which a pre-specified number of subjects is assigned to a block containing the same pre-specified number of balanced group assignments in random order\" by Alejandro Piscoya, Harold Lehmann, Paola Rosati, Eric Harvey, Bhagvan Kommadi, Jesus Lopez-Alcalde, Sorana d. Bolboaca, Janice Tufte"}, {"code": "expert-comments", "valueString": "I think I'm hung up on the word \"balanced\". Does allocation in block design need to be balanced? Couldn't a block design allocate subjects to treatment arms in a 2:1, or other \"unbalanced\" ratio?"}], "definition": "A randomized assignment in which a pre-specified number of subjects is assigned to a block containing the same pre-specified ratio of group assignments in random order."}, {"code": "SEVCO:01009", "display": "adaptive randomization", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Mario Tristan, Kenneth Wilkins, Erfan Shamsoddin, Ellen Jepson"}, {"code": "approval", "valueString": "9/9 as of 8/9/2021: Erfan Shamsoddin, Paola Rosati, Eric Harvey, Bhagvan Kommadi, Brian S. Alper, Cheow Peng Ooi, Janice Tufte, Joanne Dehnbostel, Alejandro Piscoya"}, {"code": "negative-vote", "valueString": "2021-07-19 vote 7-1 on \"A randomized assignment in which a participant\u2019s group assignment probability is adjusted based on any factor such that the likelihood of assignment is not the same for all participants.\" by Alejandro Piscoya, Harold Lehmann, Paola Rosati, Eric Harvey, Bhagvan Kommadi, Jesus Lopez-Alcalde, Sorana d. Bolboaca, Janice Tufte, 2021-07-26 vote 6-1 by Paola Rosati, Eric Harvey, Bhagvan Kommadi, Jesus Lopez-Alcalde, Janice Tufte, Mario Tristan"}, {"code": "expert-comments", "valueString": "I deem this kind of adaptation could determine conflict of interests or a new kind of bias. I disagree with adding an adaptive randomization as a new term 7-26-21 comment: Again, why and for what you wish to maintain this term? I think the term adaptive randomization risks a severe selection bias. In ethical terms, I deem there is no justification to proceed with such a methodology in clinical trials."}], "definition": "A randomized assignment in which a participant\u2019s group assignment probability is adjusted based on any factor such that the likelihood of assignment is not the same for all participants."}]}, {"code": "SEVCO:01005", "concept": [{"code": "SEVCO:01004", "display": "quasi-randomized assignment", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Michael Panzer, Janice Tufte, Erfan Shamsoddin, Ellen Jepson, Khalid Shahin"}, {"code": "approval", "valueString": "7/7 as of 7/26/2021: Mario Tristan, Paola Rosati, Eric Harvey, Bhagvan Kommadi, Jesus Lopez-Alcalde, Leo Orozco, Janice Tufte"}, {"code": "negative-vote", "valueString": "2021-07-19 vote 6-2 on \"An interventional study design with a method of allocation that is not limited to random chance but is intended to produce similar baseline groups for experimentation.\" by Alejandro Piscoya, Harold Lehmann, Paola Rosati, Eric Harvey, Bhagvan Kommadi, Jesus Lopez-Alcalde, Sorana d. Bolboaca, Janice Tufte"}, {"code": "expert-comments", "valueString": "Which is the difference between thisquasi-randomized assignment and theadaptive randomization? It is unclearwhy we should insert these two terms inthe glossary I would specify in the definition thatquasi-randomisation is a non-randommethod of allocation"}, {"code": "comment", "valueString": "Quasi-random methods of allocation include allocation by alternate order of entry, date of birth, day of the week, month of the year, or medical record number"}], "definition": "An interventional study design with a method of allocation that is not limited to random chance but is intended to produce similar baseline groups for experimentation."}], "display": "non-randomized assignment", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Michael Panzer, Janice Tufte, Erfan Shamsoddin, Ellen Jepson, Khalid Shahin"}, {"code": "approval", "valueString": "9/9 as of 8/9/2021: Erfan Shamsoddin, Paola Rosati, Eric Harvey, Bhagvan Kommadi, Brian S. Alper, Cheow Peng Ooi, Janice Tufte, Joanne Dehnbostel, Alejandro Piscoya"}, {"code": "negative-vote", "valueString": "2021-07-19 vote 6-2 on \"An interventional study design in which an independent variable (an exposure or intervention) is prospectively assigned or modified by methods other than random chance to separate groups.\" by Alejandro Piscoya, Harold Lehmann, Paola Rosati, Eric Harvey, Bhagvan Kommadi, Jesus Lopez-Alcalde, Sorana D. Bolboaca, Janice Tufte, 2021-07-26 vote 6-1 by Paola Rosati, Eric Harvey, Bhagvan Kommadi, Jesus Lopez-Alcalde, Janice Tufte, Mario Tristan"}, {"code": "expert-comments", "valueString": "In this case, if the patients choose which is the arm they want to be in it would beok to insert this term. I presumetherefore that if the choice is made bythe researchers they offer a clearjustification for it in the protocol As written, this category would include all quasi-randomized designs. If this is the intent, fine. If this was not the intent, perhaps we could change \"..randomized..\" to \"..randomized or quasi-randomized..\" 7-26-21 comment: We usually have started the definitions by saying \"A xxx assignment that...\" (see previous ones in this page). That is, we define the assigment. However, for\"Non-Randomized Assignment\" we start by saying \"An interventional study design...\" I propose to describe the \"assignment\" (avoid starting by defining the study design itself)"}], "definition": "An interventional study design in which an independent variable (an exposure or intervention) is prospectively assigned or modified by methods other than random chance to separate groups.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "interventional research with non-randomized assignment"}]}, {"code": "SEVCO:01029", "concept": [{"code": "SEVCO:01041", "display": "pragmatic clinical trial", "property": [{"code": "external-definitions", "valueString": "NCIt:  Pragmatic Trial = A study designed to test the effectiveness of an intervention in a broad routine clinical practice. Term used to describe a clinical study designed to examine the benefits of a product under real world conditions.\nUMLS: Works about randomized clinical trials that compare interventions in clinical settings and which look at a range of effectiveness outcomes and impacts.\nCDISC Glossary: pragmatic trial = Term used to describe a clinical study designed to examine the benefits of a product under real world conditions.\nEDDA: pragmatic clinical trial = Randomized clinical trials that compare interventions in clinical settings and which look at a range of effectiveness outcomes and impacts. [MeSH_2015]\nSCO: pragmatic trial = A study designed to test the effectiveness of an intervention in a broad routine clinical practice.\n\"Pragmatic trials are designed to evaluate the effectiveness of interventions in real-life routine practice conditions, whereas explanatory trials aim to test whether an intervention works under optimal situations. The pragmatic trial, on the other hand, is designed to test interventions in the full spectrum of everyday clinical settings in order to maximize applicability and generalizability. The research question under investigation is whether an intervention actually works in real life.\" (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3181997/)"}, {"code": "comment", "valueString": "\"Pragmatic trials are designed to evaluate the effectiveness of interventions in real-life routine practice conditions, whereas explanatory trials aim to test whether an intervention works under optimal situations. The pragmatic trial, on the other hand, is designed to test interventions in the full spectrum of everyday clinical settings in order to maximize applicability and generalizability. The research question under investigation is whether an intervention actually works in real life.\" (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3181997/)"}, {"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Paul Whaley, Janice Tufte, Kenneth Wilkins, Harold Lehmann"}, {"code": "negative-vote", "valueString": "2021-11-30 vote 5-1 by Alejandro Piscoya, Robin Ann Yurk, Muhammad Afzal, Paul Whaley, Janice Tufte, Jesus Lopez-Alcalde"}, {"code": "expert-comments", "valueString": "2021-11-30 comments: (The definition in the current form is fine however the last part may be thought like;\nwhere \"everyday\" means day-to-day clinical practice wherein the conditions are not modified for the conduct of the research.),  Suggested alternative: = A clinical trial designed to test the effects of an intervention under everyday conditions, where \"everyday conditions\" means clinical conditions are not modified for the conduct of the research"}, {"code": "approval", "valueString": "2021-12-07 vote 5-0 by Mario Tristan, Robin Ann Yurk, Janice Tufte, CP Ooi, Joanne Dehnbostel"}], "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "pragmatic trial"}], "definition": "A clinical trial conducted under conditions of routine clinical practice."}, {"code": "SEVCO:01038", "display": "expanded access study", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "compassionate use trial"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "compassionate use study"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "expanded access trial"}], "property": [{"code": "external-definitions", "valueString": "from CTO:\n\nExpanded Access Study\n\nStudies that provide a means for obtaining an experimental drug or device for patients who are not adequately treated by existing therapy, who do not meet the eligibility criteria for enrollment, or who are otherwise unable to participate in another clinical study. Expanded Access studies include individual-patient IND, treatment IND, compassionate use, emergency use or continued access. An investigational drug product (including biological product) available through expanded access for patients who do not qualify for enrollment in a clinical trial. Expanded Access includes all expanded access types under section 561 of the Federal Food, Drug, and Cosmetic Act: (1) for individual patients, including emergency use; (2) for intermediate-size patient populations; and (3) under a treatment IND or treatment protocol.\n\n\nfrom NCIt:\n\nExpanded Access Study\n\nStudies that provide a means for obtaining an experimental drug or device for patients who are not adequately treated by existing therapy, who do not meet the eligibility criteria for enrollment, or who are otherwise unable to participate in another clinical study. Expanded Access studies include individual-patient IND, treatment IND, compassionate use, emergency use or continued access. \n\n\nalso Compassionate Treatment (compassionate use trial, expanded access trial, pre-approval access)\n\nProviding experimental therapies to very sick individuals even though they don't meet the critera for inclusion in a trial.\n\nA way to provide an investigational therapy to a patient who is not eligible to receive that therapy in a clinical trial, but who has a serious or life-threatening illness for which other treatments are not available. Compassionate use trials allow patients to receive promising but not yet fully studied or approved cancer therapies when no other treatment option exists.\n\nA potential pathway for a patient with an immediately life-threatening condition or serious disease or condition to gain access to an investigational medical product (drug, biologic, or medical device) for treatment outside of clinical trials when no comparable or satisfactory alternative therapy options are available. NOTE: The intent is treatment, as opposed to research. Individual, Intermediate-size, and Widespread Use Expanded Access, also Emergency IND, are all programs administered under FDA guidelines. Additionally, the US Right-to-Try Act, which is independent of FDA, expands access. [FDA Expanded Access: Information for Physicians]\n\n\n\nfrom EDDA:\n\ncompassionate use trial (expanded access trial, compassionate treatment)\n\nProviding experimental therapies to very sick individuals even though they don't meet the critera for inclusion in a trial. [NCI 2014_12E]\n\nProviding an investigational therapy to a patient who is not eligible to receive that therapy in a clinical trial, but who has a serious or life-threatening illness for which other treatments are not available. Compassionate use trials allow patients to receive promising but not yet fully studied or approved therapies when no other treatment option exists. Also called expanded access trial. [MeSH 2014_2014_02_10]\n\n\nshared as a comment: Expanded access is the use of an investigational new drug, biologics, and medical devices used to diagnose, monitor, or treat patients with serious diseases or conditions for which there are no comparable or satisfactory therapy options available outside of clinical trials. (USA FDA)"}, {"code": "comment", "valueString": "Expanded Access studies include individual-patient investigational new drug (IND), treatment IND, compassionate use, emergency use or continued access."}, {"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Harold Lehmann"}, {"code": "approval", "valueString": "2022-02-15 vote 10-0 by Paul Whaley, Andrew Beck, Brian S. Alper, Paola Rosati, Robin Ann Yurk, Janice Tufte, Jesus Lopez-Alcalde, Yasser Sami Amer, Harold Lehmann, Alejandro Piscoya"}, {"code": "expert-comments", "valueString": "2022-02-15 comment: Define IND acronym under comment for application under individual patient IND, treatment IND"}], "definition": "A clinical trial that provides a means for obtaining an experimental drug or device for patients who are not adequately treated by existing therapy, who do not meet the eligibility criteria for enrollment, or who are otherwise unable to participate in another clinical study."}, {"code": "SEVCO:01030", "display": "phase 1 trial", "concept": [{"code": "SEVCO:01031", "display": "exploratory investigational new drug study", "property": [{"code": "external-definitions", "valueString": "the original source at https://www.fda.gov/regulatory-information/search-fda-guidance-documents/exploratory-ind-studies\nFDA GUIDANCE DOCUMENT\nExploratory IND Studies\nGuidance for Industry, Investigators, and Reviewers\nJANUARY 2006\ninvestigational new drug (IND)\n\nFor the purposes of this guidance the phrase exploratory IND study is intended to describe a clinical trial that\n\nis conducted early in phase 1,\ninvolves very limited human exposure, and\nhas no therapeutic or diagnostic intent (e.g., screening studies, microdose studies). \n\nSuch exploratory IND studies are conducted prior to the traditional dose escalation, safety, and tolerance studies that ordinarily initiate a clinical drug development program.  The duration of dosing in an exploratory IND study is expected to be limited (e.g., 7 days).\n\n\nfrom CTO:\n\nEarly Phase I clinical trial (Phase 0 trial, Phase 0 clinical trial, Pre-Clinical Trial)\n\nA clinical trial that is at an Early Phase i or Phase 0, which is designed to use an investigational agent that is available only in very limited quantities and which has never previously given to humans or for which there is extremely limited human experience. Phase 0 clinical trials are intended to enable researchers to understand the path of the drug in the body and its efficacy. Adverse event reporting in Phase 0 trials is expedited. [def-source: NCI] Exploratory trials, involving very limited human exposure, with no therapeutic or diagnostic intent (e.g., screening studies, microdose studies). (Formerly listed as \"Phase 0\") A clinical trial that is at Early Phase 1 or Phase 0\n\nfrom SCO:\n\t\nnot included\n\nfrom NCIt:\n\nPreferred Name:  Exploratory Investigational New Drug Study\n\nDefinition:  A type of clinical trial that involves low dosage and short duration of drug exposure for a limited number of study participants with the intent of gathering preliminary data on the mechanism of action, pharmacodynamics, pharmacokinetics, or bioavailability of promising therapeutic candidate agents in human subjects.\n\nCDISC-GLOSS Definition:  A clinical study that is conducted early in Phase 1; involves very limited human exposure and has no therapeutic or diagnostic intent (e.g., screening studies, microdose studies) [FDA Guidance for industry, investigators, and Reviewers: exploratory IND studies, January 2006] See also Phase 0.\n\nFirst-in-Human Study = A type of phase 1 clinical trial in which the test product is administered to human beings for the first time. \n\nPhase 0 Trial = Pre-Clinical Trial = A clinical trial that uses an investigational agent that is available only in very limited quantities and which has never previously given to humans or for which there is extremely limited human experience. Phase 0 clinical trials are intended to enable researchers to understand the path of the drug in the body and its efficacy. Adverse event reporting in Phase 0 trials is expedited.\n\nFirst-in-human trials, in a small number of subjects, that are conducted before Phase 1 trials and are intended to assess new candidate therapeutic and imaging agents. The study agent is administered at a low dose for a limited time, and there is no therapeutic or diagnostic intent. NOTE: FDA Guidance for Industry, Investigators, and Reviewers: Exploratory IND Studies, January 2006 classifies such studies as Phase 1. NOTE: A Phase 0 study might not include any drug delivery but may be an exploration of human material from a study (e.g., tissue samples or biomarker determinations). [Improving the Quality of Cancer Clinical Trials: Workshop summary-Proceedings of the National Cancer Policy Forum Workshop, improving the Quality of Cancer Clinical Trials (Washington, DC, Oct 2007)] (CDISC glossary)\n\nFirst-in-human trials, in a small number of subjects, that are conducted before Phase 1 trials and are intended to assess new candidate therapeutic and imaging agents. The study agent is administered at a low dose for a limited time, and there is no therapeutic or diagnostic intent. NOTE: FDA Guidance for Industry, Investigators, and Reviewers: Exploratory IND Studies, January 2006 classifies such studies as Phase 1. NOTE: A Phase 0 study might not include any drug delivery but may be an exploration of human material from a study (e.g., tissue samples or biomarker determinations). [Improving the Quality of Cancer Clinical Trials: Workshop summary-Proceedings of the National Cancer Policy Forum Workshop, improving the Quality of Cancer Clinical Trials (Washington, DC, Oct 2007)]   )\n\nfrom OCRe:\n\t\nPhase 0 = A Phase 0 trial is an exploratory trial involving very limited human exposure, with no therapeutic or diagnostic intent (e.g., screening study, microdose study).\n\nfrom EDDA:\n\npre-clinical trial = phase 0 trial = A clinical trial that uses an investigational agent that is available only in very limited quantities and which has never previously given to humans or for which there is extremely limited human experience. Phase 0 clinical trials are intended to enable researchers to understand the path of the drug in the body and its efficacy. Adverse event reporting in Phase 0 trials is expedited. [NCI 2014_12E]"}, {"code": "comment", "valueString": "According to the original FDA guidance, such exploratory IND studies are conducted prior to the traditional dose escalation, safety, and tolerance studies that ordinarily initiate a clinical drug development program.  The duration of dosing in an exploratory IND study is expected to be limited (e.g., 7 days).\n\nA type of clinical trial that involves low dosage and short duration of drug exposure for a limited number of study participants with the intent of gathering preliminary data on the mechanism of action, pharmacodynamics, pharmacokinetics, or bioavailability of promising therapeutic candidate agents in human subjects.\n\nLess official terms (phase 0 trial, pre-clinical trial) have been used to describe a clinical trial that uses an investigational agent that has never previously given to humans or for which there is extremely limited human experience. A Phase 0 study might not include any drug delivery but may be an exploration of human material from a study (e.g., tissue samples or biomarker determinations)."}, {"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Paul Whaley, Janice Tufte, Olga Vovk"}, {"code": "negative-vote", "valueString": "2022-01-25 vote 8-1 by Harold Lehmann, Alejandro Piscoya, Janice Tufte, Paola Rosati, Robin Ann Yurk, Philippe Rocca-Serra, Mario Tristan, Brian S. Alper, Jesus Lopez-Alcalde"}, {"code": "expert-comments", "valueString": "2022-01-25 comments: I had to read a couple of times and check the hierarchy to appreciate this definition, but I agree.\nFor a later version of SEVCO, we probably should put citations (\"original FDA guidance\") into the documentation.\nconcern over the use of the term 'phase 1' in the definition and the presence of an Alternative term 'phase 0 study`."}, {"code": "approval", "valueString": "2022-02-01 vote 5-0 by Paola Rosati, Mario Tristan, Robin Ann Yurk, Janice Tufte, Brian S. Alper"}], "definition": "A clinical trial that is conducted early in phase 1, involves very limited human exposure, and has no therapeutic or diagnostic intent (e.g., screening studies, microdose studies).", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "phase 0 study"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "pre-clinical trial"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "exploratory ind study"}]}], "property": [{"code": "external-definitions", "valueString": "https://www.ecfr.gov/current/title-21/chapter-I/subchapter-D/part-312/subpart-B/section-312.21 is the US Code of Federal Regulations Title 21 (Food and Drugs) Chapter I Subchapter D Part 312 Subpart B \u00a7 312.21 and includes:\n\n\u00a7 312.21 Phases of an investigation.\n\nAn IND may be submitted for one or more phases of an investigation. The clinical investigation of a previously untested drug is generally divided into three phases. Although in general the phases are conducted sequentially, they may overlap. These three phases of an investigation are a[sic] follows:\n\n....\n\nPhase 1. \n\n(1) Phase 1 includes the initial introduction of an investigational new drug into humans. Phase 1 studies are typically closely monitored and may be conducted in patients or normal volunteer subjects. These studies are designed to determine the metabolism and pharmacologic actions of the drug in humans, the side effects associated with increasing doses, and, if possible, to gain early evidence on effectiveness. During Phase 1, sufficient information about the drug's pharmacokinetics and pharmacological effects should be obtained to permit the design of well-controlled, scientifically valid, Phase 2 studies. The total number of subjects and patients included in Phase 1 studies varies with the drug, but is generally in the range of 20 to 80. \n\n(2) Phase 1 studies also include studies of drug metabolism, structure-activity relationships, and mechanism of action in humans, as well as studies in which investigational drugs are used as research tools to explore biological phenomena or disease processes.\n\n\n\nfrom CTO:\n\nPhase I trial (phase I study, early-stage clinical trial, phase I protocol, phase I clinical trial, trial phase 1)\nA clinical research protocol designed to test a new biomedical intervention in a small group of people for the first time. A Phase I trial can be to establish the toxicity of a new treatment with escalating intensity of the treatment administered and/or to determine the side effects of a new treatment for a particular indication in subjects. Includes initial studies to determine the metabolism and pharmacologic actions of drugs in humans, the side effects associated with increasing doses, and to gain early evidence of effectiveness; may include healthy participants and/or patients.\n\n\t\n\t\nThe initial introduction of an investigational new drug into humans. Phase 1 studies are typically closely monitored and may be conducted in patients or normal volunteer subjects. NOTE: These studies are designed to determine the metabolism and pharmacologic actions of the drug in humans, the side effects associated with increasing doses, and, if possible, to gain early evidence on effectiveness. During Phase 1, sufficient information about the drug's pharmacokinetics and pharmacological effects should be obtained to permit the design of well-controlled, scientifically valid, Phase 2 studies. The total number of subjects and patients included in Phase I studies varies with the drug, but is generally in the range of 20 to 80. Phase 1 studies also include studies of drug metabolism, structure-activity relationships, and mechanism of action in humans, as well as studies in which investigational drugs are used as research tools to explore biological phenomena or disease processes. [After FDA CDER Handbook, ICH E8] (CDISC glossary)\n\nThe first step in testing a new treatment in humans. These studies test the best way to give a new treatment (for example, by mouth, intravenous infusion, or injection) and the best dose. The dose is usually increased a little at a time in order to find the highest dose that does not cause harmful side effects. Because little is known about the possible risks and benefits of the treatments being tested, phase I trials usually include only a small number of patients who have not been helped by other treatments.\n\nThe initial introduction of an investigational new drug into humans. Phase 1 studies are typically closely monitored and may be conducted in patients or normal volunteer subjects. NOTE: These studies are designed to determine the metabolism and pharmacologic actions of the drug in humans, the side effects associated with increasing doses, and, if possible, to gain early evidence on effectiveness. During Phase 1, sufficient information about the drug's pharmacokinetics and pharmacological effects should be obtained to permit the design of well-controlled, scientifically valid Phase 2 studies. The total number of subjects and patients included in Phase 1 studies varies with the drug, but is generally in the range of 20 to 80. Phase 1 studies also include studies of drug metabolism, structure-activity relationships, and mechanism of action in humans, as well as studies in which investigational drugs are used as research tools to explore biological phenomena or disease processes. [after FDA CDER handbook, ICH E8]\n\nfrom SCO:\n\t\nphase I trial not independently defined\n\nfrom NCIt:\n\nsame as CTO\n\nfrom OCRe:\n\t\nA Phase 1 trial includes initial studies to determine the metabolism and pharmacologic actions of drugs in humans, the side effects associated with increasing doses, and to gain early evidence of effectiveness; may include healthy participants and/or patients.\n\nfrom EDDA:\n\nA clinical research protocol designed to test a new biomedical intervention in a small group of people for the first time. A Phase I trial can be to establish the toxicity of a new treatment with escalating intensity of the treatment administered and/or to determine the side effects of a new treatment for a particular indication in subjects. [NCI 2014_12E] \n\nStudies performed to evaluate the safety of diagnostic, therapeutic, or prophylactic drugs, devices, or techniques in healthy subjects and to determine the safe dosage range (if appropriate). These tests also are used to determine pharmacologic and pharmacokinetic properties (toxicity, metabolism, absorption, elimination, and preferred route of administration). They involve a small number of persons and usually last about 1 year. This concept includes phase I studies conducted both in the U.S. and in other countries. [MeSH 2014_2014_02_10]\n\nfrom INTERNATIONAL COUNCIL FOR HARMONISATION OF TECHNICAL REQUIREMENTS FOR PHARMACEUTICALS FOR HUMAN USE (ICH HARMONISED GUIDELINE) GENERAL CONSIDERATIONS FOR CLINICAL STUDIES E8(R1) https://database.ich.org/sites/default/files/E8-R1_Guideline_Step4_2021_1006.pdf Adopted on 6 October 2021\n\n4.3.1 Human Pharmacology\nThe protection of study participants should always be the first priority when designing early\nclinical studies, especially for the initial administration of an investigational product to humans\n(usually referred to as phase 1). These studies may be conducted in healthy volunteer\nparticipants or in a selected population of patients who have the condition or the disease,\ndepending on drug properties and the objectives of the development programme.\n\nThese studies typically address one or a combination of the following aspects:\n\n4.3.1.1 Estimation of Initial Safety and Tolerability\nThe initial and subsequent administration of a drug to humans is usually intended to determine\nthe tolerability of the dose range expected to be evaluated in later clinical studies and to\ndetermine the nature of adverse reactions that can be expected. These studies typically include\nboth single and multiple dose administration.\n\n4.3.1.2 Pharmacokinetics\nCharacterisation of a drug's absorption, distribution, metabolism, and excretion continues\nthroughout the development programme, but the preliminary characterisation is an essential\nearly goal. Pharmacokinetic studies are particularly important to assess the clearance of the\ndrug and to anticipate possible accumulation of parent drug or metabolites, interactions with\nmetabolic enzymes and transporters, and potential drug-drug interactions. Some\npharmacokinetic studies are commonly conducted in later phases to answer more specialised\nquestions. For orally administered drugs, the study of food effects on bioavailability is\nimportant to inform the dosing instructions in relation to food. Obtaining pharmacokinetic\ninformation in sub-populations with potentially different metabolism or excretion, such as\npatients with renal or hepatic impairment, geriatric patients, children, and ethnic subgroups\nshould be considered (ICH E4 Dose-Response Studies, E7 Clinical Trials in Geriatric\nPopulation, E11, and E5, respectively).\n\n4.3.1.3 Pharmacodynamics & Early Measurement of Drug Activity\nDepending on the drug and the endpoint of interest, pharmacodynamic studies and studies\nrelating drug levels to response (PK/PD studies) may be conducted in healthy volunteer\nparticipants or in patients with the condition or disease. If there is an appropriate measure,\npharmacodynamic data can provide early estimates of activity and efficacy and may guide the\ndosage and dose regimen in later studies.\n\n\nfrom March 1998 https://www.ema.europa.eu/en/documents/scientific-guideline/ich-e-8-general-considerations-clinical-trials-step-5_en.pdf\n\n3.1.3.1 Phase I (Most typical kind of study: Human Pharmacology)\nPhase I starts with the initial administration of an investigational new drug into humans.\nAlthough human pharmacology studies are typically identified with Phase I, they may also be\nindicated at other points in the development sequence. Studies in this phase of development\nusually have non-therapeutic objectives and may be conducted in healthy volunteer subjects\nor certain types of patients, e.g. patients with mild hypertension. Drugs with significant\npotential toxicity, e.g. cytotoxic drugs, are usually studied in patients. Studies in this phase\ncan be open, baseline controlled or may use randomisation and blinding, to improve the\nvalidity of observations.\nStudies conducted in Phase I typically involve one or a combination of the following aspects:\na) Estimation of Initial Safety and Tolerability\nThe initial and subsequent administration of an investigational new drug into humans is\nusually intended to determine the tolerability of the dose range expected to be needed for later\nclinical studies and to determine the nature of adverse reactions that can be expected. These\nstudies typically include both single and multiple dose administration.\nb) Pharmacokinetics\nCharacterisation of a drug's absorption, distribution, metabolism, and excretion continues\nthroughout the development plan. Their preliminary characterisation is an important goal of\nPhase I. Pharmacokinetics may be assessed via separate studies or as a part of efficacy, safety\nand tolerance studies. Pharmacokinetic studies are particularly important to assess the\nclearance of the drug and to anticipate possible accumulation of parent drug or metabolites\nand potential drug-drug interactions. Some pharmacokinetic studies are commonly conducted\nin later phases to answer more specialised questions. For many orally administered drugs,\nespecially modified release products, the study of food effects on bioavailability is important.\nObtaining pharmacokinetic information in sub-populations such as patients with impaired\nelimination (renal or hepatic failure), the elderly, children, women and ethnic subgroups\nshould be considered. Drug-drug interaction studies are important for many drugs; these are\ngenerally performed in phases beyond Phase I but studies in animals and in vitro studies of\nmetabolism and potential interactions may lead to doing such studies earlier.\nc) Assessment of Pharmacodynamics\nDepending on the drug and the endpoint studied, pharmacodynamic studies and studies\nrelating drug blood levels to response (PK/PD studies) may be conducted in healthy volunteer\nsubjects or in patients with the target disease. In patients, if there is an appropriate measure,\npharmacodynamic data can provide early estimates of activity and potential efficacy and may\nguide the dosage and dose regimen in later studies. \nd) Early Measurement of Drug Activity\nPreliminary studies of activity or potential therapeutic benefit may be conducted in Phase I as\na secondary objective. Such studies are generally performed in later phases but may be\nappropriate when drug activity is readily measurable with a short duration of drug exposure in\npatients at this early stage."}, {"code": "comment", "valueString": "Phase 1 trials are often the first step in testing a new treatment in humans and may include safety assessment, measurement of metabolism and pharmacologic actions of a drug in humans, or the side effects associated with increasing doses. Phase 1 studies often include between 20 and 80 subjects, and often involve healthy subjects."}, {"code": "editors", "valueString": "Brian S. Alper, Paul Whaley, Harold Lehmann, Joanne Dehnbostel"}, {"code": "negative-vote", "valueString": "2022-01-04 vote 5-2 by Robin Ann Yurk, Harold Lehmann, janice tufte, Paola Rosati, C P Ooi,  Paul Whaley, Joanne Dehnbostel"}, {"code": "expert-comments", "valueString": "2022-01-04 comments: Perhaps adding the following may improve the clarity \"It may include testing the best way to give a new treatment (for example, by mouth, infusion into a vein, or injection)\".\n\n \"providing the initial investigation\" sounds a bit vague compared to the other trial phase definitions. Also, can a trial really \"provide an investigation\"? Maybe suggest changing to \"in which xxx is investigated\", where \"xxx\" is a tighter definition of what \"the initial\" is referring to.\n\n2022-01-11 comment: I would suggest not adding how many subjects are typically involved, maybe state that these usually have very small sample sizes. Unfortunately, sample sizes have decreased over time. https://bmjopen.bmj.com/content/11/12/e053377"}, {"code": "approval", "valueString": "2022-01-11 vote 7-0 by Harold Lehmann, Jesus Lopez-Alcalde, Mario Tristan, janice tufte, Paul Whaley,  Andrew Beck, Robin Ann Yurk"}], "definition": "A clinical trial to gather initial evidence in humans to support further investigation of an intervention.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "phase I trial"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "phase 1 study"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "phase I clinical trial"}]}, {"code": "SEVCO:01032", "display": "phase 1/phase 2 trial", "property": [{"code": "external-definitions", "valueString": "from CTO:\n\nphase I/II trial (trial phase 1/2, trial phase 1-2)\n\nTrials that are a combination of phases 1 and 2. A clinical research protocol designed to study the safety, dosage levels and response to new treatment. Phase I/II trials combine a Phase I and a Phase II trial of the same treatment into a single protocol.\n\nA class of clinical study that combines elements characteristic of traditional Phase I and Phase II trials. See also Phase I, Phase II.\n\nA trial to study the safety, dosage levels, and response to a new treatment.\n\nfrom SCO:\n\t\nphase I/II trial (trial phase 1/2, trial phase 1-2)\n\nA clinical research protocol designed to study the safety, dosage levels and response to new treatment. Phase I/II trials combine a Phase I and a Phase II trial of the same treatment into a single protocol.\n\nfrom NCIt:\n\nsame as CTO\n\nfrom OCRe:\n\t\nnot included\n\nfrom EDDA:\n\nphase I/II trial (trial phase 1/2, trial phase 1-2)\n\nA class of clinical study that combines elements characteristic of traditional Phase I and Phase II trials. See also Phase I, Phase II. [NCIT_14.08d] [Contributing_Source_CDISC]\n\nA clinical research protocol designed to study the safety, dosage levels and response to new treatment. Phase I/II trials combine a Phase I and a Phase II trial of the same treatment into a single protocol. [NCIT_14.08d]\n\nA trial to study the safety, dosage levels, and response to a new treatment. [NCIT_14.08d]"}, {"code": "editors", "valueString": "Brian S. Alper, Paul Whaley, Joanne Dehnbostel, Janice Tufte"}, {"code": "negative-vote", "valueString": "2022-01-18 vote 3-2 by Harold Lehmann, Paul Harris, Robin Ann Yurk, raradhikaag@gmail.com, Paul Whaley"}, {"code": "comment", "valueString": "A phase 1 trial is a clinical trial to gather initial evidence in humans to support further investigation of an intervention.\nA phase 2 trial is a clinical trial to gather evidence of effectiveness and safety for an intervention in patients with the disease or condition under study, but not intended to provide an adequate basis for regulatory approval for clinical use."}, {"code": "expert-comments", "valueString": "2022-01-18 comments: Does it matter that the Term has Arabic numerals and the Definition, Roman?\nConsider adding a comment for application to improve definition interpretation with individual term definitions for Phase I/Phase 2 trial\nNot sure I quite understand what the \"separate sets of design parameters with\" phrase means here?"}, {"code": "approval", "valueString": "2022-01-25 vote 9-0 by Harold Lehmann, Alejandro Piscoya, Janice Tufte, Paola Rosati, Robin Ann Yurk, Philippe Rocca-Serra, Mario Tristan, Brian S. Alper, Jesus Lopez-Alcalde"}], "definition": "A clinical trial with a component meeting the definition of phase 1 trial and a component meeting the definition of phase 2 trial.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "phase I/II trial"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "phase 1-2 trial"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "phase 1/2 trial"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "trial phase 1-2"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "trial phase 1/2"}]}, {"code": "SEVCO:01033", "display": "phase 2 trial", "property": [{"code": "external-definitions", "valueString": "https://www.ecfr.gov/current/title-21/chapter-I/subchapter-D/part-312/subpart-B/section-312.21 is the US Code of Federal Regulations Title 21 (Food and Drugs) Chapter I Subchapter D Part 312 Subpart B \u00a7 312.21 and includes:\n\n\u00a7 312.21 Phases of an investigation.\n\nAn IND may be submitted for one or more phases of an investigation. The clinical investigation of a previously untested drug is generally divided into three phases. Although in general the phases are conducted sequentially, they may overlap. These three phases of an investigation are a[sic] follows:\n\n....\n\nPhase 2.  Phase 2 includes the controlled clinical studies conducted to evaluate the effectiveness of the drug for a particular indication or indications in patients with the disease or condition under study and to determine the common short-term side effects and risks associated with the drug. Phase 2 studies are typically well controlled, closely monitored, and conducted in a relatively small number of patients, usually involving no more than several hundred subjects.\n\n\n\nfrom CTO:\n\nPhase II trial\nA clinical research protocol designed to study a biomedical or behavioral intervention in a larger group of people (several hundred), to evaluate the drug's effectiveness for a particular indication in patients with the disease or condition under study, and to determine the common short-term side effects and risks associated with the intervention. Includes controlled clinical studies conducted to evaluate the effectiveness of the drug for a particular indication or indications in participants with the disease or condition under study and to determine the common short-term side effects and risks.\n\n\t\nPhase 2. Controlled clinical studies conducted to evaluate the effectiveness of the drug for a particular indication or indications in patients with the disease or condition under study and to determine the common short-term side effects and risks associated with the drug. NOTE: Phase 2 studies are typically well controlled, closely monitored, and conducted in a relatively small number of patients, usually involving no more than several hundred subjects. [After FDA CDER Handbook, ICH E8] (CDISC glossary)\n\nA study to test whether a new treatment has an anticancer effect (for example, whether it shrinks a tumor or improves blood test results) and whether it works against a certain type of cancer.\n\nControlled clinical studies conducted to evaluate the effectiveness of the drug for a particular indication or indications in patients with the disease or condition under study and to determine the common short-term side effects and risks associated with the drug. NOTE: Phase 2 studies are typically well controlled, closely monitored, and conducted in a relatively small number of patients, usually involving no more than several hundred subjects. [after FDA CDER handbook, ICH E8]\n\nfrom SCO:\n\t\nphase II trial not independently defined\n\nfrom NCIt:\n\nsame as CTO\n\nfrom OCRe:\n\t\nA Phase 2 trial includes controlled clinical studies conducted to evaluate the effectiveness of the drug for a particular indication or indications in patients with the disease or condition under study and to determine the common short-term side effects and risks.\n\nfrom EDDA:\nA clinical research protocol designed to study a biomedical or behavioral intervention in a larger group of people (several hundred), to evaluate the drug's effectiveness for a particular indication in patients with the disease or condition under study, and to determine the common short-term side effects and risks associated with the intervention. [NCI 2014_12E] Studies that are usually controlled to assess the effectiveness and dosage (if appropriate) of diagnostic, therapeutic, or prophylactic drugs, devices, or techniques. These studies are performed on several hundred volunteers, including a limited number of patients with the target disease or disorder, and last about two years. This concept includes phase II studies conducted in both the U.S. and in other countries. [MeSH 2014_2014_02_10]\nA clinical research protocol designed to study a biomedical or behavioral intervention in a larger group of people (several hundred), to evaluate the drug's effectiveness for a particular indication in patients with the disease or condition under study, and to determine the common short-term side effects and risks associated with the intervention. [NCI 2014_12E]\n\nStudies that are usually controlled to assess the effectiveness and dosage (if appropriate) of diagnostic, therapeutic, or prophylactic drugs, devices, or techniques. These studies are performed on several hundred volunteers, including a limited number of patients with the target disease or disorder, and last about two years. This concept includes phase II studies conducted in both the U.S. and in other countries. [MeSH 2014_2014_02_10]\n\nfrom INTERNATIONAL COUNCIL FOR HARMONISATION OF TECHNICAL REQUIREMENTS FOR PHARMACEUTICALS FOR HUMAN USE (ICH HARMONISED GUIDELINE) GENERAL CONSIDERATIONS FOR CLINICAL STUDIES E8(R1) https://database.ich.org/sites/default/files/E8-R1_Guideline_Step4_2021_1006.pdf Adopted on 6 October 2021\n\nAfter initial clinical studies provide sufficient information on safety, clinical pharmacology and\ndose, exploratory and confirmatory studies (usually referred to as phases 2 and 3, respectively)\nare conducted to further evaluate both the safety and efficacy of the drug. \n\nExploratory studies are designed to investigate safety and efficacy in a selected population of\npatients for whom the drug is intended. Additionally, these studies aim to refine the effective\ndose(s) and regimen, refine the definition of the targeted population, provide a more robust\nsafety profile for the drug, and include evaluation of potential study endpoints for subsequent\nstudies. Exploratory studies may provide information on the identification and determination\nof factors that affect the treatment effect and, possibly combined with modelling and\nsimulation, serve to support the design of later confirmatory studies.\n\nfrom March 1998 https://www.ema.europa.eu/en/documents/scientific-guideline/ich-e-8-general-considerations-clinical-trials-step-5_en.pdf\n\n3.1.3.2 Phase II (Most typical kind of study: Therapeutic Exploratory)\nPhase II is usually considered to start with the initiation of studies in which the primary\nobjective is to explore therapeutic efficacy in patients.\nInitial therapeutic exploratory studies may use a variety of study designs, including\nconcurrent controls and comparisons with baseline status. Subsequent trials are usually\nrandomised and concurrently controlled to evaluate the efficacy of the drug and its safety for\na particular therapeutic indication. Studies in Phase II are typically conducted in a group of\npatients who are selected by relatively narrow criteria, leading to a relatively homogeneous\npopulation and are closely monitored.\nAn important goal for this phase is to determine the dose(s) and regimen for Phase III trials.\nEarly studies in this phase often utilise dose escalation designs (see ICH E4) to give an early\nestimate of dose response and later studies may confirm the dose response relationship for the\nindication in question by using recognised parallel dose-response designs (could also be\ndeferred to phase III). Confirmatory dose response studies may be conducted in Phase II or\nleft for Phase III. Doses used in Phase II are usually but not always less than the highest doses\nused in Phase\u2020I.\nAdditional objectives of clinical trials conducted in Phase II may include evaluation of\npotential study endpoints, therapeutic regimens (including concomitant medications) and\ntarget populations (e.g. mild versus severe disease) for further study in Phase II or III. These\nobjectives may be served by exploratory analyses, examining subsets of data and by including\nmultiple endpoints in trials."}, {"code": "comment", "valueString": "Phase 2 trials are typically controlled clinical studies conducted to evaluate the effectiveness of the intervention for a particular indication and to determine the common short-term side effects and risks associated with the intervention. Phase 2 trials may have a goal of determining the dose(s) or regimen(s) for Phase 3 trials. Phase 2 studies usually include no more than several hundred subjects."}, {"code": "editors", "valueString": "Brian S. Alper, Paul Whaley, Joanne Dehnbostel, Harold Lehmann"}, {"code": "negative-vote", "valueString": "2021-01-04 vote 5-2 by Robin Ann Yurk, Harold Lehmann, janice tufte, Paola Rosati, C P Ooi, Joanne Dehnbostel, Paul Whaley"}, {"code": "expert-comments", "valueString": "2021-01-04 comments: The first part of the definition is ok. In the second part, I would suggest to change with \"An insufficient evidence for the intervention tested or the desired patients' number failure could occur thus impeding regulatory approval for clinical use\"\nComment Suggestion to add to comment for term from extracted from notes-3.1.3.2:  An important goal for this phase is to determine the dose(s) and regimen for Phase III trials.\n\nEarly studies in this phase often utilize dose escalation designs (see ICH E4) to give an early estimate of dose response and later studies may confirm the dose response relationship for the indication in question by using recognized parallel dose-response designs (could also be deferred to phase III)\n\nMinor change - the phrasing is a little awkward, suggest \"gather evidence about the effectiveness and safety of an intervention in patients with the disease or condition under study, but not sufficient...\". \n\nI am not sure the comment for application is fully consistent with the definitions (what about safety?).\n\n2022-01-11 comment: I would suggest not adding how many subjects are typically involved, maybe state that these usually have small sample sizes. Unfortunately, sample sizes have decreased over time. https://bmjopen.bmj.com/content/11/12/e053377"}, {"code": "approval", "valueString": "2022-01-11 vote 7-0 by Jesus Lopez-Alcalde, Harold Lehmann, Mario Tristan, janice tufte, Paul Whaley, Andrew Beck, Robin Ann Yurk"}], "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "phase II trial"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "phase 2 study"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "exploratory clinical study"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "phase II clinical trial"}], "definition": "A clinical trial to gather evidence of effectiveness and safety for an intervention in patients with the disease or condition under study, but not intended to provide an adequate basis for regulatory approval for clinical use."}, {"code": "SEVCO:01034", "display": "phase 2/phase 3 trial", "property": [{"code": "external-definitions", "valueString": "from CTO:\n\nphase II/III trial (trial phase 2/3, trial phase 2-3)\n\nTrials that are a combination of phases 2 and 3. A type of clinical study that combines elements characteristic of traditional Phase II and Phase III trials.\n\nA trial to study response to a new treatment and the effectiveness of the treatment compared with the standard treatment regimen.\n\nA class of clinical study that combines elements characteristic of traditional Phase II and Phase III trials.\n\nfrom SCO:\n\t\nnot included\n\nfrom NCIt:\n\nphase II/III trial (trial phase 2/3, trial phase 2-3)\n\nA type of clinical study that combines elements characteristic of traditional Phase II and Phase III trials.\n\nA trial to study response to a new treatment and the effectiveness of the treatment compared with the standard treatment regimen.\n\nA class of clinical study that combines elements characteristic of traditional Phase II and Phase III trials.\n\nfrom OCRe:\n\t\nnot included\n\nfrom EDDA:\n\nphase II/III trial (trial phase 2/3, trial phase 2-3)\n\nA type of clinical study that combines elements characteristic of traditional Phase II and Phase III trials. [NCIT_14.08d]\n\nA class of clinical study that combines elements characteristic of traditional Phase II and Phase III trials. [NCIT_14.08d] [Contributing_Source_CDISC]\n\nA trial to study response to a new treatment and the effectiveness of the treatment compared with the standard treatment regimen. [NCIT_14.08d]\n\n\n\"Designs that combine phase II and III functions (ie, phase II/III designs) have separate sets of design parameters that correspond to their phase II and III components.\" -- Korn EL et al. Design Issues in Randomized Phase II/III Trials. J Clin Oncol 2012 https://ascopubs.org/doi/full/10.1200/JCO.2011.38.5732. https://europepmc.org/backend/ptpmcrender.fcgi?accid=PMC3295562&blobtype=pdf"}, {"code": "editors", "valueString": "Brian S. Alper, Paul Whaley, Joanne Dehnbostel, Janice Tufte"}, {"code": "negative-vote", "valueString": "2022-01-18 vote 2-3 by Harold Lehmann, Paul Harris, Robin Ann Yurk, raradhikaag@gmail.com, Paul Whaley\n2022-01-25 vote 9-1 by Harold Lehmann, Alejandro Piscoya, Janice Tufte, Paola Rosati, Robin Ann Yurk, Philippe Rocca-Serra, Mario Tristan, Brian S. Alper, Jesus Lopez-Alcalde, Paul Whaley\n2022-02-01 vote 4-1 by Paola Rosati, Mario Tristan, Robin Ann Yurk, Janice Tufte, Brian S. Alper"}, {"code": "expert-comments", "valueString": "2022-01-18 comments: Phase 2/3 trials determine efficacy of a new biomedical intervention i.e. whether it works as intended in a larger group of study participants, and monitor adverse effects so that the intervention may be used safely.\nConsider adding a comment for application to improve definition interpretation with individual term definitions for Phase 2/Phase 3 trial\nNot sure I quite understand what the \"separate sets of design parameters with\" phrase means here?\n2022-01-25 comment: As already pointed out, to me these definitions seem incongruent and lack specification of the outcomes used, namely core clinical outcomes relevant for patients. Are pahse 2 and phase 3 trials designed to gather evidence of 'effectiveness' and safety or 'efficacy' and monitor adverse effects of a new biomedical intervention? For what outcome? The three sentences proposed in the comment for application of this code seem overlapping the two terms (i.e. is it still efficacy the right term used for trials or is it effectiveness, commonly used for prospective observational studies?). I think it is important to justify why the two terms are used for clinical trial designs.\n2022-02-01 comment: To me this definition has no clear meaning. As your are working and struggling so hard to define and clarify the scientific evidence code system, I wish to participate to the meeting to discuss with you this tricky definition. If you agree, please, let me know."}, {"code": "comment", "valueString": "A phase 2 trial is a clinical trial to gather evidence of effectiveness and safety for an intervention in patients with the disease or condition under study, but not intended to provide an adequate basis for regulatory approval for clinical use.\nA phase 3 trial is a clinical trial to gather the evidence of effectiveness and safety of an intervention, intended to provide an adequate basis for regulatory approval for clinical use."}, {"code": "approval", "valueString": "2022-02-08 vote 7-0 by Paola Rosati, Mario Tristan, Robin Ann Yurk, Janice Tufte, Brian S. Alper, Paul Whaley, Sunu Alice Cherian"}], "definition": "A clinical trial with a component meeting the definition of phase 2 trial and a component meeting the definition of phase 3 trial.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "phase II/III trial"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "phase 2-3 trial"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "phase 2/3 trial"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "trial phase 2-3"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "trial phase 2/3"}]}, {"code": "SEVCO:01035", "display": "phase 3 trial", "property": [{"code": "external-definitions", "valueString": "https://www.ecfr.gov/current/title-21/chapter-I/subchapter-D/part-312/subpart-B/section-312.21 is the US Code of Federal Regulations Title 21 (Food and Drugs) Chapter I Subchapter D Part 312 Subpart B \u00a7 312.21 and includes:\n\n\u00a7 312.21 Phases of an investigation.\n\nAn IND may be submitted for one or more phases of an investigation. The clinical investigation of a previously untested drug is generally divided into three phases. Although in general the phases are conducted sequentially, they may overlap. These three phases of an investigation are a[sic] follows:\n\n....\n\nPhase 3.  Phase 3 studies are expanded controlled and uncontrolled trials. They are performed after preliminary evidence suggesting effectiveness of the drug has been obtained, and are intended to gather the additional information about effectiveness and safety that is needed to evaluate the overall benefit-risk relationship of the drug and to provide an adequate basis for physician labeling. Phase 3 studies usually include from several hundred to several thousand subjects.\n\n\n\nfrom CTO:\n\nPhase III trial\nIncludes trials conducted after preliminary evidence suggesting effectiveness of the drug has been obtained, and are intended to gather additional information to evaluate the overall benefit-risk relationship of the drug. A clinical research protocol designed to investigate the efficacy of the biomedical or behavioral intervention in large groups of human subjects (from several hundred to several thousand), to confirm efficacy, to monitor adverse reactions to the new medication or treatment regimen with respect to long-term use and by comparing the intervention to other standard or experimental interventions as well as to a placebo.\n\n\t\nPhase 3. Studies are expanded controlled and uncontrolled trials. They are performed after preliminary evidence suggesting effectiveness of the drug has been obtained, and are intended to gather the additional information about effectiveness and safety that is needed to confirm efficacy and evaluate the overall benefit-risk relationship of the drug and to provide an adequate basis for physician labeling. NOTE: Phase 3 studies usually include from several hundred to several thousand subjects. [After FDA CDER Handbook, ICH E8] (CDISC glossary)\n\nA study to compare the results of people taking a new treatment with the results of people taking the standard treatment (for example, which group has better survival rates or fewer side effects). In most cases, studies move into phase III only after a treatment seems to work in phases I and II. Phase III trials may include hundreds of people.\n\nStudies are expanded controlled and uncontrolled trials. They are performed after preliminary evidence suggesting effectiveness of the drug has been obtained and are intended to gather the additional information about effectiveness and safety that is needed to confirm efficacy and evaluate the overall benefit-risk relationship of the drug and to provide an adequate basis for physician labeling. NOTE: Phase 3 studies usually include from several hundred to several thousand subjects. [after FDA CDER handbook, ICH E8]\n\nfrom SCO:\n\t\nA clinical research protocol designed to investigate the efficacy of the biomedical or behavioral intervention in large groups of human subjects (from several hundred to several thousand), to confirm efficacy, to monitor adverse reactions to the new medication or treatment regimen with respect to long-term use and by comparing the intervention to other standard or experimental interventions as well as to a placebo.\n\nfrom NCIt:\nPhase III trial (Phase III Clinical Trial; Phase III Trial; phase 3; Trial Phase 3; PHASE III TRIAL; phase III trial; Phase III Trials; 3; Phase 3 Study; Clinical Trials, Phase III; Phase III Study; Phase III Protocol)\nA clinical research protocol designed to investigate the efficacy of the biomedical or behavioral intervention in large groups of human subjects (from several hundred to several thousand), to confirm efficacy, to monitor adverse reactions to the new medication or treatment regimen with respect to long-term use and by comparing the intervention to other standard or experimental interventions as well as to a placebo.\n\nfrom OCRe:\nA Phase 3 trial includes expanded controlled and uncontrolled trials after preliminary evidence suggesting effectiveness of the drug has been obtained, and are intended to gather additional information to evaluate the overall benefit-risk relationship of the drug and provide an adequate basis for physician labeling.\n\nfrom EDDA:\nComparative studies to verify the effectiveness of diagnostic, therapeutic, or prophylactic drugs, devices, or techniques determined in phase II studies. During these trials, patients are monitored closely by physicians to identify any adverse reactions from long-term use. These studies are performed on groups of patients large enough to identify clinically significant responses and usually last about three years. This concept includes phase III studies conducted in both the U.S. and in other countries. [MeSH 2014_2014_02_10] \nA clinical research protocol designed to investigate the efficacy of the biomedical or behavioral intervention in large groups of human subjects (from several hundred to several thousand), to confirm efficacy, to monitor adverse reactions to the new medication or treatment regimen with respect to long-term use and by comparing the intervention to other standard or experimental interventions as well as to a placebo. [NCI 2014_12E]\n\nfrom INTERNATIONAL COUNCIL FOR HARMONISATION OF TECHNICAL REQUIREMENTS FOR PHARMACEUTICALS FOR HUMAN USE (ICH HARMONISED GUIDELINE) GENERAL CONSIDERATIONS FOR CLINICAL STUDIES E8(R1) https://database.ich.org/sites/default/files/E8-R1_Guideline_Step4_2021_1006.pdf Adopted on 6 October 2021\n\nAfter initial clinical studies provide sufficient information on safety, clinical pharmacology and\ndose, exploratory and confirmatory studies (usually referred to as phases 2 and 3, respectively)\nare conducted to further evaluate both the safety and efficacy of the drug. \n\nConfirmatory studies are designed to confirm the preliminary evidence accumulated in earlier clinical studies that a drug is safe and effective for use for the intended indication and recipient population. These studies are often intended to provide an adequate basis for marketing approval, and to support adequate instructions for use of the drug and official product information. They aim to evaluate the drug in participants with or at risk of the condition or disease who represent those who will receive the drug once approved. This may include investigating subgroups of patients with frequently occurring or potentially relevant comorbidities  (e.g., cardiovascular disease, diabetes, hepatic and renal impairment) to characterise the safe and effective use of the drug in patients with these conditions. \n\nConfirmatory studies may evaluate the efficacy and safety of more than one dose or the use of the drug in different stages of disease or in combination with one or more other drugs. If the intent is to administer a drug for a long period of time, then studies involving extended exposure to the drug should be conducted (ICH E1 Clinical Safety for Drugs used in Long-Term Treatment). Irrespective of the intended duration of administration, the duration of effect of the drug will also inform the duration of follow-up.\n\nStudy endpoints selected for confirmatory studies should be clinically relevant and reflect disease burden or be of adequate surrogacy for predicting disease burden or sequelae. \n\nfrom March 1998 https://www.ema.europa.eu/en/documents/scientific-guideline/ich-e-8-general-considerations-clinical-trials-step-5_en.pdf\n\n3.1.3.3 Phase III (Most typical kind of study: Therapeutic Confirmatory)\nPhase III usually is considered to begin with the initiation of studies in which the primary objective is to demonstrate, or confirm therapeutic benefit.\nStudies in Phase III are designed to confirm the preliminary evidence accumulated in Phase II that a drug is safe and effective for use in the intended indication and recipient population. These studies are intended to provide an adequate basis for marketing approval. Studies in Phase III may also further explore the dose-response relationship, or explore the drug's use in wider populations, in different stages of disease, or in combination with another drug. For drugs intended to be administered for long periods, trials involving extended exposure to the drug are ordinarily conducted in Phase III, although they may be started in Phase II (see ICH E1). ICH E1 and ICH E7 describe the overall clinical safety database considerations for chronically administered drugs and drugs used in the elderly. These studies carried out in Phase III complete the information needed to support adequate instructions for use of the drug (official product information)."}, {"code": "comment", "valueString": "Phase 3 trials are typically conducted after preliminary evidence suggests effectiveness and usually have the primary objective to demonstrate or confirm therapeutic benefit compared to placebo or a standard treatment. Phase 3 studies usually include from several hundred to several thousand subjects. Study endpoints for phase 3 trials should be clinically relevant or of adequate surrogacy for predicting clinical effects."}, {"code": "editors", "valueString": "Brian S. Alper, Paul Whaley, Joanne Dehnbostel, Janice Tufte, Kenneth Wilkins, Harold Lehmann"}, {"code": "negative-vote", "valueString": "2021-12-21 vote 2-2 by Robin Ann Yurk, C P Ooi, Janice Tufte, Paul Whaley\n2022-01-04 vote 5-2 by Robin Ann Yurk, Harold Lehmann, Janice Tufte, Paola Rosati, C P Ooi, Joanne Dehnbostel, Paul Whaley\n2022-01-11 vote 6-1 by Jesus Lopez-Alcalde, Harold Lehmann, Mario Tristan, janice tufte, Paul Whaley, Andrew Beck, Robin Ann Yurk"}, {"code": "expert-comments", "valueString": "2021-12-21 comments: Note: consider adding the following comments from comments from previous reviewers to improve interpretation.\n\n3.1.3.3 \u201cPhase III usually is considered to begin with the initiation of studies in which the primary objective is to demonstrate, or confirm therapeutic benefit.\u201d\n\nEDDA:  \u201cComparative studies to verify the effectiveness of diagnostic, therapeutic, or prophylactic drugs, devices, or techniques determined in phase II studies\u2026. A clinical research protocol designed to investigate the efficacy of the biomedical or behavioral intervention in large groups of human subjects (from several hundred to several thousand), to confirm efficacy, to monitor adverse reactions to the new medication or treatment regimen with respect to long-term use and by comparing the intervention to other standard or experimental interventions as well as to a placebo\u201d\n..................\nI think the pieces are there but the phrasing is difficult to parse.\n\n\n2022-01-04 comments: Perhaps adding \"compared with a standard treatment\" may improve the clarity. \n\nMinor change - the phrasing is a little awkward, suggest \"gather evidence about the effectiveness and safety of an intervention that is needed...\". \n\n2022-01-11 comments: I would suggest not adding how many subjects are typically involved. Unfortunately, sample sizes have decreased over time. https://bmjopen.bmj.com/content/11/12/e053377\n\nMinor change for consistency with other trial definitions: \"A clinical trial to gather evidence of effectiveness and safety of an intervention, that is intended to provide an adequate basis for regulatory approval for clinical use.\""}, {"code": "approval", "valueString": "2022-01-18 vote 6-0 by Harold Lehmann, Paul Harris, Robin Ann Yurk, Paola Rosati, raradhikaag@gmail.com, Paul Whaley"}], "definition": "A clinical trial to gather the evidence of effectiveness and safety of an intervention, intended to provide an adequate basis for regulatory approval for clinical use.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "phase III trial"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "phase 3 study"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "confirmatory clinical study"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "phase III clinical trial"}]}, {"code": "SEVCO:01036", "display": "post-marketing study", "property": [{"code": "external-definitions", "valueString": "from CTO:\n\nPhase IV Trial (Phase IV Study, Phase IV clinical trial, phase 4 study, phase 4 trial, trial phase 4)\n\nStudies of FDA-approved drugs to delineate additional information including the drug's risks, benefits, and optimal use. A randomized, controlled trial that is designed to evaluate the long-term safety and efficacy of a drug for a given indication. Often they are designed to study side effects that may have become apparent after the phase III study was completed.\n\nAfter a treatment has been approved and is being marketed, it is studied in a phase IV trial to evaluate side effects that were not apparent in the phase III trial. Thousands of people are involved in a phase IV trial.\n\nPost approval studies to delineate additional information about the drug's risks, benefits, and optimal use that may be requested by regulatory authorities in conjunction with marketing approval. NOTE: These studies could include, but would not be limited to, studying different doses or schedules of administration than were used in Phase 2 studies, use of the drug in other patient populations or other stages of the disease, or use of the drug over a longer period of time. [after FDA CDER handbook, ICH E8]\n\nPhase 4. Postmarketing (Phase 4) studies to delineate additional information about the drug's risks, benefits, and optimal use that may be requested by regulatory authorities in conjunction with marketing approval. NOTE: These studies could include, but would not be limited to, studying different doses or schedules of administration than were used in Phase 2 studies, use of the drug in other patient populations or other stages of the disease, or use of the drug over a longer period of time. [After FDA CDER Handbook, ICH E8] (CDISC glossary)\n\nfrom SCO:\n\t\nnot included\n\nfrom NCIt:\n\nPhase IV Trial (Phase IV Study, Phase IV clinical trial, phase 4 study, phase 4 trial, trial phase 4)\n\nA randomized, controlled trial that is designed to evaluate the long-term safety and efficacy of a drug for a given indication. Often they are designed to study side effects that may have become apparent after the phase III study was completed.\n\nAfter a treatment has been approved and is being marketed, it is studied in a phase IV trial to evaluate side effects that were not apparent in the phase III trial. Thousands of people are involved in a phase IV trial.\n\nPost approval studies to delineate additional information about the drug's risks, benefits, and optimal use that may be requested by regulatory authorities in conjunction with marketing approval. NOTE: These studies could include, but would not be limited to, studying different doses or schedules of administration than were used in Phase 2 studies, use of the drug in other patient populations or other stages of the disease, or use of the drug over a longer period of time. [after FDA CDER handbook, ICH E8]\n\nPhase 4. Postmarketing (Phase 4) studies to delineate additional information about the drug's risks, benefits, and optimal use that may be requested by regulatory authorities in conjunction with marketing approval. NOTE: These studies could include, but would not be limited to, studying different doses or schedules of administration than were used in Phase 2 studies, use of the drug in other patient populations or other stages of the disease, or use of the drug over a longer period of time. [After FDA CDER Handbook, ICH E8] (CDISC glossary)\n\nfrom OCRe:\n\t\nA Phase 4 study monitors FDA-approved drug to delineate additional information including the drug's risks, benefits, and optimal use.\n\nfrom EDDA:\n\nA randomized, controlled trial that is designed to evaluate the long-term safety and efficacy of a drug for a given indication. Often they are designed to study side effects that may have become apparent after the phase III study was completed. [NCIT_14.08d]\n\nAfter a treatment has been approved and is being marketed, it is studied in a phase IV trial to evaluate side effects that were not apparent in the phase III trial. Thousands of people are involved in a phase IV trial. [NCIT_14.08d]\n\nPhase 4. Postmarketing (Phase 4) studies to delineate additional information about the drug's risks, benefits, and optimal use that may be requested by regulatory authorities in conjunction with marketing approval. NOTE: These studies could include, but would not be limited to, studying different doses or schedules of administration than were used in Phase 2 studies, use of the drug in other patient populations or other stages of the disease, or use of the drug over a longer period of time. [After FDA CDER Handbook, ICH E8] [Contributing Source_CDISC] [NCIT_14.08d]"}, {"code": "comment", "valueString": "Post-marketing studies (phase IV trials) are often used to evaluate adverse effects that were not apparent in phase III trials, and may involve thousands of patients. Postmarketing (Phase 4) studies to delineate additional information about the drug's risks, benefits, and optimal use that may be requested by regulatory authorities in conjunction with marketing approval."}, {"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Harold Lehmann, Paul Whaley"}, {"code": "approval", "valueString": "2022-02-15 vote 10-0 by Paul Whaley, Andrew Beck, Paola Rosati, Robin Ann Yurk, Janice Tufte, Jesus Lopez-Alcalde, Yasser Sami Amer, Harold Lehmann, Alejandro Piscoya, Joanne Dehnbostel"}, {"code": "expert-comments", "valueString": "2022-02-15 comment: Maybe add hyphen between \"already\" and \"approved\""}], "definition": "A clinical trial to gather additional evidence of effectiveness and safety of an intervention for an already approved clinical use.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "phase IV trial"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "phase 4 trial"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "phase 4 study"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "trial phase 4"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "post-approval study"}]}], "display": "clinical trial", "definition": "Interventional research in which one or more healthcare-related actions (i.e., a diagnostic, prognostic, therapeutic, preventive or screening method or intervention) is evaluated for effects on health-related biomedical or behavioral processes and/or outcomes.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Joanne Dehnbostel, Janice Tufte, Harold Lehmann, Paul Whaley"}, {"code": "negative-vote", "valueString": "2021-11-30 vote 7-1 by Alejandro Piscoya, Mario Tristan, Robin Ann Yurk, Muhammad Afzal, Paola Rosati, Paul Whaley, Janice Tufte, Jesus Lopez-Alcalde\n2021-12-07 vote 4-1 by Mario Tristan, Robin Ann Yurk, Janice Tufte, Joanne Dehnbostel, CP Ooi"}, {"code": "expert-comments", "valueString": "2021-11-30 comments: (We should include the classical definition for  Phase lV Field Trials of Health Interventions: A Toolbox. 3rd edition.\nSmith PG, Morrow RH, Ross DA, editors.\nOxford (UK): OUP Oxford; 2015 Jun 1.https://www.ncbi.nlm.nih.gov/books/NBK305508/), Instead of \"methods\" I would use the term \"interventions\". I also miss the term \"prognostic\" as they are not diagnostic or screening. Besides, it would be important to highlight that the clinical trial is done in humans\n\n2021-12-07 comment: A clinical trial is a type of research that studies new tests and treatments and evaluates their effects on human health outcomes. The medical intervention can be drugs, cells and other biological products, surgical procedures, radiological procedures, devices, behavioural treatments and preventive care."}, {"code": "comment", "valueString": "Some definitions for \"clinical trial\" include human subject research for effects on human health outcomes. The term \"human\" was not added to this definition because a study design with animal subjects for effects on animal health outcomes to inform veterinary care would be considered a clinical trial. However, a study design with animal subjects to inform human health outcomes would not be considered a clinical trial."}, {"code": "external-definitions", "valueString": "NIH Clinical Trial Definition = A research study[1] in which one or more human subjects[2] are prospectively assigned[3] to one or more interventions[4] (which may include placebo or other control) to evaluate the effects of those interventions on health-related biomedical or behavioral outcomes.[5] \n\n[4]An intervention is defined as a manipulation of the subject or subject\u2019s environment for the purpose of modifying one or more health-related biomedical or behavioral processes and/or endpoints.  Examples include:  drugs/small molecules/compounds; biologics; devices; procedures (e.g., surgical techniques); delivery systems (e.g., telemedicine, face-to-face interviews); strategies to change health-related behavior (e.g., diet, cognitive therapy, exercise, development of new habits); treatment strategies; prevention strategies; and, diagnostic strategies.\n\nfrom https://grants.nih.gov/grants/guide/notice-files/NOT-OD-15-015.html"}, {"code": "approval", "valueString": "2021-12-14 vote 6-0 by Joanne Dehnbostel, Jesus Lopez-Alcalde, Robin Ann Yurk, Janice Tufte, Paul Whaley, Brian S. Alper"}]}], "display": "interventional research", "property": [{"code": "editors", "valueString": "Mario Tristan, Joanne Dehnbostel, Harold Lehmann, Khalid Shahin, Brian S. Alper"}, {"code": "approval", "valueString": "12/12 as of 5/31/2021: Eric Harvey, Bhagvan Kommadi, Brian Alper, Sebastien Bailly, Alejandro Piscoya, Harold Lehmann, KM Saif-Ur-Rahman, Paola Rosati, Sorana D. Bolboaca, Asiyah Lin, Leo Orozco, Erfan Shamsoddin"}, {"code": "negative-vote", "valueString": "2021-05-17 vote 6-2 on \"Interventional research = In a prospective study, an independent variable is manipulated or assigned by the investigator to evaluate a response or outcome (the dependent variable).\" by Eric Harvey, Bhagvan Kommadi, Paola Rosati, KM Saif-Ur-Rahman, Ahmad Sofi-Mahmudi, Jesus Lopez-Alcalde, Sorana D. Bolboaca, Harold Lehmann, 2021-05-24 vote 10-1 on Interventional  research=\"A study design in which an independent variable (an exposure or intervention) is prospectively assigned or modified by the investigator to evaluate a response in the dependent variable (an effect or outcome).\" by Alejandro Piscoya, Philippe Rocca-Serra, KM Saif-Ur-Rahman, Eric Harvey, Harold Lehmann, Bhagvan Kommadi, Sorana D. Bolboaca, Jes\u00fas L\u00f3pez-Alcalde, Paola Rosati, Tatyana Shamliyan, Brian Alper"}, {"code": "expert-comments", "valueString": "I would avoid the term prospective study, as this term is ambiguous.  Suggested change to \"A study in whichi the independent variable is prospectively manipulated or assigned by the invesigator\u2026\" Manipulate = to control, manipulate or influence suggestion to delete \"the dependent variable\" which mixes language of analysis vs. design with \"response\"   5-24-2021 No major disagreement with the definition but uneasy to have 'intervention study' as (unspecified) synonym as doing so convey that a plan (the study design) is the same as the execution of the plan (the study). The same applies to 'Primary research...) I think that we need to clarify the goals: Experiments examine cause-and-effect relationship by measuring outcomes when a particular factor (exposure, intervention, independent variable) is manipulated and controlled during and after experiment (inference). I think that we should clarify the subjects of experiments: consent people or animals"}, {"code": "comment", "valueString": "We acknowledge that interventional study design and interventional study  may not be exact synonyms of interventional research, but interventional research could be used to encompass both design and implementation of the design"}], "definition": "A study design in which an independent variable (an exposure or intervention) is prospectively assigned or modified by the investigator to evaluate a response in the dependent variable (an effect or outcome).", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "interventional study"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "interventional study design"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "interventional primary research"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "international method of research"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "experimental research"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "experimental study"}]}, {"code": "SEVCO:01002", "display": "observational research", "definition": "A study design in which the independent variables (exposures or interventions) are not prospectively assigned or modified by the investigator.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "observational study"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "observational study design"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "observational primary research"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "observational method of research"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "non-interventional research"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "observational study"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "observational study design"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "observational primary research"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "non-interventional research"}], "property": [{"code": "editors", "valueString": "Mario Tristan, Joanne Dehnbostel, Harold Lehmann, Khalid Shahin, Brian S. Alper"}, {"code": "approval", "valueString": "8/8 as of 6/7/2021: Asiyah Lin, KM Saif-Ur-Rahman, Harold Lehmann, Sebastien Bailly, Bhagvan Kommadi, Mario Tristan, Leo Orozco, Ahmad Sofi-Mahmudi"}, {"code": "negative-vote", "valueString": "2021-05-17 vote 5-3 on \"Observational research = In a prospective or retrospective study, an independent variable is measured but not manipulated by the investigator to evaluate a response or outcome (the dependent variable).\" by Eric Harvey, Bhagvan Kommadi, Paola Rosati, KM Saif-Ur-Rahman, Ahmad Sofi-Mahmudi, Jesus Lopez-Alcalde, Sorana D. Bolboaca, Harold Lehmann, 2021-05-24 vote 8-3 on Observational research=\"A study design in which the variables (exposures, interventions, and outcomes) are not prospectively assigned or modified by the investigator.\" by Alejandro Piscoya, Philippe Rocca-Serra, KM Saif-Ur-Rahman, Eric Harvey, Harold Lehmann, Bhagvan Kommadi, Sorana D. Bolboaca, Jes\u00fas L\u00f3pez-Alcalde, Paola Rosati, Tatyana Shamliyan, Brian Alper, , 2021-05-31 vote 11-1 on Observational research=\"A study design in which the independent variables (exposures or interventions) are not prospectively assigned or modified by the investigator.\" by Eric Harvey, Bhagvan Kommadi, Brian Alper, Sebastien Bailly, Alejandro Piscoya, Harold Lehmann, KM Saif-Ur-Rahman, Paola Rosati, Sorana D. Bolboaca, Asiyah Lin, Leo Orozco, Erfan Shamsoddin"}, {"code": "expert-comments", "valueString": "I dislike the term \"manipulated\" in the definition -- suggest change to:  In a prospective or retrospective study, without any specific intervention assigned to participants, an investigator observes and measures an intervention or procedure (the independent variable) to assess or learn more about an effect or outcome (the dependent variable). \"In a prospective or retrospective study, an independent variable (a predictor) is obeserved or measured by the investigator to evaluate a response or an outcome (the dependent variable).\" I would delete \"in a prospective or retrospective study\" as it could be ambispective    5-24-2021 similar comment about the synonyms assigned the class (conflating plan/design) with the object realised by executing a plan I think that the outcomes are never assigned or modified by the investigator (they are measured). Thus, to be consistent with the definition of interve\u2026suggest to remove \"outcomes\" from ( )   (is there a semantic difference between \"are not\" and \"none is\"?) I suggest to clarify the goal as drawing causal inferences from the observed association between exposure and outcomes  5-31-2021 comment The suggested definition is a non-interventional study definition. Not sure if a non-interventional is fully equivalent to observational studies"}, {"code": "comment", "valueString": "We acknowledge that observational study design and observational study may not be exact synonyms of observational research, but observational research could be used to encompass both design and implementation of the design. In the context of coding study design factors, observational research is commonly used to denote non-interventional research."}], "concept": [{"code": "SEVCO:01037", "display": "post-marketing surveillance study", "definition": "An observational study to identify adverse events related to the use of an approved clinical intervention.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "postmarketing evaluation study"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "postmarketing evaluation study"}], "property": [{"code": "external-definitions", "valueString": "from CTO:\n\nnot included\n\nfrom SCO:\n\t\nnot included\n\nfrom NCIt:\n\nPostmarketing Surveillance\n\nPrograms to identify adverse events that did not appear during the drug approval process.\n\nOngoing safety monitoring of marketed drugs. See also Phase 4 studies, Phase 5 studies.\n\nalso Phase V Trial (phase 5, trial phase 5)\n\nPostmarketing surveillance is sometimes referred to as Phase V. See outcomes research.\n\nfrom OCRe:\n\t\nnot included\n\nfrom EDDA:\n\npostmarketing evaluation study (post-marketing product surveillance)\n\nSurveillance of drugs, devices, appliances, etc., for efficacy or adverse effects, after they have been released for general sale. [MeSH 2014_2014_02_10]"}, {"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Paul Whaley, Harold Lehmann"}, {"code": "approval", "valueString": "2022-02-15 vote 10-0 by Paul Whaley, Andrew Beck, Brian S. Alper, Paola Rosati, Janice Tufte, Jesus Lopez-Alcalde, Yasser Sami Amer, Harold Lehmann, Alejandro Piscoya, Joanne Dehnbostel"}, {"code": "expert-comments", "valueString": "2022-02-15 comments: Alternative terms could be: Post-marketing evaluation study, \n(Do we need to connect the \"approval\" to an indication?"}]}]}, {"code": "SEVCO:01010", "concept": [{"code": "SEVCO:01011", "display": "parallel cohort design", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Ellen Jepson, Kenneth Wilkins, Mario Tristan, Harold Lehmann"}, {"code": "approval", "valueString": "9/9 as of 8/9/2021: Erfan Shamsoddin, Paola Rosati, Eric Harvey, Bhagvan Kommadi, Brian S. Alper, Cheow Peng Ooi, Janice Tufte, Joanne Dehnbostel, Alejandro Piscoya"}], "definition": "A comparative study design in which the groups are compared concurrently and participants are expected to remain in the groups being compared for the entire duration of participation in the study.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "concurrent cohort study"}]}, {"code": "SEVCO:01012", "concept": [{"code": "SEVCO:01024", "display": "controlled crossover cohort design", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Kenneth Wilkins, Harold Lehmann, Janice Tufte, Michael Panzer"}, {"code": "approval", "valueString": "7/7 as of 8/23/2021: Eric Harvey, Bhagvan Kommadi, Brian S. Alper, Cheow Peng Ooi, Janice Tufte, Leo Orozco, Alejandro Piscoya"}], "definition": "A crossover cohort design in which two or more cohorts have different orders of exposures."}, {"code": "SEVCO:01025", "display": "single-arm crossover design", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Kenneth Wilkins, Harold Lehmann, Janice Tufte, Michael Panzer"}, {"code": "approval", "valueString": "7/7 as of 8/23/2021: Eric Harvey, Bhagvan Kommadi, Brian S. Alper, Cheow Peng Ooi, Janice Tufte, Leo Orozco, Alejandro Piscoya"}], "definition": "A crossover cohort design in which all participants are in a single cohort with the same order of exposures."}], "display": "crossover cohort design", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Kenneth Wilkins, Harold Lehmann, Janice Tufte, Michael Panzer"}, {"code": "approval", "valueString": "7/7 as of 8/23/2021: Eric Harvey, Bhagvan Kommadi, Brian S. Alper, Cheow Peng Ooi, Janice Tufte, Leo Orozco, Alejandro Piscoya"}, {"code": "negative-vote", "valueString": "8/9 as of 8/9/2021: voting on \"A comparative study design in which participants receive two or more alternative exposures during separate periods of time.\" by Erfan Shamsoddin, Paola Rosati, Eric Harvey, Bhagvan Kommadi, Brian S. Alper, Cheow Peng Ooi, Janice Tufte, Joanne Dehnbostel, Alejandro Piscoya"}, {"code": "expert-comments", "valueString": "8/9/21 comment: It's not clear from this definition that each group of participants receives the same 2 or more exposures, but not in the same time sequence"}], "definition": "A comparative study design in which participants receive two or more alternative exposures during separate periods of time.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "crossover study"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "crossover trial"}]}, {"code": "SEVCO:01013", "display": "case control design", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Harold Lehmann, Janice Tufte, Michael Panzer"}, {"code": "approval", "valueString": "7/7 as of 8/23/2021: Eric Harvey, Bhagvan Kommadi, Brian S. Alper, Cheow Peng Ooi, Janice Tufte, Leo Orozco, Alejandro Piscoya"}], "definition": "A comparative study design in which the groups being compared are defined by outcome presence (case) or absence (control)."}, {"code": "SEVCO:01014", "concept": [{"code": "SEVCO:01020", "concept": [{"code": "SEVCO:01021", "display": "twin study design", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Kenneth Wilkins"}, {"code": "approval", "valueString": "8/8 as of 9/12/2021: Eric Harvey, Bhagvan Kommadi, Brian S. Alper, Cheow Peng Ooi, Janice Tufte, Paola Rosati, Robin Ann Yurk, MD, MPH, Mario Tristan"}], "definition": "A family study design in which twin siblings are compared."}], "display": "family study design", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Kenneth Wilkins"}, {"code": "approval", "valueString": "8/8 as of 9/12/2021: Eric Harvey, Bhagvan Kommadi, Brian S. Alper, Cheow Peng Ooi, Janice Tufte, Paola Rosati, Robin Ann Yurk, MD, MPH, Mario Tristan"}], "definition": "A matched study design in which related or non-related family members are compared.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "familial study"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "family study"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "family based study"}]}], "display": "matching for comparison", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Harold Lehmann, Janice Tufte, Michael Panzer"}, {"code": "approval", "valueString": "7/7 as of 8/23/2021: Eric Harvey, Bhagvan Kommadi, Brian S. Alper, Cheow Peng Ooi, Janice Tufte, Leo Orozco, Alejandro Piscoya"}], "definition": "A comparative study design in which individual participants in different groups being compared are paired or matched into sets based on selected attributes for within-set analysis.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "matched study design"}]}, {"code": "SEVCO:01015", "display": "cluster as unit of allocation", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Harold Lehmann, Janice Tufte, Michael Panzer"}, {"code": "approval", "valueString": "7/7 as of 8/23/2021: Eric Harvey, Bhagvan Kommadi, Brian S. Alper, Cheow Peng Ooi, Janice Tufte, Leo Orozco, Alejandro Piscoya"}], "definition": "A comparative study design in which participants are allocated to exposures (interventions) by their membership in groups (called clusters) rather than by individualized assignments.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "clustering for comparison"}]}], "display": "comparative study design", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Ellen Jepson, Kenneth Wilkins, Mario Tristan"}, {"code": "approval", "valueString": "9/9 as of 8/9/2021: Erfan Shamsoddin, Paola Rosati, Eric Harvey, Bhagvan Kommadi, Brian S. Alper, Cheow Peng Ooi, Janice Tufte, Joanne Dehnbostel, Alejandro Piscoya"}], "definition": "A study design in which two or more groups are compared.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "comparative research"}]}, {"code": "SEVCO:01023", "concept": [{"code": "SEVCO:01016", "display": "uncontrolled cohort design", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Harold Lehmann, Michael Panzer"}, {"code": "approval", "valueString": "7/7 as of 8/23/2021: Eric Harvey, Bhagvan Kommadi, Brian S. Alper, Cheow Peng Ooi, Janice Tufte, Leo Orozco, Alejandro Piscoya"}], "definition": "A non-comparative study design in which two or more participants are evaluated in a single group (or cohort).", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "single cohort design"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "case series design"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "non-controlled cohort design"}]}, {"code": "SEVCO:01017", "display": "case report", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Harold Lehmann, Michael Panzer"}, {"code": "approval", "valueString": "7/7 as of 8/23/2021: Eric Harvey, Bhagvan Kommadi, Brian S. Alper, Cheow Peng Ooi, Janice Tufte, Leo Orozco, Alejandro Piscoya"}], "definition": "A non-comparative study design in which a single participant is evaluated.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "case study"}]}], "display": "non-comparative study design", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Harold Lehmann, Michael Panzer"}, {"code": "approval", "valueString": "7/7 as of 8/23/2021: Eric Harvey, Bhagvan Kommadi, Brian S. Alper, Cheow Peng Ooi, Janice Tufte, Leo Orozco, Alejandro Piscoya"}], "definition": "A study design with no comparisons between groups with different exposures and no comparisons between groups with different outcomes.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "non-comparative research"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "descriptive study"}]}, {"code": "SEVCO:01022", "concept": [{"code": "SEVCO:01044", "display": "ecological design", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Harold Lehmann"}, {"code": "approval", "valueString": "5/5 as of 10/18/2021: Cheow Peng Ooi, Janice Tufte, Robin Ann Yurk, Eric Harvey, Joanne Dehnbostel"}, {"code": "negative-vote", "valueString": "6 to 1 in 2021-09-20 vote with 7 participants (Ecological design = A comparative study design in which populations are compared. An ecologic study is a non individual-human study in which the unit of observation is a population or community.) - Robin Ann Yurk, Janice Tufte, Eric Harvey, Jesus Lopez-Alcalde, Mario Tristan, Sorana D Bolboaca, Paola Rosati, 8 to 1 vote on 2021-09-27 with 9 participants (Ecological design [Population-based design, Ecologic study, Population study] = A comparative study design in which populations are compared. An ecologic study is a non-individual study in which the unit of observation is a population or community.) - Jesus Lopez-Alcalde, Asiyah Lin, Eric Harvey, Bhagvan Kommadi, Alejandro Piscoya, Robin Ann Yurk, Mario Tristan, Paola Rosati, Janice Tufte"}, {"code": "expert-comments", "valueString": "2021-09-20 comment:  I miss here the explicit declaration that ecological studies are observational. A cluster trial can randomise communities and is not an ecological study. Besides, and I may be worng, but an ecological study may include non-humans, for example, ecological study of air contamination levels in Spain compared to Italy. 2021-09-27 comment: The differences of ecologic studies and other population based studies are not reflected. consider adding \"Variables in an ecologic analysis may be aggregate measures, environmental measures, or global measures.\""}], "definition": "A study design in which the unit of observation is a population or community defined by social relationships or physical surroundings.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "ecologic study"}]}], "display": "population-based design", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Harold Lehmann"}, {"code": "comment", "valueString": "The term \u2018population-based study\u2019 is generally used for an observational comparative study design in which populations are compared."}, {"code": "approval", "valueString": "5/5 as of 10/18/2021: Cheow Peng Ooi, Janice Tufte, Robin Ann Yurk, Eric Harvey, Joanne Dehnbostel"}], "definition": "A study design in which the unit of observation is a population or community.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "population study"}]}]}, {"code": "SEVCO:00998", "display": "study design process", "definition": "A specification of a sequence of actions for a component or part of a study design.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "study design component"}], "property": [{"code": "comment", "valueString": "Study design is defined as a plan specification for how and what kinds of data will be gathered as part of an investigation which may produce testable explanations, conclusions and predictions or test a hypothesis."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Kenneth Wilkins, Joanne Dehnbostel"}, {"code": "approval", "valueString": "2022-03-22 vote 5-0 by Joanne Dehnbostel, Jesus Lopez-Alcalde, Philippe Rocca-Serra, Mario Tristan, Robin Ann Yurk"}], "concept": [{"code": "SEVCO:01027", "display": "cross sectional data collection", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Kenneth Wilkins"}, {"code": "approval", "valueString": "8/8 as of 9/12/2021: Eric Harvey, Bhagvan Kommadi, Brian S. Alper, Cheow Peng Ooi, Janice Tufte, Paola Rosati, Robin Ann Yurk, MD, MPH, Mario Tristan"}, {"code": "expert-comments", "valueString": "The word \"feature\" was added to the definition on March 7, 2022 to match the change in hierarchical terms."}], "definition": "A study design process in which data is collected at a single point in time.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "cross-sectional study"}]}, {"code": "SEVCO:01028", "concept": [{"code": "SEVCO:01018", "concept": [{"code": "SEVCO:01019", "display": "before and after comparison", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Kenneth Wilkins"}, {"code": "approval", "valueString": "8/8 as of 9/12/2021: Eric Harvey, Bhagvan Kommadi, Brian S. Alper, Cheow Peng Ooi, Janice Tufte, Paola Rosati, Robin Ann Yurk, MD, MPH, Mario Tristan"}], "definition": "A time series design which includes comparisons of observations before and after an event or exposure.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "before and after design"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "pre-post design"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "before-after comparison"}]}], "display": "time series design", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Kenneth Wilkins"}, {"code": "approval", "valueString": "8/8 as of 9/12/2021: Eric Harvey, Bhagvan Kommadi, Brian S. Alper, Cheow Peng Ooi, Janice Tufte, Paola Rosati, Robin Ann Yurk, MD, MPH, Mario Tristan"}], "definition": "A longitudinal data collection which includes a set of time-ordered observations.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "multiple time point comparison"}]}], "display": "longitudinal data collection", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Kenneth Wilkins"}, {"code": "approval", "valueString": "8/8 as of 9/12/2021: Eric Harvey, Bhagvan Kommadi, Brian S. Alper, Cheow Peng Ooi, Janice Tufte, Paola Rosati, Robin Ann Yurk, MD, MPH, Mario Tristan"}, {"code": "expert-comments", "valueString": "The word \"feature\" was added to the definition on March 7, 2022 to match the change in hierarchical terms."}], "definition": "A study design process in which data is collected at two or more points in time.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "longitudinal study"}]}, {"code": "SEVCO:01045", "display": "primary data collection", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Paul Whaley, Mario Tristan"}, {"code": "negative-vote", "valueString": "2022-02-22 vote 7-1 by Paola Rosati, Sunu Alice Cherian, Joanne Dehnbostel, Sumalatha A, Rebecca Baker, Robin Ann Yurk, Janice Tufte, Harold Lehmann \n2022-03-01 vote 3-3 by Joanne Dehnbostel, Robin Ann Yurk, Paul Whaley, Nisha Mathew, Paola Rosati, Sunu Alice Cherian\n2022-03-15 vote 5-1 by Mario Tristan, Paul Whaley, nisha mathew, Philippe Rocca-Serra, Harold Lehmann, Janice Tufte\n2022-03-22 vote 5-1 by Joanne Dehnbostel, Jesus Lopez-Alcalde, Philippe Rocca-Serra, Mario Tristan, Robin Ann Yurk, nelle.stocquart"}, {"code": "expert-comments", "valueString": "2022-02-22 comments: Definition: Data recorded and collected during the study.\nFor parallelism with \"secondary data collection,\" perhaps write, \"for the purpose of the current study.\"2022-03-01 comments:\nA data collection technique in which the data are collected and recorded during the study for the purpose of the same study.\nFor the term definition---I would edit so it reads...A study design in which the data are collected and recorded to answer a new research question.\nData collection is not study design, it can called as a technique A data collection technique in which data is recorded and collected during the study for the purpose of the same study.\n2022-03-15 comments: ok, if 'study design feature' is understood as 'part specified by study design plan/protocol', but sounds like a process\n\"in which\" sounds strange for a \"feature.\" (\"Color is a feature in which...\" does not sound right.) Perhaps a...feature regarding how data are recorded...\"?\n2022-03-22 comment: Suggest modify definition or create a comment for application so it reads:  A Study design method in which the data are collected for original research to answer new research questions."}, {"code": "comment", "valueString": "The study design process includes the source and method for data collection. When the data are collected for original research to answer the original research questions, this is called primary data collection."}, {"code": "approval", "valueString": "2022-03-29 vote 6-0 by Paul Whaley, Robin Ann Yurk, Mario Tristan, Jesus Lopez-Alcalde, Brian S. Alper, Cau\u00ea Monaco"}], "definition": "A study design process in which the data are recorded and collected during the study for the purpose of the same study.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "study-generated data collection"}]}, {"code": "SEVCO:01026", "concept": [{"code": "SEVCO:01039", "display": "real world data collection from healthcare records", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Ilkka Kunnamo"}, {"code": "negative-vote", "valueString": "2022-03-15 vote 4-2 by Mario Tristan, Paul Whaley, Nisha Mathew, Philippe Rocca-Serra, Harold Lehmann, Janice Tufte\n2022-03-22 vote 4-1 by Joanne Dehnbostel, Jesus Lopez-Alcalde, Philippe Rocca-Serra, Mario Tristan, nelle.stocquart\n2022-03-29 vote 3-1 by Paul Whaley, Mario Tristan, Jesus Lopez-Alcalde, Cau\u00ea Monaco\n2022-04-05 vote 6-1 by Cau\u00ea Monaco, Paola Rosati, Harold Lehmann, Mario Tristan, Robin Ann Yurk, Jesus Lopez-Alcalde, Nisha Mathew"}, {"code": "expert-comments", "valueString": "2022-03-15 comments: ok, if 'study design feature' is understood as 'part specified by study design plan/protocol', but sounds like a process\nwould proposed, \"...for the purpose...\" (as in primary data collection)\nSeems like we should add that the original data is then used for a secondary research purpose in the definition, not only explain in Alternative terms\n2022-03-22 comment: \u00eddem: Proposal: \"A study design process in which the data are collected from data collected for a purpose of recording healthcare delivery in a record controlled by a healthcare professional.\"2022-03-29 comment: \"medical records\" and \"health records\" seem to be much more widely used expressions than \"healthcare delivery records\"2022-04-05 comments: Suggest make a comment or distinction in the term definition that the primary data collected is categorized as real world data for the purpose of delivering professional healthcare services.  The data set can be used for secondary data collection."}, {"code": "comment", "valueString": "This term is used when the original data collection (primary data collection) is done for the purpose of delivering professional healthcare services.  The secondary use of this data (sometimes called 'real world data') for research is then called secondary data collection."}, {"code": "approval", "valueString": "2022-04-19 vote 5-0 by Cau\u00ea Monaco, Jesus Lopez-Alcalde, Harold Lehmann, Robin Ann Yurk, Muhammad Afzal"}], "definition": "Real world data collection from data obtained routinely for a purpose of recording healthcare delivery in a record controlled by a healthcare professional.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "RWD collection from clinical care records"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "RWD from health care records"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "RWD from healthcare delivery records"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "real world data collection from medical records"}]}, {"code": "SEVCO:01050", "display": "real world data collection from personal health records", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Ilkka Kunnamo"}, {"code": "negative-vote", "valueString": "2022-03-15 vote 4-2 by Mario Tristan, Paul Whaley, nisha mathew, Philippe Rocca-Serra, Harold Lehmann, Janice Tufte\n2022-03-22 vote 4-1 by Joanne Dehnbostel, Jesus Lopez-Alcalde, Philippe Rocca-Serra, Mario Tristan, nelle.stocquart\n2022-03-29 vote 5-0 by Paul Whaley, Mario Tristan, Jesus Lopez-Alcalde, Cau\u00ea Monaco, Brian S. Alper\nTHEN TERM CHANGED 2022-04-05"}, {"code": "expert-comments", "valueString": "2022-03-15 comments: ok, if 'study design feature' is understood as 'part specified by study design plan/protocol', but sounds like a process\nMight suggest \"the purpose,\" again\nadd in the definition that the original ddata is then used for a seconday purpose\n2022-03-22 comment: dem: Proposal: \"A study design process in which the data are collected from data collected for a purpose of recording data related to personal health in a record controlled by the person, guardian, or caretaker.\""}, {"code": "approval", "valueString": "2022-04-19 vote 5-0 by Cau\u00ea Monaco, Jesus Lopez-Alcalde, Harold Lehmann, Brian S. Alper, Muhammad Afzal"}], "definition": "Real world data collection from data obtained routinely for a purpose of recording data related to personal health in a record controlled by the person, guardian, or caretaker.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "real world data collection from personal care records"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "RWD collection from personal medical records"}]}, {"code": "SEVCO:01040", "display": "real world data collection from healthcare financing records", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte"}, {"code": "negative-vote", "valueString": "2022-03-15 vote 4-2 by Mario Tristan, Paul Whaley, nisha mathew, Philippe Rocca-Serra, Harold Lehmann, Janice Tufte\n2022-03-22 vote 4-1 by Joanne Dehnbostel, Jesus Lopez-Alcalde, Philippe Rocca-Serra, Mario Tristan, nelle.stocquart\n2022-03-29 vote 5-0 by Paul Whaley, Mario Tristan, Jesus Lopez-Alcalde, Cau\u00ea Monaco, Brian S. Alper\nTHEN TERM CHANGED 2022-04-05"}, {"code": "expert-comments", "valueString": "2022-03-15 comments: ok, if 'study design feature' is understood as 'part specified by study design plan/protocol', but sounds like a process\n\"the purpose\"add original financial data is then used for secondary analysis etc\n2022-03-22 comment: \u00cddem. \"A study design process in which the data are collected from data collected for a purpose of recording healthcare financing\""}, {"code": "approval", "valueString": "2022-04-19 vote 5-0 by Cau\u00ea Monaco, Jesus Lopez-Alcalde, Harold Lehmann, Brian S. Alper, Muhammad Afzal"}], "definition": "Real world data collection from data obtained routinely for a purpose of recording healthcare financing.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "RWD collection from healthcare financing records"}]}, {"code": "SEVCO:01048", "concept": [{"code": "SEVCO:01046", "display": "real world data collection from monitoring procedures", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte"}, {"code": "negative-vote", "valueString": "2022-03-15 vote 5-1 by Mario Tristan, Paul Whaley, nisha mathew, Philippe Rocca-Serra, Harold Lehmann, Janice Tufte\n2022-03-22 vote 4-1 by Joanne Dehnbostel, Jesus Lopez-Alcalde, Philippe Rocca-Serra, Mario Tristan, nelle.stocquart\n2022-03-29 vote 5-0 by Paul Whaley, Mario Tristan, Jesus Lopez-Alcalde, Cau\u00ea Monaco, Brian S. Alper\nTHEN TERM CHANGED 2022-04-05"}, {"code": "expert-comments", "valueString": "2022-03-15 comments: ok, if 'study design feature' is understood as 'part specified by study design plan/protocol', but sounds like a process\n\"the purpose\"2022-03-22 comment: \u00cddem. \"A study design process in which the data are collected from data collected for a purpose of repeated testing.\""}, {"code": "approval", "valueString": "2022-04-19 vote 5-0 by Cau\u00ea Monaco, Jesus Lopez-Alcalde, Harold Lehmann, Brian S. Alper, Muhammad Afzal"}], "definition": "Real world data collection from data obtained routinely for a purpose of repeated testing.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "RWD collection from monitoring procedures"}]}], "display": "real world data collection from testing procedures", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte"}, {"code": "negative-vote", "valueString": "2022-03-15 vote 4-2 by Mario Tristan, Paul Whaley, nisha mathew, Philippe Rocca-Serra, Harold Lehmann, Janice Tufte\n2022-03-22 vote 4-1 by Joanne Dehnbostel, Jesus Lopez-Alcalde, Philippe Rocca-Serra, Mario Tristan, nelle.stocquart\n2022-03-29 vote 5-0 by Paul Whaley, Mario Tristan, Jesus Lopez-Alcalde, Cau\u00ea Monaco, Brian S. Alper\nTHEN TERM CHANGED 2022-04-05"}, {"code": "expert-comments", "valueString": "2022-03-15 comments: ok, if 'study design feature' is understood as 'part specified by study design plan/protocol', but sounds like a process\n\"the purpose\"and  then used for secondary research purposes\n2022-03-22 comment: \u00cddem. \"A study design process in which the data are collected from data collected for a purpose of testing, such as diagnostic testing or screening examination\""}, {"code": "approval", "valueString": "2022-04-19 vote 5-0 by Cau\u00ea Monaco, Jesus Lopez-Alcalde, Harold Lehmann, Brian S. Alper, Muhammad Afzal"}], "definition": "Real world data collection from data obtained routinely for a purpose of testing, such as diagnostic testing or screening examination.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "RWD collection from testing procedures"}]}], "display": "real world data collection", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Paul Whaley, Mario Tristan"}, {"code": "negative-vote", "valueString": "2022-02-22 vote 7-1 by Paola Rosati, Sunu Alice Cherian, Joanne Dehnbostel, Sumalatha A, Rebecca Baker, Robin Ann Yurk, Janice Tufte, Harold Lehmann\n2022-03-15 vote 5-1 by Mario Tristan, Paul Whaley, nisha mathew, Philippe Rocca-Serra, Harold Lehmann, Janice Tufte\n2022-03-22 vote 4-2 by Joanne Dehnbostel, Jesus Lopez-Alcalde, Philippe Rocca-Serra, Mario Tristan, Robin Ann Yurk, nelle.stocquart\n2022-03-29 vote 4-1 by Paul Whaley, Robin Ann Yurk, Mario Tristan, Jesus Lopez-Alcalde, Cau\u00ea Monaco\n2022-04-05 vote 6-0 by Cau\u00ea Monaco, Harold Lehmann, Mario Tristan, Robin Ann Yurk, Jesus Lopez-Alcalde, Nisha Mathew\nTHEN THE TERM CHANGED to Real World Data Collection\n2022-04-19 vote 3-1 by Cau\u00ea Monaco, Robin Ann Yurk, Jesus Lopez-Alcalde, Harold Lehmann"}, {"code": "expert-comments", "valueString": "2022-02-22 comment: Definition: Data gathered from studies, surveys, experiments that have been done by other people for other studies\n2022-03-15 comment: ok, if 'study design feature' is understood as 'part specified by study design plan/protocol', but sounds like a process\n2022-03-22 comments: The proposed definition only details the source of the data but not the data collection itself. I propose: \"A study design process in which the data are collected from data collected for a purpose other than the current study\".\nSuggest modify definition or create a comment for application so it reads.  A study design method in which the previously collected data is used to answer new and additional research questions.  Some example of the types of studies are retrospective study etc..\n2022-03-29 comment: In the comment for application--suggestion.  Delete phrase   When data are collected.  I would combined sentence When data are used in the form of analysis and interpretation from original research to answer additional research questions separate from the original research.  \n\n2022-04-12 comments: For Term definition:  Suggest revising definition to A study design process in which the study data are obtained from data collected for recording data for business purposes.  \nComment for application:  Add this statement, There are different categories of research such as business research, marketing research, insurance research etc.\n\"data are obtained from data collected\" may be changed to \"data are obtained from a source for data collection\"\n2022-04-19 comment: Suggest edit the term definition.  The Alternative term and comment for application are fine.  There are different kinds of research business research that can be classified as real world data.   The term definition should read....A study design in which the study data processes are obtained from a natural environment rather than controlled research."}, {"code": "comment", "valueString": "Real world data collection occurs when the study uses data obtained from a source that was not created for research as a primary purpose.  A study can involve both primary data collection (with some data collected by a process created for the purpose of the study investigation) and real world data collection (with some data collected from a process created for a routine business or operational purpose). If a study involves both primary data collection and real world data collection, both terms can be applied."}, {"code": "approval", "valueString": "2022-05-06 vote 7-0 by Mario Tristan, Robin Ann Yurk, Eric M Harvey, nisha mathew, Paola Rosati, Harold Lehmann, Janice Tufte"}], "definition": "A study design process in which the study data are obtained from a source of data collected during a routine process in the natural environment rather than using a process designed or controlled by the researcher.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "RWD collection"}]}, {"code": "SEVCO:01049", "display": "secondary data collection from prior research", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Mario Tristan"}, {"code": "negative-vote", "valueString": "2022-03-15 vote 5-1 by Mario Tristan, Paul Whaley, nisha mathew, Philippe Rocca-Serra, Harold Lehmann, Janice Tufte\n2022-03-22 vote 4-1 by Joanne Dehnbostel, Jesus Lopez-Alcalde, Philippe Rocca-Serra, Mario Tristan, nelle.stocquart"}, {"code": "expert-comments", "valueString": "2022-03-15 comments: ok, if 'study design feature' is understood as 'part specified by study design plan/protocol', but sounds like a process\n2022-03-22 comments: \u00cddem. \"A study design process in which the data are collected from data collected during a different study than the current study\"When does this recording happen?"}, {"code": "approval", "valueString": "2022-03-29 vote 5-0 by Mario Tristan, Paul Whaley, Cau\u00ea Monaco, Joanne Dehnbostel, Harold Lehmann"}], "definition": "A study design process in which the data are collected from data obtained during a different study than the current study."}, {"code": "SEVCO:01042", "display": "secondary data collection from a registry", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Ilkka Kunnamo"}, {"code": "external-definitions", "valueString": "\"For the purposes of this guide, a patient registry is an organized system that uses observational study methods to collect uniform data (clinical and other) to evaluate specified outcomes for a population defined by a particular disease, condition, or exposure, and that serves one or more predetermined scientific, clinical, or policy purposes\" -- in https://effectivehealthcare.ahrq.gov/sites/default/files/pdf/registries-guide-3rd-edition_research.pdf"}, {"code": "negative-vote", "valueString": "2022-03-15 vote 3-2 by Mario Tristan, Paul Whaley, nisha mathew, Philippe Rocca-Serra, Harold Lehmann\n2022-03-22 vote 4-1 by Joanne Dehnbostel, Jesus Lopez-Alcalde, Philippe Rocca-Serra, Mario Tristan, nelle.stocquart"}, {"code": "expert-comments", "valueString": "2022-03-15 comments: the term discovery is not suitable.  Can we have some other term?\nok, if 'study design feature' is understood as 'part specified by study design plan/protocol', but sounds like a process\n2022-03-22 comments: \u00cddem. \"A study design process in which the data are collected from data collected in a system organized to obtain and maintain uniform data for discovery and analysis\"The definition needs to be more, When did this happen? Before the study starts?"}, {"code": "approval", "valueString": "2022-03-29 vote 5-0 by Paul Whaley, Mario Tristan, Jesus Lopez-Alcalde, Cau\u00ea Monaco, Brian S. Alper"}], "definition": "A study design process in which the data are collected from a system organized to obtain and maintain uniform data for discovery and analysis, and this system is organized prior to the current study."}, {"code": "SEVCO:01047", "display": "DEPRECATED: mixed primary and secondary data collection", "definition": "A study design process in which some data are originally recorded and collected for the purpose of the study and some data are originally recorded and collected for a purpose other than the study", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Paul Whaley, Khalid Shahin"}, {"code": "deprecated", "valueString": "DEPRECATED: We decided 2022-03-08 to drop the term as it can be handled by coding 2 or more other terms."}]}, {"code": "SEVCO:01051", "display": "multisite data collection", "definition": "A study design process in which data are collected from two or more geographic locations.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Kenneth Wilkins, Mario Tristan"}, {"code": "negative-vote", "valueString": "2022-05-06 vote 6-1 by Mario Tristan, Robin Ann Yurk, Eric M Harvey, nisha mathew, Paola Rosati, Harold Lehmann, Janice Tufte"}, {"code": "expert-comments", "valueString": "2022-04-26 comment: As stated, this term has too much overlap with \"Multicentric\" Why do we need this term?"}, {"code": "comment", "valueString": "For studies conducted across multiple contexts (administrative or logistical) that are distinct from geographic locations, potentially introducing greater variability beyond multisite data collection, use the term Multicentric."}, {"code": "approval", "valueString": "2022-05-10 vote 7-0 by Mario Tristan, Robin Ann Yurk, Eric M Harvey, nisha mathew, Paola Rosati, Harold Lehmann, Janice Tufte"}]}, {"code": "SEVCO:01086", "display": "quantitative analysis", "definition": "A study design process in which data are analyzed with mathematical or statistical methods and formulas.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Joanne Dehnbostel, Khalid Shahin"}, {"code": "negative-vote", "valueString": "2022-05-17 vote 8-1 by Paul Whaley, Harold Lehmann, Robin Ann Yurk, Janice Tufte, Paola Rosati, Eric Harvey, raradhikaag@gmail.com, Cau\u00ea Monaco, Jesus Lopez-Alcalde\n2022-05-24 vote 5-1 by Robin Ann Yurk, nelle.stocquart@kce.fgov.be, Eric M Harvey, Mario Tristan, Harold Lehmann, Jesus Lopez-Alcalde"}, {"code": "expert-comments", "valueString": "2022-05-17 comments: Suggest including examples of quantitative analysis so as to improve your definition as there are many categories of quantitative methods:  ie survey methods, logistic regression,...etc\nQuantitative and qualitative have categorical results I believe\n2022-05-24 comment: An analytic approach using statistical methods and formulas to report the data for interpretation\n2022-05-26 comment: I would leave the description of a qualitative analysis out of the comment for application"}, {"code": "comment", "valueString": "The distinction of quantitative vs. qualitative analysis refers to whether mathematical processing is involved, whether or not the analysis includes numerical variables. Processing a categorical variable (e.g. values of happy, sad, or jealous as a response to \"How are you feeling?\") to produce numerical results (e.g. 30% happy, 50% sad, 20% surprised) would be classified as a Quantitative analysis."}, {"code": "approval", "valueString": "2022-06-07 vote 5-0 by Brian S. Alper, Paola Rosati, Eric M Harvey, Mario Tristan, Harold Lehmann"}]}, {"code": "SEVCO:01087", "display": "qualitative analysis", "definition": "A study design process in which data are analyzed, without primary reliance on mathematical or statistical techniques, by coding and organizing data to provide interpretation or understanding of experiences or hypotheses.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Joanne Dehnbostel, Khalid Shahin"}, {"code": "negative-vote", "valueString": "2022-05-17 vote 5-4 by Paul Whaley, Harold Lehmann, Robin Ann Yurk, Janice Tufte, Paola Rosati, Eric Harvey, raradhikaag@gmail.com, Cau\u00ea Monaco, Jesus Lopez-Alcalde\n2022-05-24 vote 4-1 by Robin Ann Yurk, Eric M Harvey, Mario Tristan, Harold Lehmann, Jesus Lopez-Alcalde"}, {"code": "expert-comments", "valueString": "2022-05-17 comments: What about ordinal data such as low/medium/high? I think I would view that as qualitative.\nSuggest revise definition to include examples of the analysis methods as Alternative terms or comment for applications:  ie focus groups.  There are many new software tools which apply quantitative methods to qualitative studies.\nQuantitative and qualitative have categorical results I believe\nDisagree - (Sorry, maybe you already know my comment here ;>). From my experience, qualitative analysis produces more than descriptive or categorical results, and uses a range of essential complex methodologies for producing unattainable results from trials. Some methods are inductive, others are deductive, or a mix of both. This modify the results achievable. For example, phenomenology from categorical codes produces new understanding of people's lived experiences (deemed robust, even from a small but convenient sample of people), whereas grounded theory, from descriptive and categorical data results, discovers or creates novel theories, crucial for subsequent research scrutiny, even for a trial. \nI would suggest to define qualitative analysis differently = A study design process in which data, analysed and coded to produce descriptive and categorical results, lead to new understanding of people's lived experiences or new theories, unattainable from quantitative studies, essential for future trials.\nIn my opinion, descriptive numerical results come from quantitative analysis also (for example, incidence of SARS-COV2 per 100.000 habitants). I am not an expert in qualitative research but I guess it tackles phenomenons which can be observed but not measured.\n\n2022-05-24 comment: Qualitative analysis provide a description or summary to understand exploratory experiences and patterns, themes in the data which can provide the framework for additional data interpretation through other analysis such as quantitative analysis.  An example of a qualitative method is focus groups.  Technology exists such as natural language processing or other software to report the analysis.\n\n2022-05-26 comment: I would leave the description for a quantitative analysis out of the definition.  I would also delete the example of feelings as this can be quantified through satisfaction research which is a quantitative analysis.  I would give an example of focus groups or nature language processing.  The method involves identifying themes in narrative text."}, {"code": "comment", "valueString": "The distinction of quantitative vs. qualitative analysis refers to whether mathematical processing is involved, whether or not the analysis includes numerical variables. Processing a categorical variable (e.g. values of happy, sad, or jealous as a response to \"How are you feeling?\") to produce numerical results (e.g. 30% happy, 50% sad, 20% surprised) would be classified as a Quantitative analysis. Processing the transcripts of interviews to categorize phrases and report themes identified across interviews would be classified as a Qualitative analysis. Qualitative analysis techniques may include phenomenology development from categorical codes, and may result in discovery or creation of theories that are unattainable through quantitative analysis."}, {"code": "approval", "valueString": "2022-06-07 vote 5-0 by Brian S. Alper, Paola Rosati, Eric M Harvey, Mario Tristan, Harold Lehmann"}]}, {"code": "SEVCO:01060", "display": "blinding of study participants", "definition": "A study design process in which study participants are not informed of their intervention assignment.", "property": [{"code": "comment", "valueString": "Masking of study participants involves actions to conceal information that could lead to their awareness of their intervention assignment, such as provision of placebo or simulated interventions that mimic the target interventions."}, {"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Harold Lehmann, Janice Tufte"}, {"code": "approval", "valueString": "2022-08-23 vote 6-0 by Mario Tristan, Cau\u00ea Monaco, Janice Tufte, Philippe Rocca-Serra, Eric Harvey, Robin Ann Yurk"}], "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "masking of study participants"}]}, {"code": "SEVCO:01061", "display": "blinding of intervention providers", "definition": "A study design process in which the people administering the intervention are not informed of the intervention assignment.", "property": [{"code": "comment", "valueString": "Masking of intervention providers involves actions to conceal information that could lead to their awareness of the intervention assigned to individual study participants, such as provision of placebo interventions that mimic the target interventions.\n\nThe terms 'double-blinding' and 'triple-blinding' are not clearly and consistently defined terms but typically suggest blinding of intervention providers."}, {"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Harold Lehmann, Janice Tufte, Kenneth Wilkins"}, {"code": "approval", "valueString": "2022-08-23 vote 6-0 by Mario Tristan, Cau\u00ea Monaco, Janice Tufte, Philippe Rocca-Serra, Eric Harvey, Robin Ann Yurk"}], "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "masking of intervention providers"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "blinding of intervention deliverers"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "masking of intervention deliverers"}]}, {"code": "SEVCO:01062", "display": "blinding of outcome assessors", "definition": "A study design process in which the people determining the outcome are not informed of the intervention assignment.", "property": [{"code": "comment", "valueString": "Masking of outcome assessors involves actions to conceal information that could lead to their awareness of the intervention assigned to individual study participants to minimize the influence of such awareness on the determination of outcome measurement values.\n\nThe terms 'triple-blinding' and 'quadruple-blinding' are not clearly and consistently defined terms but may suggest blinding of outcome assessors."}, {"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Harold Lehmann, Janice Tufte, Kenneth Wilkins"}, {"code": "approval", "valueString": "2022-08-23 vote 5-0 by Mario Tristan, Cau\u00ea Monaco, Janice Tufte, Philippe Rocca-Serra, Eric Harvey"}], "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "masking of outcome assessors"}]}, {"code": "SEVCO:01063", "display": "blinding of data analysts", "definition": "A study design process in which the people managing or processing the data and statistical analysis are not informed of the intervention assignment.", "property": [{"code": "comment", "valueString": "The term 'data analysts' is meant to include any person who works with the data at any point between data collection and the reporting of analyzed results.\n\nMasking of data analysts involves actions to conceal information that could lead to their awareness of the intervention assigned to individual study participants, such as noninformative labeling used to represent the study groups.\n\nThe terms 'triple-blinding' and 'quadruple-blinding' are not clearly and consistently defined terms but may suggest blinding of data analysts."}, {"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Harold Lehmann, Janice Tufte, Kenneth Wilkins"}, {"code": "approval", "valueString": "2022-08-23 vote 5-0 by Mario Tristan, Cau\u00ea Monaco, Janice Tufte, Philippe Rocca-Serra, Eric Harvey"}], "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "masking of data analysts"}]}, {"code": "SEVCO:01064", "display": "allocation concealment", "definition": "A study design process in which all parties influencing study enrollment and allocation to study groups are unaware of the group assignment for the study participant at the time of enrollment and allocation.", "property": [{"code": "comment", "valueString": "Allocation concealment occurs before and during the enrollment process and refers to limiting awareness of assignment during the process of recruitment and assignment to groups. Other blinding and masking terms refer to limiting awareness of the assignment during and after enrollment."}, {"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Harold Lehmann"}, {"code": "approval", "valueString": "2022-08-30 vote 8-0 by Janice Tufte, nisha mathew,: Philippe Rocca-Serra, Jesus Lopez-Alcalde, Harold Lehmann, Muhammad Afzal, Cau\u00ea Monaco, Eric Harvey"}], "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "blinding of randomization assignment"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "masking of randomization assignment"}]}]}, {"code": "SEVCO:00999", "concept": [{"code": "SEVCO:01043", "display": "multicentric", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte"}, {"code": "comment", "valueString": "This term may be used for studies conducted across multiple contexts (administrative or logistical) that are distinct from geographic locations, potentially introducing greater variability beyond multisite data collection."}, {"code": "negative-vote", "valueString": "2022-03-15 vote 5-1 by Mario Tristan, Paul Whaley, nisha mathew, Philippe Rocca-Serra, Harold Lehmann, Robin Ann Yurk\n2022-04-26 vote 3-0 by Eric M Harvey, Robin Ann Yurk, Mario Tristan"}, {"code": "expert-comments", "valueString": "2022-03-15 comments: Suggest add to multiple contexts (reserach)\n\na multicenter study is_a study. 'multicentric' would be a subtype of study_design_feature.  \na concern here is that the current definition conflates 2 entities: a study and a characteristic of that study. \nAt the end of the day, it depends on how the modeling will be made, e.g <study> <has_some_study_design_feature> <type of study_design_feature>\n\nOr should it be \"Multicenter data collection\"  ?"}, {"code": "approval", "valueString": "2022-05-06 vote 6-0 by Mario Tristan, Robin Ann Yurk, Eric M Harvey, nisha mathew, Paola Rosati, Harold Lehmann"}], "definition": "A study design feature in which two or more institutions are responsible for the conduct of the study.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "multi-institutional study"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "multicenter trial"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "multicenter study"}]}, {"code": "SEVCO:01052", "display": "includes patient-reported outcome", "definition": "A study design feature in which one or more outcomes are reported directly from the patient without interpretation by a clinician or researcher.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "includes patient-reported outcomes"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "PRO"}], "property": [{"code": "comment", "valueString": "Examples of patient-reported outcomes include symptoms, pain, quality of life, satisfaction with care, adherence to treatment, and perceived value of treatment. Data collection methods including surveys and interviews may obtain patient-reported outcomes. Reports derived from wearable devices would not typically include patient-reported outcomes. Such data may be coded with 'Real world data collection from monitoring procedures' (SEVCO:01046)."}, {"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Joanne Dehnbostel"}, {"code": "external-definitions", "valueString": "The U.S. Food and Drug Administration (FDA) defines a patient-reported outcome (PRO) as \u201cany report of the status of a patient\u2019s health condition that comes directly from the patient, without interpretation of the patient\u2019s response by a clinician or anyone else [1].\u201d -- from https://dcricollab.dcri.duke.edu/sites/NIHKR/KR/PRO%20Resource%20Chapter.pdf"}, {"code": "negative-vote", "valueString": "2022-04-26 vote 3-0 by Eric M Harvey, Robin Ann Yurk, Mario Tristan"}, {"code": "expert-comments", "valueString": "2022-04-26 comment: Suggest adding to the comment for application:  data methods to collect Patient Reported Outcomes such as survey data.\n2022-05-06 comments: Perhaps direct the reader to \"Patient generated health data\" or whatever else is the SEVCO term for \"wearables\" or other data sources (e.g., bluetooth scale).\nSuggest adding to the comment for application:  data methods to collect Patient Reported Outcomes such as survey data.\n2022-06-07 preferred term changed from \"Patient-reported outcome\" to \"Includes patient-reported outcome\" to maintain consistency with sibling concepts"}, {"code": "approval", "valueString": "2022-05-06 vote 7-0 by Mario Tristan, Robin Ann Yurk, Eric M Harvey, nisha mathew, Paola Rosati, Harold Lehmann, Janice Tufte"}]}, {"code": "SEVCO:01053", "display": "includes patient-centered outcome", "definition": "A study design feature in which one or more measures are outcomes that patients directly care about, i.e. outcomes that are directly related to patients' experience of their life.", "property": [{"code": "comment", "valueString": "In healthcare research, outcomes are effects on patients or populations, including changes to health status, behavior, or knowledge as well as patient satisfaction and quality of life. A patient-centered outcome qualifies the type of outcome as that which patients directly care about, i.e. outcomes that are directly related to patients' experience of their life. Examples of patient-centered outcomes include mortality, morbidity, symptoms, and quality of life. Some use 'clinical outcome' as synonymous with 'patient-centered outcome' while some use 'clinical outcome' to represent outcomes that would assessed as part of healthcare practice."}, {"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Joanne Dehnbostel, Mario Tristan, Khalid Shahin"}, {"code": "negative-vote", "valueString": "2022-05-06 vote 5-2 by Mario Tristan, Robin Ann Yurk, Eric M Harvey, nisha mathew, Paola Rosati, Harold Lehmann, Janice Tufte\n2022-05-17 vote 7-2 by Paul Whaley, Harold Lehmann, Robin Ann Yurk, Paola Rosati, Eric Harvey, raradhikaag@gmail.com, Cau\u00ea Monaco, Jesus Lopez-Alcalde, Janice Tufte"}, {"code": "expert-comments", "valueString": "2022-04-26 comment: Suggest Adding to comment for application:  Population Statistics such as mortality, morbidity.   Development of clinical outcomes is based on using a framework such as the Donabedian model:  Structure, Process, Outcomes where outcomes have some relationship to structural or process measures in clinical care.....\n2022-05-06 comment:  I understand the goal of \"quantity or quality of life,\" but I think it's too abstract--and limiting (\"Quantity of life\" is limited to life expectancy). I haven't reviewed other definitions, but the flavor is, \"outcomes that patients care about.\" (\"Function\" is left off the list of \"examples\", albeit there is a large overlap with \"morbidity,\" \"symptoms,\" and \"quality of life.\") (See the Comments for Application for Surrogate Outcome!)\n2022-05-17 comments: The definition seems to be in the comment: \"A clinical outcome qualifies the type of outcome as that which patients directly care about.\" The definition as proposed doesn't really make sense to me.\nThe definition, Alternative terms and comment for application are correct.  However, it is more specific to patient reported outcomes.  Clinical outcomes are more broad and also includes:  physiologic measures, condition specific measures.....etc. Clinical outcomes can be structural, process or outcomes in the donabedian framework and or combined as composite outcomes.\nWhile patient centered outcomes are typically considered clinical outcomes, they also indicate the observed outcomes  by the clinician but not so much by the patient. \n\n2022-05-26 comment: Suggest revise term definition so it is more inclusive or all healthcare or clinical outcomes, such as mortality, morbidity, physiologic measures, symptoms, experiences.  The term is not a study design but a measure.\n\nFor example:\nA healthcare measure which captures results from healthcare populations, settings structures, processes, and patients directly related to their care with healthcare settings, people, providers, and interventions.\n\nInsert other Alternative terms:  Morbidity, Mortality, Symptoms, Experience of Care, Health Status, Quality of life.  Suggest delete Patient Oriented Outcome, Patient Important Outcome, Patient Relevant Outcome, Patient Centered OUtcome, Includes clinical outcomes,"}, {"code": "approval", "valueString": "2022-06-07 vote 5-0 by Brian S. Alper, Paola Rosati, Eric M Harvey, Mario Tristan, Harold Lehmann"}], "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "includes patient-oriented outcome"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "includes patient-important outcome"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "includes patient-relevant outcome"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "includes clinical outcome"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "includes patient-centered outcome measure"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "includes clinical outcome measure"}]}, {"code": "SEVCO:01054", "display": "includes disease-oriented outcome", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "includes disease-oriented outcome measure"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "includes surrogate outcome"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "includes surrogate outcome measure"}], "definition": "A study design feature in which one or more measures are outcomes that relate to a health or illness condition but are not outcomes which patients directly care about.", "property": [{"code": "comment", "valueString": "In healthcare research, outcomes are effects on patients or populations, including changes to health status, behavior, or knowledge as well as patient satisfaction and quality of life. A patient-centered outcome qualifies the type of outcome as that which patients directly care about. Examples of patient-centered outcomes include mortality, morbidity, symptoms, and quality of life. A disease-oriented outcome qualifies the type of outcome as that which patients do not directly care about. Examples of disease-oriented outcomes include laboratory test measurements, imaging study findings, and calculated risk estimates. In this context, disease-oriented outcomes may be used as surrogate outcomes or proxy outcomes for ultimate effects on patient-centered outcomes, but do not provide direct evidence of effects on patient-centered outcomes."}, {"code": "editors", "valueString": "Brian S. Alper, Mario Tristan, Joanne Dehnbostel, Kenneth Wilkins, Khalid Shahin"}, {"code": "negative-vote", "valueString": "2022-05-06 vote 4-2 by Mario Tristan, Robin Ann Yurk, nisha mathew, Paola Rosati, Harold Lehmann, Janice Tufte\n2022-05-17 vote 6-2 by Paul Whaley, Harold Lehmann, Robin Ann Yurk, Paola Rosati, Eric Harvey, raradhikaag@gmail.com, Cau\u00ea Monaco, Jesus Lopez-Alcalde"}, {"code": "expert-comments", "valueString": "2022-05-06 comments: I would refer to whatever \"clinical outcome\" is defined as: \"...indirect measures of clinical outcomes\". The Comment for Application is redefining Clinical Outcome. I would spend that space pointing out that some surrogates are predictive (e.g., cholesterol levels, for MIs)  and others are after the fact (e.g., sales of orange juice for treating the flu).\nSuggestion--look at the wikipedia definition, then explore other mapping definitions.  The current term definition and comment for application need improvement.\n\n\"In clinical trials, a surrogate endpoint is a measure of effect of a specific treatment that may correlate with a real clinical endpoint but does not necessarily have a guaranteed relationship. The National Institutes of Health defines surrogate endpoint as \"a biomarker intended to substitute for a clinical endpoint\".  wikipedia...\n\n2022-05-17 comments: Maybe edit to \"An indirect measure of quantity or quality of life, presumed or believed to have an effect on clinical outcomes.\"I would focus on revising and define surrogate first and then include a broad definition, not just specific to clinical outcomes.\n\n2022-05-26 comment: Surrogate Outcome is a proxy measure for capturing the outcome of interest.\n\nAlternative Terms:  delete disease oriented and surrogate outcome measure.  Suggest add:  Proxy Outcome Measure.\n\nComment for application:  Delete first 3 sentences.\nEdit the last sentence so it reads:   A surrogate outcome is a measure which captures an approximate measure.  Examples of surrogate outcomes includes survey measures rating scales for a child by the parent or teacher.  Geriatric rating scales from paid or professional caregivers for a seriously ill or geriatric patient are other examples."}, {"code": "approval", "valueString": "2022-06-07 vote 5-0 by Brian S. Alper, Paola Rosati, Eric M Harvey, Mario Tristan, Harold Lehmann"}]}, {"code": "SEVCO:01085", "display": "includes process measure", "definition": "A study design feature in which one or more outcomes are actions or behaviors of a healthcare professional or care team.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Khalid Shahin, Kenneth Wilkins"}, {"code": "negative-vote", "valueString": "2022-05-17 vote 7-1 by Paul Whaley, Harold Lehmann, Robin Ann Yurk, Paola Rosati, Eric Harvey, raradhikaag@gmail.com, Cau\u00ea Monaco, Jesus Lopez-Alcalde\n2022-05-17 vote 8-2 by Paul Whaley, Harold Lehmann, Robin Ann Yurk, Paola Rosati, Eric Harvey, raradhikaag@gmail.com, Cau\u00ea Monaco, Jesus Lopez-Alcalde, nelle.stocquart@kce.fgov.be, Mario Tristan\n2022-05-31 vote 8-2 by Paul Whaley, Harold Lehmann, Robin Ann Yurk, Paola Rosati, Eric Harvey, raradhikaag@gmail.com, Cau\u00ea Monaco, Jesus Lopez-Alcalde, nelle.stocquart@kce.fgov.be, Mario Tristan"}, {"code": "expert-comments", "valueString": "2022-05-17 comment: Process Measure is included in the donabedian framework of structure, process, outcomes.  Do you want to define just for healthcare process measure versus keep the definition broad to include such as a series of steps or tasks providing a measurement pathway for any industry and the examples in healthcare processes are....\n2022-05-24 comments: repeat 2022-05-17 comment plus:\nyou need to provide more info, it is not clear as such\n\n2022-05-31 comments:\nyou need to provide more info, it is not clear as such\nAdd comment for application with examples:  A process measures captures the steps to care such as \nLab test orders, Referrals....The literature defines a process measure in the donabedian framework of structure, process, outcomes."}, {"code": "comment", "valueString": "A process outcome measure is a measure of change in actions or behaviors conducted in the process of healthcare delivery or clinical care, such as obtaining laboratory tests or referrals for follow-up care."}, {"code": "approval", "valueString": "2022-06-07 vote 5-0 by Brian S. Alper, Paola Rosati, Eric M Harvey, Mario Tristan, Harold Lehmann"}], "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "includes process outcome"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "includes process outcome measure"}]}, {"code": "SEVCO:01089", "display": "study goal", "definition": "A study design feature specifying the intent of the study.", "concept": [{"code": "SEVCO:01096", "display": "evaluation goal", "property": [{"code": "external-definitions", "valueString": "Medical Subject Heading (MESH): this heading is used as a Publication Type; for original report of the conduct or results of a specific evaluation study; a different heading EVALUATION STUDIES AS TOPIC is used for general design, methodology, economics, etc. of evaluation studies\nScope Note\nWorks consisting of studies determining the effectiveness or utility of processes, personnel, and equipment. https://meshb.nlm.nih.gov/record/ui?ui=D023362"}, {"code": "comment", "valueString": "Intended to include all forms of evaluation study. (Child concepts for program, process, personnel and equipment evaluations may be added later.)"}, {"code": "editors", "valueString": "Kenneth Wilkins, Joanne Dehnbostel"}, {"code": "approval", "valueString": "2022-07-12 vote 6-0 by Philippe Rocca-Serra, Jesus Lopez-Alcalde, Paola Rosati, Harold Lehmann, Eric Harvey, Janice Tufte"}], "definition": "A study goal to assess the efficiency, effectiveness, and impact of a given program, process, person or piece of equipment.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "evaluation study goal"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "evaluation aim"}]}, {"code": "SEVCO:01097", "display": "derivation goal", "definition": "A study goal with the intent to generate a predictive algorithm.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Kenneth Wilkins"}, {"code": "approval", "valueString": "2022-07-19 vote 8-0 by Paola Rosati, Cau\u00ea Monaco, Paul Whaley, Philippe Rocca-Serra, Harold Lehmann, Mario Tristan, Jesus Lopez-Alcalde, Eric Harvey"}], "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "derivation study goal"}]}, {"code": "SEVCO:01098", "display": "validation goal", "property": [{"code": "external-definitions", "valueString": "https://meshb.nlm.nih.gov/record/ui?ui=D023361\nMeSH Heading:  Validation Study\nAnnotation:\nThis heading is used as a Publication Type for original report of the conduct or results of a specific validation study. A different heading VALIDATION STUDIES AS TOPIC is used for general design, methodology, economics, etc. of validation studies. CATALOGER: Do not use\nScope Note:\nWorks consisting of research using processes by which the reliability and relevance of a procedure for a specific purpose are established.\nEntry Term(s):\nValidation Studies"}, {"code": "comment", "valueString": "Procedures that may be assessed in validation studies include predictive algorithms, measurement instruments, and educational materials. Internal validation is tested in populations from the source used for derivation of the procedure. External validation is tested in populations that differ from the source used for derivation of the procedure."}, {"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Kenneth Wilkins, Harold Lehmann"}, {"code": "negative-vote", "valueString": "2022-07-19 vote 8-1 by Paola Rosati, Cau\u00ea Monaco, Paul Whaley, Philippe Rocca-Serra, Harold Lehmann, Mario Tristan, Jesus Lopez-Alcalde, Eric Harvey, Janice Tufte"}, {"code": "expert-comments", "valueString": "2022-07-19 comment: \"Relevance\" is a value judgment that is not the hallmark of a validation study. (It requires elicitation of this judgment from experts or potential users.)\nAccuracy, while difficult to measure, is certainly a validation aspiration (goal). Thus, validation of instruments assesses their sensitivity and specificity (measures of \"accuracy\").\nPerhaps a broader goal is \"performance\", which would include accuracy but also applicability across sites or other external contexts.\nAlso, typo: \"*from* the source used...\""}, {"code": "approval", "valueString": "2022-07-26 vote 6-0 by Jesus Lopez-Alcalde, Harold Lehmann, Paola Rosati, Eric Harvey, Janice Tufte, Mario Tristan"}], "definition": "A study goal with the intent to determine the reliability and/or performance of a procedure for a specific predictive, classification, measurement, or communication purpose.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "validation study goal"}]}, {"code": "SEVCO:01088", "display": "comparison goal", "definition": "A study design feature in which the study intent is to compare two or more interventions or exposures.", "property": [{"code": "external-definitions", "valueString": "MeSH term \"Equivalence Trial\" https://www.ncbi.nlm.nih.gov/mesh/2023172 Trial that aims to show a new treatment is no better and no worse than the standard treatment.\n\nYear introduced: 2018\n\nDo not include MeSH terms found below this term in the MeSH hierarchy.\n\nTree Number(s): V03.175.250.500.500.125\n\nMeSH Unique ID: D000073843\n\nEntry Terms:\n\nNon-Inferiority Trial\nNoninferiority Trial\nSuperiority Trial\nEquivalence Clinical Trial"}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Kenneth Wilkins, Joanne Dehnbostel"}, {"code": "approval", "valueString": "2022-06-21 vote 5-0 by Janice Tufte, Louis Leff, Mario Tristan, Eric M Harvey, Muhammad Afzal"}], "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "comparative analysis goal"}], "concept": [{"code": "SEVCO:01091", "display": "comparative effectiveness goal", "definition": "A study design feature in which the study intent is to compare two or more interventions with respect to benefits and/or harms.", "property": [{"code": "comment", "valueString": "In 2009, the Institute of Medicine committee defined comparative effectiveness research (CER) as: \"Comparative effectiveness research is the generation and synthesis of evidence that compares the benefits and harms of alternative methods to prevent, diagnose, treat, and monitor a clinical condition or to improve the delivery of care. The purpose of CER is to assist consumers, clinicians, purchasers, and policy makers to make informed decisions that will improve health care at both the individual and population levels.\""}, {"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Joanne Dehnbostel, Khalid Shahin"}, {"code": "external-definitions", "valueString": "Defining comparative effectiveness research (CER) was the first order of business for the Institute of Medicine Committee on Initial Priorities for CER. The Institute of Medicine committee approached the task of defining CER by identifying the common theme in the 6 extant definitions. The definition follows: \"Comparative effectiveness research is the generation and synthesis of evidence that compares the benefits and harms of alternative methods to prevent, diagnose, treat, and monitor a clinical condition or to improve the delivery of care. The purpose of CER is to assist consumers, clinicians, purchasers, and policy makers to make informed decisions that will improve health care at both the individual and population levels.\" https://pubmed.ncbi.nlm.nih.gov/20473202/"}, {"code": "approval", "valueString": "2022-06-21 vote 5-0 by Janice Tufte, Louis Leff, Mario Tristan, Eric M Harvey, Muhammad Afzal"}], "concept": [{"code": "SEVCO:01090", "display": "comparative efficacy goal", "definition": "A study design feature in which the study intent is to compare two or more interventions with respect to effectiveness in ideal conditions.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Joanne Dehnbostel, Khalid Shahin"}, {"code": "approval", "valueString": "2022-06-28 vote 8-0 by Jesus Lopez-Alcalde, Philippe Rocca-Serra, Harold Lehmann, Muhammad Afzal, Janice Tufte, Louis Leff, Mario Tristan, Eric M Harvey"}, {"code": "expert-comments", "valueString": "2022-06-28 comment: what does \"in ideal conditions\" really mean? is it necessary ?"}, {"code": "comment", "valueString": "Efficacy is defined as effectiveness in ideal conditions. In this context, an efficacy goal is a type of effectiveness goal. Efficacy is used to distinguish the context from effectiveness in 'real-world' settings."}]}, {"code": "SEVCO:01092", "display": "comparative safety goal", "definition": "A study design feature in which the study intent is to compare two or more interventions with respect to harms.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Joanne Dehnbostel, Khalid Shahin"}, {"code": "approval", "valueString": "2022-06-28 vote 8-0 by Jesus Lopez-Alcalde, Philippe Rocca-Serra, Harold Lehmann, Muhammad Afzal, Janice Tufte, Louis Leff, Mario Tristan, Eric M Harvey"}, {"code": "expert-comments", "valueString": "2022-06-28 comment: no need to be \"in ideal conditions\" ? see related comment on. \"comparative efficacy goal\" class textual definition"}]}]}, {"code": "SEVCO:01093", "display": "equivalence goal", "property": [{"code": "external-definitions", "valueString": "MeSH term \"Equivalence Trial\" https://www.ncbi.nlm.nih.gov/mesh/2023172 Trial that aims to show a new treatment is no better and no worse than the standard treatment.\n\nYear introduced: 2018\n\nDo not include MeSH terms found below this term in the MeSH hierarchy.\n\nTree Number(s): V03.175.250.500.500.125\n\nMeSH Unique ID: D000073843\n\nEntry Terms:\n\nNon-Inferiority Trial\nNoninferiority Trial\nSuperiority Trial\nEquivalence Clinical Trial"}, {"code": "comment", "valueString": "An Equivalence Goal is only applicable with a Comparative study design. \nThe prespecified range representing absence of a meaningful difference may be defined with an equivalence margin."}, {"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Joanne Dehnbostel"}, {"code": "negative-vote", "valueString": "2022-07-12 vote 4-2 by Philippe Rocca-Serra, Jesus Lopez-Alcalde, Paola Rosati, Janice Tufte, Harold Lehmann, Eric Harvey"}, {"code": "expert-comments", "valueString": "2022-07-12 comments: harmonize the definition to match the pattern used for the other terms. e.g. \"evaluation goal\" is a study goal in which the objective is to assess the efficience, effectivement and impact of a given process, process, person or piece of equipment'\n\nso Equivalence Goal is a study goal in which the study intent is to compare two or more interventions or exposures and determine that any difference in effects is within a prespecified range representing absence of a meaningful difference\n\nI think this definition is unclear. Is the equivalence goal an aim of a study? Which kind of study? My understanding is: Given a prespecified range (of results?) showing an absence of a meaningful (for which kind of subjects/previous research?) difference between two interventions/exposures, the equivalence goal assesses that there is no difference in effects. Is this the meaning of this definition? Which kind of study could give a valid result in terms of equivalence? An RCT?"}, {"code": "approval", "valueString": "2022-07-19 vote 8-0 by Paola Rosati, Cau\u00ea Monaco, Paul Whaley, Philippe Rocca-Serra, Harold Lehmann, Mario Tristan, Jesus Lopez-Alcalde, Eric Harvey"}], "definition": "A study goal with the intent to compare two or more interventions or exposures and determine that any difference in effects is within a prespecified range representing absence of a meaningful difference."}, {"code": "SEVCO:01094", "display": "non-inferiority goal", "property": [{"code": "external-definitions", "valueString": "MeSH term \"Equivalence Trial\" https://www.ncbi.nlm.nih.gov/mesh/2023172 Trial that aims to show a new treatment is no better and no worse than the standard treatment.\n\nYear introduced: 2018\n\nDo not include MeSH terms found below this term in the MeSH hierarchy.\n\nTree Number(s): V03.175.250.500.500.125\n\nMeSH Unique ID: D000073843\n\nEntry Terms:\n\nNon-Inferiority Trial\nNoninferiority Trial\nSuperiority Trial\nEquivalence Clinical Trial"}, {"code": "comment", "valueString": "A Non-inferiority Goal is only applicable with a Comparative study design. \nThe threshold between a meaningful difference and absence of a meaningful difference may be called a non-inferiority margin."}, {"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Joanne Dehnbostel"}, {"code": "negative-vote", "valueString": "2022-07-12 vote 3-2 by Philippe Rocca-Serra, Jesus Lopez-Alcalde, Paola Rosati, Harold Lehmann, Eric Harvey"}, {"code": "expert-comments", "valueString": "2022-07-12 comments: so Non-Inferiorty Goal is a study goal in which....\nI have the same doubts already given for the equivalence goal"}, {"code": "approval", "valueString": "2022-07-19 vote 8-0 by Paola Rosati, Cau\u00ea Monaco, Paul Whaley, Philippe Rocca-Serra, Harold Lehmann, Mario Tristan, Jesus Lopez-Alcalde, Eric Harvey"}], "definition": "A study goal with the intent to compare two or more interventions or exposures and determine that any difference in effects is below a prespecified value representing a threshold between a meaningful difference and absence of a meaningful difference."}, {"code": "SEVCO:01095", "display": "superiority goal", "property": [{"code": "external-definitions", "valueString": "MeSH term \"Equivalence Trial\" https://www.ncbi.nlm.nih.gov/mesh/2023172 Trial that aims to show a new treatment is no better and no worse than the standard treatment.\n\nYear introduced: 2018\n\nDo not include MeSH terms found below this term in the MeSH hierarchy.\n\nTree Number(s): V03.175.250.500.500.125\n\nMeSH Unique ID: D000073843\n\nEntry Terms:\n\nNon-Inferiority Trial\nNoninferiority Trial\nSuperiority Trial\nEquivalence Clinical Trial"}, {"code": "comment", "valueString": "A Superiority Goal is only applicable with a Comparative study design. \n\nA superiority study goal may be exploratory (to detect a difference) or confirmatory (to establish that a difference exists with a degree of certainty).\n\nA superiority goal is not the opposite of a non-inferiority goal. A superiority goal uses a threshold of zero difference while an inferiority goal uses a threshold of a meaningful difference.\n\nSome superiority comparisons are conducted following determination of non-inferiority.\n\nPlacebo-controlled trials are typically superiority studies.\n\nSuperiority, as commonly used, is 'statistical superiority,' with null used as the threshold of effect. An approach representing 'clinical superiority' would use the non-inferiority margin as the threshold of effect."}, {"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Joanne Dehnbostel, Harold Lehmann"}, {"code": "negative-vote", "valueString": "2022-07-12 vote 4-1 by Philippe Rocca-Serra, Jesus Lopez-Alcalde, Paola Rosati, Harold Lehmann, Eric Harvey"}, {"code": "expert-comments", "valueString": "2022-07-12 comment: so Superiority Goal is a study goal in which...\n2022-07-19 comment: alter definition to \"...and detect *meaningful* difference in effects\" (in order to be consistent with Equivalence and Non-inferiority Study Goals')"}, {"code": "approval", "valueString": "2022-07-19 vote 9-0 by Paola Rosati, Cau\u00ea Monaco, Paul Whaley, Philippe Rocca-Serra, Harold Lehmann, Mario Tristan, Jesus Lopez-Alcalde, Eric Harvey, Janice Tufte"}], "definition": "A study goal with the intent to compare two or more interventions or exposures and detect a difference in effects.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "superiority study goal"}]}]}], "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Kenneth Wilkins, Joanne Dehnbostel"}, {"code": "approval", "valueString": "2022-06-21 vote 5-0 by Janice Tufte, Louis Leff, Mario Tristan, Eric M Harvey, Muhammad Afzal"}, {"code": "expert-comments", "valueString": "2022-06-21 comment: Another alternate term could be \"Study Objective\""}], "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "study aim"}]}, {"code": "SEVCO:01100", "display": "allocation ratio", "definition": "A study design feature describing the intended relative proportion of assignment across groups.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Kenneth Wilkins"}, {"code": "comment", "valueString": "The allocation ratio may be expressed as Treatment:Control, e.g., 2:1, or, in the case of two treatment arms and one control, e.g. 2:2:1."}, {"code": "approval", "valueString": "2023-04-10 vote 5-0 by Harold Lehmann, Joanne Dehnbostel, Eric Harvey, Janice Tufte, Jesus Lopez-Alcalde"}, {"code": "expert-comments", "valueString": "2023-04-10 comment Perhaps add to Comment for Application something like, \"The allocation ratio is usually expressed as Treatment:Control, e.g., 2:1 or 2:2:1, in the case of two treatment arms.\""}]}], "display": "study design feature", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Paul Whaley, Janice Tufte"}, {"code": "comment", "valueString": "Study design is defined as a plan specification for how and what kinds of data will be gathered as part of an investigation which may produce testable explanations, conclusions and predictions or test a hypothesis."}, {"code": "expert-comments", "valueString": "2022-03-15 comments: I agree with the definition but feel this is meta-vocabulary that helps us talk about elements of study design that are not part of the code system itself. So I don't know if it should be included in the code system as a code, or if we should be considering some other means for defining these terms (e.g. in documentation or guidance about SEVCO).\nnot a fan of the synonym \"study design factor\" as it could cause confusion with 'Study Factor\", Independent Variable. How different Study Design is from Study Protocol? \"Study design planned process\"  could cover the following subtypes\nFor the comment for application include ...as a technical plan specification....\n2022-03-22 comment: The definition of \"Study design\" seems to exclude the \"statistical analysis\". Am I right?"}, {"code": "negative-vote", "valueString": "2022-03-15 vote 7-0 by Mario Tristan, Paul Whaley, nisha mathew, Philippe Rocca-Serra, Harold Lehmann, Janice Tufte, Robin Ann Yurk (but then the definition changed with the creation of Study Design Process)\n2022-03-22 vote 5-1 by Joanne Dehnbostel, Jesus Lopez-Alcalde, Philippe Rocca-Serra, Mario Tristan, nelle.stocquart, Robin Ann Yurk"}, {"code": "approval", "valueString": "2022-03-29 vote 8-0 by Paul Whaley, Mario Tristan, Jesus Lopez-Alcalde, Cau\u00ea Monaco, Joanne Dehnbostel, Philippe Rocca-Serra, Robin Ann Yurk, nelle.stocquart"}], "definition": "An aspect or characteristic of a study design.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "study design characteristic"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "study design aspect"}]}, {"code": "SEVCO:00001", "display": "bias", "definition": "A systematic distortion in research results (estimation of effect, association, or inference). Distortions in research results means differences between the reported results (findings, conclusions, effect estimates) and the actuality (the truth, the estimand [the quantity targeted for estimation]).", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "false certainty"}], "property": [{"code": "editors", "valueString": "Brian S. Alper, Philippe Rocca-Serra, Joanne Dehnbostel, Mario Tristan, Harold Lehmann; Kenneth Wilkins, Janice Tufte, Muhammad Afzal"}, {"code": "approval", "valueString": "8/8 as of 2021-02-26: , Harold Lehmann, Khalid Shahin, Eric Harvey, Jes\u00fas L\u00f3pez-Alcalde, Joanne Dehnbostel, Muhammad Afzal, Paola Rosati, Eric Au, 5/5 for second sentence as of 8/30/2021: Eric Harvey, Harold Lehmann, Mario Tristan, Bhagvan Kommadi, Janice Tufte"}], "concept": [{"code": "SEVCO:00002", "concept": [{"code": "SEVCO:00003", "concept": [{"code": "SEVCO:00004", "display": "inappropriate selection criteria", "property": [{"code": "editors", "valueString": "Brian S. Alper, Tatyana Shamliyan, Bhagvan Kommadi, Muhammad Afzal, Khalid Shahin, Harold Lehmann, Philippe Rocca-Serra, Asiyah Yu Lin, Joanne Dehnbostel"}, {"code": "approval", "valueString": "10/10 as of 3/22/2021 Harold Lehmann, Eric Harvey, Bhagvan Kommadi, Jesus Lopez-Alcalde, Ahmad Sofi-Mahmudi, Tatyana Shamliyan, Muhammad Afzal, Paola Rosati, Joanne Dehnbostel, Marc Duteau"}, {"code": "negative-vote", "valueString": "2021-03-19 vote 9-2 on \"A bias resulting from inclusion and exclusion criteria used to select participating subjects that could make the included participants unrepresentative of the population of interest.\" by Brian S. Alper, Tatyana Shamliyan, Bhagvan Kommadi, Muhammad Afzal, Khalid Shahin, Harold Lehmann, Philippe Rocca-Serra, Asiyah Yu Lin"}], "definition": "A selection bias resulting from inclusion and exclusion criteria used to select participating subjects that could result in differences between the study participants and the population of interest.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "selection bias due to inappropriate selection criteria"}]}, {"code": "SEVCO:00005", "concept": [{"code": "SEVCO:00014", "display": "inappropriate data source for participant selection", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Khalid Shahin, Muhammad Afzal, Bhagvan Kommadi"}, {"code": "approval", "valueString": "6/6 as of 4/12/2021: KM Saif-Ur-Rahman, Bhagvan Kommadi, Joanne Dehnbostel, Paola Rosati, Jes\u00fas L\u00f3pez-Alcalde, Tatyana Shamliyan"}], "definition": "Participant selection bias due to inappropriate data source for sampling frame.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "participant selection bias due to inappropriate data source for sampling frame"}]}], "display": "inappropriate sampling strategy", "property": [{"code": "editors", "valueString": "Brian S. Alper, Tatyana Shamliyan, Bhagvan Kommadi, Muhammad Afzal, Khalid Shahin, Harold Lehmann, Philippe Rocca-Serra, Joanne Dehnbostel"}, {"code": "approval", "valueString": "10/10 as of 3/22/2021 Harold Lehmann, Eric Harvey, Bhagvan Kommadi, Jesus Lopez-Alcalde, Ahmad Sofi-Mahmudi, Tatyana Shamliyan, Muhammad Afzal, Paola Rosati, Joanne Dehnbostel, Marc Duteau"}, {"code": "negative-vote", "valueString": "2021-03-19 vote 9-2 on \"A bias resulting from the sample frame, sampling procedure, or methods used to recruit participating subjects that could make the included participants unrepresentative of the population of interest.\" by Brian S. Alper, Tatyana Shamliyan, Bhagvan Kommadi, Muhammad Afzal, Khalid Shahin, Harold Lehmann, Philippe Rocca-Serra"}], "definition": "A selection bias resulting from the sampling frame, sampling procedure, or methods used to recruit participating subjects that could result in differences between the study participants and the population of interest.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "biased sampling strategy"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "inappropriate sample frame"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "inappropriate sampling frame"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "inappropriate sampling procedure"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "selection bias due to inappropriate sampling strategy"}]}, {"code": "SEVCO:00006", "concept": [{"code": "SEVCO:00008", "display": "inadequate enrollment of eligible subjects", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Philippe Rocca-Serra, Marc Duteau, Khalid Shahin, Asiyah Yu Lin, Muhammad Afzal, Tatyana Shamliyan"}, {"code": "approval", "valueString": "11/11 as of 3/29/2021: Alejandro Piscoya, Eric Harvey, Bhagvan Kommadi, Ahmad Sofi-Mahmudi, Eric Au, Joanne Dehnbostel, Marc Duteau, Brian S. Alper, Jes\u00fas L\u00f3pez-Alcalde, Tatyana Shamliyan, Paola Rosati"}, {"code": "negative-vote", "valueString": "2021-03-26 vote 8-2 on \"Inadequate enrollment = A selection bias due to a rate of study entry among eligible subjects that is not sufficient for the included sample to be considered representative of the population of interest.\" by Harold Lehmann, Tatyana Shamliyan, Muhammad Afzal, Eric Au, Paola Rosati, Mario Tristan, Alejandro Piscoya, Bhagvan Kommadi, Jes\u00fas L\u00f3pez-Alcalde, Eric Harvey"}], "definition": "A selection bias in which insufficient enrollment of eligible subjects results in differences (recognized or unrecognized) between the included participants and the population of interest that distorts the research results.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "selection bias due to inadequate enrollment"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "non-representative sample due to inadequate enrollment"}]}, {"code": "SEVCO:00012", "concept": [{"code": "SEVCO:00013", "display": "depletion of susceptibles", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Khalid Shahin"}, {"code": "approval", "valueString": "9/9 as of 4/9/2021: Alejandro Piscoya, KM Saif-Ur-Rahman, Bhagvan Kommadi, Eric Harvey, Joanne Dehnbostel, Paola Rosati, Harold Lehmann, Jes\u00fas L\u00f3pez-Alcalde, Tatyana Shamliyan"}], "definition": "A non-representative sample due to exclusion of susceptible participants who have already had an outcome due to prior exposure. For example, the inclusion of prevalent users of a medication misrepresents the initial adverse effects rate by excluding persons who do not tolerate the medication.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "prevalent user bias"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "non-representative sample due to depletion of susceptibles"}]}], "display": "non-representative sample due to timing or duration of exposure", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Khalid Shahin"}, {"code": "approval", "valueString": "9/9 as of 4/9/2021: Alejandro Piscoya, KM Saif-Ur-Rahman, Bhagvan Kommadi, Eric Harvey, Joanne Dehnbostel, Paola Rosati, Harold Lehmann, Jes\u00fas L\u00f3pez-Alcalde, Tatyana Shamliyan"}], "definition": "A selection bias in which the timing or duration of exposure influences the outcome, and the timing or duration of exposure in the sample does not represent that of the population of interest. This selection bias may occur when the selection for study participation is not coincident with the initiation of the exposure or intervention under investigation.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "mismatch in start of intervention and start of follow-up"}]}], "display": "non-representative sample", "property": [{"code": "editors", "valueString": "Brian S. Alper, Tatyana Shamliyan, Bhagvan Kommadi, Muhammad Afzal, Khalid Shahin, Harold Lehmann, Philippe Rocca-Serra, Joanne Dehnbostel"}, {"code": "approval", "valueString": "10/10 as of 3/22/2021 Harold Lehmann, Eric Harvey, Bhagvan Kommadi, Jesus Lopez-Alcalde, Ahmad Sofi-Mahmudi, Tatyana Shamliyan, Muhammad Afzal, Paola Rosati, Joanne Dehnbostel, Marc Duteau"}, {"code": "negative-vote", "valueString": "2021-03-19 vote 10-1 on \"Differences between the included participants and the population of interest that distorts the research results (estimation of effect, association, or inference), limiting external validity or applicability.\" by Brian S. Alper, Tatyana Shamliyan, Bhagvan Kommadi, Muhammad Afzal, Khalid Shahin, Harold Lehmann, Philippe Rocca-Serra"}], "definition": "A selection bias due to differences between the included participants and the population of interest that distorts the research results (estimation of effect, association, or inference), limiting external validity or applicability.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "selection bias due to non-representative sample"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "unrepresentative sample"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "nonrepresentative sample"}]}, {"code": "SEVCO:00009", "display": "post-baseline factors influence enrollment selection", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Philippe Rocca-Serra, Marc Duteau, Khalid Shahin, Asiyah Yu Lin, Harold Lehmann, Mario Tristan"}, {"code": "approval", "valueString": "9/9 as of 4/5/2021: Alejandro Piscoya, KM Saif-Ur-Rahman, Bhagvan Kommadi, Eric Harvey, Joanne Dehnbostel, Mario Tristan, Harold Lehmann, Jes\u00fas L\u00f3pez-Alcalde, Tatyana Shamliyan"}], "definition": "A selection bias in which factors observed after study entry, baseline, or start of follow-up influence enrollment", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "participant selection bias due to post-baseline factors"}], "concept": [{"code": "SEVCO:00212", "display": "participant selection bias due to early study termination", "definition": "A selection bias due to premature closure of study enrollment.", "property": [{"code": "comment", "valueString": "'Early termination bias affecting enrollment' is a type of 'Post-baseline factors influence enrollment selection' which is defined as 'A selection bias in which factors observed after study entry, baseline, or start of follow-up influence enrollment.'\nTo express bias related to making the decision to terminate a study, use 'Early Study Termination Bias'."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Paul Whaley, Kenneth Wilkins, Muhammad Afzal"}, {"code": "negative-vote", "valueString": "2022-03-25 vote 7-1 by Muhammad Afzal, Paul Whaley, Mario Tristan, Joanne Dehnbostel, Jesus Lopez-Alcalde, Philippe Rocca-Serra, Paola Rosati, Robin Ann Yurk"}, {"code": "expert-comments", "valueString": "2022-03-25 comment: Recommend simplifying the term and then add your test to the term definition.\nFor example edit term to Early Study Termination Bias.  Term definition should read.  Selection Bias due to premature closing of a study enrollment for the participants...."}, {"code": "approval", "valueString": "2022-04-08 vote 12-0 by Muhammad Afzal, Paul Whaley, Mario Tristan, Joanne Dehnbostel, Jesus Lopez-Alcalde, Philippe Rocca-Serra, Paola Rosati, Robin Ann Yurk, nelle.stocquart, nisha mathew, Harold Lehmann, Cau\u00ea Monaco"}], "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "early termination bias affecting enrollment"}]}]}, {"code": "SEVCO:00010", "display": "factor associated with exposure influences enrollment selection", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Khalid Shahin, Harold Lehmann, Mario Tristan, Bhagvan Kommadi, Muhammad Afzal"}, {"code": "approval", "valueString": "9/9 as of 4/5/2021: Alejandro Piscoya, KM Saif-Ur-Rahman, Bhagvan Kommadi, Eric Harvey, Joanne Dehnbostel, Mario Tristan, Harold Lehmann, Jes\u00fas L\u00f3pez-Alcalde, Tatyana Shamliyan"}], "definition": "A selection bias in which a factor associated with the exposure under investigation influences study enrollment", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "participant selection bias due to factor associated wiith exposure"}]}, {"code": "SEVCO:00011", "display": "factor associated with outcome influences enrollment selection", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Khalid Shahin, Harold Lehmann, Mario Tristan, Bhagvan Kommadi, Muhammad Afzal"}, {"code": "approval", "valueString": "9/9 as of 4/5/2021: Alejandro Piscoya, KM Saif-Ur-Rahman, Bhagvan Kommadi, Eric Harvey, Joanne Dehnbostel, Mario Tristan, Harold Lehmann, Jes\u00fas L\u00f3pez-Alcalde, Tatyana Shamliyan"}], "definition": "A selection bias in which a factor associated with the outcome under investigation influences study enrollment", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "participant selection bias due to factor associated wiith outcome"}]}], "display": "participant selection bias", "property": [{"code": "editors", "valueString": "Brian S. Alper, Tatyana Shamliyan, Bhagvan Kommadi, Muhammad Afzal, Khalid Shahin, Harold Lehmann, Philippe Rocca-Serra, Asiyah Yu Lin, Joanne Dehnbostel"}, {"code": "approval", "valueString": "10/10 as of 3/22/2021 Harold Lehmann, Eric Harvey, Bhagvan Kommadi, Jesus Lopez-Alcalde, Ahmad Sofi-Mahmudi, Tatyana Shamliyan, Muhammad Afzal, Paola Rosati, Joanne Dehnbostel, Marc Duteau"}, {"code": "negative-vote", "valueString": "2021-03-08 vote 7-2 on \"A selection bias where key characteristics of the participants differ systematically from the population of interest.\" by Harold Lehmann, Philippe Rocca-Serra, Joanne Dehnbostel, 2021-03-19 vote 10-1 on \"A bias resulting from methods used to select participating subjects, factors that influence initial study participation, or differences between the study participants and the population of interest\" by Brian S. Alper, Tatyana Shamliyan, Bhagvan Kommadi, Muhammad Afzal, Khalid Shahin, Harold Lehmann, Philippe Rocca-Serra, Asiyah Yu Lin"}], "definition": "A selection bias resulting from methods used to select participating subjects, factors that influence initial study participation, or differences between the study participants and the population of interest"}, {"code": "SEVCO:00015", "display": "study selection bias", "definition": "A selection bias resulting from factors that influence study selection, from methods used to include or exclude studies for evidence synthesis, or from differences between the study sample and the population of interest", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "bias in study selection"}], "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Khalid Shahin, Muhammad Afzal, Philippe Rocca-Serra"}, {"code": "approval", "valueString": "6/6 as of 4/26/2021: Eric Harvey, Bhagvan Kommadi, Harold Lehmann, Mario Tristan, Jes\u00fas L\u00f3pez-Alcalde, Tatyana Shamliyan\n2024-04-19 vote 8-0 by Cau\u00ea Monaco, Janice Tufte, Homa Keshavarz, Sheyu Li, Khalid Shahin, Lenny Vasanthan, Harold Lehmann, Eric Harvey"}], "concept": [{"code": "SEVCO:00262", "display": "bias in study eligibility criteria", "definition": "A study selection bias specific to the inclusion and exclusion criteria.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Harold Lehmann"}, {"code": "comment", "valueString": "If the study eligibility criteria (inclusion and exclusion criteria for study selection) result in a dataset that is non-representative of the population of interest, then the criteria introduce systematic error. \n\nA study selection bias is a selection bias resulting from factors that influence study selection, from methods used to include or exclude studies for evidence synthesis, or from differences between the study sample and the population of interest."}, {"code": "approval", "valueString": "2024-02-02 vote 5-0 by Brian S. Alper, Harold Lehmann, Xing Song, Cau\u00ea Monaco, Eric Harvey"}], "concept": [{"code": "SEVCO:00273", "display": "study eligibility criteria not prespecified", "definition": "A bias in study eligibility criteria in which the criteria are not stated before the study selection process occurs.", "property": [{"code": "external-definitions", "valueString": "from ROBIS 1.1 Did the review adhere to pre-defined objectives and eligibility criteria?\nA systematic review should begin with a clearly focused question or objective which is reflected in the criteria used for deciding whether studies are eligible for inclusion. Details that should be specified a priori in a review protocol vary according to review type, but should generally include the study designs, study participants, and types of interventions/exposures that are eligible. If outcomes or outcome domains are to form part of the eligibility criteria, this should be stated clearly. Any exclusions should also be pre-specified. Where a protocol providing this information is available, the answer to this question would be \u201cYes\u201d. Where no protocol is available but information about pre-defined objectives and detailed eligibility criteria are supplied, and there is good reason to believe that these were specified in advance and adhered to throughout the\nreview, assessors can consider answer this question \u201cProbably Yes\u201d. Any post hoc changes to the eligibility criteria or outcomes must keep faith with the objectives of the review, and be properly justified and documented. In the absence of a pre-published protocol, where information about pre-defined objectives and eligibility criteria are only available post hoc in the review publication, unless there is some reason to believe that these details were specified in advance and adhered to from the start of the review, this question should be answered \u201cProbably No\u201d. Where all or some of these details are missing, this question should be answered \u201cNo\u201d."}, {"code": "comment", "valueString": "Failure to specify the study eligibility criteria before evaluating studies for selection can lead to a situation in which the data discovered during the study selection process influences the criteria for selection in a way that introduces systematic error."}, {"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Kenneth Wilkins, Homa Keshavarz"}, {"code": "approval", "valueString": "2024-02-16 vote 6-0 by Javier Bracchiglione, Lenny Vasanthan, Xing Son, Brian S. Alper, Harold Lehmann, Eric Harvey"}]}, {"code": "SEVCO:00274", "display": "study eligibility criteria not appropriate for review question", "definition": "A bias in study eligibility criteria due to a mismatch between the inclusion and exclusion criteria and the research question.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Kenneth Wilkins, Homa Keshavarz, Xing Song"}, {"code": "external-definitions", "valueString": "from ROBIS 1.2 Were the eligibility criteria appropriate for the review question?\nThe eligibility criteria should stem from the review question and should provide sufficient detail to enable judgement about whether the studies that are included are appropriate to the question. The information required is likely to vary by topic. For example, in order to judge appropriateness, the assessor might need a clear description of the population in terms of the age range and diagnosis of the study participants, the setting in which the study was conducted, the dose of a drug, or the frequency of exposure. To answer this question the assessor is likely to require some content knowledge."}, {"code": "comment", "valueString": "The mismatch between the inclusion and exclusion criteria and the research question may relate to differences in the population, exposures, or outcomes studies from those of interest."}, {"code": "negative-vote", "valueString": "2024-02-16 vote 5-1 by Javier Bracchiglione, Lenny Vasanthan, Xing Song, Brian S. Alper, Harold Lehmann, Eric Harvey"}, {"code": "expert-comments", "valueString": "2024-02-16 comment: I would simplify the definition to: \"A bias in study eligibility criteria derived from a mismatch between the inclusion and exclusion criteria, and the research question, that could result in an inappropriate selection of studies\""}, {"code": "approval", "valueString": "2024-03-08 vote 5-0 :Lenny Vasanthan, Harold Lehmann, Janice Tufte, Javier Bracchiglione, Eric Harvey"}]}, {"code": "SEVCO:00275", "display": "study eligibility criteria ambiguous", "definition": "A bias in study eligibility criteria due to unclear specification.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Kenneth Wilkins, Homa Keshavarz"}, {"code": "external-definitions", "valueString": "from ROBIS 1.3 Were eligibility criteria unambiguous?\nSpecific information about the characteristics of eligible studies must be provided, as far as possible avoiding any ambiguities about the types of study, population, interventions, comparators and outcomes. Criteria should be sufficiently detailed that the review could be replicated using the criteria specified. A number of important details are commonly missing from the eligibility criteria in systematic reviews. For example, details about the diagnosis of study participants. Diagnosis might be made using a number of different methods, some of which might be more valid or accurate than others. Review authors should have decided in advance which diagnostic methods are appropriate to their review question in order to avoid introducing potential biases during the review process. Similarly, specific details about interventions/exposures and comparators must be provided, including characteristics such as medication dose, frequency of administration, concurrent treatments, and so on. The assessor is likely to require some content knowledge to answer this question, but where specific queries remain about the stated eligibility criteria, \u201cNo\u201d or \u201cProbably No\u201d judgements can usually be made."}, {"code": "comment", "valueString": "Eligibility criteria that are not sufficiently described to enable reproduction of study selection can introduce systematic error."}, {"code": "approval", "valueString": "2024-02-16 vote 5-0 by Lenny Vasanthan, Xing Son, Brian S. Alper, Harold Lehmann, Eric Harvey"}]}, {"code": "SEVCO:00276", "display": "study eligibility criteria limits for study characteristics not appropriate", "definition": "A bias in study eligibility criteria that is specific to restrictions based on characteristics of the study design, conduct, or findings.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Xing Song, Joanne Dehnbostel, Kenneth Wilkins, Homa Keshavarz"}, {"code": "external-definitions", "valueString": "from ROBIS 1.4 Were all restrictions in eligibility criteria based on study characteristics appropriate?\nAny restrictions applied on the basis of study characteristics must be clearly described and a sound rationale provided. These details will enable assessors to judge whether such restrictions were appropriate. Examples might be the study design, the date the study was published, the size of the study, some measure of study quality, and available outcomes measures. This question is different from the one above which refers to whether the eligibility criteria are appropriate to the review question. Where sufficient information is available, and the assessor is reasonably satisfied that the restrictions are appropriate, this question can be answered \u201cYes or \u201cProbably Yes\u201d. Where restrictions around study characteristics are not justified and there is insufficient information to judge whether these restrictions are appropriate, this question should be answered \u201cProbably No\u201d or \u201cNo\u201d. Where eligibility criteria are sufficiently detailed, and no restrictions around study characteristics are explicitly reported, it can be assumed that none were imposed, and the question should be answered \u201cYes\u201d."}, {"code": "comment", "valueString": "Any restrictions applied on the basis of study characteristics should not introduce a bias in study eligibility criteria. Examples of such restrictions may include criteria based on study size, study design, study quality, or date when the study was conducted.\n\nIn the ROBIS tool used for risk of bias assessment of systematic reviews, there is a question (1.4 Were all restrictions in eligibility criteria based on study characteristics appropriate?) that is different from the one which refers to whether the eligibility criteria are appropriate to the review question. Therefore, a separate term is available in SEVCO."}, {"code": "negative-vote", "valueString": "2024-02-23 vote 5-1 by Homa Keshavarz, Harold Lehmann, Javier Bracchiglione, Lenny Vasanthan, Xing Song, Eric Harvey"}, {"code": "expert-comments", "valueString": "2024-02-23 comment: As it is, study characteristics could refer to clinical characteristics (e.g. age), which could indeed be appropriate. I would state that it refers to methodological characteristics."}, {"code": "approval", "valueString": "2024-03-08 vote 5-0 Lenny Vasanhan, Harold Lehmann, Eric Harvey, Janice Tufte, Homa Kashavarz"}]}, {"code": "SEVCO:00277", "display": "study eligibility criteria limits for study report characteristics not appropriate", "definition": "A bias in study eligibility criteria that is specific to restrictions on the status, structure, language, or accessibility of the study report.", "property": [{"code": "external-definitions", "valueString": "from ROBIS 1.5 Were any restrictions in eligibility criteria based on sources of information appropriate?\nAny restrictions applied on the basis of sources of information must be clearly described and a sound rationale provided. These details will enable assessors to judge whether such restrictions were appropriate. Examples might be the publication status or format, language, and availability of data. This question is different from the question in domain 2 which is about restricting searches. Where eligibility criteria are sufficiently detailed, but no restrictions based on sources of information are explicitly reported, it must be assumed that none were imposed, and the question should be answered \u201cYes\u201d."}, {"code": "comment", "valueString": "Examples of study report characteristics include publication status (including preprints and unpublished data), format, language, and availability of data, as well as the date of publication.\nThe ROBIS tool used for assessing risk of bias of systematic reviews includes a signaling question '1.5 Were any restrictions in eligibility criteria based on sources of information appropriate?'"}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Kenneth Wilkins, Homa Keshavarz"}, {"code": "expert-comments", "valueString": "2024-02-16 comment: (in comments for application, there is a dot after the parenthesis that needs to be removed)"}, {"code": "approval", "valueString": "2024-02-23 vote 5-0 by Homa Keshavarz, Harold Lehmann, Javier Bracchiglione, Lenny Vasanthan, Eric Harvey"}]}]}, {"code": "SEVCO:00269", "display": "language bias", "definition": "A bias in search strategy or study eligibility criteria that results from restrictions regarding the language of the study report.", "property": [{"code": "external-definitions", "valueString": "https://catalogofbias.org/biases/language-bias/"}, {"code": "comment", "valueString": "Limiting the study reports included in a systematic review by language may result in an incomplete view of the truly available evidence.\n\nThe terms <a href=\"https://fevir.net/resources/CodeSystem/27270#SEVCO:00266\" target=\"_blank\">search strategy limits for study report characteristics not appropriate</a> and <a href=\"https://fevir.net/resources/CodeSystem/27270#SEVCO:00277\" target=\"_blank\">study eligibility criteria limits for study report characteristics not appropriate</a> are used to describe types of study selection bias that results from restrictions regarding the study report, distinguishing different steps in the search and selection process."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Muhammad Afzal, Kenneth Wilkins"}, {"code": "expert-comments", "valueString": "05-03-2024 \n\"what is interesting about this term is that language in terms of terms changes and actually can begin to mean something other than the original intent- later original term might mean something else down the road\""}, {"code": "approval", "valueString": "05-03-2024 5-0 by Homa Keshavarz, Eric Harvey, Janice Tufte, Lenny Vasanthan, Harold Lehmann"}]}, {"code": "SEVCO:00270", "display": "geography bias", "definition": "A bias in search strategy or study eligibility criteria that results from restrictions regarding the geographic origin of the research.", "property": [{"code": "external-definitions", "valueString": "The role of geographic bias in knowledge diffusion: a systematic review and narrative synthesis (https://researchintegrityjournal.biomedcentral.com/articles/10.1186/s41073-019-0088-0) includes \"geographic bias...are biased by the geographic origin of the research\" and \"geographic bias, such as the role of institutional affiliation, country of origin...\" and \"geographic bias, i.e., local, regional, national, or international\""}, {"code": "comment", "valueString": "Limiting the study reports included in a systematic review by country of origin may result in an incomplete view of the truly available evidence.\n\nThe geographic origin of the research may refer to the location of the research participants, the investigators, or their associated organizations.\n\nThe terms <a href=\"https://fevir.net/resources/CodeSystem/27270#SEVCO:00266\" target=\"_blank\">search strategy limits for study report characteristics not appropriate</a> , <a href=\"https://fevir.net/resources/CodeSystem/27270#SEVCO:00276\" target=\"_blank\">study eligibility criteria limits for study characteristics not appropriate</a> and <a href=\"https://fevir.net/resources/CodeSystem/27270#SEVCO:00277\" target=\"_blank\">study eligibility criteria limits for study report characteristics not appropriate</a> are used to describe types of study selection bias that results from restrictions regarding the study report, distinguishing different steps in the search and selection process."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Muhammad Afzal, Joanne Dehnbostel"}, {"code": "approval", "valueString": "05-03-2024 5-0 by Homa Keshavarz, Eric Harvey, Janice Tufte, Lenny Vasanthan, Harold Lehmann"}]}, {"code": "SEVCO:00272", "display": "publication bias", "definition": "A study selection bias in which the publicly available studies are not representative of all conducted studies.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "study selection bias due to selective reporting bias"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "study selection bias due to non-reporting bias"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "study selection bias due to reporting bias"}], "property": [{"code": "comment", "valueString": "Publication bias arises from the failure to identify all studies that have been conducted, either published (i.e., publicly available) or unpublished. The term 'studies' means evidence or research results in any form where such studies would meet the study eligibility criteria without consideration of criteria regarding the form of publication. The phrase 'publicly available studies' means the studies are available to the broad academic community and the public through established distribution channels in any form, including forms with restricted access.  Established distribution channels include peer-reviewed journals, books, conference proceedings, dissertations, reports by governmental or research organizations, preprints, and study registries.\n\nPublication bias often leads to an overestimate in the effect in favor of the study hypothesis, because studies with statistically significant positive results are more likely to be publicly available.\n\nThe terms <a href=\"https://fevir.net/resources/CodeSystem/27270#SEVCO:00023\" target=\"_blank\">reporting bias</a> and <a href=\"https://fevir.net/resources/CodeSystem/27270#SEVCO:00024\" target=\"_blank\">selective reporting bias</a> are used to describe biases in study reports, i.e., reporting bias. To avoid confusion between biases in study reports and biases in study selection, when either 'reporting bias' or 'selective reporting bias' are used as alternative for 'publication bias', the term is appended to 'study selection bias due to' as shown below:\n&#9;\u2022 study selection bias due to reporting bias\n&#9;\u2022 study selection bias due to selective reporting bias"}, {"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Muhammad Afzal, Joanne Dehnbostel, Khalid Shahin"}, {"code": "negative-vote", "valueString": "2024-03-29 vote 7-1 by Philippe Rocca-Serra, Sheyu Li, Harold Lehmann, Javier Bracchiglione, Lenny Vasanthan, Cau\u00ea Monaco, Eric Harvey, Jennifer Hunter\n2024-04-12 vote 6-1 by Sheyu Li, Jennifer Hunter, Janice Tufte, Eric Harvey, Homa Keshavarz, Lenny Vasanthan, Harold Lehmann\n2024-04-19 vote 8-1 by Janice Tufte, Homa Keshavarz, Sheyu Li, Khalid Shahin, Lenny Vasanthan, Harold Lehmann, Eric Harvey, Jennifer Hunter, Cau\u00ea Monaco\n2024-04-26 vote 4-1 by Homa Keshavarz, Sean Grant, Lenny Vasanthan, Jennifer Hunter, Eric Harvey\n2024-05-03 vote 6-1 by Harold Lehmann, Lenny Vasanthan, Jennifer Hunter, janice Tufte, Eric Harvey, Homa Keshavarz, Khalid Shahin"}, {"code": "expert-comments", "valueString": "2024-03-29 comment:\nThe current definition does not reflect the information of 'publication', which is the core of the term. I understand that it is not good to use the same word in the definition and the term itself. Nevertheless, the word available could be vague - studies could be available in registration website only but not published. For different authors, the 'availability' of the studies are different. \n\nA suggested definition:\nA study selection bias in which the published studies are not representative of the conducted studies.\t\nalternatively: \nA study selection bias in which the studies available in the literature database are not representative of all conducted studies.\n\n2024-04-12 comment:\nPublication bias arises from the failure to identify all studies that have been conducted, either published (i.e., publicly available) or unpublished. Typically, publication bias leads to an overestimate in the effect in favour of the study hypothesis. This is because studies with statistically significant positive results are more likely to be publicly available or published in English-language journals.\n\n2024-04-19 comment:\nConsider adding some alternate terms used by Cochrane: non-reporting bias; bias due to missing results. https://training.cochrane.org/handbook/current/chapter-07#section-7-1\n\n2024-04-26 comments:\n1) Suggest revising second paragraph slightly to \"Publication bias often (but not always) leads to...\"2N) The last paragraph/sentence in application is long and difficult to read. Here is a suggestion:\nThe terms reporting bias and selective reporting bias are used to describe biases in study reports. To avoid ambiguous use as alternative terms for publication bias, the terms are appended to 'study selection bias due to'.\n\n2024-05-03 comments:\nThe last paragraph is still very difficult to read, and I understand what we are trying to communicate. What about this suggestion?\nThe terms reporting bias and selective reporting bias are used to describe biases in study reports. To avoid confusion between biases in study reports and biases in study selection, when either 'reporting bias' or 'selective reporting bias' are used as alternative for 'publication bias', the term is appended to 'study selection bias due to'."}, {"code": "approval", "valueString": "2024-05-10 vote 10-0 by Saphia Mokrane, Sheyu Li, Harold Lehmann, Brian S. Alper, Homa Keshavarz, Lenny Vasanthan, Cau\u00ea Monaco, Jennifer Hunter, Eric Harvey, Khalid Shahin"}]}, {"code": "SEVCO:00395", "display": "bias in search strategy", "definition": "A study selection bias specific to the strategy used to identify potentially eligible studies.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Kenneth Wilkins, Homa Keshavarz, Muhammad Afzal, Joanne Dehnbostel"}, {"code": "expert-comments", "valueString": "2024-02-23 comment: Although I am not 100% sure if this qualifies as \"study selection\" bias"}, {"code": "approval", "valueString": "2024-02-23 vote 6-0 by Khalid Shahin, Homa Keshavarz, Harold Lehmann, Javier Bracchiglione, Lenny Vasanthan, Eric Harvey"}], "concept": [{"code": "SEVCO:00263", "display": "database search sources inadequate", "definition": "A bias in search strategy in which the electronic sources are not sufficient to find the studies available in electronic sources.", "property": [{"code": "external-definitions", "valueString": "from ROBIS 2.1 Did the search include an appropriate range of databases/electronic sources for published and unpublished reports?\nThe assessor needs to judge what constitutes an appropriate range of databases. This will vary according to review topic. It is anticipated that at a minimum a MEDLINE and EMBASE search would be conducted. Searches of material published as conference reports should also be considered along with a search of research registers. Guidance on the appropriate range of databases can be found in SR guidance such as the Cochrane Handbook,5 or from the Centre for Reviews and Dissemination (CRD) website (http://www.york.ac.uk/inst/crd/finding_studies_systematic_reviews.htm)"}, {"code": "comment", "valueString": "The set of databases (electronic sources) expected to include the studies of interest will vary with the review topic."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Kenneth Wilkins, Caue Monaco, Homa Keshavarz"}, {"code": "approval", "valueString": "Expert working group agreement 2024-03-01 5-0 vote by Eric Harvey, Harold Lehmann, Khalid Shahin, Javier Bracchiglione, Homa Keshavarz"}]}, {"code": "SEVCO:00264", "display": "non-database search sources inadequate", "definition": "A bias in search strategy in which the sources other than electronic database sources are not sufficient to find the studies available.", "property": [{"code": "external-definitions", "valueString": "from ROBIS 2.2 Were methods additional to database searching used to identify relevant reports?\nAdditional methods such as citation searches, contacting experts, reference checking, handsearching etc. should have been performed."}, {"code": "comment", "valueString": "The set of sources other than databases (electronic sources) expected to include the studies of interest will vary with the review topic."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Kenneth Wilkins, Caue Monaco, Homa Keshavarz"}, {"code": "expert-comments", "valueString": "2024-03-08 \"I wonder about globally and developing nations where CHW workers are collecting data perhaps not electronically\" , \"Similar to other comments global data might be collected oin paper- qualitative - observational studies\""}, {"code": "approval", "valueString": "2024-03-08 6-0 Eric Harvey, Harold Lehmann, Javier Bracchiglione, Janice Tufte, Homa Kashavarz, Lenny Vasanthan"}]}, {"code": "SEVCO:00265", "display": "search strategy not sensitive", "definition": "A bias in search strategy in which the search terms and combinations of search terms are not sufficient to find the studies available.", "property": [{"code": "external-definitions", "valueString": "from ROBIS 2.3 Were the terms and structure of the search strategy likely to retrieve as many eligible studies as possible?\nA full search strategy showing all the search terms used, in sufficient detail to replicate the search, is required to be able to fully judge this question. If only limited details are provided, such as a list of search terms with no indication of how these are combined, assessors may be able to make a \u201cProbably Yes\u201d or \u201cProbably No\u201d judgment. Assessors should consider whether the search strategy included an appropriate range of terms for the topic, whether a combination of controlled terms (such as Medical Subject Headings (MeSH) for Medline) and words in the title and abstract were used, and whether any filters applied were appropriate. For example, for DTA reviews the use of filters has been shown to miss relevant studies and so this question should be answered as No for a strategy that includes such filters. Guidance on the critical appraisal of search strategies can be found in the PRESS Evidence-Based Checklist (http://ejournals.library.ualberta.ca/index.php/EBLIP/article/view/7402)."}, {"code": "comment", "valueString": "The search terms and combinations of search terms expected to include the studies of interest will vary with the review topic."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Kenneth Wilkins, Caue Monaco, Homa Keshavarz"}, {"code": "approval", "valueString": "2024-03-08 vote 5-0 Eric Harvey, Harold Lehmann, Javier Bracchiglione, Homa Kasharvarz, Lenny Vasanthan"}]}, {"code": "SEVCO:00266", "display": "search strategy limits for study report characteristics not appropriate", "definition": "A bias resulting from search strategy criteria implemented due to practical considerations for implementation, including properties of a report or its accessibility.", "property": [{"code": "external-definitions", "valueString": "from ROBIS 2.4 Were restrictions based on date, publication format, or language appropriate?\nIf no restrictions were applied to the search strategy then this question should be answered as Yes. This is different from the question in domain 1 (1.5) which is about restriction to selection criteria. Information is required on all three components of this question (i.e. date, publication format and language) to be able to fully judge this item. Restriction of papers based on language (e.g. restriction to English language articles) or publication format (e.g. restriction to full text published studies) is rarely (if ever) appropriate, and so if any such restrictions were applied then this question should usually be answered as \u201cNo\u201d. Restrictions on date may be appropriate but should be supported by a clearly described rationale for this question to be answered as \u201cYes\u201d. For example, if a medication or test was not available before a certain date then it is reasonable to only start searches from the date at which the medication or test first became available."}, {"code": "comment", "valueString": "A bias in search strategy that is specific to restrictions on the date, status, structure, language, or accessibility of the study report. Accessibility refers to where a resource is available and how one gains access to it."}, {"code": "editors", "valueString": "Harold Lehmann, Kenneth Wilkins, Homa Keshavarz, Khalid Shahin, Joanne Dehnbostel"}, {"code": "approval", "valueString": "2024-03-15 vote 5-0 by Xing Song, Lenny Vasanthan, Harold Lehmann, Homa Keshavarz, Eric Harvey"}]}]}, {"code": "SEVCO:00267", "display": "misapplication of study eligibility criteria", "definition": "A study selection bias due to inappropriate implementation of the study inclusion and exclusion criteria.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "nonadherence to study eligibility criteria"}], "property": [{"code": "editors", "valueString": "Sheyu Li, Ken Wilkins, Muhammad Afzal, Homa Keshavarz, Joanne Dehnbostel"}, {"code": "negative-vote", "valueString": "2024-03-29 vote 7-1 by Philippe Rocca-Serra, Sheyu Li, Harold Lehmann, Javier Bracchiglione, Jennifer Hunter, Homa Keshavarz, Lenny Vasanthan, Eric Harvey"}, {"code": "expert-comments", "valueString": "2024-03-29 comment:\nThe title/name needs work. Maybe something like: Bias due to non-adherence to eligibility criteria?"}, {"code": "approval", "valueString": "2024-04-12 vote 6-0 by Harold Lehmann, Sheyu Li, Jennifer Hunter, Janice Tufte, Homa Keshavarz, Eric Harvey"}]}, {"code": "SEVCO:00345", "display": "bias related to selection of the studies for synthesis", "definition": "A study selection bias due to inappropriate choice of studies included in the synthesis.", "property": [{"code": "external-definitions", "valueString": "ROBIS 4.1 Did the synthesis include all studies that it should?"}, {"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Kenneth Wilkins, Airton Stein, Harold Lehmann"}, {"code": "expert-comments", "valueString": "2025-05-17 comment: (There could be a link to \"Selection bias\", making the point that this term is the equivalent for synthesis studies.)\n\n2024-05-24 comment: Hmm. Maybe change, \"typical use\" to \"typical risk\"?\n\n2024-06-07 comments re: \"synthesis missing eligible studies\" = \"A synthesis bias in which eligible studies were not included in the evidence synthesis.\"1N) The term itself is new to me: is there a more established term?\nre: \"synthesis missing eligible studies\" = \"A synthesis bias in which eligible studies were not included in the evidence synthesis.\"2N) It is confusing regarding synthesis. Evidence synthesis includes quantitative synthesis (meta-analysis typically) and qualitative synthesis. The comments may mean that a study is included in a qualitative synthesis but not a quantitative synthesis. It can be true, but why? Typically it can be some synthestic gap, e.g., the unavailability of zero events in a meta-analysis. \nThe definition can be revised as A synthesis bias in which eligible studies were not included in the some parts of evidence syntheses.\n\n2024-06-14 comment re: \"bias related to selection of the data for synthesis\" = \"A synthesis bias due to inappropriate choice of data included in the synthesis before the synthesis is applied.\"1N) I understand the concept though I am not clear how this is a \"bias\"? \"Inappropriate\" choice just sounds like poor study execution rather than a bias.\n\n\n2024-08-09 comment re: \"bias related to selection of the studies for synthesis\" = \"A synthesis bias due to inappropriate choice of studies included in the synthesis before the synthesis is applied.\"1N)\nWhat is the difference between this bias and selection bias?   Is it is related to some technical barriers such as zero even issue? The synthesis have to opt out the zero event trials because of the restriction of the statistical methods.\n\n\n2024-08-16 comment re: \"bias related to selection of the studies for synthesis\" = \"A study selection bias due to inappropriate choice of studies included in the synthesis.\"1N)\nI fail to see how the comments for application differ from bias related to the selection of the data for synthesis. There seems to be considerable overlap.\n\nReferring to a \"specific meta-analysis\" may be the issue, as this requires the selection of specific results from the included studies. Additionally, a meta-analysis is only one example of how results can be synthesized, and it does not account for other data (e.g., qualitative). Perhaps something like the following might work: \"A potential use of this term is when studies were included in the overall review, yet none of the study results or findings (quantitative or qualitative) were analyzed or synthesized.\n\nI'm unsure that \"and appropriate for synthesis\" is correct. For instance, an included study may have measured the outcome of interest but not reported the results in a way that can be used in the planned meta-analysis (e.g., only the p value is reported, or no SDM/SE is reported). Even though the results cannot be used (i.e., are not appropriate) for the meta-analysis, there is still a risk of distorted results which constitutes bias. Perhaps I am mistaken, and this bias only refers to errors of judgement by the reviewers.\n\n\n2024-08-23 comment re: \"bias related to selection of the studies for synthesis\" = \"A study selection bias due to inappropriate choice of studies included in the synthesis.\"1Y)\nI Could suggest a petit change in 'comment for application'...\"If the selected for synthesis do not match the available studies, there is a risk of distorted results which constitutes bias.\""}, {"code": "approval", "valueString": "2024-08-23 vote 9-0 by Carlos Alva-Diaz, Elma OMERAGIC, Lenny Vasanthan, Harold Lehmann, Philippe Rocca-Serra, Eric Harvey, Sean Grant, Airton Tetelbom Stein, Homa Keshavarz"}, {"code": "comment", "valueString": "A potential use of this term is when studies meeting the review criteria were available but not included in the review. Another potential use of this term is when studies were included in the overall review but were not included in a specific meta-analysis or specific synthesis. If the studies selected for synthesis do not match the available studies, there is a risk of distorted results which constitutes bias.\nThe term 'bias related to selection of the studies for synthesis' matches the ROBIS signaling question 4.1 'Did the synthesis include all studies that it should?'\nIf a study was selected for the overall review but the data was not extracted from the study for a specific analysis or synthesis, then use [bias related to selection of the data for synthesis](https://fevir.net/resources/CodeSystem/27270#SEVCO:00352)"}, {"code": "negative-vote", "valueString": "2024-05-17 vote 5-0 by Saphia Mokrane, Lenny Vasanthan, Sheyu Li, Eric Harvey, Harold Lehmann\n2024-05-24 vote 7-0 by Homa Keshavarz, Sheyu Li, Eric Harvey, Lenny Vasanthan, Harold Lehmann, Janice Tufte, Saphia Mokrane\n2024-06-07 vote 6-2 by Sean Grant, Saphia Mokrane, Sheyu Li, Lenny Vasanthan, Harold Lehmann, Eric Harvey, Carlos Alva-Diaz, Kailei Nong\n2024-06-14 vote 7-1 by Yaowaluk Ngoenwiwatkul, Homa Keshavarz, Sean Grant, Sheyu Li, Eric Harvey, Lenny Vasanthan, Harold Lehmann, Janice Tufte\n2024-06-21 vote 8-0 by Cau\u00ea Monaco, Lenny Vasanthan, Homa Keshavarz, Yaowaluk Ngoenwiwatkul, Harold Lehmann, Sean Grant, Eric Harvey, Carlos Alva-Diaz BUT THEN THE TERM CHANGED from 'data' to 'studies'\n2024-08-09 vote 7-1 by Brian S. Alper, Harold Lehmann, Homa Keshavarz, Sheyu Li, Sean Grant, Eric Harvey, Lenny Vasanthan, Airton Tetelbom Stein\n2024-08-16 vote 5-1 by Cau\u00ea Monaco, Bhagvan Kommadi, Jennifer Hunter, Eric Harvey, Harold Lehmann, Airton Tetelbom Stein"}]}, {"code": "SEVCO:00268", "display": "bias in study selection process", "definition": "A study selection bias due to an inadequate process for screening and/or evaluating potentially eligible studies.", "property": [{"code": "external-definitions", "valueString": "from ROBIS 2.5 Were efforts made to minimise errors in selection of studies?\nBoth the process of screening titles and abstracts and of assessing full text studies for inclusion are covered by this question. Information on both are required to be able to fully judge this item. For an answer of \u201cYes\u201d, titles and abstracts should be screened independently by at least two reviewers and full text inclusion assessment should involve at least two reviewers (either independently or with one performing the assessment and the second checking the decision)."}, {"code": "comment", "valueString": "An adequate process for screening and evaluating potentially eligible studies should generally include at least two independent reviewers for any steps that involve subjective judgment. Any step involving subjective judgment may introduce systematic distortions into the research findings."}, {"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Muhammad Afzal, Joanne Dehnbostel, Khalid Shahin"}, {"code": "negative-vote", "valueString": "2024-03-29 vote 6-1 by Philippe Rocca-Serra, Sheyu Li, Harold Lehmann, Javier Bracchiglione, Lenny Vasanthan, Eric Harvey, Jennifer Hunter\n2024-04-12 vote 6-2 by Cau\u00ea Monaco, Sheyu Li, Jennifer Hunter, Janice Tufte, Eric Harvey, Homa Keshavarz, Lenny Vasanthan, Harold Lehmann"}, {"code": "expert-comments", "valueString": "2024-03-29 comments:\n1) Although the comment for application may be questionable for some specific cases.\n2N) The title/name needs more work. Perhaps something like: Study screening bias? Or just: Screening bias?\n\n2024-04-12 comments:\n1N) The term 'bias' refers to systematic error but back-to-back check by different reviewers reduce only random error. I do not think the definition and comment are in line. For my own experience, there is little room for bias during the study selection. \n2N) Suggest replace \"and\" with \"or\", as I am assuming that screening refers to T&A screening and evaluating refers to full text inclusion assessment. The bias could arise from one step only.\nConsider adding some alternative terms e.g., bias in study selection, bias in selection of studies (that maps to ROBIS), screening bias, and/or study screening bias.\n3) Re Comment for Application: There are other strategies, besides 2 independent readers, but I suppose the word, \"generally,\" addresses my concern."}, {"code": "approval", "valueString": "2024-04-19 vote 9-0 by Cau\u00ea Monaco, Sheyu Li, Jennifer Hunter, Janice Tufte, Eric Harvey, Homa Keshavarz, Lenny Vasanthan, Harold Lehmann, Khalid Shahin"}]}]}], "display": "selection bias", "property": [{"code": "editors", "valueString": "Brian S. Alper, Tatyana Shamliyan, Bhagvan Kommadi, Muhammad Afzal, Khalid Shahin, Harold Lehmann, Philippe Rocca-Serra, Asiyah Yu Lin, Joanne Dehnbostel"}, {"code": "approval", "valueString": "8/8 as of 3/5/2021 Eric Au, Alejandro Piscoya, Mario Tristan, Brian Alper, Zbys Fedorowicz, Bhagvan Kommadi, Eric Harvey, Muhammad Afzal"}, {"code": "comment", "valueString": "Selection bias can occur before the study starts (inherent in the study protocol) or after the study starts (during study execution)."}], "definition": "A bias resulting from methods used to select subjects or data, factors that influence initial study participation, or differences between the study sample and the population of interest"}, {"code": "SEVCO:00016", "display": "confounding covariate bias", "definition": "A situation in which the effect or association between an exposure and outcome is distorted by another variable. For confounding covariate bias to occur the distorting variable must be (1) associated with the exposure and the outcome, (2) not in the causal pathway between exposure and outcome, and (3) unequally distributed between the groups being compared.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Philippe Rocca-Serra, Muhammad Afzal, Janice Tufte, Bhagvan Kommadi"}, {"code": "approval", "valueString": "2023-07-14 vote 5-0 by Paul Whaley, Harold Lehmann, Cau\u00ea Monaco, Jesus Lopez-Alcalde, Paola Rosati"}, {"code": "negative-vote", "valueString": "2021-05-07 vote 4-2 on \"Comparator Bias = A bias resulting from differences (other than in variables directly involved in the analysis) between the groups being compared.\" by KM Saif-Ur-Rahman, Harold Lehmann, Alejandro Piscoya, Paola Rosati, Tatyana Shamliyan, Bhagvan Kommadi\n2021-05-10 vote 11-1 on \"Confounding Covariate Bias = A bias resulting from differences in covariates (variables other than the exposure and outcome) between the groups being compared.\" by Eric Harvey, KM Saif-Ur-Rahman, Janice Tufte, Bhagvan Kommadi, Paola Rosati,  Alejandro Piscoya, Harold Lehmann, Ahmad Sofi-Mahmudi, Eric Au, Jesus Lopez-Alcalde, Tatyana Shamliyan, Joanne Dehnbostel\nAGREEMENT VOTE 8/8 as of 5/17/2021: Tatyana Shamliyan, Janice Tufte, Mario Tristan, Bhagvan Kommadi, Jes\u00fas L\u00f3pez-Alcalde, Isaac Fwemba, Eric Harvey, Paola Rosati\n\nOn 2023-06-16 the Steering Group corrected a technical error in the definition (between A or B ... corrected to ... between A and B), and added a Comment for Application, so re-opened the term for vote."}, {"code": "expert-comments", "valueString": "A bias resulting from differences (other than in variables directly involved in the analysis) between the groups being compared. ---led to --- Which differences do you mean between the groups?  This definition seems unclear.  Defining a Comparator bias means to addresss some possible specific explanation. Or it is preferable to delete this bias. The definition is for selection bias resulting from nonrandom allocation of participants to interventions. Random allocation of trial participants to interentions would reduce this bias. Comprator seletion would not.  A bias resulting from differences in covariates (variables other than the exposure and outcome) between the groups being compared -- led to I agree with the definition but I suggest detailing that the covariate is associated to the outcome"}, {"code": "comment", "valueString": "Association of any two variables includes direct associations and indirect associations through each of the variables having direct associations with a third variable."}], "concept": [{"code": "SEVCO:00032", "concept": [{"code": "SEVCO:00031", "display": "inadequate allocation concealment", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Janice Tufte, Philippe Rocca-Serra"}, {"code": "approval", "valueString": "10/10 as of 6/11/2021: Names not captured"}], "definition": "An allocation bias resulting from awareness of the assigned intervention before study enrolment and intervention assignment"}, {"code": "SEVCO:00278", "display": "bias due to non-randomized allocation", "definition": "An allocation bias resulting from a process of assigning participants or subjects to different groups or conditions which is not random.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "nonrandom allocation bias"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "non-random allocation bias"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "bias due to non-random allocation"}], "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Kenneth Wilkins, Joanne Dehnbostel, Muhammad Afzal"}, {"code": "comment", "valueString": "A confounding covariate bias is defined as a situation in which the effect or association between an exposure and outcome is distorted by another variable. For confounding covariate bias to occur the distorting variable must be (1) associated with the exposure and the outcome, (2) not in the causal pathway between exposure and outcome, and (3) unequally distributed between the groups being compared.\n\nAllocation bias is defined as a confounding covariate bias resulting from *methods for assignment* of the independent variable by the investigator to evaluate a response or outcome.\n\nMethods for assignment that are not random may introduce confounding with measured or unmeasured variables.\n\nNon-random methods of generation of an allocation sequence may introduce a confounding covariate bias through associations with one ore more non-random variables related to sequence generation. A non-random allocation sequence may be described as a predictable sequence in mathematical terms.\n\nThe SEVCO term [Quasi-Randomized assignment](https://fevir.net/resources/CodeSystem/27270#SEVCO:01004) is defined as an interventional study design with a method of allocation that is not limited to random chance but is intended to produce similar baseline groups for experimentation. Although Quasi-Randomized assignment is \"intended to produce similar baseline groups\" the term is classified as a type of [Non-randomized assignment](https://fevir.net/resources/CodeSystem/27270#SEVCO:01005). Examples of non-random methods (which may be called 'partially randomized' or 'quasi-random') include every other participant, day of the week, even/odd identification number, birth date, etc."}, {"code": "negative-vote", "valueString": "2023-05-12 vote 4-1 by Brian S. Alper, Joanne Dehnbostel, Janice Tufte, Jesus Lopez-Alcalde, Harold Lehmann\n2023-05-26 vote 5-1 by Harold Lehmann, Jesus Lopez-Alcalde, Sunu Alice Cherian, Brian S. Alper, Muhammad Afzal, Joanne Dehnbostel\n2023-06-09 vote 4-1 by Eric Harvey, Cau\u00ea Monaco, Paul Whaley, Sunu Alice Cherian, Harold Lehmann\n2023-06-16 vote 3-2 by Eric Harvey, Paul Whaley, Sunu Alice Cherian, Harold Lehmann, Paola Rosati\n2023-07-14 vote 4-1 by Jesus Lopez-Alcalde, Paul Whaley, Harold Lehmann, Cau\u00ea Monaco, Paola Rosati"}, {"code": "expert-comments", "valueString": "2023-05-12 comment: Does this term definition actually define \"inadequate\" = potentially predictable sequence ? seems like an innapropriate allocation bias perhaps\n2023-05-26 comment: Defintion: Methods of allocating study participants to treatment comparison groups that are not random, but are intended to produce similar groups. \nAlternative terms: Quasi random allocation\n2023-06-09 comment: The comment for application describes \"unrecognised associations\", but the definition talks about \"potentially predictable\", which implies exploiting a recognised association to break blinding. I am not sure it can be both of these.\n2023-06-16 comments:\nType of bias that arises in research studies when the process of assigning participants or subjects to different groups or conditions is not random.\nI think I remember my original concern now - in the definition, the problem is not that the sequence is predictable, it is that the sequence is associated with another variable, thus introducing this other variable as a confounder. Unless it is about the investigator being able to break blinding, in which case the concept of the sequence being predictable is important.\n\n2023-07-14 comment: I think non-random methods are those clearly non-random, such as allocation by provider's preferences. However, quasi-random methods are those that apply a method that attempts to be random but that it isn't. Example: day of the week.\n\n2023-07-28 comment: For consistency, should we call it, \"Confounding Bias due to non-randomized allocation\"?"}, {"code": "approval", "valueString": "2023-07-28 vote 5-0 by Brian S. Alper, Paul Whaley, Jesus Lopez-Alcalde, Eric Harvey, Harold Lehmann"}]}], "display": "allocation bias", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Muhammad Afzal, Janice Tufte, Bhagvan Kommadi"}, {"code": "approval", "valueString": "8/8 as of 5/17/2021: Tatyana Shamliyan, Janice Tufte, Mario Tristan, Bhagvan Kommadi, Jes\u00fas L\u00f3pez-Alcalde, Isaac Fwemba, Eric Harvey, Paola Rosati"}, {"code": "negative-vote", "valueString": "2021-05-07 vote 5-1 on \"Comparator Selection Bias = A comparator bias resulting from methods for selection of or allocation to groups for comparative analysis that have the potential to introduce differences (other than in variables directly involved in the analysis) between the groups being compared.\" by KM Saif-Ur-Rahman, Harold Lehmann, Alejandro Piscoya, Paola Rosati, Tatyana Shamliyan, Bhagvan Kommadi, 2021-05-10 vote 11-1 on \"Allocation Bias = A confounding covariate bias resulting from methods for assignment of exposures in an interventional study.\" by Eric Harvey, KM Saif-Ur-Rahman, Janice Tufte, Bhagvan Kommadi, Paola Rosati,  Alejandro Piscoya, Harold Lehmann, Ahmad Sofi-Mahmudi, Eric Au, Jesus Lopez-Alcalde, Tatyana Shamliyan, Joanne Dehnbostel"}, {"code": "expert-comments", "valueString": "A comparator bias resulting from methods for selection of or allocation to groups for comparative analysis that have the potential to introduce differences (other than in variables directly involved in the analysis) between the groups being compared. -- led to--- Selection of comparators would not reduce differences between compared groups.  A confounding covariate bias resulting from methods for assignment of exposures in an interventional study. --led to-- In my opinion, in an interventional study the investigator assigns the intervention, not the exposures.  The differences in the covariates results from the methods for the assignment of the intervention. For example not concealed allocation."}], "definition": "A confounding covariate bias resulting from methods for assignment of the independent variable by the investigator to evaluate a response or outcome."}, {"code": "SEVCO:00033", "display": "comparator selection bias", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Muhammad Afzal, Janice Tufte, Bhagvan Kommadi"}, {"code": "approval", "valueString": "8/8 as of 5/17/2021: Tatyana Shamliyan, Janice Tufte, Mario Tristan, Bhagvan Kommadi, Jes\u00fas L\u00f3pez-Alcalde, Isaac Fwemba, Eric Harvey, Paola Rosati"}, {"code": "comment", "valueString": "This situation is more commonly related to observational research."}], "definition": "A confounding covariate bias resulting from methods used to select participating subjects, or factors that influence study participation, for the comparator group.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "comparison group selection bias"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "comparator group selection bias"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "comparison selection bias"}]}, {"code": "SEVCO:00034", "display": "confounding difference", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Muhammad Afzal, Janice Tufte, Bhagvan Kommadi, Philippe Rocca-Serra"}, {"code": "approval", "valueString": "8/8 as of 6/7/2021: KM Saif-Ur-Rahman, Sebastien Bailly, Bhagvan Kommadi, Leo Orozco, Alejandro Piscoya, Jes\u00fas L\u00f3pez-Alcalde, Janice Tufte, Paola Rosati"}, {"code": "negative-vote", "valueString": "2021-05-07 vote 5-1 on \"Recognized Difference with Potential for Confounding = A comparator bias resulting from known differences (other than in variables directly involved in the analysis) between the groups being compared.\" by KM Saif-Ur-Rahman, Harold Lehmann, Alejandro Piscoya, Paola Rosati, Tatyana Shamliyan, Bhagvan Kommadi, , 2021-05-24 vote 6-1 on \"A confounding covariate bias in which the unequal distribution of a potentially distorting variable is recognized.\" by Harold Lehmann, Eric Harvey, KM Saif-Ur-Rahman, Bhagvan Kommadi, janice tufte, Paola Rosati, Jesus Lopez-Alcalde"}, {"code": "expert-comments", "valueString": "A comparator bias resulting from known differences (other than in variables directly involved in the analysis) between the groups being compared. -- led to-- This defintion seems tricky. If you find any diference between groups that can go astray with analysis you simply address the potention for confounding explicitly in the discussion session of yoru protocol/paper The potnetial for confounding needs to be consideriend in the protocol, and specifically addresssed int eh post-analysis to avoid any further bias. The term comparator bias is misleading since differnece between groups would not be reduced by selecting different comparators.   If this is recognized and adjusted for, is it still a bias? Seems that we need to address this circumstance."}, {"code": "comment", "valueString": "The potentially distorting variable is a covariate, and not the exposure or the outcome. Even if adjusted for in the analysis, a risk of bias can be present."}], "definition": "A confounding covariate bias in which the unequal distribution of a potentially distorting variable is recognized.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "recognized difference with potential for confounding"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "recognized confounding difference"}]}, {"code": "SEVCO:00280", "display": "confounding by time of observation", "definition": "A confounding covariate bias in which the distorting variable is the time at which the outcome is measured or observed.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "confounding by follow-up time"}], "property": [{"code": "comment", "valueString": "A confounding covariate bias is defined as a situation in which the effect or association between an exposure and outcome is distorted by another variable. For confounding covariate bias to occur the distorting variable must be (1) associated with the exposure and the outcome, (2) not in the causal pathway between exposure and outcome, and (3) unequally distributed between the groups being compared.\n\nThe time at which the outcome is measured or observed may be absolute (e.g. a specific date) or relative (e.g. 3 months after study enrollment).\n\nTo understand \"confounding by time of observation\" consider the following example:\n\nAn observational study is comparing patients with asthma taking Superdrug and patients with asthma not taking Superdrug.  The outcome of interest is mortality. The patients taking Superdrug are observed for their full duration of exposure to Superdrug. For comparison, the control group not receiving Superdrug is measured during a 1-year calendar period.\n\nFor the mortality outcome comparing Superdrug vs. no Superdrug, the time of observation for the control group is consistently 1 year but for the Superdrug group the time of observation varies for each patient. This comparison is confounded by the time of observation."}, {"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Muhammad Afzal, Kenneth Wilkins, Paul Whaley"}, {"code": "negative-vote", "valueString": "2023-06-09 vote 3-1 by Eric Harvey, Cau\u00ea Monaco, Paul Whaley, Sunu Alice Cherian\n2023-06-16 vote 4-1 by Paola Rosati, Eric Harvey, Paul Whaley, Sunu Alice Cherian, Harold Lehmann\n2023-07-14 vote 7-0 by Muhammad Afzal, Joanne Dehnbostel, Khalid Shahin, Jesus Lopez-Alcalde, Paul Whaley, Harold Lehmann, Cau\u00ea Monaco\nTHEN REOPENED\n2023-08-04 due to comment that suggests removing parenthetical from definition"}, {"code": "expert-comments", "valueString": "2023-06-09 comment: The comment for application is not sufficiently informative. I am also not sure I understand what the definition means - what is the importance of recognition of unequal distribution of follow-up time?\n2023-06-16 comments: A confounding that occurs when the relationship between an exposure or intervention and an outcome is confounded by the time at which the outcome is measured or observed. \nAlternate terms: time-varying confounding\nComment for application: This occurs when both the exposure and the outcome change over time, and there are other time-dependent factors that influence the outcome\n\nThe Comment for Application seems to be repeating the definition of the parent term. I though we usually add details specific to the current term."}, {"code": "approval", "valueString": "2023-10-06 vote 5-0 by Jesus Lopez-Alcalde, Eric Harvey, Paul Whaley, Harold Lehmann, Mario Tristan"}]}, {"code": "SEVCO:00281", "display": "lead time bias", "definition": "A confounding covariate bias in which the distorting variable is the length of time that the participant has had the condition of interest at study enrollment.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "starting time bias"}], "property": [{"code": "comment", "valueString": "A Confounding Covariate Bias is defined as a situation in which the effect or association between an exposure or outcome is distorted by another variable. For confounding covariate bias to occur the distorting variable must be (1) associated with the exposure and the outcome, (2) not in the causal pathway between exposure and outcome, and (3) unequally distributed between the groups being compared.\n\nA lead time bias is often manifest as a distortion overestimating the apparent time surviving with a disease caused by bringing forward the time of its diagnosis (https://catalogofbias.org/biases/lead-time-bias/).\n\nLead time bias is a type of bias that occurs in medical screening or diagnostic tests when the early detection of a disease or condition artificially appears to improve survival or prognosis, even if it does not actually provide a true benefit in terms of overall health outcomes.\n\nLead time refers to the amount of time between the detection of a disease through early screening or diagnostic testing and the time when the disease would have been clinically detected without screening."}, {"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Muhammad Afzal, Paul Whaley"}, {"code": "external-definitions", "valueString": "Lead time bias\nA distortion overestimating the apparent time surviving with a disease caused by bringing forward the time of its diagnosis\nhttps://catalogofbias.org/biases/lead-time-bias/"}, {"code": "negative-vote", "valueString": "2023-06-09 vote 3-1 by Eric Harvey, Cau\u00ea Monaco, Paul Whaley, Sunu Alice Cherian\n2023-06-16 vote 3-2 by Eric Harvey, Paul Whaley, Sunu Alice Cherian, Harold Lehmann, Paola Rosati\n2023-07-14 vote 6-0 by Muhammad Afzal, Joanne Dehnbostel, Jesus Lopez-Alcalde, Paul Whaley, Harold Lehmann, Cau\u00ea Monaco\nTHEN REOPENED\n2023-08-04 due to comment that suggests removing parenthetical from definition"}, {"code": "expert-comments", "valueString": "2023-06-09 comment: I am not sure I can successfully parse the syntax of the definition. While I think I understand what is meant, I feel it could be phrased more clearly.\n2023-06-16 comments: Lead time bias is a type of bias that occurs in medical screening or diagnostic tests when the early detection of a disease or condition artificially appears to improve survival or prognosis, even if it does not actually provide a true benefit in terms of overall health outcomes\n\nComment for application: Lead time refers to the amount of time between the detection of a disease through early screening or diagnostic testing and the time when the disease would have been clinically detected without screening. \n\nThis definition seems difficult to understand: does it convey that lead time bias is related to the potentially distorting variable of the length of time chosen in the study in which some participants could have confounding differences between their diagnosis of the condition of interest and the time of enrolment?\nI have some problem in understanding, sorry."}, {"code": "approval", "valueString": "2023-08-18 vote 5-0 by Paul Whaley,  Eric Harvey, Mario Tristan, Cau\u00ea Monaco, Harold Lehmann"}]}, {"code": "SEVCO:00282", "display": "confounding influencing adherence to intervention", "definition": "A confounding covariate bias in which the distorting variable is associated with deviations from the intended intervention.", "property": [{"code": "comment", "valueString": "A confounding covariate bias is defined as a situation in which the effect or association between an exposure or outcome is distorted by another variable. For confounding covariate bias to occur the distorting variable must be (1) associated with the exposure and the outcome, (2) not in the causal pathway between exposure and outcome, and (3) unequally distributed between the groups being compared.\n\nFor 'Confounding influencing adherence to intervention', the association of the distorting variable and the exposure is specific to deviations from the intended exposure (intended intervention). Deviations from the intended intervention may include deviations from the intervention protocol or lack of adherence. Lack of adherence includes imperfect compliance, cessation of intervention, crossovers to the comparator intervention and switches to another active intervention.\n\nThe term 'Confounding influencing adherence to intervention' is distinct from 'Performance Bias' (including 'Nonadherence of participants' or 'Imbalance in deviations from intended interventions') in that an additional variable (the distorting variable or confounding covariate) is acting as a confounder, while the 'Performance Bias' may occur with or without any differences in a third variable."}, {"code": "external-definitions", "valueString": "trigger question from ROBINS-I: 1.3. Were intervention discontinuations or switches likely to be related to factors that are prognostic for the outcome?"}, {"code": "expert-comments", "valueString": "2023-06-02 comment from steering group: need to see the background to ROBINS-I to understand context for this term\n2023-07-28 comment: I think the definition is good but the comment for application should specifically address this term and not just duplicate the definition of confounding covariate bias.\n2023-08-11 comment: Is this the same as compliance bias, or compliance bias  (\"https://catalogofbias.org/biases/compliance-bias/\") is a subtype of this? If \"compliance bias\" is a synonim, should be added as such. If not, should be added as a separate term"}, {"code": "editors", "valueString": "Brian Alper, Joanne Dehnbostel, Harold Lehmann, Paul Whaley, Kenneth Wilkins"}, {"code": "negative-vote", "valueString": "2023-07-28 vote 3-1 by Eric Harvey, Harold Lehmann, Jesus Lopez-Alcalde, Paul Whaley\n2023-08-04 vote 5-0 by Joanne Dehnbostel, Philippe Rocca-Serra, Eric Harvey, Harold Lehmann, Mario Tristan BUT comment suggests removing parenthetical from definition\n2023-08-11 vote 3-1 by Mario Tristan, Cau\u00ea Monaco, Eric Harvey, Joanne Dehnbostel"}, {"code": "approval", "valueString": "2023-09-29 vote 5-0 by Joanne Dehnbostel, Harold Lehmann, Paul Whaley, Eric Harvey, Mario Tristan"}]}, {"code": "SEVCO:00284", "display": "confounding by indication", "definition": "A confounding covariate bias in which the distorting variable is the reason for receiving an exposure.", "property": [{"code": "external-definitions", "valueString": "Confounding by indication\nA distortion that modifies an association between an exposure and an outcome, caused by the presence of an indication for the exposure that is the true cause of the outcome.\nfrom https://catalogofbias.org/biases/confounding-by-indication/"}, {"code": "comment", "valueString": "A Confounding Covariate Bias is defined as a situation in which the effect or association between an exposure or outcome is distorted by another variable. For confounding covariate bias to occur the distorting variable must be (1) associated with the exposure and the outcome, (2) not in the causal pathway between exposure and outcome, and (3) unequally distributed between the groups being compared.\n\nThe term 'indication' is derived from the medical community, in which the reason that an intervention is provided is called the indication. A reason for not providing an intervention may be called a 'contraindication' rather than 'indication to not provide'.\n\nFor example, people exposed to chemotherapy have higher mortality. This observation can easily be confounded by people exposed to chemotherapy having a higher rate of cancer (as the reason for receiving the chemotherapy)."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Kenneth Wilkins, Muhammad Afzal"}, {"code": "approval", "valueString": "2023-08-18 vote 5-0 by Paul Whaley,  Eric Harvey, Mario Tristan, Cau\u00ea Monaco, Joanne Dehnbostel"}, {"code": "negative-vote", "valueString": "2023-05-12 vote 5-0 by Muhammad Afzal, Brian S. Alper, Joanne Dehnbostel, Jesus Lopez-Alcalde, Harold Lehmann \nBUT THEN TERM CHANGED WITH HIERARCHY CHANGE on 2023-06-30\n2023-07-14 vote 2-1 by Jesus Lopez-Alcalde, Paul Whaley, Harold Lehmann\n2023-07-28 vote 3-1 by Paul Whaley, Jesus Lopez-Alcalde, Eric Harvey, Harold Lehmann\n2023-08-04 vote 5-0 by Joanne Dehnbostel, Philippe Rocca-Serra, Eric Harvey, Harold Lehmann, Mario Tristan BUT comment suggests removing parenthetical from definition"}, {"code": "expert-comments", "valueString": "2023-05-12 comment: For Comment for Application, I thought we usually put the definition of the parent term first, and the comments about this child. So I would arrange the current 1, 2, 3 paragraphs as 2, 1, 3.\n\nAnd I think what is now the first paragraph should start with, \"A confounding different bias...\"\n2023-07-01 comment: I would add to the definition \"or lack of\". Thus: \"A confounding covariate bias in which the confounder (distorting variable) is the reason for (or for lack of) an intended exposure.\n\n2023-07-14 comment: I think the definition is good but the comment for application should specifically address this term in more detail than providing a definition for \"indication\". It is a complex concept and I am not sure I understand what is happening with this bias.\n\n2023-07-28 comment: I still feel that an example of how the reason for receiving an exposure can end up being a confounder would be helpful."}]}, {"code": "SEVCO:00388", "display": "confounding by contraindication", "definition": "A confounding covariate bias in which the distorting variable is the reason for not receiving an exposure.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Kenneth Wilkins, Caue Monaco"}, {"code": "comment", "valueString": "A Confounding Covariate Bias is defined as a situation in which the effect or association between an exposure or outcome is distorted by another variable. For confounding covariate bias to occur the distorting variable must be (1) associated with the exposure and the outcome, (2) not in the causal pathway between exposure and outcome, and (3) unequally distributed between the groups being compared.\n\nThe term 'indication' is derived from the medical community, in which the reason that an intervention is provided is called the indication. A reason for not providing an intervention may be called a 'contraindication' rather than 'indication to not provide'.\n\nFor example, people with cancer exposed to surgery for curative resection have lower mortality than other people with cancer. This observation can easily be confounded by people exposed to surgery for curative resection having a lower rate of metastatic cancer (which is a contraindication to such a surgery)."}, {"code": "negative-vote", "valueString": "2023-07-28 vote 3-1 by Paul Whaley, Jesus Lopez-Alcalde, Eric Harvey, Harold Lehmann\n2023-08-04 vote 5-0 by Joanne Dehnbostel, Philippe Rocca-Serra, Eric Harvey, Harold Lehmann, Mario Tristan BUT comment suggests removing parenthetical from definition"}, {"code": "expert-comments", "valueString": "2023-07-28 comment: I still feel that an example of how the reason for receiving an exposure can end up being a confounder would be helpful."}, {"code": "approval", "valueString": "2023-08-18 vote 5-0 by Paul Whaley,  Eric Harvey, Mario Tristan, Cau\u00ea Monaco, Joanne Dehnbostel"}]}, {"code": "SEVCO:00390", "display": "time-varying confounding affected by past exposure", "definition": "A confounding covariate bias in which the distorting variable is itself influenced by the exposure.", "property": [{"code": "comment", "valueString": "Confounding Covariate Bias is defined as a situation in which the effect or association between an exposure and outcome is distorted by another variable. For confounding covariate bias to occur the distorting variable must be (1) associated with the exposure and the outcome, (2) not in the causal pathway between exposure and outcome, and (3) unequally distributed between the groups being compared.\n\nTo distinguish \"confounding by time of observation\" from \"time-varying confounding affected by past exposure\" consider the following example:\n\nAn observational study is comparing patients with asthma taking Superdrug and patients with asthma not taking Superdrug.  The outcome of interest is mortality, both for association with the dose of Superdrug and compared to not receiving Superdrug. For comparison, the control group not receiving Superdrug is measured during a 1-year calendar period.\n\nFor the mortality outcome comparing Superdrug vs. no Superdrug, the time of observation for the control group is consistently 1 year but for the Superdrug group the time of observation varies for each patient. This comparison is confounded by the time of observation.\n\nFor the mortality outcome comparing high-dose vs. low-dose Superdrug, the confounding variable of asthma exacerbation rate is complicated in several ways. First, the asthma exacerbation rate is associated with the outcome (mortality) independent from the effects of Superdrug. Second, the asthma exacerbation rate may influence the exposure (the dose of Superdrug which is increased if frequent asthma exacerbations) and the exposure (higher dose of Superdrug) may influence the confounder (reducing the asthma exacerbation rate). This comparison of high-dose vs. low-dose Superdrug for effects on mortality is distorted by time-varying confounding affected by past exposure."}, {"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Kenneth Wilkins, Harold Lehmann, Caue Monaco"}, {"code": "expert-comments", "valueString": "2023-09-01 comment (with No vote): This term seems unnecessary. Describes a bias rarely seen."}, {"code": "approval", "valueString": "2023-10-06 vote 5-0 by Jesus Lopez-Alcalde, Eric Harvey, Paul Whaley, Harold Lehmann, Mario Tristan"}]}]}, {"code": "SEVCO:00017", "concept": [{"code": "SEVCO:00035", "display": "inadequate blinding of participants", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Muhammad Afzal, Janice Tufte, Erfan Shamsoddin, Bhagvan Kommadi, Philippe Rocca-Serra"}, {"code": "approval", "valueString": "8/8 as of 6/14/2021: Eric Harvey, Eric Au, Bhagvan Kommadi, Ahmad Sofi-Mahmudi, Erfan Shamsoddin, Janice Tufte, Joanne Dehnbostel, Leo Orozco,"}, {"code": "negative-vote", "valueString": "2021-06-07 vote 7-1 on \"Inadequate blinding of participants  = A performance bias due to awareness of the allocated intervention by participants\" by KM Saif-Ur-Rahman, Sebastien Bailly, Bhagvan Kommadi, Leo Orozco, Alejandro Piscoya, Jes\u00fas L\u00f3pez-Alcalde, Janice Tufte, Paola Rosati, 2021-06-11 vote 9-1 on same"}, {"code": "expert-comments", "valueString": "Need to distinguish blinding of intervention from blinding of allocation Inadequate blinding of participants does not always imply bias. Besides, it can also imply detection bias in patient reported outcomes"}, {"code": "comment", "valueString": "Inadequate blinding of participants is applied when there is awareness of assigned intervention AFTER intervention assignment. If there is awareness BEFORE study enrolment and intervention assignment, this would be Inadequate allocation concealment.\nThe term \"Inadequate blinding of participants\" is used to denote the TYPE of bias. Separate terms for the RATING of risk of bias are used to report the likelihood of the presence and influence of the type of bias."}], "definition": "A performance bias due to awareness of the allocated intervention by participants", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "inadequate masking of participants"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "lack of blinding of participants"}]}, {"code": "SEVCO:00036", "display": "inadequate blinding of intervention deliverers", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Muhammad Afzal, Janice Tufte, Erfan Shamsoddin, Bhagvan Kommadi, Philippe Rocca-Serra"}, {"code": "approval", "valueString": "8/8 as of 6/14/2021: Eric Harvey, Eric Au, Bhagvan Kommadi, Ahmad Sofi-Mahmudi, Erfan Shamsoddin, Janice Tufte, Joanne Dehnbostel, Leo Orozco,"}, {"code": "negative-vote", "valueString": "2021-06-07 vote 7-1 on \"Inadequate blinding of participants  = A performance bias due to awareness of the allocated intervention by individuals providing or delivering the intervention\" by KM Saif-Ur-Rahman, Sebastien Bailly, Bhagvan Kommadi, Leo Orozco, Alejandro Piscoya, Jes\u00fas L\u00f3pez-Alcalde, Janice Tufte, Paola Rosati, 2021-06-11 vote 9-1 on same"}, {"code": "expert-comments", "valueString": "Need to distinguish blinding of intervention from blinding of allocation; Should we use the term interventionalist or interventionist? Inadequate blinding of intervention deliverers does not always imply Performance bias"}, {"code": "comment", "valueString": "Inadequate blinding of intervention deliverers is applied when there is awareness of assigned intervention AFTER intervention assignment. If there is awareness BEFORE study enrolment and intervention assignment, this would be Inadequate allocation concealment.\nThe term noted here is used to denote the TYPE of bias. Separate terms for the RATING of risk of bias are used to report the likelihood of the presence and influence of the type of bias."}], "definition": "A performance bias due to awareness of the allocated intervention by individuals providing or delivering the intervention", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "inadequate masking of intervention deliverers"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "lack of blinding of intervention deliverers"}]}, {"code": "SEVCO:00037", "display": "deviation from study intervention protocol", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Muhammad Afzal, Janice Tufte, Erfan Shamsoddin, Bhagvan Kommadi"}, {"code": "approval", "valueString": "8/8 as of 6/7/2021: KM Saif-Ur-Rahman, Sebastien Bailly, Bhagvan Kommadi, Leo Orozco, Alejandro Piscoya, Jes\u00fas L\u00f3pez-Alcalde, Janice Tufte, Paola Rosati"}], "definition": "A performance bias in which the intervention received differs from the intervention specified in the study protocol"}, {"code": "SEVCO:00038", "display": "deviation from standard of care", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Muhammad Afzal, Janice Tufte, Erfan Shamsoddin, Bhagvan Kommadi"}, {"code": "approval", "valueString": "8/8 as of 6/7/2021: KM Saif-Ur-Rahman, Sebastien Bailly, Bhagvan Kommadi, Leo Orozco, Alejandro Piscoya, Jes\u00fas L\u00f3pez-Alcalde, Janice Tufte, Paola Rosati"}], "definition": "A performance bias in which the intervention or exposure received differs from the from the usual practice or expected care"}, {"code": "SEVCO:00039", "display": "nonadherence of implementation", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Muhammad Afzal, Janice Tufte, Erfan Shamsoddin, Bhagvan Kommadi"}, {"code": "approval", "valueString": "8/8 as of 6/7/2021: KM Saif-Ur-Rahman, Sebastien Bailly, Bhagvan Kommadi, Leo Orozco, Alejandro Piscoya, Jes\u00fas L\u00f3pez-Alcalde, Janice Tufte, Paola Rosati"}, {"code": "expert-comments", "valueString": "interventionist vs. intervention deliverer"}], "definition": "A performance bias in which the intervention deliverers do not completely adhere to the expected intervention", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "nonadherence of interventionalist"}]}, {"code": "SEVCO:00040", "display": "nonadherence of participants", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Muhammad Afzal, Janice Tufte, Erfan Shamsoddin, Bhagvan Kommadi"}, {"code": "approval", "valueString": "8/8 as of 6/7/2021: KM Saif-Ur-Rahman, Sebastien Bailly, Bhagvan Kommadi, Leo Orozco, Alejandro Piscoya, Jes\u00fas L\u00f3pez-Alcalde, Janice Tufte, Paola Rosati"}, {"code": "expert-comments", "valueString": "is known or unknown"}], "definition": "A performance bias in which the participants do not completely adhere to the expected intervention or exposure"}, {"code": "SEVCO:00041", "display": "imbalance in deviations from intended intervention", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Muhammad Afzal, Janice Tufte, Erfan Shamsoddin, Bhagvan Kommadi"}, {"code": "approval", "valueString": "8/8 as of 6/7/2021: KM Saif-Ur-Rahman, Sebastien Bailly, Bhagvan Kommadi, Leo Orozco, Alejandro Piscoya, Jes\u00fas L\u00f3pez-Alcalde, Janice Tufte, Paola Rosati"}], "definition": "A performance bias in which the degree of performance bias is unequally distributed between groups being compared", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "asymmetry in adherence between groups"}]}], "display": "performance bias", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Muhammad Afzal, Janice Tufte, Bhagvan Kommadi, Philippe Rocca-Serra"}, {"code": "approval", "valueString": "8/8 as of 6/7/2021: KM Saif-Ur-Rahman, Sebastien Bailly, Bhagvan Kommadi, Leo Orozco, Alejandro Piscoya, Jes\u00fas L\u00f3pez-Alcalde, Janice Tufte, Paola Rosati"}, {"code": "negative-vote", "valueString": "2021-05-24 vote 5-2 on \"A bias resulting from differences between the received exposure and the intended exposure. Such differences could be the administration of additional interventions that are inconsistent with the study protocol, or non-adherence by the interventionalists or study participants to their assigned intervention. \" by Harold Lehmann, Eric Harvey, KM Saif-Ur-Rahman, Bhagvan Kommadi, janice tufte, Paola Rosati, Jesus Lopez-Alcalde"}, {"code": "expert-comments", "valueString": "Definition of performance bias should be modified, Performance bias should involve the blinding at participant level and implementer level in definition.I would add that the differences must be present between the study arms In a RCT with an active control (for example drug A vs drug B) both study arms may have had low adherence but if these deviations from the protocol occurred homogeneously accross arms the effect estimate may not be distorted (biased). As a reviewer, I would not penalise this estimate due to high risk of performance bias. So, concerning the definition, I would propose \"A bias resulting from differences accross the study arms between the [...]\""}, {"code": "comment", "valueString": "Such differences could be the administration of additional interventions that are inconsistent with the study protocol, or non-adherence by the interventionalists or study participants to their assigned intervention. Such differences may occur based on assignment to intervention or may occur due to adherence to intervention."}], "definition": "A bias resulting from differences between the received exposure and the intended exposure.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "study exposure adherence bias"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "intervention adherence bias"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "compliance bias"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "performance adherence bias"}]}, {"code": "SEVCO:00019", "display": "attrition bias", "property": [{"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Joanne Dehnbostel, Philippe Rocca-Serra, Mario Tristan, Janice Tufte, Erfan Shamsoddin"}, {"code": "approval", "valueString": "13/13 as of 6/18/2021: Eric Au, Harold Lehmann, Erfan Shamsoddin, Ahmad Sofi-Mahmudi, Mario Tristan, Eric Harvey, Sebastien Bailly, Bhagvan Kommadi, Leo Orozco, Alejandro Piscoya, Jes\u00fas L\u00f3pez-Alcalde, Janice Tufte, Paola Rosati"}, {"code": "negative-vote", "valueString": "6/14/2021-06-14 vote 7-1 on \"Attrition Bias = A bias due to absence of expected participation or data collection after study enrollment.\" by, Eric Harvey, Eric Au, Bhagvan Kommadi, Ahmad Sofi-Mahmudi, Erfan Shamsoddin, Janice Tufte, Joanne Dehnbostel, Leo Orozco,"}, {"code": "expert-comments", "valueString": "The phrase \"after study enrolment\" might be confusing. Does enrolment apply to retrospective observational studies?"}], "definition": "A bias due to absence of expected participation or data collection after selection for study inclusion.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "missing data bias"}], "concept": [{"code": "SEVCO:00286", "display": "attrition bias due to participant attrition", "definition": "A bias due to absence of expected participation due to participant dropout, withdrawal or non-participation after selection for study inclusion.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Joanne Dehnbostel"}, {"code": "expert-comments", "valueString": "2023-04-28 comment: I would not detail that 20%: it is misleading and not evidence-based"}, {"code": "approval", "valueString": "2023-05-12 vote 6-0 by Muhammad Afzal, Brian S. Alper, Joanne Dehnbostel , Harold Lehmann, Jesus Lopez-Alcalde, Eric Harvey"}]}, {"code": "SEVCO:00287", "display": "attrition bias due to missing data", "definition": "A bias due to data loss or absence of data collection from participants after selection for study inclusion.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Joanne Dehnbostel"}, {"code": "expert-comments", "valueString": "2023-04-28 comment: I would not detail that 20%: it is misleading and not evidence-based"}, {"code": "approval", "valueString": "2023-05-12 vote 6-0 by Muhammad Afzal, Brian S. Alper, Joanne Dehnbostel , Harold Lehmann, Jesus Lopez-Alcalde, Eric Harvey"}], "concept": [{"code": "SEVCO:00386", "display": "attrition bias due to missing outcome data", "definition": "An attrition bias due to missing data specific to the dependent variable.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Joanne Dehnbostel, Muhammad Afzal, Khalid Shahin"}, {"code": "negative-vote", "valueString": "2023-05-19 5-1 Muhammad Afzal, Janice Tufte, Jesus Lopez-Alcalde, Eric Harvey, Harold Lehmann, Joanne Dehnbostel\n2023-06-09 vote 3-1 by Eric Harvey, Cau\u00ea Monaco, Paul Whaley, Harold Lehmann"}, {"code": "expert-comments", "valueString": "The information in the parentheses, \"(or data on an independent variable),\" is unclear in its intended meaning. To improve clarity, we could revise the definition.\n2023-06-09 comment: The definition is too difficult to parse, and probably too similar to the preferred term. The comment for application is also very difficult to read."}, {"code": "comment", "valueString": "In a situation of repeated measures outcomes, attrition bias due to missing outcome data can occur if one or more measurements are missing."}, {"code": "approval", "valueString": "2023-06-16 vote 5-0 by Joanne Dehnbostel, Eric Harvey, Paul Whaley, Sunu Alice Cherian, Harold Lehmann"}]}, {"code": "SEVCO:00288", "display": "attrition bias due to missing exposure data", "definition": "An attrition bias due to missing data specific to the independent variable(s) of primary interest, such as exposure or intervention.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "attrition bias due to missing intervention data"}], "property": [{"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Joanne Dehnbostel, Muhammad Afzal, Khalid Shahin, Paul Whaley"}, {"code": "negative-vote", "valueString": "2023-05-19 5-1 Muhammad Afzal, Janice Tufte, Jesus Lopez-Alcalde, Eric Harvey, Harold Lehmann, Joanne Dehnbostel"}, {"code": "expert-comments", "valueString": "The information in the parentheses, \"(or data on an independent variable),\" is unclear in its intended meaning. To improve clarity, we could revise the definition.\n2023-06-09 comment: This needs a comment for application, but the definition is clearer than for \"attrition bias due to missing outcome data\"."}, {"code": "approval", "valueString": "2023-06-09 vote 6-0 by Cau\u00ea Monaco, Eric Harvey, Paul Whaley, Harold Lehmann, Jesus Lopez-Alcalde, Sunu Alice Cherian"}, {"code": "comment", "valueString": "If coding a bias related to the classification of exposure, misclassification of exposure may be coded as Exposure Detection Bias, but if the data is excluded from analysis it may then be coded as Attrition bias due to missing exposure data."}]}, {"code": "SEVCO:00289", "display": "attrition bias due to missing modifier data", "definition": "An attrition bias due to missing data specific to a confounder or effect modifier", "property": [{"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Joanne Dehnbostel, Muhammad Afzal, Khalid Shahin"}, {"code": "comment", "valueString": "The term modifier is intended to be broad, including variables used for modeling interactions, stratification factors to account for effect modification, or other variables such as mediators that need to be accounted for when modeling the relationship between the outcome and exposure."}, {"code": "approval", "valueString": "2023-05-12 vote 5-0 by Joanne Dehnbostel, Janice Tufte, Harold Lehmann, Jesus Lopez-Alcalde, Eric Harvey"}]}, {"code": "SEVCO:00387", "display": "attrition bias due to missing data about attrition", "definition": "An attrition bias due to missing data specific to the extent of or reasons for missing data.", "property": [{"code": "comment", "valueString": "Attrition bias due to missing data is defined as a bias due to data loss or absence of data collection from participants after selection for study inclusion. Data about the amount of missing data and data about the reasons for missing data are types of data that can also be missing. For example, in a time-to-event study, the reason a participant is censored might be missing and missing such data may interfere with distinguishing informative from non-informative censoring."}, {"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Joanne Dehnbostel"}, {"code": "approval", "valueString": "2023-06-16 vote 5-0 by Joanne Dehnbostel, Eric Harvey, Paul Whaley, Sunu Alice Cherian, Harold Lehmann"}, {"code": "expert-comments", "valueString": "2023-06-16 comments: Time-to-event should be hyphenated\nFunnily enough, this came up straight after our call in relation to another bias project I am working on, so I would consider this addition useful!"}]}]}, {"code": "SEVCO:00290", "display": "imbalance in missing data", "definition": "An attrition bias in which the degree of missing data is unequally distributed between groups being compared.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Joanne Dehnbostel"}, {"code": "approval", "valueString": "2023-05-12 vote 5-0 by Joanne Dehnbostel, Janice Tufte, Harold Lehmann, Jesus Lopez-Alcalde, Eric Harvey"}]}, {"code": "SEVCO:00291", "display": "inadequate response rate", "definition": "An attrition bias in which the reason for absence of data collection is a low response rate to data collection surveys.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Joanne Dehnbostel"}, {"code": "approval", "valueString": "2023-05-12 vote 5-0 by Joanne Dehnbostel, Janice Tufte, Harold Lehmann, Jesus Lopez-Alcalde, Eric Harvey"}]}]}, {"code": "SEVCO:00020", "display": "detection bias", "definition": "A bias due to distortions in any process involved in the determination of the recorded values for a variable.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Joanne Dehnbostel, Philippe Rocca-Serra, Mario Tristan, Harold Lehmann, Janice Tufte, Muhammad Afzal; Paul Whaley"}, {"code": "negative-vote", "valueString": "6/14/2021-06-14 vote 7-1 on \"Detection Bias = A bias due to distortions in how variable values (data) are determined (measured, classified or ascertained).\" by, Eric Harvey, Eric Au, Bhagvan Kommadi, Ahmad Sofi-Mahmudi, Erfan Shamsoddin, Janice Tufte, Joanne Dehnbostel, Leo Orozco\n\nAGREEMENT REACHED 10/10 as of 8/27/2021: Eric Au, Eric Harvey, Harold Lehmann, Alejandro Piscoya, Mario Tristan, Bhagvan Kommadi, Leo Orozco, Janice Tufte, Jes\u00fas L\u00f3pez-Alcalde, Brian S. Alper --- for DEFINITION OF: A bias due to distortions in how variable values (data) are determined.  COMMENT FOR APPLICATION: Determination may include ascertainment or assessment (classification or measurement).\n\n2022-10-14 vote 3-1 by Harold Lehmann, Robin Ann Yurk, Janice Tufte, Paul Harris\n\n2022-01-21 vote 6-1 by Harold Lehmann, Robin Ann Yurk, Janice Tufte, Paul Harris, Paul Whaley, Alejandro Piscoya, Philippe Rocca-Serra"}, {"code": "expert-comments", "valueString": "We need to state that this bias relates to the \"outcome\" -- The ROB-1 says the term \"outcome assessment\" as an alternative for detection bias. The ROBINS-1 says that \"Non-differential misclassification is unrelated to the outcome and will usually bias the estimated effect of intervention towards the null\". Still though, this leads to inadvertent deviations in the outcome assessment. I would suggest to at least state that this bias relates to outcome assessment. I remember Joanne saying that we will add a few \"child concepts\" later on and if that is the case here, then it is fine. Nevertheless, the RoB2 suggests not to use these terms to prevent \"confusion\" and does not actually agree with these sub-classifications (the fist page of the introduction section). Alternative terms according to (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5130591/): \"Observer Bias\", \"Ascertainment Bias\", or \"Assessment Bias\"  8/27/21 comment: Detection bias is no included in the list the more problematic Cochrane ROB1 however (J\u00f8rgensen et al. Systematic Reviews (2016) describe alll the domains of ROB1 \"frequently implemented in a non-recommended way\" The description in general is clear.\n\n2022-10-14 comments: Do we need \"Outcome Detection Bias\" in addition to \"Detection Bias\"?\nBlinding or masking may be used to reduce the risk of distorted outcome measurement(s).\n\n2022-01-21 comment: I am not sure whether to vote yes or no: I understand the definition because I have been following our discussions and it is consistent with the bias model we have developed, but I worry that this definition may not be consistently understood or applied by a user of SEVCO - I feel there is too much unspoken metaphysical baggage that is coherent and correct but not useful.\n\n2022-01-28 comment: Not perfect but good enough to live with. Could maybe improve on ascertainment component of the comment for application."}, {"code": "comment", "valueString": "Detection of the value of the variable comprises three processes involved in the determination of the recorded values for the variable: ascertainment (providing the opportunity for assessment), assessment (measurement and/or classification), and documentation (recording of data values for analysis)."}, {"code": "approval", "valueString": "2022-01-28 vote 9-0 by Mario Tristan, Janice Tufte, Robin Ann Yurk, Brian S. Alper, C P Ooi, Harold Lehmann,  Paola Rosati, Jesus Lopez-Alcalde, Paul Whaley"}], "concept": [{"code": "SEVCO:00042", "concept": [{"code": "SEVCO:00047", "concept": [{"code": "SEVCO:00048", "display": "bias due to lack of masking for outcome determination", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Muhammad Afzal, Janice Tufte, Joanne Dehnbostel, Paul Whaley, Kenneth Wilkins"}, {"code": "negative-vote", "valueString": "8/27/2021 vote 9-1 on \"Lack of blinding during outcome assessment = A cognitive interpretive bias for outcome determination due to the outcome assessor\u2019s awareness of the participant's status with respect to the exposure of interest.\" by, Eric Au, Eric Harvey, Harold Lehmann, Alejandro Piscoya, Mario Tristan, Bhagvan Kommadi, Leo Orozco, Janice Tufte, Jes\u00fas L\u00f3pez-Alcalde, Brian S. Alper\nearlier term approved 5/5 as of 8/30/2021: Eric Harvey, Harold Lehmann, Mario Tristan, Bhagvan Kommadi, Janice Tufte"}, {"code": "expert-comments", "valueString": "2021-08-27 comment: In my opinion \"lack of blinding during outcome assessment\" does not always imply bias for outcome determination (for example, for hard outcomes, such as analytic parameters, or all-cause mortality)\n2022-03-18 comment: I would consider editing the term definition to ...lack of blinding."}, {"code": "comment", "valueString": "Lack of blinding or masking is not automatically a bias, but if awareness of exposure status systematically distorts the outcome determination then a 'Bias due to lack of masking for outcome determination' exists."}, {"code": "approval", "valueString": "2022-03-18 vote 5-0 by Mario Tristan, Robin Ann Yurk, Paola Rosati, Nisha Mathew, Brian S. Alper"}], "definition": "A cognitive interpretive bias for outcome determination due to awareness of the participant's status with respect to the exposure of interest.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "bias due to lack of blinding during outcome assessment"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "bias due to lack of masking during outcome assessment"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "awareness bias for outcome determination"}]}, {"code": "SEVCO:00049", "concept": [{"code": "SEVCO:00052", "display": "confirmation bias for outcome determination", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Muhammad Afzal, Janice Tufte, Joanne Dehnbostel, Kenneth Wilkins, Mario Tristan"}, {"code": "approval", "valueString": "5/5 as of 9/17/2021: Eric Harvey, Paola Rosati, Alejandro Piscoya, Bhagvan Kommadi, Janice Tufte,"}], "definition": "An observer bias for outcome determination due to previous opinions or knowledge of a subject\u2019s prior exposures or assessments.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "diagnostic suspicion bias for outcome determination"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "previous opinion bias for outcome determination"}]}], "display": "observer bias for outcome determination", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Muhammad Afzal, Janice Tufte, Joanne Dehnbostel"}, {"code": "approval", "valueString": "5/5 as of 8/30/2021: Eric Harvey, Harold Lehmann, Mario Tristan, Bhagvan Kommadi, Janice Tufte,"}, {"code": "negative-vote", "valueString": "8/27/2021 vote 9-1 on \"Observer bias for outcome determination = A cognitive interpretive bias for outcome determination due to subjective interpretations in the process of observing and recording information.\" by, Eric Au, Eric Harvey, Harold Lehmann, Alejandro Piscoya, Mario Tristan, Bhagvan Kommadi, Leo Orozco, Janice Tufte, Jes\u00fas L\u00f3pez-Alcalde, Brian S. Alper"}, {"code": "expert-comments", "valueString": "2021-08-27 comment: This situation seems to be covered by \"Lack of blinding for outcome determination\" and \"Outcome ascertainment bias\". I would suggest deleting this term to remove the overlap."}, {"code": "comment", "valueString": "Multiple types of bias can overlap. Observer bias is different than lack of blinding with respect to the exposure. Observer bias is about the influence of the observer's interpretation of what they are observing, whether or not the observer is aware of the participant's exposure."}], "definition": "A cognitive interpretive bias for outcome determination due to subjective interpretations in the process of observing and recording information."}, {"code": "SEVCO:00050", "display": "recall bias for outcome determination", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Muhammad Afzal, Janice Tufte, Joanne Dehnbostel"}, {"code": "approval", "valueString": "10/10 as of 8/27/2021: Eric Au, Eric Harvey, Harold Lehmann, Alejandro Piscoya, Mario Tristan, Bhagvan Kommadi, Leo Orozco, Janice Tufte, Jes\u00fas L\u00f3pez-Alcalde, Brian S. Alper"}], "definition": "A cognitive interpretive bias for outcome determination due to differences in accuracy or completeness of recall of past events or experiences."}, {"code": "SEVCO:00051", "display": "apprehension bias for outcome determination", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Muhammad Afzal, Janice Tufte, Joanne Dehnbostel, Mario Tristan"}, {"code": "approval", "valueString": "5/5 as of 8/30/2021: Eric Harvey, Harold Lehmann, Mario Tristan, Bhagvan Kommadi, Janice Tufte,"}, {"code": "negative-vote", "valueString": "8/27/2021 vote 8-2 on \"Apprehension bias for outcome determination = A cognitive interpretive bias for outcome determination due to study participants\u2019 awareness of being observed resulting in different responses or behaviors.\" by, Eric Au, Eric Harvey, Harold Lehmann, Alejandro Piscoya, Mario Tristan, Bhagvan Kommadi, Leo Orozco, Janice Tufte, Jes\u00fas L\u00f3pez-Alcalde, Brian S. Alper"}, {"code": "expert-comments", "valueString": "2021-08-27 comments: A cognitive interpretive bias for outcome determination due to study participants\u2019 awareness of being observed and resulting in different responses or behaviors. (just a slight rewording - the existing wording doesn't read well to me) This definition seems to refer to performance bias. The key is that [...] results in different responses or behaviours concerning the outcome determination."}], "definition": "A cognitive interpretive bias for outcome determination due to a study participant's responding or behaving differently when aware of being observed.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "hawthorne effect for outcome determination"}]}, {"code": "SEVCO:00053", "display": "hypothetical assessment bias for outcome determination", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Muhammad Afzal, Janice Tufte, Joanne Dehnbostel, Kenneth Wilkins, Mario Tristan"}, {"code": "approval", "valueString": "7/7 as of 9/24/21: , Janice Tufte, Brian S. Alper, Eric Harvey, Paola Rosati, Jesus Lopez-Alcalde, Bhagvan Kommadi, Mario Tristan"}], "definition": "A cognitive interpretive bias for outcome determination due to a difference between an individual\u2019s report of an imagined or hypothetical response from their actual response. The response may be a behavior or valuation.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "subjunctivity bias for outcome determination"}]}, {"code": "SEVCO:00054", "display": "mimicry bias for outcome determination", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Muhammad Afzal, Janice Tufte, Joanne Dehnbostel"}, {"code": "approval", "valueString": "7/7 as of 9/24/21: , Janice Tufte, Brian S. Alper, Eric Harvey, Paola Rosati, Jesus Lopez-Alcalde, Bhagvan Kommadi, Mario Tristan"}], "definition": "A cognitive interpretive bias for outcome determination due to a misinterpretation of observations that resemble the outcome."}, {"code": "SEVCO:00057", "display": "unacceptability bias for outcome determination", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Muhammad Afzal, Janice Tufte, Joanne Dehnbostel, Ken Wilkins, Lisa Schilling"}, {"code": "approval", "valueString": "5/5 as of 10/1/21: , Joanne Dehnbostel, Brian S. Alper, Eric Harvey, Alejandro Piscoya, Bhagvan Kommadi,"}], "definition": "A cognitive interpretive bias for outcome determination due to distortions in response, response values, or recording of responses resulting from perception of the social unacceptability of an outcome.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "unacceptable disease bias for outcome determination"}]}], "display": "cognitive interpretive bias for outcome determination", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Muhammad Afzal, Janice Tufte, Joanne Dehnbostel, Kenneth Wilkins"}, {"code": "approval", "valueString": "10/10 as of 8/27/2021: Eric Au, Eric Harvey, Harold Lehmann, Alejandro Piscoya, Mario Tristan, Bhagvan Kommadi, Leo Orozco, Janice Tufte, Jes\u00fas L\u00f3pez-Alcalde, Brian S. Alper, 7/7 for Alternative terms on 9/24/21: Janice/Brian/Eric/Paola/Jesus/Bhagvan/Mario"}, {"code": "expert-comments", "valueString": "8/27/21 comment: This bias is difficult to manage and avoid it."}], "definition": "An outcome detection bias due to the subjective nature of human interpretation.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "perception bias for outcome determination"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "subjective interpretive bias for outcome determination"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "subjectivity bias for outcome determination"}]}, {"code": "SEVCO:00058", "concept": [{"code": "SEVCO:00097", "display": "nonrepresentative observation period for outcome of interest", "property": [{"code": "editors", "valueString": "Brian S. Alper, Mario Tristan, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Muhammad Afzal"}, {"code": "negative-vote", "valueString": "10/15/2021 vote 5-2 on \"Inappropriate follow up period for outcome of interest = An outcome ascertainment bias due to differences in the time period used for observation of the outcome and the true time period for outcome occurrence.\" by Eric Harvey, Paola Rosati, Alejandro Piscoya, Joanne Dehnbostel, Robin Ann Yurk, Janice Tufte, Brian S. Alper\n10/25/21 vote 3-1 on \"Misaligned follow up period for outcome of interest = An outcome ascertainment bias due to differences in the time period used for observation of the outcome and the true time period for outcome occurrence.\" by Paola Rosati, Robin Ann Yurk, Jesus Lopez-Alcalde, Eric Harvey"}, {"code": "expert-comments", "valueString": "2021-10-15 comments: I wonder if we need to address interim analysis validity. What about adding to inappropriate 'unreliable'?; Change word Inappropriate to Different\n2021-10-25 comments: It is unclear what do you mean with 'and the true time period for outcome occurrence', On the other hand, I propose using 'period' instead of 'time period'"}, {"code": "approval", "valueString": "10/29/2021 vote 6-0 by Cheow Peng Ooi, Robin Ann Yurk, Paola Rosati, Jesus Lopez-Alcalde, Eric Harvey, Janice Tufte"}], "definition": "An outcome ascertainment bias due to differences in the period used for observation of the outcome and the period for the outcome of interest.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "misaligned follow up period for outcome of interest"}]}, {"code": "SEVCO:00098", "display": "nonrepresentative context for outcome ascertainment", "property": [{"code": "editors", "valueString": "Brian S. Alper, Mario Tristan, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Muhammad Afzal, Harold Lehmann, Paul Whaley"}, {"code": "negative-vote", "valueString": "10/15/2021 vote 6-1 on \"Unreliable method for outcome ascertainment = An outcome ascertainment bias due to methods of data collection that result in inconsistent data values.\" by Eric Harvey, Paola Rosati, Alejandro Piscoya, Joanne Dehnbostel, Robin Ann Yurk, Janice Tufte, Brian S. Alper\n10/25/21 vote 3-1 on \"Undependable method for outcome of interest = An outcome ascertainment bias due methods of data collection that result in inconsistent or incorrect data values.\" by Paola Rosati, Robin Ann Yurk, Jesus Lopez-Alcalde, Eric Harvey\n10/29/2021 vote 5-1 by Cheow Peng Ooi, Robin Ann Yurk, Paola Rosati, Jesus Lopez-Alcalde, Eric Harvey, Janice Tufte\n11/22/2021 vote 6-1\n2021-12-03 vote for priort term 7-0 by Philippe Rocca-Serra, Janice Tufte, Mario Tristan, Harold Lehmann, Paul Whaley, Joanne Dehnbostel, C  Ooi"}, {"code": "expert-comments", "valueString": "2021-10-15 comments: the word Unreliable is misleading as more applicable to measurement error than bias\n2021-10-25 comments: I do not fully understand the difference between the second and the third definitions\n2021-10-29 comments: Suggest Incorrect or inconsistent method.\n2021-11-22 comments: The term 'inconsistent' may be more appropriate  -- steering group discussion to move the \"Comment for application\" property higher on the page and see if this comment will resolve the concern"}, {"code": "comment", "valueString": "This term is used when the context used for outcome ascertainment is incorrect, insensitive, or nonspecific.  If the context (whether representative or not) is applied inconsistently, then use the term \"Inconsistency in outcome ascertainment\""}, {"code": "approval", "valueString": "2022-03-18 vote 5-0 by Mario Tristan, Robin Ann Yurk, Paola Rosati, Nisha Mathew, Brian S. Alper"}], "definition": "An outcome ascertainment bias due to differences in the context in which the outcome is observed and the intended context for the outcome of interest."}, {"code": "SEVCO:00099", "display": "inconsistency in outcome ascertainment", "property": [{"code": "editors", "valueString": "Brian S. Alper, Mario Tristan, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Muhammad Afzal, Paul Whaley, Harold Lehmann"}, {"code": "negative-vote", "valueString": "10/15/2021 vote 6-1 on \"Imbalance in application of outcome ascertainment = An outcome ascertainment bias due to differences within or between groups in how the data are collected.\" by Eric Harvey, Paola Rosati, Alejandro Piscoya, Joanne Dehnbostel, Robin Ann Yurk, Janice Tufte, Brian S. Alper\n10/25/21 vote 3-1 on \"Imbalance in application of outcome ascertainment = An outcome ascertainment bias due to differences within or between groups in how the data are collected.\" by Paola Rosati, Robin Ann Yurk, Jesus Lopez-Alcalde, Eric Harvey\n10/29/2021 vote on prior term 6-0 by Cheow Peng Ooi, Robin Ann Yurk, Paola Rosati, Jesus Lopez-Alcalde, Eric Harvey, Janice Tufte"}, {"code": "expert-comments", "valueString": "2021-10-15 comments: Imbalance is misleading as more applicable to measurement error?\n2021-10-25 comment: Suggestion, replace imbalance with Variation or Heterogeneity\n2021-10-29 comment: Alternative Terms:  Variation or Heterogeneity --> converted 2021-10-29 to suggested addition of Alternative term \"Variation in application of outcome ascertainment\" by Brian S. Alper, Kenneth Wilkins, Joanne Dehnbostel, Muhammad Afzal, Harold Lehmann, Mario Tristan, Bhagvan Kommadi"}, {"code": "comment", "valueString": "This term is used when the context (whether representative or not) is applied inconsistently. If the context used for outcome ascertainment is incorrect, insensitive, or nonspecific, then use the term \"Nonrepresentative context for outcome ascertainment\""}, {"code": "approval", "valueString": "2022-03-18 vote 5-0 by Mario Tristan, Robin Ann Yurk, Paola Rosati, Nisha Mathew, Brian S. Alper"}], "definition": "An outcome ascertainment bias due to differences within or between groups in how the data are collected.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "imbalance in outcome ascertainment"}]}], "display": "outcome ascertainment bias", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Muhammad Afzal"}, {"code": "approval", "valueString": "10/10 as of 8/27/2021: Eric Au, Eric Harvey, Harold Lehmann, Alejandro Piscoya, Mario Tristan, Bhagvan Kommadi, Leo Orozco, Janice Tufte, Jes\u00fas L\u00f3pez-Alcalde, Brian S. Alper"}], "definition": "An outcome detection bias due to distortions in how the data are collected.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "ascertainment bias for outcome determination"}]}, {"code": "SEVCO:00059", "concept": [{"code": "SEVCO:00100", "display": "inappropriate method for outcome measurement", "property": [{"code": "editors", "valueString": "Brian S. Alper, Mario Tristan, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Muhammad Afzal"}, {"code": "negative-vote", "valueString": "10/15/2021 vote 6-1 on \"Outcome measurement method inappropriate = An outcome measurement bias due to use of an incorrect method or protocol.\" by Eric Harvey, Paola Rosati, Alejandro Piscoya, Joanne Dehnbostel, Robin Ann Yurk, Janice Tufte, Brian S. Alper\n10/25/21 vote 2-2 on \"Outcome measurement method inappropriate = An outcome measurement bias due to use of an incorrect method or protocol.\" by Paola Rosati, Robin Ann Yurk, Jesus Lopez-Alcalde, Eric Harvey"}, {"code": "expert-comments", "valueString": "2021-10-15 comments: I would change word inappropriate to different as the bias is from difference in comparison not flaws or errors in scientific methods.\n2021-10-25 comments: suggest replace with incorrect method; Should not be 'Inappropriate outcome measurement method' (instead of placing the adjective at the end?)\n2022-03-11 Preferred term revised (and Alternative term added) to match corresponding changes in Exposure Detection Bias)"}, {"code": "approval", "valueString": "7 of 7 on 2021-11-05: Bhagvan Kommadi, Paola Rosati, Paul Whaley, Janice Tufte, Alejandro Piscoya, Robin Ann Yurk, Eric Harvey"}], "definition": "An outcome measurement bias due to use of an incorrect method or protocol.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "incorrect outcome measurement method"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "inappropriate outcome measurement method"}]}, {"code": "SEVCO:00101", "display": "insensitive measure bias for outcome determination", "property": [{"code": "editors", "valueString": "Brian S. Alper, Mario Tristan, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Muhammad Afzal"}, {"code": "comment", "valueString": "Use of an inadequately sensitive outcome measure is likely to result in false negative findings."}, {"code": "negative-vote", "valueString": "10/15/2021 vote 6-1 on \"Insensitive measure bias for outcome determination = An outcome measurement bias due to use of a method that does not reliably detect the outcome when the outcome is present.\" by Eric Harvey, Paola Rosati, Alejandro Piscoya, Joanne Dehnbostel, Robin Ann Yurk, Janice Tufte, Brian S. Alper\n10/25/21 vote 3-1 on \"Insensitive measure bias for outcome determination =An outcome measurement bias due to use of a method that does not reliably detect the outcome when the outcome is present.\" by Paola Rosati, Robin Ann Yurk, Jesus Lopez-Alcalde, Eric Harvey"}, {"code": "expert-comments", "valueString": "2021-10-15 comments: Change word Insensitive to Sensitivity measure bias as double negative in phrase\n2021-10-25 comment: False Negative measure Bias or Unreliable measure bias"}, {"code": "approval", "valueString": "7 of 7 on 2021-11-05: Bhagvan Kommadi, Paola Rosati, Paul Whaley, Janice Tufte, Alejandro Piscoya, Robin Ann Yurk, Eric Harvey"}], "definition": "An outcome measurement bias due to use of a method that does not reliably detect the outcome when the outcome is present.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "inadequate sensitivity for outcome measure"}]}, {"code": "SEVCO:00211", "display": "nonspecific measure bias for outcome determination", "property": [{"code": "editors", "valueString": "Brian S. Alper, Mario Tristan, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Muhammad Afzal"}, {"code": "comment", "valueString": "Use of an inadequately specific outcome measure is likely to result in false positive findings."}, {"code": "negative-vote", "valueString": "10/15/2021 vote 6-1 on \"Nonspecific measure bias for outcome determination = An outcome measurement bias due to use of a method that falsely detects the outcome when the outcome is absent.\" by Eric Harvey, Paola Rosati, Alejandro Piscoya, Joanne Dehnbostel, Robin Ann Yurk, Janice Tufte, Brian S. Alper\n10/25/21 vote 3-1 on \"Nonspecific measure bias for outcome determination = An outcome measurement bias due to use of a method that falsely detects the outcome when the outcome is absent.\" by Paola Rosati, Robin Ann Yurk, Jesus Lopez-Alcalde, Eric Harvey"}, {"code": "expert-comments", "valueString": "2021-10-15 comments: I would change to Specificity measurement bias. Remove word falsely from the definition as it implies problems with scientific methods\n2021-10-25 comment: Suggest use False Positive Measure Biac"}, {"code": "approval", "valueString": "7 of 7 on 2021-11-05: Bhagvan Kommadi, Paola Rosati, Paul Whaley, Janice Tufte, Alejandro Piscoya, Robin Ann Yurk, Eric Harvey"}], "definition": "An outcome measurement bias due to use of a method that falsely detects the outcome when the outcome is absent.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "inadequate specificity for outcome measure"}]}, {"code": "SEVCO:00102", "display": "DEPRECATED: unclear outcome measurement method", "definition": "An outcome measurement bias due to use of a method that is not reported with sufficient clarity and detail such that measurement could be replicated.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Mario Tristan, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Muhammad Afzal"}, {"code": "negative-vote", "valueString": "10/15/2021 vote 5-2 on \"Outcome measurement method unclear = An outcome measurement bias due to use of a method that is not reported with sufficient clarity and detail such that measurement could be replicated.\" by Eric Harvey, Paola Rosati, Alejandro Piscoya, Joanne Dehnbostel, Robin Ann Yurk, Janice Tufte, Brian S. Alper\n10/25/21 vote 3-1 on \"Outcome measurement method unclear = An outcome measurement bias due to use of a method that is not reported with sufficient clarity and detail such that measurement could be replicated.\" by Paola Rosati, Robin Ann Yurk, Jesus Lopez-Alcalde, Eric Harvey\n2021-11-05 vote 6-1 on \"Unclear outcome measurement method = An outcome measurement bias due to use of a method that is not reported with sufficient clarity and detail such that measurement could be replicated.\" by Bhagvan Kommadi, Paola Rosati, Paul Whaley, Janice Tufte, Alejandro Piscoya, Robin Ann Yurk, Eric Harvey"}, {"code": "expert-comments", "valueString": "2021-10-15 comments: I suggest to delete unclear and use 'unreliable' as the measurement could be replicated; I would eliminate this as this is a reviewers criticism of the design which suggests flawed methods.\n2021-10-25 comment: Should not be 'Unclear measurement method' (instead of placing the adjective at the end?)\n2021-11-05 comment: No. This does not look like a bias, it seems to be more of a shortcoming in reported methods, that may or may not be biased depending on the actual methods that were used, but have been under-specified in the documentation; I would suggest removing this as a bias."}, {"code": "deprecated", "valueString": "2021-11-05 This term was deprecated with the concept that one can use a different term for the type of Bias and apply a Rating of Factor Presence term such as Presence or absence of factor unclear.   Decision made in COKA ROB Terminology and Tooling WG by Brian Alper, Paul Whaley, Joanne Dehnbostel, Harold Lehmann, Janice Tufte, Khalid Shahin, Muhammad Afzal, Bhagvan Kommadi"}]}, {"code": "SEVCO:00103", "display": "inappropriate application of method for outcome measurement", "property": [{"code": "editors", "valueString": "Brian S. Alper, Mario Tristan, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Muhammad Afzal, Paul Whaley"}, {"code": "negative-vote", "valueString": "10/15/2021 vote 6-1 on \"Outcome measurement conduct inappropriate = An outcome measurement bias due to incorrect application of the method or protocol.\" by Eric Harvey, Paola Rosati, Alejandro Piscoya, Joanne Dehnbostel, Robin Ann Yurk, Janice Tufte, Brian S. Alper\n10/25/21 vote 2-2 on \"Outcome measurement conduct inappropriate = An outcome measurement bias due to incorrect application of the method or protocol.\" by Paola Rosati, Robin Ann Yurk, Jesus Lopez-Alcalde, Eric Harvey\n2021-11-05 vote 6-1 on \"Inappropriate outcome measurement conduct = An outcome measurement bias due to incorrect application of the method or protocol.\" by Bhagvan Kommadi, Paola Rosati, Paul Whaley, Janice Tufte, Alejandro Piscoya, Robin Ann Yurk, Eric Harvey\n2022-03-18 vote 4-1 by Mario Tristan, Robin Ann Yurk, Paola Rosati, Nisha Mathew, Brian S. Alper\n2022-03-25 vote 7-1 by Mario Tristan, Robin Ann Yurk, Paola Rosati, Philippe Rocca-Serra, Brian S. Alper, Jesus Lopez-Alcalde, Paul Whaley, Muhammad Afzal"}, {"code": "expert-comments", "valueString": "2021-10-15 comments: I would eliminate this definition - as suggests flawed study design..\n2021-10-25 comments: replace inappropriate with incorrect; Should not be 'Inappropriate outcome measurement conduct' (instead of placing the adjective at the end?)\n2021-11-05 comment: There is enormous overlap with this term and \"Inappropriate outcome measurement method\", so this one should be eliminated\nAs of 2021-11-05 this term is not being prepared for vote. The current ROB tools do not distinguish the inappropriate conduct (used in QUADAS-2) from inadequate method (used in most other ROB tools) in the same tool, so the demand for this term is uncertain and thus not applied for version 1 of the Code System.\nOn 2022-03-11 we revised this term to match corresponding changes that passed for Exposure Detection Bias.\n2022-03-18 comment: Suggest edit Alternative term from conduct to process\n2022-03-25 comment: Recommend edit term definition so it reads:  Outcome Measurement method Bias.\nSuggest reviewing your complete taxonomy of terms and identify similarities or duplicate terms and potentially integrating terms by keeping as primary term versus adding to alternate term for prior vote with similar term definition or statements."}, {"code": "comment", "valueString": "An inappropriate application of the method or protocol suggests error is introduced by the process of measurement, as distinct from the method or protocol used for measurement (which would be an Inappropriate method for outcome measurement)."}, {"code": "approval", "valueString": "2022-04-08 vote 11-1 (no rationale provided for the negative vote) by Muhammad Afzal, Paul Whaley, Mario Tristan, Brian S. Alper, Jesus Lopez-Alcalde, Philippe Rocca-Serra, Paola Rosati, Robin Ann Yurk, nelle.stocquart, nisha mathew, Harold Lehmann, Cau\u00ea Monaco"}], "definition": "An outcome measurement bias due to inappropriate application of the method or protocol."}, {"code": "SEVCO:00104", "display": "inconsistency in outcome measurement", "property": [{"code": "editors", "valueString": "Brian S. Alper, Mario Tristan, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Muhammad Afzal, Paul Whaley, Robin Ann Yurk, Harold Lehmann"}, {"code": "negative-vote", "valueString": "10/15/2021 vote 6-1 on \"Imbalance in application of outcome measurement = An outcome measurement bias due to differences within or between groups in how the data are measured.\" by Eric Harvey, Paola Rosati, Alejandro Piscoya, Joanne Dehnbostel, Robin Ann Yurk, Janice Tufte, Brian S. Alper\n10/25/21 vote 3-1 on \"Imbalance in application of outcome measurement = An outcome measurement bias due to differences within or between groups in how the data are measured.\" by Paola Rosati, Robin Ann Yurk, Jesus Lopez-Alcalde, Eric Harvey\n2021-11-05 vote 6-1 on \"Inconsistency in application of outcome measurement = An outcome measurement bias due to differences within or between groups in how the data are measured.\" by Bhagvan Kommadi, Paola Rosati, Paul Whaley, Janice Tufte, Alejandro Piscoya, Robin Ann Yurk, Eric Harvey\n2021-11-22 vote 3-2 on \"Inconsistency in application of outcome measurement\" = \"An outcome measurement bias due to differences within or between groups in how the data are measured.\"2021-12-10 vote 5-1 by Joanne Dehnbostel, Janice Tufte, Robin Ann Yurk, Paola Rosati, Jesus Lopez-Alcalde, Paul Whaley\nPRIOR AGREEMENT 2021-12-17 vote 6-0 by Robin Ann Yurk, Janice Tufte, Paul Whaley, Mario Tristan, C P Ooi, Jesus Lopez-Alcalde FOR DEFINITION: An outcome measurement bias due to differences within groups in how the data are measured. AND COMMENT FOR APPLICATION: \"How the data are measured\" may refer to the methods applied for data measurement or the application of those methods."}, {"code": "expert-comments", "valueString": "2021-10-15 comments: I would eliminate this definition\n2021-10-25 comment: Replace Imbalance with Heterogeneity\n2021-11-05 comment:  This is a specific type of \"Inappropriate outcome measurement method\" so this term should be moved into that position or eliminated (are we really going to describe all of the inappropriate methods?) [[discussed in COKA WG and noted that ROB2 has separate questions 4.1 and 4.2 for these terms so we need to support that]\n2021-11-22 comments: \"The wording 'inconsistent method of outcome measurement' may better reflect the definition\" and \"May be pedantic, but is it data that are measured, or the outcome as a variable (that results in data)? I also wonder if we mean differences within groups - some variation would be expected, but what matters is if the variation results in systematic error in measuring the variable between groups. If we feel that e.g. a study design where two different ways of measuring outcome were implemented within groups, but this did not lead to bias across the exposure and control arms, then I would vote yes (pending clarification of \"data\").\"2021-12-10 comment: It seems to not quite be correctly written. The two choices for definition are differently phrased (\"application of methods\" / \"methods applied\")even though I think they are supposed to refer to across groups or within groups, but both refer to within groups, so I am not sure how to interpret this.\n2022-01-21 comment: As a comment: Is this term redundant, if the two child terms are the complete set of options for inconsistency in outcome measurement?"}, {"code": "comment", "valueString": "\"How the observed outcomes are measured\" may refer to the methods applied for measurement or the application of those methods."}, {"code": "approval", "valueString": "2022-01-21 vote 6-0 by Harold Lehmann, Robin Ann Yurk, Janice Tufte, Paul Whaley, Alejandro Piscoya, Philippe Rocca-Serra"}], "definition": "An outcome measurement bias due to differences within groups in how the observed outcomes are measured.", "concept": [{"code": "SEVCO:00243", "display": "inconsistency in instruments used for outcome measurement", "definition": "An outcome measurement bias due to differences within groups in the instruments used for measurement.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Mario Tristan, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Muhammad Afzal, Harold Lehmann, Paul Whaley"}, {"code": "negative-vote", "valueString": "2021-12-17 vote 5-1 by Robin Ann Yurk, Janice Tufte, Paul Whaley, C P Ooi, Paola Rosati, Jesus Lopez-Alcalde\n2022-01-07 vote 5-1 by Robin Ann Yurk, Janice Tufte, Paul Whaley, Paola Rosati, Harold Lehmann, Mario Tristan"}, {"code": "expert-comments", "valueString": "2021-12-17 comment: To me there is no semantic difference between this definition and the other subordinate term for inconsistency in outcome measurement (application of methods ? methods applied)\n2022-01-07 comment: I would approve this, except I am still not sure that one can measure data (\"facts and statistics collected together for reference or analysis\"). One can collect data, or measure a variable, but I don't think one can collect data."}, {"code": "comment", "valueString": "Instruments used for measurement may include devices, surveys, and technologies. The concepts of \"instruments used for measurement\" is distinct from \"process used for measurement\" which may include protocols, techniques, and variations in context."}, {"code": "approval", "valueString": "2022-01-21 vote 7-0 by Andrew Beck, Harold Lehmann, Robin Ann Yurk, Paul Whaley, Janice Tufte, Alejandro Piscoya, Philippe Rocca-Serra"}]}, {"code": "SEVCO:00244", "display": "inconsistency in processes used for outcome measurement", "definition": "An outcome measurement bias due to differences within groups in the processes by which the instruments are used for measurement.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Mario Tristan, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Muhammad Afzal, Harold Lehmann, Paul Whaley"}, {"code": "negative-vote", "valueString": "2021-12-17 vote 5-1 by Robin Ann Yurk, Janice Tufte, Paul Whaley, C P Ooi, Paola Rosati, Jesus Lopez-Alcalde\n2022-01-07 vote 5-1 by Robin Ann Yurk, Janice Tufte, Paul Whaley, Paola Rosati, Harold Lehmann, Mario Tristan"}, {"code": "expert-comments", "valueString": "2021-12-17 comment: To me there is no semantic difference between this definition and the other subordinate term for inconsistency in outcome measurement (application of methods ? methods applied)\n2022-01-07 comment: I would approve this, except I am still not sure that one can measure data (\"facts and statistics collected together for reference or analysis\"). One can collect data, or measure a variable, but I don't think one can collect data."}, {"code": "comment", "valueString": "The processes used for measurement may include protocols, techniques, and variations in context. The concept of \"processes used for measurement\" is distinct from \"instruments used for measurement\" which may include devices, surveys, and technologies."}, {"code": "approval", "valueString": "2022-01-21 vote 7-0 by Andrew Beck, Harold Lehmann, Robin Ann Yurk, Paul Whaley, Janice Tufte, Alejandro Piscoya, Philippe Rocca-Serra"}]}]}, {"code": "SEVCO:00240", "display": "imbalance in outcome measurement", "definition": "An outcome measurement bias due to differences between groups in how the observed outcomes are measured.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Paul Whaley, Robin Ann Yurk, Janice Tufte, Harold Lehmann, Mario Tristan, Kenneth Wilkins, Muhammad Afzal"}, {"code": "comment", "valueString": "\"How the observed outcomes are measured\" may refer to the methods applied for measurement or the application of those methods."}, {"code": "negative-vote", "valueString": "2021-12-10 vote 5-0 by Janice Tufte, Robin Ann Yurk, Paola Rosati, Jesus Lopez-Alcalde, Paul Whaley but steering group decided to make changes consistent with changes to Inconsistency in outcome measurement.\nPRIOR AGREEMENT 2021-12-17 vote 5-0 by Robin Ann Yurk, Janice Tufte, Paul Whaley, C P Ooi, Paola Rosati FOR DEFINITION: An outcome measurement bias due to differences between groups in how the data are measured. WITH COMMENT FOR APPLICATION: \"How the data are measured\" may refer to the methods applied for data measurement or the application of those methods."}, {"code": "expert-comments", "valueString": "2021-12-10 comment: Referring back to my comment on the inconsistency in method, I realise I hadn't read it quite right. In both cases, they maybe aren't quite as easy to parse as would be ideal but I can't think of a better definition. Maybe a use note to refer to how the terms are similar and clarify when one vs. the other should be used?\n2022-01-21 comments: The term definition and comment is the same for Inconsistency in outcome measurement bias.  Suggest combining the two terms by listing one as an Alternative term. (yellow highlighting in messaging applied to show the differences in the terms)\nAs a comment: Is this term redundant, if the two child terms are the complete set of options for inconsistency in outcome measurement?"}, {"code": "approval", "valueString": "2022-01-21 vote 6-0 by Harold Lehmann, Robin Ann Yurk, Paul Whaley, Janice Tufte, Alejandro Piscoya, Philippe Rocca-Serra"}], "concept": [{"code": "SEVCO:00245", "display": "imbalance in instruments used for outcome measurement", "definition": "An outcome measurement bias due to differences between groups in the instruments used for measurement.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Mario Tristan, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Muhammad Afzal, Harold Lehmann, Paul Whaley"}, {"code": "negative-vote", "valueString": "2021-12-17 vote 4-1 by Janice Tufte, Paul Whaley, C P Ooi, Paola Rosati, Jesus Lopez-Alcalde\n2022-01-07 vote 5-1 by Robin Ann Yurk, Janice Tufte, Paul Whaley, Paola Rosati, Harold Lehmann, Mario Tristan"}, {"code": "expert-comments", "valueString": "2021-12-17 comment: To me there is no semantic difference between this definition and the other subordinate term for inconsistency in outcome measurement (application of methods ? methods applied)\n2022-01-07 comment: I would approve this, except I am still not sure that one can measure data (\"facts and statistics collected together for reference or analysis\"). One can collect data, or measure a variable, but I don't think one can collect data."}, {"code": "comment", "valueString": "Instruments used for measurement may include devices, surveys, and technologies. The concepts of \"instruments used for measurement\" is distinct from \"process used for measurement\" which may include protocols, techniques, and variations in context."}, {"code": "approval", "valueString": "2022-01-21 vote 7-0 by Harold Lehmann, Robin Ann Yurk, Paul Whaley, Janice Tufte, Alejandro Piscoya, Philippe Rocca-Serra, Andrew Beck"}]}, {"code": "SEVCO:00246", "display": "imbalance in processes used for outcome measurement", "definition": "An outcome measurement bias due to differences between groups in the processes by which the instruments are used for measurement.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Mario Tristan, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Muhammad Afzal, Harold Lehmann, Paul Whaley"}, {"code": "negative-vote", "valueString": "2021-12-17 vote 4-1 by Janice Tufte, Paul Whaley, C P Ooi, Paola Rosati, Robin Ann Yurk\n2022-01-07 vote 5-1 by Robin Ann Yurk, Janice Tufte, Paul Whaley, Paola Rosati, Harold Lehmann, Mario Tristan"}, {"code": "expert-comments", "valueString": "2021-12-17 comment: To me there is no semantic difference between this definition and the other subordinate term for inconsistency in outcome measurement (application of methods ? methods applied)\n2022-01-07 comment: I would approve this, except I am still not sure that one can measure data (\"facts and statistics collected together for reference or analysis\"). One can collect data, or measure a variable, but I don't think one can collect data."}, {"code": "comment", "valueString": "The processes used for measurement may include protocols, techniques, and variations in context. The concept of \"processes used for measurement\" is distinct from \"instruments used for measurement\" which may include devices, surveys, and technologies."}, {"code": "approval", "valueString": "2022-01-21 vote 7-0 by Harold Lehmann, Robin Ann Yurk, Paul Whaley, Janice Tufte, Alejandro Piscoya, Philippe Rocca-Serra, Andrew Beck"}]}]}], "display": "outcome measurement bias", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Muhammad Afzal; Paul Whaley"}, {"code": "negative-vote", "valueString": "PRIOR AGREEMENT 10/10 as of 8/27/2021: Eric Au, Eric Harvey, Harold Lehmann, Alejandro Piscoya, Mario Tristan, Bhagvan Kommadi, Leo Orozco, Janice Tufte, Jes\u00fas L\u00f3pez-Alcalde, Brian S. Alper WITH DEFINTION: An outcome detection bias due to distortions in how the data are measured."}, {"code": "expert-comments", "valueString": "2022-01-11 comment: Outcome Measurement Bias has a similar term definition as Outcome Classification Bias.  May need to add an additional comment for application from T&O discussion."}, {"code": "comment", "valueString": "If one is addressing a bias in the instruments or processes used to measure the observed outcome, use Outcome Measurement Bias. If one is addressing how the measured outcome is categorized, use Outcome Classification Bias."}, {"code": "approval", "valueString": "2022-01-21 vote 7-0 by Harold Lehmann, Robin Ann Yurk, Janice Tufte, Paul Harris, Paul Whaley, Alejandro Piscoya, Philippe Rocca-Serra"}], "definition": "An outcome detection bias due to distortions in how the observed outcomes are measured.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "measurement bias for outcome determination"}]}, {"code": "SEVCO:00060", "concept": [{"code": "SEVCO:00061", "concept": [{"code": "SEVCO:00105", "concept": [{"code": "SEVCO:00108", "display": "surrogate marker bias for outcome classification", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Muhammad Afzal, Paul Whaley"}, {"code": "negative-vote", "valueString": "10/15/2021 vote 6-1 on \"Surrogate marker bias for outcome classification = A nonrepresentative definition for outcome classification due to use of a factor associated with the outcome rather than a direct observation of the outcome.\" by Eric Harvey, Paola Rosati, Alejandro Piscoya, Joanne Dehnbostel, Robin Ann Yurk, Janice Tufte, Brian S. Alper\n2021-11-29 vote 3-3 on \"Surrogate marker bias for outcome classification\" = \"A nonrepresentative definition for outcome classification due to use of a proxy for the outcome rather than a direct observation of the outcome.\""}, {"code": "expert-comments", "valueString": "2021-10-15 comments: I would edit the definition: An outcome classification system bias due to use of a definition that is proxy rather than direct observation of the outcome. {{Definition changed as result of this comment}}\n2021-11-29 comments: The 10/15 comments stated that the definition should start with \"An outcome classification system bias....\"; but this definition does not. A little pickier, I might say, \"result from use of a definition\" rather than \"due to\". The latter sounds like the bias will always occur; the former, that there is a bias as a result, in this instance.\nI'm not sure I fully understand this definition. A surrogate would generally be used in place of an outcome that cannot readily be observed in a research setting. I am not sure how this can be a classification error (the surrogate is what the surrogate is). I can, however, see how it could be an error in inference (assuming that because the exposure affects the surrogate, then the exposure also affects the outcome of actual interest). Is this a helpful way of thinking about this, or would it just be over-complicating matters?\nThis suggested definition is more appropriate: An outcome classification system bias due to use of a definition that is proxy rather than direct observation of the outcome"}, {"code": "approval", "valueString": "2021-12-10 vote 5-0 by Paul Whaley, Janice Tufte, Robin Ann Yurk, Paola Rosati, Jesus Lopez-Alcalde"}], "definition": "An outcome classification system bias due to use of a definition that is proxy for the outcome rather than direct observation of the outcome.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "substitution bias for outcome classification"}]}], "display": "nonrepresentative definition for outcome classification", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Muhammad Afzal, Paul Whaley"}, {"code": "negative-vote", "valueString": "10/15/2021 vote 6-1 on \"Nonrepresentative definition for outcome classification = An outcome classification system bias due to a definition or threshold that does not represent the outcome of interest.\" by Eric Harvey, Paola Rosati, Alejandro Piscoya, Joanne Dehnbostel, Robin Ann Yurk, Janice Tufte, Brian S. Alper\n2021-11-29 vote 6-1 on \"Nonrepresentative definition for outcome classification\" = \"An outcome classification system bias due to a definition or threshold that does not represent the outcome of interest.\" by Harold Lehmann, Paul Whaley, Janice Tufte, C P Ooi, Joanne Dehnbostel, Philippe Rocca-Serra, Robin Ann Yurk"}, {"code": "expert-comments", "valueString": "2021-10-15 comments: I would eliminate this definition\n2021-11-29 comments: (\"represent in its entirety\" instead? A definition could *partially* represent the outcome of interest, so perhaps we want to make clear that this bias is invoked only for something that is more than \"partial\"?) \"Represent\" feels ambiguous, would it be useful to clarify what is meant here? Is it that it includes outcomes in addition to that of interest, and/or excludes outcomes that are of interest? Maybe that doesn't make things clearer."}, {"code": "approval", "valueString": "2021-12-10 vote 5-0 by Paul Whaley, Janice Tufte, Robin Ann Yurk, Paola Rosati, Jesus Lopez-Alcalde"}], "definition": "An outcome classification system bias due to a mismatch between the outcome of interest and the definition or threshold used for outcome measurement."}, {"code": "SEVCO:00106", "display": "post-hoc definition of outcome", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Muhammad Afzal, Paul Whaley"}, {"code": "negative-vote", "valueString": "10/15/2021 vote 6-1 on \"Definition not prespecified for outcome classification = An outcome classification system bias due to absence of a predetermined definition.\" by Eric Harvey, Paola Rosati, Alejandro Piscoya, Joanne Dehnbostel, Robin Ann Yurk, Janice Tufte, Brian S. Alper\n10/25/21 vote 3-1 on \"Definition not prespecified for outcome classification = An outcome classification system bias due to absence of a predetermined definition.\" by Paola Rosati, Robin Ann Yurk, Jesus Lopez-Alcalde, Eric Harvey\n2021-12-03 vote 5-2 by Harold Lehmann, Paul Whaley, Janice Tufte, C P Ooi, Joanne Dehnbostel, Philippe Rocca-Serra, Robin Ann Yurk\n2021-12-10 vote 2-2 by Paul Whaley, Robin Ann Yurk, Paola Rosati, Jesus Lopez-Alcalde"}, {"code": "expert-comments", "valueString": "2021-10-15 comments: I would eliminate this definition as suggest flawed study design\n2021-10-25 comment: I would phrase 'Not prespecified definition for outcome classification'\n2021-12-03 comments: It feels uninformative to define \"not prespecified\" as \"not predetermined\". I wonder if \"predetermined\" can be clarified - presumably, the issue here is that the outcome is defined post-hoc, after data collection, so that outcome ends up being defined around the data rather than specified in advance of conduct of the research.  //   Rephrasing to this 'No prespecified definition for outcome classification' may be clearer and easier to understand. \n2021-12-10 comments: Consider removing term.  As methods are permitted to be revised for a variety of reasons with new definitions but would be described in methods or a revised protocol.  If truly post-hoc after a data set is closed then there are different issues for discussion.  ///   Suggest changing \"due to determination of the outcome definition\" to \"due to outcome being defined\""}, {"code": "approval", "valueString": "2022-01-07 vote 9-0 by Robin Ann Yurk, Janice Tufte, Paul Whaley, C P Ooi, Paola Rosati, Jesus Lopez-Alcalde, Harold Lehmann, Joanne Dehnbostel, Mario Tristan"}], "definition": "An outcome classification system bias due to defining the outcome after interacting with the study data.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "post-hoc outcome definition"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "definition for outcome classification not prespecified"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "no prespecified definition for outcome classification"}]}, {"code": "SEVCO:00107", "display": "deprecated: unclear definition for outcome classification", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Muhammad Afzal"}, {"code": "negative-vote", "valueString": "10/15/2021 vote 5-2 on \"Definition unclear for outcome classification = An outcome classification system bias due to use of a definition that is not reported with sufficient clarity and detail such that classification could be replicated.\" by Eric Harvey, Paola Rosati, Alejandro Piscoya, Joanne Dehnbostel, Robin Ann Yurk, Janice Tufte, Brian S. Alper\n10/25/21 vote 3-1 on \"Definition unclear for outcome classification = An outcome classification system bias due to use of a definition that is not reported with sufficient clarity and detail such that classification could be replicated.\" by Paola Rosati, Robin Ann Yurk, Jesus Lopez-Alcalde, Eric Harvey"}, {"code": "expert-comments", "valueString": "2021-10-15 comments: As above detail, I suggest to change unclear with 'unreliable'; I would eliminate this definition as suggest flawed study design.\n2021-10-25 comment: I would phrase 'Unclear definition for outcome classification'"}, {"code": "deprecated", "valueString": "2021-11-12 This term was deprecated with the concept that one can use a different term for the type of Bias and apply a Rating of Factor Presence term such as Presence or absence of factor unclear.   Decision made in COKA ROB Terminology and Tooling WG by Brian Alper, Joanne Dehnbostel, Muhammad Afzal, Kenneth Wilkins, Mario Tristan"}], "definition": "An outcome classification system bias due to use of a definition that is not reported with sufficient clarity and detail such that classification could be replicated."}], "display": "outcome classification system bias", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Mario Tristan"}, {"code": "approval", "valueString": "5/5 as of 9/17/2021: Eric Harvey, Paola Rosati, Alejandro Piscoya, Bhagvan Kommadi, Janice Tufte,"}, {"code": "comment", "valueString": "An outcome classification system bias suggests an internal validity problem in which  the definition or threshold used for outcome classification does not represent the outcome of interest. If considering an external validity problem, the \"Wrong question bias\" (term not yet defined) may be used. An outcome classification system bias is present when there are differences between the outcome of interest and the definition or threshold used for outcome classification."}], "definition": "An outcome classification bias resulting from the definition or threshold used for outcome classification.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "definition bias for outcome determination"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "outcome definition bias"}]}, {"code": "SEVCO:00062", "display": "outcome classification process bias", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Mario Tristan"}, {"code": "approval", "valueString": "7/7 as of 9/24/21: , Janice Tufte, Brian S. Alper, Eric Harvey, Paola Rosati, Jesus Lopez-Alcalde, Bhagvan Kommadi, Mario Tristan"}, {"code": "negative-vote", "valueString": "4-1 vote as of 9/17/2021 regarding Outcome Classification Process Bias (SEVCO:00062) (Classification process bias for outcome determination) [Draft Term] = An outcome misclassification bias resulting from the application of the method used for outcome classification.: Eric Harvey, Paola Rosati, Alejandro Piscoya, Bhagvan Kommadi, Janice Tufte,"}, {"code": "expert-comments", "valueString": "comment: \"This might be related to outcome classification bias (child relationship)\""}], "definition": "An outcome classification bias resulting from the application of the method used for outcome classification.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "classification process bias for outcome determination"}]}, {"code": "SEVCO:00063", "display": "incorporation bias for outcome determination", "definition": "An outcome classification bias due to the inclusion of the exposure under investigation in the method or process used for outcome classification.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Mario Tristan"}, {"code": "approval", "valueString": "5/5 as of 9/17/2021: Eric Harvey, Paola Rosati, Alejandro Piscoya, Bhagvan Kommadi, Janice Tufte,"}, {"code": "comment", "valueString": "In predictive model research, incorporation bias for outcome determination occurs if the predictor (explanatory variable) is included in the outcome definition."}]}], "display": "outcome classification bias", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Muhammad Afzal, Paul Whaley"}, {"code": "negative-vote", "valueString": "PRIOR AGREEMENT 10/10 as of 8/27/2021: Eric Au, Eric Harvey, Harold Lehmann, Alejandro Piscoya, Mario Tristan, Bhagvan Kommadi, Leo Orozco, Janice Tufte, Jes\u00fas L\u00f3pez-Alcalde, Brian S. Alper, 7/7 for renaming on 9/24/21: Janice/Brian/Eric/Paola/Jesus/Bhagvan/Mario  FOR DEFINITION: An outcome detection bias due to distortions in how the data are classified."}, {"code": "expert-comments", "valueString": "2022-01-11 comment: Outcome Classification Bias has a similar term definition as Outcome Measurement Bias.  May need to add an additional comment for application from T&O discussion."}, {"code": "comment", "valueString": "If one is addressing a bias in the instruments or processes used to measure the observed outcome, use Outcome Measurement Bias. If one is addressing how the measured outcome is categorized, use Outcome Classification Bias."}, {"code": "approval", "valueString": "2022-01-21 vote 7-0 by Harold Lehmann, Robin Ann Yurk, Janice Tufte, Paul Harris, Paul Whaley, Alejandro Piscoya, Philippe Rocca-Serra"}], "definition": "An outcome detection bias due to distortions in how the observed outcomes are classified.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "misclassification bias for outcome determination"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "outcome misclassification bias"}]}], "display": "outcome detection bias", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Philippe Rocca-Serra, Mario Tristan, Janice Tufte, Harold Lehmann, Erfan Shamsoddin, Muhammad Afzal, Kenneth Wilkins"}, {"code": "approval", "valueString": "10/10 as of 8/27/2021: Eric Au, Eric Harvey, Harold Lehmann, Alejandro Piscoya, Mario Tristan, Bhagvan Kommadi, Leo Orozco, Janice Tufte, Jes\u00fas L\u00f3pez-Alcalde, Brian S. Alper"}], "definition": "A detection bias due to distortions in how an outcome is determined."}, {"code": "SEVCO:00043", "display": "exposure detection bias", "definition": "A detection bias due to distortions in how an exposure of interest is determined.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Philippe Rocca-Serra, Mario Tristan, Janice Tufte, Harold Lehmann, Erfan Shamsoddin, Muhammad Afzal, Kenneth Wilkin"}, {"code": "approval", "valueString": "10/10 as of 8/27/2021: Eric Au, Eric Harvey, Harold Lehmann, Alejandro Piscoya, Mario Tristan, Bhagvan Kommadi, Leo Orozco, Janice Tufte, Jes\u00fas L\u00f3pez-Alcalde, Brian S. Alper"}, {"code": "comment", "valueString": "The exposure of interest can be an intervention or a prognostic factor, depending on the research context."}], "concept": [{"code": "SEVCO:00055", "concept": [{"code": "SEVCO:00056", "display": "bias due to lack of masking for exposure determination", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Muhammad Afzal, Janice Tufte, Joanne Dehnbostel, Kenneth Wilkins, Paul Whaley"}, {"code": "comment", "valueString": "The exposure of interest can be an intervention or a prognostic factor, depending on the research context. Lack of blinding is not automatically a bias, but if awareness of some data systematically distorts the exposure determination then a 'Bias due to lack of masking for exposure determination' exists."}, {"code": "negative-vote", "valueString": "2022-02-04 vote 5-1 by Jesus Lopez-Alcalde, Paul Whaley, Mario Tristan, Robin Ann Yurk, Janice Tufte, Brian S. Alper\n2022-02-11 vote 8-1 by Mario Tristan, Paul Whaley, Sunu Alice Cherian, Janice Tufte, Robin Ann Yurk, Alejandro Piscoya, Harold Lehmann, Yasser Sami Amer, Jesus Lopez-Alcalde\n2022-02-18 vote 10-3 by Rebecca Baker, Brian S. Alper, Mario Tristan, Paul Whaley, Sunu Alice Cherian, Janice Tufte, Robin Ann Yurk, Alejandro Piscoya, Harold Lehmann, Yasser Sami Amer, Jesus Lopez-Alcalde, Joanne Dehnbostel,Sumalatha A"}, {"code": "expert-comments", "valueString": "2022-02-04 comment: Is it just awareness of the participant's status with respect solely to the outcome of interest? I could imagine being aware of e.g. socioeconomic status rather than outcome, and this potentially having an influence on exposure assessment. Blinding I think is supposed to be to as many characteristics of the participant as possible.\n2022-02-11 comment: This definition assumes that the \"Lack of blinding for exposure determination\" always associates bias, which may not be the case. For example, if we want to assess the role of sex as a prognostic factor for ICU admission, the participant may not be blinded but this does not cause bias in his/her prognostic factor determination (sex)\n2022-02-18 comments: As \"lack of blinding\" is contributing to but not the bias itself, perhaps rename to Awareness bias for exposure determination\nThis definition assumes that the \"Lack of blinding for exposure determination\" always associates bias, which may not be the case. For example, if we want to assess the role of sex as a prognostic factor for ICU admission, the participant may not be blinded but this does not cause bias in his/her prognostic factor determination (sex)\nNot much difference between existing and new terminology \n2022-02-25 comment: Suggest removing Lack of blinding during exposure assessment from Alternative term and just list the other 3 Alternative terms.  The comment is based on your comment for application description."}, {"code": "approval", "valueString": "2022-02-25 vote 8-0 by Robin Ann Yurk, Sunu Alice Cherian, Paola Rosati, Harold Lehmann, Joanne Dehnbostel, Janice Tufte, nisha mathew, Paul Whaley"}], "definition": "A cognitive interpretive bias for exposure determination due to awareness of the participant's status with respect to the outcome of interest or other relevant exposures.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "bias due to lack of blinding during exposure assessment"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "bias due to lack of masking during exposure assessment"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "awareness bias for exposure determination"}]}, {"code": "SEVCO:00238", "concept": [{"code": "SEVCO:00239", "display": "confirmation bias for exposure determination", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Muhammad Afzal, Janice Tufte, Joanne Dehnbostel, Kenneth Wilkins, Mario Tristan"}, {"code": "comment", "valueString": "The exposure of interest can be an intervention or a prognostic factor, depending on the research context."}, {"code": "approval", "valueString": "2022-02-04 vote 5-0 by Jesus Lopez-Alcalde, Mario Tristan, Robin Ann Yurk, Janice Tufte, Brian S. Alper"}], "definition": "An observer bias for exposure determination due to previous opinions or knowledge of a subject\u2019s prior exposures or assessments.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "diagnostic suspicion bias for exposure determination"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "previous opinion bias for exposure  determination"}]}], "display": "observer bias for exposure determination", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Muhammad Afzal, Janice Tufte, Joanne Dehnbostel"}, {"code": "comment", "valueString": "The exposure of interest can be an intervention or a prognostic factor, depending on the research context.\nMultiple types of bias can overlap. Observer bias is different than lack of blinding with respect to the outcome. Observer bias is about the influence of the observer's interpretation of what they are observing, whether or not the observer is aware of the participant's outcome."}, {"code": "approval", "valueString": "2022-02-04 vote 6-0 by Jesus Lopez-Alcalde, Paul Whaley, Mario Tristan, Robin Ann Yurk, Janice Tufte, Brian S. Alper"}], "definition": "A cognitive interpretive bias for exposure determination due to subjective interpretations in the process of observing and recording information."}, {"code": "SEVCO:00214", "display": "recall bias for exposure determination", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Muhammad Afzal, Janice Tufte, Joanne Dehnbostel"}, {"code": "comment", "valueString": "The exposure of interest can be an intervention or a prognostic factor, depending on the research context."}, {"code": "approval", "valueString": "2022-02-04 vote 5-0 by Jesus Lopez-Alcalde, Mario Tristan, Robin Ann Yurk, Janice Tufte, Paul Whaley"}], "definition": "A cognitive interpretive bias for exposure determination due to differences in accuracy or completeness of recall of past events or experiences."}, {"code": "SEVCO:00215", "display": "apprehension bias for exposure determination", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Muhammad Afzal, Janice Tufte, Joanne Dehnbostel, Mario Tristan"}, {"code": "comment", "valueString": "The exposure of interest can be an intervention or a prognostic factor, depending on the research context."}, {"code": "approval", "valueString": "2022-02-04 vote 5-0 by Jesus Lopez-Alcalde, Mario Tristan, Robin Ann Yurk, Janice Tufte, Paul Whaley"}, {"code": "expert-comments", "valueString": "2022-02-04 comment: What about using Hawthorne Effect for term definition and Apprehension Bias for Alternative term"}], "definition": "A cognitive interpretive bias for exposure determination due to a study participant's responding or behaving differently when aware of being observed.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "hawthorne effect for exposure determination"}]}, {"code": "SEVCO:00216", "display": "hypothetical assessment bias for exposure determination", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Muhammad Afzal, Janice Tufte, Joanne Dehnbostel, Kenneth Wilkins, Mario Tristan"}, {"code": "comment", "valueString": "The exposure of interest can be an intervention or a prognostic factor, depending on the research context. The response may be a behavior or valuation. An individual's response to \"What would you do?\" or \"What would you have done?\" (an imagined or hypothetical response) may be different than the individual's response to \"What did you do?\" or observation of the individual's behavior (a reporting of an actual response). This bias is relevant for preference studies."}, {"code": "negative-vote", "valueString": "2022-02-04 vote 4-1 by Jesus Lopez-Alcalde, Mario Tristan, Robin Ann Yurk, Janice Tufte, Paul Whaley"}, {"code": "expert-comments", "valueString": "2022-02-04 comments: Is there a spelling error in Subjunctivity?\nA minor issue - would the sentence \"The response may be a behavior or valuation.\" be better placed in the comment for application (otherwise, would vote yes)\n2022-02-11 comment: I would add a comment for application for the word hypothetical"}, {"code": "approval", "valueString": "2022-02-11 vote 9-0 by Mario Tristan, Paul Whaley, Sunu Alice Cherian, Robin Ann Yurk, Alejandro Piscoya, Harold Lehmann, Yasser Sami Amer, Jesus Lopez-Alcalde, Janice Tufte"}], "definition": "A cognitive interpretive bias for exposure determination due to a difference between an individual\u2019s report of an imagined or hypothetical response from their actual response.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "subjunctivity bias for exposure determination"}]}, {"code": "SEVCO:00217", "display": "mimicry bias for exposure determination", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Muhammad Afzal, Janice Tufte, Joanne Dehnbostel, Kenneth Wilkins"}, {"code": "comment", "valueString": "The exposure of interest can be an intervention or a prognostic factor, depending on the research context. Other terms (Exposure Ascertainment Bias, Exposure Measurement Bias, Exposure Classification Bias) may be used to describe the process in Exposure Detection in which the bias occurs. The term 'Mimicry bias for exposure determination' is used to represent the type of cognitive interpretive bias occurring in this process."}, {"code": "expert-comments", "valueString": "2022-02-18 comments: Suggest insert Alternative term:  Duplicate\nI'm not quite sure this is clear enough, though I don't have any concrete suggestions for improvement. It might be that I am not familiar enough with the issue in question to interpret the definition. Reading around this a bit, it resembles a misclassification type bias (for a given set of observations, the observer takes X to be cause when the true cause is Y). Given our model for bias (see our flow diagram), might it be better defined in those terms? -- RESOLVED IN GROUP DISCUSSION"}, {"code": "approval", "valueString": "2022-02-18 vote 11-0 by Jesus Lopez-Alcalde, Mario Tristan, Robin Ann Yurk, Janice Tufte, Paul Whaley, Yasser Sami Amer, Harold Lehmann, Alejandro Piscoya, Sunu Alice Cherian, Joanne Dehnbostel, Sumalatha A"}], "definition": "A cognitive interpretive bias for exposure determination due to a misinterpretation of observations that resemble the exposure."}, {"code": "SEVCO:00218", "display": "unacceptability bias for exposure determination", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Muhammad Afzal, Janice Tufte, Joanne Dehnbostel, Ken Wilkins, Lisa Schilling"}, {"code": "comment", "valueString": "The exposure of interest can be an intervention or a prognostic factor, depending on the research context."}, {"code": "approval", "valueString": "2022-02-04 vote 5-0 by Jesus Lopez-Alcalde, Mario Tristan, Robin Ann Yurk, Janice Tufte, Paul Whaley"}], "definition": "A cognitive interpretive bias for exposure determination due to distortions in response, response values, or recording of responses resulting from perception of the social unacceptability of an exposure.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "unacceptable disease bias for exposure determination"}]}], "display": "cognitive interpretive bias for exposure determination", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Muhammad Afzal, Janice Tufte, Joanne Dehnbostel, Kenneth Wilkins"}, {"code": "comment", "valueString": "The exposure of interest can be an intervention or a prognostic factor, depending on the research context. The human interpretation can be that of the observer or participant."}, {"code": "expert-comments", "valueString": "2022-02-04 comment: Consistency of phrasing with other definitions (\"bias due to distortions in...\"), need comment for application."}, {"code": "approval", "valueString": "2022-02-04 vote 6-0 by Jesus Lopez-Alcalde, Paul Whaley, Mario Tristan, Robin Ann Yurk, Janice Tufte, Brian S. Alper"}], "definition": "An exposure detection bias due to the subjective nature of human interpretation.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "perception bias for exposure determination"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "subjective interpretive bias for exposure  determination"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "subjectivity bias for exposure determination"}]}, {"code": "SEVCO:00219", "concept": [{"code": "SEVCO:00220", "display": "nonrepresentative observation period for exposure of interest", "property": [{"code": "editors", "valueString": "Brian S. Alper, Mario Tristan, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Muhammad Afzal"}, {"code": "comment", "valueString": "The exposure of interest can be an intervention or a prognostic factor, depending on the research context."}, {"code": "negative-vote", "valueString": "2022-02-04 vote 4-1 by Jesus Lopez-Alcalde, Paul Whaley, Mario Tristan, Robin Ann Yurk, Janice Tufte"}, {"code": "expert-comments", "valueString": "2022-02-04 comment: I think this is about right but it could perhaps be tidied up a bit, e.g. using \"time period\" in both instances of \"period\""}, {"code": "approval", "valueString": "2022-02-11 vote 9-0 by Mario Tristan, Paul Whaley, Sunu Alice Cherian, Robin Ann Yurk, Alejandro Piscoya, Harold Lehmann, Yasser Sami Amer, Jesus Lopez-Alcalde, Janice Tufte"}], "definition": "An exposure ascertainment bias due to differences in the time period used for observation of the exposure and the intended time period for the exposure of interest.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "misaligned follow up period for exposure of interest"}]}, {"code": "SEVCO:00221", "display": "nonrepresentative context for exposure ascertainment", "property": [{"code": "editors", "valueString": "Brian S. Alper, Mario Tristan, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Muhammad Afzal, Harold Lehmann, Paul Whaley"}, {"code": "comment", "valueString": "The exposure of interest can be an intervention or a prognostic factor, depending on the research context.\nThis term is used when the context used for exposure ascertainment is incorrect, insensitive, or nonspecific.  If the context (whether representative or not) is applied inconsistently, then use the term \"Inconsistency in exposure ascertainment\""}, {"code": "negative-vote", "valueString": "2022-02-18 vote 10-1 by Jesus Lopez-Alcalde, Paul Whaley, Mario Tristan, Robin Ann Yurk, Janice Tufte, Yasser Sami Amer, Harold Lehmann, Alejandro Piscoya, Sunu Alice Cherian, Joanne Dehnbostel, Sumalatha A"}, {"code": "expert-comments", "valueString": "2022-02-18 comments: Comment for application.  I would delete sentence:  If the method (whether dependable or undependable) is applied inconsistently then use the term inconsistency in application of exposure of ascertainment.  \nI'm not sure if \"undependable\" is the word we really want to use. Also, (1) no method for exposure ascertainment will give a strictly \"correct\" result, (2) inconsistency can result in random error and imprecision, not necessarily bias, (3) we are presumably worried about consistency over- or under-reading of a measurement method compared to some (possibly hypothetical) gold standard? Overall, it feels like there is more to discuss here.\n2022-02-25 comment: I would delete or edit the current Alternative term and replace with insensitive, or nonspecific context for exposure ascertainment."}, {"code": "approval", "valueString": "2022-02-25 vote 8-0 by Robin Ann Yurk, Sunu Alice Cherian, Paola Rosati, Harold Lehmann, Joanne Dehnbostel, Janice Tufte, nisha mathew, Paul Whaley"}], "definition": "An exposure ascertainment bias due to differences in the context in which the exposure is observed and the intended context for the exposure of interest."}, {"code": "SEVCO:00222", "display": "inconsistency in exposure ascertainment", "property": [{"code": "editors", "valueString": "Brian S. Alper, Mario Tristan, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Muhammad Afzal, Harold Lehmann, Paul Whaley"}, {"code": "comment", "valueString": "The exposure of interest can be an intervention or a prognostic factor, depending on the research context.\nThis term is used when the context (whether representative or not) is applied inconsistently. If the context used for exposure ascertainment is incorrect, insensitive, or nonspecific, then use the term \"Nonrepresentative context for exposure ascertainment\""}, {"code": "negative-vote", "valueString": "2022-02-18 vote 8-1 by Jesus Lopez-Alcalde, Paul Whaley, Mario Tristan, Robin Ann Yurk, Janice Tufte, Yasser Sami Amer, Harold Lehmann, Alejandro Piscoya, Sunu Alice Cherian, Joanne Dehnbostel, Sumalatha A"}, {"code": "expert-comments", "valueString": "2022-02-18 comments: I would add comment for application from previous term. \n If the method (whether dependable or undependable) is applied inconsistently then use the term inconsistency in application of exposure of ascertainment.  \nI don't really understand the term \"Inconsistency in application of exposure ascertainment\" - I am not clear what the nouns and verbs actually are here, nor what they refer to. I have been involved in the discussion of the underlying bias model and I still don't grasp the meaning here.\n2022-02-25 comment: I would remove Alternative term."}, {"code": "approval", "valueString": "2022-02-25 vote 8-0 by Robin Ann Yurk, Sunu Alice Cherian, Paola Rosati, Harold Lehmann, Joanne Dehnbostel, Janice Tufte, nisha mathew, Paul Whaley"}], "definition": "An exposure ascertainment bias due to differences within or between groups in how the data are collected.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "imbalance in exposure ascertainment"}]}], "display": "exposure ascertainment bias", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Muhammad Afzal"}, {"code": "comment", "valueString": "The exposure of interest can be an intervention or a prognostic factor, depending on the research context."}, {"code": "approval", "valueString": "2022-02-04 vote 5-0 by Jesus Lopez-Alcalde, Paul Whaley, Mario Tristan, Robin Ann Yurk, Janice Tufte"}, {"code": "expert-comments", "valueString": "2022-02-04 comment: Suggest modify Alternative term to Data Collection Bias"}], "definition": "An exposure detection bias due to distortions in how the data are collected.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "ascertainment bias for exposure determination"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "data collection bias for exposure determination"}]}, {"code": "SEVCO:00223", "concept": [{"code": "SEVCO:00224", "display": "inappropriate method for exposure measurement", "property": [{"code": "editors", "valueString": "Brian S. Alper, Mario Tristan, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Muhammad Afzal"}, {"code": "comment", "valueString": "The exposure of interest can be an intervention or a prognostic factor, depending on the research context."}, {"code": "negative-vote", "valueString": "2022-02-25 vote 11-2 by Paul Whaley, Mario Tristan, Robin Ann Yurk, Janice Tufte, Yasser Sami Amer, Harold Lehmann, Alejandro Piscoya, Sunu Alice Cherian, Jesus Lopez-Alcalde, Sumalatha A, Joanne Dehnbostel, Paola Rosati, nisha mathew"}, {"code": "expert-comments", "valueString": "2022-02-25 comments: I would list measurement methods as examples under comment for application, such as pharma, survey...\nI am not sure of the difference between this bias and \"Undependable method for exposure ascertainment\" bias. It also seems to me that \"inappropriate\" is a subjective term so I am not sure how it should be applied. [Side note: in the ballot, it might be useful to have terms arranged as they are in the SEVCO hierarchy, as this might be causing some of the confusion I am experiencing.]\nThe previous term convey almost similar meaning"}, {"code": "approval", "valueString": "2022-03-11 vote 5-0 by Janice Tufte, Harold Lehmann, Philippe Rocca-Serra, nisha mathew, Paul Whaley"}], "definition": "An exposure measurement bias due to use of an incorrect method or protocol.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "incorrect exposure measurement method"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "inappropriate exposure measurement method"}]}, {"code": "SEVCO:00225", "display": "insensitive measure bias for exposure determination", "property": [{"code": "editors", "valueString": "Brian S. Alper, Mario Tristan, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Muhammad Afzal"}, {"code": "comment", "valueString": "The exposure of interest can be an intervention or a prognostic factor, depending on the research context. Use of an inadequately sensitive exposure measure is likely to result in false negative findings."}, {"code": "expert-comments", "valueString": "2022-02-18 comments: Suggest use term as Sensitivity Measure bias for exposure determination and insensitive measure bias for exposure determination for alternate term.\n\"Sensitivity\" is not, in my experience, viewed exclusively in terms of measurement. Some experimental models cannot show the exposure (or outcome) because they are incapable of it, however it is measured in situ. For example, if the exposure was measured via presence of a metabolite, but the participant was not able to produce the metabolite, then the experiment would be insensitive regardless of measurement method. I am not sure this affects us here, but does it suggest a need for us to handle sensitivity in a comprehensive fashion? (Perhaps also specificity?)\n\nAs a side note, defining sensitivity well could be important for progress on risk of bias assessment methods used by EPA, who currently have assessment of \"sensitivity\" as a separate issue entirely outside of risk of bias assessment. \nNEGATIVE VOTE CHANGED TO POSITIVE DURING DISCUSSION 2022-02-25"}, {"code": "approval", "valueString": "2022-02-25 vote 13-0 by Paul Whaley, Mario Tristan, Robin Ann Yurk, Janice Tufte, Yasser Sami Amer, Harold Lehmann, Alejandro Piscoya, Sunu Alice Cherian, Jesus Lopez-Alcalde, Sumalatha A, Joanne Dehnbostel, Paola Rosati, nisha mathew"}], "definition": "An exposure measurement bias due to use of a method that does not reliably detect the exposure when the exposure is present.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "inadequate sensitivity for exposure measure"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "inadequate sensitivity for exposure determination"}]}, {"code": "SEVCO:00226", "display": "nonspecific measure bias for exposure determination", "property": [{"code": "editors", "valueString": "Brian S. Alper, Mario Tristan, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Muhammad Afzal"}, {"code": "comment", "valueString": "The exposure of interest can be an intervention or a prognostic factor, depending on the research context. Use of an inadequately specific exposure measure is likely to result in false positive findings."}, {"code": "approval", "valueString": "2022-02-04 vote 5-0 by Paul Whaley, Mario Tristan, Robin Ann Yurk, Janice Tufte, Jesus Lopez-Alcalde"}, {"code": "expert-comments", "valueString": "2022-02-04 comment: Suggest use Specificity measure bias for exposure determination and non-specific measure bias for exposure determination for Alternative term."}], "definition": "An exposure measurement bias due to use of a method that falsely detects the exposure when the exposure is absent.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "inadequate specificity for exposure measure"}]}, {"code": "SEVCO:00228", "display": "inappropriate application of method for exposure measurement", "property": [{"code": "editors", "valueString": "Brian S. Alper, Mario Tristan, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Muhammad Afzal, Paul Whaley"}, {"code": "change-for-vote", "valueString": "Noted for Outcome Detection Bias: As of 2021-11-05 this term is not being prepared for vote. The current ROB tools do not distinguish the inappropriate conduct (used in QUADAS-2) from inadequate method (used in most other ROB tools) in the same tool, so the demand for this term is uncertain and thus not applied for version 1 of the Code System."}, {"code": "comment", "valueString": "The exposure of interest can be an intervention or a prognostic factor, depending on the research context. An inappropriate application of the method or protocol suggests error is introduced by the process of measurement, as distinct from the method or protocol used for measurement (which would be an Inappropriate method for exposure measurement)."}, {"code": "negative-vote", "valueString": "2022-02-25 vote 12-1 by Paul Whaley, Mario Tristan, Robin Ann Yurk, Janice Tufte, Yasser Sami Amer, Harold Lehmann, Alejandro Piscoya, Sunu Alice Cherian, Jesus Lopez-Alcalde, Sumalatha A, Joanne Dehnbostel, Paola Rosati, nisha mathew"}, {"code": "expert-comments", "valueString": "2022-02-11 comments: Add alternate term:  Incorrect application of exposure measurement bias.\nI think this is OK, but the term should be rewritten so it is easier to read and understand what it means (the syntax is awkward, as it could be read as one adjective and three nouns)\n2022-03-11 comment: In documenting this, and the \"inappropriate method for exposure measurement\", I think it would be helpful to document what we mean by e.g. \"method\" vs. \"application of method\". I feel these are meta-terms like \"study design feature\" that are part of the scaffolding of SEVCO, but not part of SEVCO itself."}, {"code": "approval", "valueString": "2022-03-11 vote 5-0 by Janice Tufte, Harold Lehmann, Philippe Rocca-Serra, nisha mathew, Paul Whaley"}], "definition": "An exposure measurement bias due to inappropriate application of the method or protocol.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "inappropriate exposure measurement conduct"}]}, {"code": "SEVCO:00229", "display": "inconsistency in exposure measurement", "property": [{"code": "editors", "valueString": "Brian S. Alper, Mario Tristan, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Muhammad Afzal"}, {"code": "comment", "valueString": "The exposure of interest can be an intervention or a prognostic factor, depending on the research context. \"How the observed exposures are measured\" may refer to the methods applied for measurement or the application of those methods."}, {"code": "approval", "valueString": "2022-02-11 vote 9-0 by Jesus Lopez-Alcalde, Mario Tristan, Robin Ann Yurk, Paul Whaley, Janice Tufte, Sunu Alice Cherian, Alejandro Piscoya, Harold Lehmann, Yasser Sami Amer"}], "definition": "An exposure measurement bias due to differences within groups in how the observed exposures are measured.", "concept": [{"code": "SEVCO:00247", "display": "inconsistency in instruments used for exposure measurement", "definition": "An exposure measurement bias due to differences within groups in the instruments for measurement.", "property": [{"code": "comment", "valueString": "The exposure of interest can be an intervention or a prognostic factor, depending on the research context.\nInstruments used for measurement may include devices, surveys, and technologies. The concepts of \"instruments used for measurement\" is distinct from \"process used for measurement\" which may include protocols, techniques, and variations in context."}, {"code": "editors", "valueString": "Brian S. Alper, Mario Tristan, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Muhammad Afzal, Harold Lehmann, Paul Whaley"}, {"code": "approval", "valueString": "2022-02-11 vote 8-0 by Jesus Lopez-Alcalde, Mario Tristan, Robin Ann Yurk, Janice Tufte, Sunu Alice Cherian, Alejandro Piscoya, Harold Lehmann, Yasser Sami Amer"}]}, {"code": "SEVCO:00248", "display": "inconsistency in processes used for exposure measurement", "definition": "An exposure measurement bias due to differences within groups in the processes by which the instruments are used for measurement.", "property": [{"code": "comment", "valueString": "The exposure of interest can be an intervention or a prognostic factor, depending on the research context.\nThe processes used for measurement may include protocols, techniques, and variations in context. The concept of \"processes used for measurement\" is distinct from \"instruments used for measurement\" which may include devices, surveys, and technologies."}, {"code": "editors", "valueString": "Brian S. Alper, Mario Tristan, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Muhammad Afzal, Harold Lehmann, Paul Whaley"}, {"code": "approval", "valueString": "2022-02-11 vote 8-0 by Jesus Lopez-Alcalde, Mario Tristan, Robin Ann Yurk, Janice Tufte, Sunu Alice Cherian, Alejandro Piscoya, Harold Lehmann, Yasser Sami Amer"}]}]}, {"code": "SEVCO:00241", "display": "imbalance in exposure measurement", "definition": "An exposure measurement bias due to differences between groups in how the observed exposures are measured.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Paul Whaley, Robin Ann Yurk, Janice Tufte, Harold Lehmann"}, {"code": "comment", "valueString": "The exposure of interest can be an intervention or a prognostic factor, depending on the research context. \"How the observed exposures are measured\" may refer to the methods applied for data measurement or the application of those methods."}, {"code": "approval", "valueString": "2022-02-11 vote 8-0 by Jesus Lopez-Alcalde, Mario Tristan, Robin Ann Yurk, Janice Tufte, Sunu Alice Cherian, Alejandro Piscoya, Harold Lehmann, Yasser Sami Amer"}], "concept": [{"code": "SEVCO:00249", "display": "imbalance in instruments used for exposure measurement", "definition": "An exposure measurement bias due to differences between groups in the instruments used for measurement.", "property": [{"code": "comment", "valueString": "The exposure of interest can be an intervention or a prognostic factor, depending on the research context.\nInstruments used for measurement may include devices, surveys, and technologies. The concepts of \"instruments used for measurement\" is distinct from \"process used for measurement\" which may include protocols, techniques, and variations in context."}, {"code": "editors", "valueString": "Brian S. Alper, Mario Tristan, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Muhammad Afzal, Harold Lehmann, Paul Whaley"}, {"code": "approval", "valueString": "2022-02-11 vote 8-0 by Jesus Lopez-Alcalde, Mario Tristan, Robin Ann Yurk, Janice Tufte, Sunu Alice Cherian, Alejandro Piscoya, Harold Lehmann, Yasser Sami Amer"}]}, {"code": "SEVCO:00250", "display": "imbalance in processes used for exposure measurement", "definition": "An exposure measurement bias due to differences between groups in the processes by which the instruments are used for measurement.", "property": [{"code": "comment", "valueString": "The exposure of interest can be an intervention or a prognostic factor, depending on the research context.\nThe processes used for measurement may include protocols, techniques, and variations in context. The concept of \"processes used for measurement\" is distinct from \"instruments used for measurement\" which may include devices, surveys, and technologies."}, {"code": "editors", "valueString": "Brian S. Alper, Mario Tristan, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Muhammad Afzal, Harold Lehmann, Paul Whaley"}, {"code": "approval", "valueString": "2022-02-11 vote 8-0 by Jesus Lopez-Alcalde, Mario Tristan, Robin Ann Yurk, Janice Tufte, Sunu Alice Cherian, Alejandro Piscoya, Harold Lehmann, Yasser Sami Amer"}]}]}], "display": "exposure measurement bias", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Muhammad Afzal"}, {"code": "comment", "valueString": "The exposure of interest can be an intervention or a prognostic factor, depending on the research context.\nIf one is addressing a bias in the instruments or processes used to measure the observed exposure, use Exposure Measurement Bias. If one is addressing how the measured exposure is categorized, use Exposure Classification Bias."}, {"code": "approval", "valueString": "2022-02-04 vote 5-0 by Jesus Lopez-Alcalde, Paul Whaley, Mario Tristan, Robin Ann Yurk, Janice Tufte"}], "definition": "An exposure detection bias due to distortions in how the observed exposures are measured.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "measurement bias for exposure determination"}]}, {"code": "SEVCO:00230", "concept": [{"code": "SEVCO:00231", "concept": [{"code": "SEVCO:00232", "concept": [{"code": "SEVCO:00233", "display": "surrogate marker bias for exposure classification", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Muhammad Afzal, Paul Whaley"}, {"code": "comment", "valueString": "The exposure of interest can be an intervention or a prognostic factor, depending on the research context."}, {"code": "expert-comments", "valueString": "2022-02-11 comment: Suggest add Alternative term:  proxy bias for exposure classification system."}, {"code": "negative-vote", "valueString": "2022-02-11 vote 8-0 by Jesus Lopez-Alcalde, Mario Tristan, Robin Ann Yurk, Janice Tufte, Sunu Alice Cherian, Alejandro Piscoya, Harold Lehmann, Yasser Sami Amer [but definition changed to match change to parent term]"}, {"code": "approval", "valueString": "2022-02-18 vote 5-0 by Joanne Dehnbostel, Sumalatha A, Janice Tufte, Harold Lehmann, Paul Whaley"}], "definition": "An exposure definition bias due to use of a definition that is proxy for the exposure rather than direct observation of the exposure.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "substitution bias for exposure classification"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "proxy bias for exposure classification"}]}], "display": "nonrepresentative definition for exposure classification", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Muhammad Afzal, Paul Whaley"}, {"code": "comment", "valueString": "The exposure of interest can be an intervention or a prognostic factor, depending on the research context."}, {"code": "expert-comments", "valueString": "2022-02-11 comment: Should there be a hyphen between \"classification\" and \"system\"? (Is it a system(s) bias or a classification-system bias?) (I think this question applies to several definitions)"}, {"code": "negative-vote", "valueString": "2022-02-11 vote 8-0 by Jesus Lopez-Alcalde, Mario Tristan, Robin Ann Yurk, Janice Tufte, Sunu Alice Cherian, Alejandro Piscoya, Harold Lehmann, Yasser Sami Amer [but definition changed to match change to parent term]"}, {"code": "approval", "valueString": "2022-02-18 vote 6-0 by Joanne Dehnbostel, Alejandro Piscoya, Sumalatha A, Janice Tufte, Harold Lehmann, Paul Whaley"}], "definition": "An exposure definition bias due to a mismatch between the exposure of interest and the definition or threshold used for exposure measurement."}, {"code": "SEVCO:00234", "display": "post-hoc definition of exposure", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Muhammad Afzal, Paul Whaley"}, {"code": "comment", "valueString": "The exposure of interest can be an intervention or a prognostic factor, depending on the research context."}, {"code": "negative-vote", "valueString": "2022-02-11 vote 8-0 by Jesus Lopez-Alcalde, Mario Tristan, Robin Ann Yurk, Janice Tufte, Sunu Alice Cherian, Alejandro Piscoya, Harold Lehmann, Yasser Sami Amer [but definition changed to match change to parent term]"}, {"code": "approval", "valueString": "2022-02-18 vote 5-0 by Joanne Dehnbostel, Sumalatha A, Janice Tufte, Harold Lehmann, Paul Whaley"}], "definition": "An exposure definition bias due to definition of the exposure after interacting with the study data.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "definition for exposure classification not prespecified"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "post-hoc exposure definition"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "no prespecified definition for exposure classification"}]}], "display": "exposure definition bias", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Mario Tristan, Harold Lehmann, Paul Whaley"}, {"code": "comment", "valueString": "The exposure of interest can be an intervention or a prognostic factor, depending on the research context.\nAn exposure definition bias suggests an internal validity problem in which the definition or threshold used for exposure classification does not represent the exposure of interest. If considering an external validity problem, the \"Wrong question bias\" (term not yet defined) may be used. An exposure definition bias is present when there are differences between the exposure of interest and the definition or threshold used for exposure classification."}, {"code": "expert-comments", "valueString": "2022-02-11 comments: Suggest Alternative term:  threshold bias for exposure determination.  \nSuggest remove sentence on external validity problem....\nIn the comments, \"term not yet identified\", should be flagged for later replacement."}, {"code": "negative-vote", "valueString": "2022-02-11 vote 8-0 by Jesus Lopez-Alcalde, Mario Tristan, Robin Ann Yurk, Janice Tufte, Sunu Alice Cherian, Alejandro Piscoya, Harold Lehmann, Yasser Sami Amer [but comment discussion led to new term]"}, {"code": "approval", "valueString": "2022-02-18 vote 5-0 by Joanne Dehnbostel, Sumalatha A, Janice Tufte, Harold Lehmann, Paul Whaley"}], "definition": "An exposure classification bias resulting from the definition or threshold used for exposure classification.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "definition bias for exposure determination"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "threshold bias for exposure determination"}]}, {"code": "SEVCO:00236", "display": "classification process bias for exposure determination", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Mario Tristan, Harold Lehmann, Paul Whaley"}, {"code": "comment", "valueString": "The exposure of interest can be an intervention or a prognostic factor, depending on the research context. \nA classification process bias for exposure determination suggests error is introduced by the process of classification, as distinct from the definition or threshold used (which would be an Exposure Definition Bias)."}, {"code": "expert-comments", "valueString": "2022-02-11 comments: I would provide an example such as survey severity classification example of a method.\n(Inconsistent capitalization)"}, {"code": "negative-vote", "valueString": "2022-02-11 vote 8-0 by Jesus Lopez-Alcalde, Mario Tristan, Robin Ann Yurk, Janice Tufte, Sunu Alice Cherian, Alejandro Piscoya, Harold Lehmann, Yasser Sami Amer [but term changed to parallel changes to Exposure Definition Bias]"}, {"code": "approval", "valueString": "2022-02-18 vote 6-0 by Joanne Dehnbostel, Sumalatha A, Robin Ann Yurk, Janice Tufte, Harold Lehmann, Paul Whaley"}], "definition": "An exposure classification bias resulting from the application of the method used for exposure classification."}, {"code": "SEVCO:00237", "display": "incorporation bias for exposure determination", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Mario Tristan, Paul Whaley"}, {"code": "comment", "valueString": "The exposure of interest can be an intervention or a prognostic factor, depending on the research context. If the statistical analysis assumes independence of two variables, but one variable incorporates the other variable in its definition, the assumption will be false and the result will be distorted."}, {"code": "negative-vote", "valueString": "2022-02-25 vote 11-2 by Paul Whaley, Mario Tristan, Robin Ann Yurk, Janice Tufte, Yasser Sami Amer, Harold Lehmann, Alejandro Piscoya, Sunu Alice Cherian, Jesus Lopez-Alcalde, Sumalatha A, Joanne Dehnbostel, Paola Rosati, nisha mathew"}, {"code": "expert-comments", "valueString": "2022-02-18 comments: Needs an Alternative term or new term definition. I.e. Inclusion Bias for exposure definition for the term.  Alternative term;  eligibility bias for exposure determination\nDefinitely needs a comment for application, I can't picture what this means!"}, {"code": "approval", "valueString": "2022-03-11 vote 5-0 by Janice Tufte, Harold Lehmann, Philippe Rocca-Serra, nisha mathew, Paul Whaley"}], "definition": "An exposure classification bias due to the inclusion of the outcome or other relevant exposures under investigation in the method or process used for exposure classification."}], "display": "exposure classification bias", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Muhammad Afzal"}, {"code": "comment", "valueString": "The exposure of interest can be an intervention or a prognostic factor, depending on the research context.\nIf one is addressing a bias in the instruments or processes used to measure the observed exposure, use Exposure Measurement Bias. If one is addressing how the measured exposure is categorized, use Exposure Classification Bias."}, {"code": "approval", "valueString": "2022-02-11 vote 8-0 by Jesus Lopez-Alcalde, Mario Tristan, Robin Ann Yurk, Janice Tufte, Sunu Alice Cherian, Alejandro Piscoya, Harold Lehmann, Yasser Sami Amer"}], "definition": "An exposure detection bias due to distortions in how the observed exposures are classified.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "misclassification bias for exposure determination"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "exposure misclassification bias"}]}]}, {"code": "SEVCO:00044", "display": "confounder detection bias", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Muhammad Afzal"}, {"code": "approval", "valueString": "10/10 as of 8/27/2021: Eric Au, Eric Harvey, Harold Lehmann, Alejandro Piscoya, Mario Tristan, Bhagvan Kommadi, Leo Orozco, Janice Tufte, Jes\u00fas L\u00f3pez-Alcalde, Brian S. Alper"}], "definition": "A detection bias due to distortions in how the data for a potential confounder are determined."}, {"code": "SEVCO:00045", "display": "detection bias related to the reference standard", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Muhammad Afzal"}, {"code": "approval", "valueString": "10/10 as of 8/27/2021: Eric Au, Eric Harvey, Harold Lehmann, Alejandro Piscoya, Mario Tristan, Bhagvan Kommadi, Leo Orozco, Janice Tufte, Jes\u00fas L\u00f3pez-Alcalde, Brian S. Alper"}], "definition": "A detection bias due  to distortions in how the reference standard result is determined.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "bias for reference standard result determination"}]}, {"code": "SEVCO:00046", "display": "detection bias related to the index test", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Muhammad Afzal"}, {"code": "approval", "valueString": "5/5 as of 8/30/2021: Eric Harvey, Harold Lehmann, Mario Tristan, Bhagvan Kommadi, Janice Tufte,"}, {"code": "negative-vote", "valueString": "8/27/2021 vote 8-1 on \"Detection Bias related to the index test (Bias for index text result determination) = A detection bias due to distortions in how the index text result is determined.\" by, Eric Au, Eric Harvey, Harold Lehmann, Alejandro Piscoya, Mario Tristan, Bhagvan Kommadi, Leo Orozco, Janice Tufte, Jes\u00fas L\u00f3pez-Alcalde, Brian S. Alper"}, {"code": "expert-comments", "valueString": "2021-08-27 comment: I think the word \"text\" should be \"test\" in the Alternative term and definition. Please consider broadening this term and definition to include distortions in how the index event is determined"}], "definition": "A detection bias due to distortions in how the index test result is determined.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "bias for index test result determination"}]}, {"code": "SEVCO:00383", "display": "data entry bias", "definition": "A detection bias due to differences between measured values and recorded values.", "property": [{"code": "comment", "valueString": "Data Entry Bias may include distorted results due to errors in transcription, translation, or transposition between the measured value and the recorded value, or between a recorded value and a subsequent recording of the value."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Janice Tufte, Muhammad Afzal, Kenneth Wilkins"}, {"code": "approval", "valueString": "2022-08-26 vote 7-0 by nisha mathew, Philippe Rocca-Serra, Jesus Lopez-Alcalde, Harold Lehmann, Mario Tristan, Cau\u00ea Monaco, Eric Harvey"}], "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "data recording bias"}]}, {"code": "SEVCO:00389", "display": "inappropriate time interval between predictor assessment and outcome determination", "definition": "A detection bias involving the time interval between the observation of the predictor and outcome, where the interval used by the study differs from the interval assumed by the predictive model.", "property": [{"code": "comment", "valueString": "Nonrepresentative observation period for outcome of interest is defined as an outcome ascertainment bias due to differences in the period used for observation of the outcome and the period for the outcome of interest.\n\nNonrepresentative observation period for exposure of interest is defined as an exposure ascertainment bias due to differences in the time period used for observation of the exposure and the intended time period for the exposure of interest.\n\nIn the context of predictive modeling, the time interval between the exposure (predictor) and the outcome should be representative of the time interval of interest."}, {"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Muhammad Afzal, Kenneth Wilkins, Harold Lehmann"}, {"code": "negative-vote", "valueString": "2023-10-06 vote 3-1 by Jesus Lopez-Alcalde, Harold Lehmann, Eric Harvey, Paul Whaley"}, {"code": "expert-comments", "valueString": "2023-10-06 comment: Two problems: (1) I am not sure how the definition equates to the term - in the term, it is about inappropriate time interval, but in the definition it is about the time interval not being that which is intended and representative of application of model. (2) I don't understand what is meant by the phrase \"the intended time interval between the predictor and outcome that is representative of the application of the predictive model\" - there are too many concepts all at once here, I think?"}, {"code": "approval", "valueString": "2023-10-20 vote 5-0 by Muhammad Afzal, Eric Harvey, Harold Lehmann, Louis Leff, Joanne Dehnbostel"}]}]}, {"code": "SEVCO:00021", "display": "analysis bias", "definition": "A bias related to the analytic process applied to the data.", "property": [{"code": "editors", "valueString": "Harold Lehmann, Brian S. Alper, Joanne Dehnbostel, Janice Tufte, Philippe Rocca-Serra, Mhuammad Afzal, Kenneth Wilkins"}, {"code": "approval", "valueString": "6/6 as of 8/15/2021: Harold Lehmann, Brian S. Alper, Joanne Dehnbostel, Janice Tufte, Mhuammad Afzal, Eric Harvey"}], "concept": [{"code": "SEVCO:00022", "display": "bias related to selection of the analysis", "definition": "An analysis bias due to inappropriate choice of analysis methods before the analysis is applied.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "analysis selection bias"}], "property": [{"code": "editors", "valueString": "Harold Lehmann, Brian S. Alper, Joanne Dehnbostel, Janice Tufte, Philippe Rocca-Serra, Mhuammad Afzal, Kenneth Wilkins"}, {"code": "approval", "valueString": "6/6 as of 8/15/2021: Harold Lehmann, Brian S. Alper, Joanne Dehnbostel, Janice Tufte, Mhuammad Afzal, Eric Harvey"}, {"code": "comment", "valueString": "An analysis selection after the analysis is applied would be considered a Selective Analysis Reporting Bias."}, {"code": "external-definitions", "valueString": "ROBIS 4.2 Were all pre-defined analyses reported or departures explained?"}], "concept": [{"code": "SEVCO:00376", "display": "bias related to selection of the data for analysis", "concept": [{"code": "SEVCO:00213", "display": "bias due to post-baseline factors influencing selection of the data for analysis", "definition": "A bias related to selection of the data analysis based on participant characteristics observed after study enrollment.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Mario Tristan, Joanne Dehnbostel"}, {"code": "external-definitions", "valueString": "ROBINS-I 2.1. Was selection of participants into the study (or into the analysis) based on participant characteristics observed after the start of intervention?"}, {"code": "approval", "valueString": "2022-05-13 vote 6-0 by Eric Harvey, raradhikaag@gmail.com, Jesus Lopez-Alcalde, Janice Tufte, Mario Tristan, Paola Rosati"}]}, {"code": "SEVCO:00312", "display": "missing or inadequate intention-to-treat analysis", "definition": "A bias related to selection of the data analysis in which data are not completely analyzed according to the original assignment to comparison groups in an interventional study.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Mario Tristan, Joanne Dehnbostel"}, {"code": "negative-vote", "valueString": "2022-05-13 vote 4-1 by Eric Harvey, raradhikaag@gmail.com, Jesus Lopez-Alcalde, Mario Tristan, Paola Rosati\n2022-05-20 vote 9-1 by Joanne Dehnbostel, nelle.stocquart@kce.fgov.be, Eric M Harvey, Jesus Lopez-Alcalde, Paul Whaley, Robin Ann Yurk, Harold Lehmann, raradhikaag@gmail.com, Mario Tristan, Paola Rosati\n2022-05-27 vote 4-1 by Robin Ann Yurk, Mario Tristan, Jesus Lopez-Alcalde, Eric M Harvey, Harold Lehmann"}, {"code": "expert-comments", "valueString": "2022-05-13 comment: Instead of defining \"Inadequate intention-to-treat analysis\" why not defining waht \"intention-to-treat analysis\" is?\n2022-05-20 comment: Suggest change term name to Intention to Treat Analysis and remove word inadequate from the term as this term includes the limitation of the analysis in the definition.\n2022-05-27 comment: Missing Data Analysis:  examples are imputation of data according to rules. \nPurpose:  To provide additional validity that the data are not biased from the missing data. {{2022-05-27 discussion suggests this can be handled by the SEVCO:00307 term [Inappropriate handling of missing data] which is classified as a 'Bias in processing of data'}}"}, {"code": "comment", "valueString": "An intention-to-treat analysis may be defined as analysis of all randomized subjects according to their assigned intervention rather than according to the intervention actually received. There is considerable variation in reported studies with respect to the use of the term 'intention-to-treat analysis' and 'modified intention-to-treat analysis' but if the risk of bias assessment suggests an insufficient accounting for all participants as intended then one may report 'Inadequate intention-to-treat analysis'.\nIn non-randomized studies, this term may be used to denote missing or inadequate analysis according to the intended treatment, e.g prescribed medication vs. taken medication."}, {"code": "approval", "valueString": "2022-06-03 vote 6-0 by Joanne Dehnbostel, Mario Tristan, Eric M Harvey, Harold Lehmann, Brian S. Alper, Jesus Lopez-Alcalde"}], "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "inadequate as-randomized analysis"}]}, {"code": "SEVCO:00313", "display": "missing or inadequate per-protocol analysis", "definition": "A bias related to selection of the data analysis in which data are not completely analyzed according to the study protocol.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Mario Tristan, Joanne Dehnbostel, Paul Whaley, Harold Lehmann, Muhammad Afzal"}, {"code": "negative-vote", "valueString": "2022-05-13 vote 4-1 by Eric Harvey, raradhikaag@gmail.com, Jesus Lopez-Alcalde, Mario Tristan, Paola Rosati\n2022-05-20 vote 7-3 by Joanne Dehnbostel, nelle.stocquart@kce.fgov.be, Eric M Harvey, Jesus Lopez-Alcalde, Paul Whaley, Robin Ann Yurk, Harold Lehmann, raradhikaag@gmail.com, Mario Tristan, Paola Rosati\n2022-05-27 vote 4-1 by Robin Ann Yurk, Mario Tristan, Jesus Lopez-Alcalde, Eric M Harvey, Harold Lehmann"}, {"code": "expert-comments", "valueString": "2022-05-20 comments: I do not fully agree with this definition. I propose following the Cochrane Handbook: \nNa\u00efve \u2018per-protocol\u2019 analysis: analysis restricted to individuals who adhered to their assigned interventions.\n\nMoreover, there is another analysis that is often biased: \n\n\u2018As-treated\u2019 analysis: analysis in which participants are analysed according to the intervention they actually received, even if their randomized allocation was to a different treatment group\n\nI would present these as different analyses (not as synonims)\n\nhttps://training.cochrane.org/handbook/current/chapter-08\n------\nI think I see what the definition is saying but it is rather hard to parse.\nre: \"Inadequate per-protocol analysis\" = \"A bias related to selection of the data analysis in which data are not completely analyzed according to the assignment to comparison groups according to the interventions received.\"\nSuggest edit term so it reads per protocol analysis and remove the word inadequate. This type of analysis includes the bias in the term already\n\n2022-05-13 comment: Instead of defining \"Inadequate per-protocol analysis\" why not defining what \"per-protocol anlysis\" is?\n\n2022-05-27 comment: Missing Data Analysis:  examples are imputation of data according to rules. \nPurpose:  To provide additional validity that the data are not biased from the missing data. {{2022-05-27 discussion suggests this can be handled by the SEVCO:00307 term [Inappropriate handling of missing data] which is classified as a 'Bias in processing of data'}}"}, {"code": "comment", "valueString": "A per-protocol analysis may be defined as analysis of participants according to adherence to the assigned intervention (the 'treatment protocol') and/or according to adherence to the data collection protocol. Adherence may refer to adherence by the study participants or study personnel."}, {"code": "approval", "valueString": "2022-06-03 vote 6-0 by Joanne Dehnbostel, Mario Tristan, Eric M Harvey, Harold Lehmann, Brian S. Alper, Jesus Lopez-Alcalde"}]}, {"code": "SEVCO:00381", "display": "missing or inadequate as-treated analysis", "definition": "A bias related to selection of the data analysis in which data are not completely analyzed according to the interventions actually received.", "property": [{"code": "comment", "valueString": "An as-treated analysis may be defined as analysis of subjects according to the intervention actually received rather than their assigned intervention."}, {"code": "editors", "valueString": "Brian S. Alper, Paul Whaley, Harold Lehmann, Joanne Dehnbostel"}, {"code": "expert-comments", "valueString": "2022-05-20 comments (from precursor term of Inadequate per-protocol analysis): I do not fully agree with this definition. I propose following the Cochrane Handbook: \nNa\u00efve \u2018per-protocol\u2019 analysis: analysis restricted to individuals who adhered to their assigned interventions.\n\nMoreover, there is another analysis that is often biased: \n\n\u2018As-treated\u2019 analysis: analysis in which participants are analysed according to the intervention they actually received, even if their randomized allocation was to a different treatment group\n\nI would present these as different analyses (not as synonims)\n\nhttps://training.cochrane.org/handbook/current/chapter-08\n------\nI think I see what the definition is saying but it is rather hard to parse.\nre: \"Inadequate per-protocol analysis\" = \"A bias related to selection of the data analysis in which data are not completely analyzed according to the assignment to comparison groups according to the interventions received.\"\nSuggest edit term so it reads per protocol analysis and remove the word inadequate. This type of analysis includes the bias in the term already\n\n2022-05-27 comment: Missing Data Analysis:  examples are imputation of data according to rules. \nPurpose:  To provide additional validity that the data are not biased from the missing data. {{2022-05-27 discussion suggests this can be handled by the SEVCO:00307 term [Inappropriate handling of missing data] which is classified as a 'Bias in processing of data'}}"}, {"code": "approval", "valueString": "2022-06-03 vote 6-0 by Joanne Dehnbostel, Mario Tristan, Eric M Harvey, Harold Lehmann, Brian S. Alper, Jesus Lopez-Alcalde"}]}], "definition": "An analysis bias due to inappropriate choice of data included in the analysis before the analysis is applied.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Mario Tristan, Joanne Dehnbostel"}, {"code": "comment", "valueString": "An analysis selection after the analysis is applied would be considered a Selective Analysis Reporting Bias."}, {"code": "approval", "valueString": "2022-05-13 vote 6-0 by Eric Harvey, raradhikaag@gmail.com, Jesus Lopez-Alcalde, Janice Tufte, Mario Tristan, Paola Rosati"}]}, {"code": "SEVCO:00377", "display": "bias related to selection of the variables for analysis", "concept": [{"code": "SEVCO:00292", "display": "bias related to selection of the variables for adjustment for confounding", "definition": "An analysis bias due to inappropriate choice of the variables for adjustment for confounding before the analysis is applied.", "property": [{"code": "comment", "valueString": "An analysis selection after the analysis is applied would be considered a Selective Analysis Reporting Bias."}, {"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Mario Tristan, Joanne Dehnbostel, Muhammad Afzal"}, {"code": "approval", "valueString": "2022-05-13 vote 5-0 by Eric Harvey, raradhikaag@gmail.com, Jesus Lopez-Alcalde, Mario Tristan, Paola Rosati"}, {"code": "expert-comments", "valueString": "This term was determined to also match 'Post-intervention confounding different (draft) Code: SEVCO:00283' which was originally derived from the trigger question from ROBINS-I: 1.6. Did the authors control for any post-intervention variables that could have been affected by the intervention?   Detailed analysis found this to be more about improper control of 'confounding variables' that were not truly confounding variables."}], "concept": [{"code": "SEVCO:00299", "display": "bias controlling for time-varying confounding", "definition": "A bias related to selection of the variables for adjustment for confounding in which the confounding is time-dependent.", "property": [{"code": "comment", "valueString": "An analysis selection after the analysis is applied would be considered a Selective Analysis Reporting Bias."}, {"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Joanne Dehnbostel, Mario Tristan, Muhammad Afzal"}, {"code": "approval", "valueString": "2022-05-13 vote 6-0 by Eric Harvey, raradhikaag@gmail.com, Jesus Lopez-Alcalde, Mario Tristan, Paola Rosati, Janice Tufte"}]}, {"code": "SEVCO:00301", "display": "inadequate adherence effect analysis", "definition": "A bias related to selection of the variables for adjustment for confounding by adherence.", "property": [{"code": "comment", "valueString": "An analysis selection after the analysis is applied would be considered a Selective Analysis Reporting Bias."}, {"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Mario Tristan, Joanne Dehnbostel, Muhammad Afzal"}, {"code": "approval", "valueString": "2022-05-13 vote 6-0 by Eric Harvey, raradhikaag@gmail.com, Jesus Lopez-Alcalde, Mario Tristan, Paola Rosati, Janice Tufte"}], "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "bias controlling for adherence effect"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "bias controlling for confounding by adherence"}]}]}, {"code": "SEVCO:00302", "display": "predictors included in outcome definition", "definition": "An analysis bias due to inappropriate choice of the variables for estimation of association in which one variable is incorporated in the definition of the other variable.", "property": [{"code": "comment", "valueString": "Predictors are also called covariates, risk indicators, prognostic factors, determinants, index test results, or independent variables (https://www.acpjournals.org/doi/10.7326/M18-1377).\n\nIf a predictor in the model forms part of the definition or assessment of the outcome that the model predicts, the association between predictor and outcome will likely be overestimated, and estimates of model performance will be optimistic; in diagnostic research, this problem is generally called incorporation bias. (https://www.acpjournals.org/doi/10.7326/M18-1377)\n\nWhen this type of analysis bias is applied to predictive model analyses (in which the predictor is the exposure of interest), this type of bias is equivalent to \"Incorporation bias for outcome determination\" [SEVCO:00063]"}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Kenneth Wilkins"}, {"code": "approval", "valueString": "2022-07-29 vote 5-0 by Janice Tufte, Philippe Rocca-Serra, Jesus Lopez-Alcalde, Harold Lehmann, Eric Harvey"}, {"code": "expert-comments", "valueString": "2022-07-29 comment: should \"incorporation bias\" be added as 'Alternative term' ?"}]}, {"code": "SEVCO:00319", "display": "bias related to selection of predictors based on univariable analysis", "definition": "An analysis bias due to inappropriate choice of the predictor variables for estimation of association in which predictors are selected based on statistically significant univariable associations (without adjustment for other predictors).", "property": [{"code": "comment", "valueString": "Predictors are also called covariates, risk indicators, prognostic factors, determinants, index test results, or independent variables (https://www.acpjournals.org/doi/10.7326/M18-1377)."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Kenneth Wilkins"}, {"code": "external-definitions", "valueString": "PROBAST (https://www.acpjournals.org/doi/10.7326/M18-1377).:\n4.5 Was selection of predictors based on univariable analysis avoided? (Model development studies only)\n\nA data set will often have many features that could be used as candidate predictors, and in many studies researchers want to reduce the number of predictors during model development to produce a simpler model.\n\nIn a univariable analysis, individual predictors are tested for their association with the outcome. Researchers often select the predictors with a statistically significant univariable association (for example, P < 0.05) for inclusion in the development of a final prediction model. This method can lead to incorrect predictor selection because predictors are chosen on the basis of their statistical significance as a single predictor rather than in context with other predictors (49, 50, 191). Bias occurs when univariable modeling results in omission of variables from the model, because some predictors are important only after adjustment for other predictors, known from previous research to be important, did not reach statistical significance in the particular development set (for example, due to small sample size). Also, predictors may be selected on the basis of a spurious (accidental) association with the outcome in the development set.\n\nA better approach to decide on omitting, combining, or including candidate predictors in multivariable modeling is to use nonstatistical methods\u2014that is, methods without any statistical univariable pretesting of the associations between candidate predictors and outcome. Better methods include those based on existing knowledge of previously established predictors in combination with the reliability, consistency, applicability, availability, and costs of predictor measurement relevant to the targeted setting. Well-established predictors and those with clinical credibility should be included and retained in a prediction model regardless of any statistical significance (49, 50, 192). Alternatively, some statistical methods that are not based on prior statistical tests between predictor and outcome can be used to reduce the number of modeled predictors (for example, principal components analysis)."}, {"code": "approval", "valueString": "2022-07-29 vote 5-0 by Janice Tufte, Philippe Rocca-Serra, Jesus Lopez-Alcalde, Harold Lehmann, Eric Harvey"}]}], "definition": "An analysis bias due to inappropriate choice of variables included in the analysis before the analysis is applied.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Mario Tristan, Joanne Dehnbostel, Muhammad Afzal"}, {"code": "comment", "valueString": "An analysis selection after the analysis is applied would be considered a Selective Analysis Reporting Bias."}, {"code": "approval", "valueString": "2022-05-13 vote 5-0 by Eric Harvey, raradhikaag@gmail.com, Jesus Lopez-Alcalde, Mario Tristan, Paola Rosati"}]}, {"code": "SEVCO:00378", "display": "bias related to selection of the analytic framework", "concept": [{"code": "SEVCO:00297", "display": "inappropriate statistical model", "definition": "A bias related to selection of the analytic framework in which the analytic model does not match the dataset characteristics or does not match the intention of the analysis.", "property": [{"code": "comment", "valueString": "A bias related to selection of the analytic framework is defined as an analysis bias due to inappropriate choice of the analytic framework before the analysis is applied.\n\nAn inappropriate statistical model may include one in which there is a mismatch between the realities of the data and the assumptions required for the analytic model. Complexities in the data may include univariate concerns (e.g. skewness or outliers) and multivariate concerns (e.g. curvilinearity, co-linearity, or latent associations between variables)."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Kenneth Wilkins, Muhammad Afzal, Joanne Dehnbostel"}, {"code": "negative-vote", "valueString": "2022-05-20 vote 5-1 by Joanne Dehnbostel, Eric M Harvey, Mario Tristan, Jesus Lopez-Alcalde, Paul Whaley, Harold Lehmann"}, {"code": "expert-comments", "valueString": "2022-05-20 comment:\nI like this term and definition but I am not sure it is adequately differentiated from \"Bias related to selection of the analytic framework\". I think the term needs changing in some way.\n2022-09-30 Steering Group change to Comment to application: comment added to this term instead of creating a new term for 'Inappropriate handling of complexities in the data'"}, {"code": "approval", "valueString": "2022-05-27 vote 5-0 by Mario Tristan, Jesus Lopez-Alcalde, Eric M Harvey, Harold Lehmann, Joanne Dehnbostel"}], "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "inappropriate analytic model"}], "concept": [{"code": "SEVCO:00375", "display": "inappropriate modeling of censoring", "property": [{"code": "external-definitions", "valueString": "PROBAST 4.6 Were complexities in the data (e.g. censoring, competing risks, sampling of controls) accounted for appropriately?"}, {"code": "comment", "valueString": "An inappropriate statistical model is a bias related to selection of the analytic framework in which the analytic model does not match the dataset characteristics or does not match the intention of the analysis.\n\nThe \"ranges of potential observation\" may include periods of time (temporal ranges within which observation may occur), or ranges of detection with a measurement instrument  (ranges of values that could be observed).\n\nThe concept of ranges of potential observation in which data observation is \"not possible\" may include impossibility due to physical realities (such as timing after competing risks or measurement instruments with limited ranges of detection) or impossibility due to administrative decisions (such as the observation period defined by the study protocol)."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Kenneth Wilkins, Joanne Dehnbostel, Muhammad Afzal"}, {"code": "approval", "valueString": "2022-10-20 vote 7-0 by Philippe Rocca-Serra, Harold Lehmann, Joanne Dehnbostel, Mario Tristan, Paul Whaley, Janice Tufte, Eric Harvey"}], "definition": "An inappropriate statistical model due to inappropriate accounting for ranges of potential observation in which data observation is not possible."}]}, {"code": "SEVCO:00316", "display": "bias due to selection of the statistical significance threshold", "definition": "An analysis bias resulting from selection of an inappropriate threshold for statistical significance.", "concept": [{"code": "SEVCO:00317", "display": "bias related to multiple comparison adjustment", "definition": "An analysis bias resulting from selection of a threshold for statistical significance which does not appropriately account for the effect of multiple comparisons on the statistical probability related to the result.", "property": [{"code": "comment", "valueString": "This bias may cause inappropriate rejection of the null hypothesis due to an unmodified threshold for significance in the face of multiple comparisons. This bias may also occur when adjustment for multiple comparisons is inappropriately applied and leads to failure to reject the null hypothesis.\n\nA bias due to selection of the statistical significance threshold is defined as an analysis bias resulting from selection of an inappropriate threshold for statistical significance.\n\nIn frequentist analysis, statistical significance is the rejection of the null hypothesis based on the p value. In Bayesian analysis, statistical significance is the acceptance of the hypothesis based on the posterior probability."}, {"code": "editors", "valueString": "Harold Lehmann, Kenneth Wilkins, Joanne Dehnbostel, Paul Whaley"}, {"code": "negative-vote", "valueString": "2022-06-10 vote 3-2 by Brian S. Alper, Robin Ann Yurk, Paola Rosati, Mario Tristan, Harold Lehmann\n2022-06-17 vote 4-1 by Paul Whaley, Muhammad Afzal, Eric M Harvey, Jesus Lopez-Alcalde, Paola Rosati"}, {"code": "expert-comments", "valueString": "2022-06-10 comments: The measure does not have a statistical probability, the finding or result has a statistical probability. Change definition to \"A statistical significance threshold selection bias in which the threshold for statistical significance does not account for the effect of multiple comparisons on the statistical probability related to the result.\"Is this a bias or just an incomplete analysis due to data requirements needed to compute the multiple comparison adjustment.\n2022-06-17  comment: Looking at the significance threshold bias terms, the other two refer to selection of the analytic framework, but this one does not. Is there a reason for that?"}, {"code": "approval", "valueString": "2022-06-24 vote 5-0 by Muhammad Afzal, Mario Tristan, Harold Lehmann, Eric Harvey, Louis Leff"}]}, {"code": "SEVCO:00382", "display": "mismatch of significance threshold and purpose", "definition": "An analysis bias resulting from selection of a threshold for statistical significance which is inappropriate due to a mismatch between (1) how the statistical probability related to the result is determined and (2) the purpose for categorizing the result as statistically significant.", "property": [{"code": "comment", "valueString": "A threshold used for variable selection in regression analysis is often more liberal than a threshold used in hypothesis testing. Similarly a situation regarding safety may tolerate a higher chance of false positive findings so significance threshold may be higher. Some factors to consider include sample size, power of the test, and expected losses from Type I and Type II errors.\n\nIn frequentist analysis, statistical significance is the rejection of the null hypothesis based on the p value. In Bayesian analysis, statistical significance is the acceptance of the hypothesis based on the posterior probability."}, {"code": "editors", "valueString": "Harold Lehmann, Kenneth Wilkins, Joanne Dehnbostel, Mario Tristan, Paul Whaley"}, {"code": "external-definitions", "valueString": "How to Choose the Level of Significance: A Pedagogical Note -- The level of significance should be chosen with careful consideration of the key factors such as the sample size, power of the test, and expected losses from Type I and II errors. While the conventional levels may still serve as practical benchmarks, they should not be adopted mindlessly and mechanically for every application.  \n(https://mpra.ub.uni-muenchen.de/66373/1/MPRA_paper_66373.pdf)"}, {"code": "negative-vote", "valueString": "2022-06-10 vote 2-2 by Brian S. Alper, Robin Ann Yurk, Mario Tristan, Harold Lehmann\n2022-06-17 vote 4-1 by Paul Whaley, Muhammad Afzal, Eric M Harvey, Jesus Lopez-Alcalde, Paola Rosati"}, {"code": "expert-comments", "valueString": "2022-06-10 comments: A mismatch can occur even if the purpose was taken into account. As the term name \"Mismatch of significance threshold and purpose\" is a match for the definition of the parent term (Statistical significance threshold selection bias) there is a question of whether this term is needed.\nReceiver operator curves are traditionally a statistic used to represent the continuum of cut point for the threshold value.  The Sensitivity and Specificity can be calculated to evaluate the validity of the threshold cut point.\n2022-06-17 comment: Add \"Bias related to...\" at beginning for consistency with others. What work is \"selection of the analytic framework\" doing in this definition?"}, {"code": "approval", "valueString": "2022-06-24 vote 5-0 by Muhammad Afzal, Mario Tristan, Harold Lehmann, Eric Harvey, Janice Tufte"}]}], "property": [{"code": "comment", "valueString": "The statistical significance threshold is part of the analytic framework. A bias related to selection of the analytic framework is defined as an analysis bias due to inappropriate choice of the analytic framework before the analysis is applied.\n\nIn frequentist analysis, statistical significance is the rejection of the null hypothesis based on the p value. In Bayesian analysis, statistical significance is the acceptance of the hypothesis based on the posterior probability."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Kenneth Wilkins, Muhammad Afzal, Joanne Dehnbostel, Paul Whaley"}, {"code": "negative-vote", "valueString": "2022-06-10 vote 5-1 by Brian S. Alper, Robin Ann Yurk, Paola Rosati, Mario Tristan, Harold Lehmann, Eric M Harvey\n2022-06-17 vote 4-1 by Paul Whaley, Muhammad Afzal, Eric M Harvey, Jesus Lopez-Alcalde, Paola Rosati"}, {"code": "expert-comments", "valueString": "2022-06-10 comment: Consider editing the term definition to just Statistical significance threshold.  For the Alternative term remove word bias.  For the comment for application remove the first sentence about bias.\n2022-06-17 comments: I think I get it, but it is a bit tortured and I wonder if a normal user would interpret it correctly or understand it?\nI am not sure we can rephrase the concept name making it more compact like \"Statistical significance threshold selection bias\""}, {"code": "approval", "valueString": "2022-06-24 vote 5-0 by Mario Tristan, Harold Lehmann, Eric Harvey, Janice Tufte, Louis Leff"}], "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "significance-threshold selection bias"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "statistical significance threshold selection bias"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "bias related to selection of the threshold for statistical significance"}]}, {"code": "SEVCO:00304", "display": "immortal time bias", "definition": "A bias related to selection of the analytic framework in which an outcome variable includes an observation period during which the outcome could not have occurred.", "property": [{"code": "comment", "valueString": "Consider a study in which a sample is followed from 2000 to 2010. Mortality during this time period is the outcome, and receipt of Superdrug is the exposure. \n--If 20 people received Superdrug in 2009 and 5 of them died in the subsequent year, the mortality with Superdrug is 25%. \n--If 20 people never received Superdrug and 1 died each year so by 2010 the mortality without Superdrug is 50%. \n\nInterpreting this result as Superdrug having a 50% relative risk reduction for mortality would be biased (distorted) by not accounting for the 9 years of time (immortal time) that the Superdrug recipients must have survived to be able to receive Superdrug in 2009.\n\nIf the outcome variable were defined as mortality 2009-2010, there would be no bias and the result would be a 150% relative risk increase.\n\nIf the outcome variable were defined as mortality 2000-2010, there is an immortal time bias (the Superdrug recipients could not have died before receiving Superdrug)."}, {"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Harold Lehmann, Joanne Dehnbostel, Paul Whaley, Janice Tufte"}, {"code": "external-definitions", "valueString": "Catalog of bias:   A distortion that modifies an association between an exposure and an outcome, caused when a cohort study is designed so that follow-up includes a period of time where participants in the exposed group cannot experience the outcome and are essentially 'immortal'.\n\nin https://academic.oup.com/aje/article/167/4/492/233064 :\nImmortal time refers to a span of time in the observation or follow-up period of a cohort during which the outcome under study could not have occurred (13, 14). It usually occurs with the passing of time before a subject initiates a given exposure. While a subject is not truly immortal during this time span, the subject necessarily had to remain event free until start of exposure to be classified as exposed. An incorrect consideration of this unexposed time period in the design or analysis will lead to immortal time bias.\n\nin JAMA https://jamanetwork.com/journals/jama/article-abstract/2776315\nSuch studies may be subject to immortal time bias, meaning that, during the period of observation, there is some interval during which the outcome event cannot occur\n\nin https://watermark.silverchair.com/dyab157.pdf\nIn particular, incorrect handling of follow-up times in terms of exposure status in the analysis of such studies may introduce immortal time bias (ITB) in favour of the exposed group.2,3 Immortal time refers to a period of time in which, by design, participants in the exposed group cannot experience the outcome. This often  happens in pharmacoepidemiologic studies in which treatment is prescribed at variable times (with delay) after disease diagnosis. The bias occurs when the exposed group is considered to be exposed during their entire follow-up time (even during periods in which they are theoretically unexposed) or their unexposed follow-up times are discarded.2,3"}, {"code": "negative-vote", "valueString": "2022-07-15 vote 5-1 by Mario Tristan, Philippe Rocca-Serra, Jesus Lopez-Alcalde, Eric Harvey, Harold Lehmann, Janice Tufte"}, {"code": "expert-comments", "valueString": "2022-07-15 comment: Why the need to specify \"in a larger sample\" in the second sentence, since there is no assumption about size of the sample in the first assertion?"}, {"code": "approval", "valueString": "2022-07-22 vote 7-0 by Mario Tristan, Paul Whaley, Philippe Rocca-Serra, Harold Lehmann, Jesus Lopez-Alcalde, Janice Tuft, Eric Harvey"}]}, {"code": "SEVCO:00293", "display": "inadequate sample size", "definition": "A bias related to selection of the analytic framework in which the sample size invalidates the assumptions of the analytic framework.", "property": [{"code": "comment", "valueString": "An example of 'Inadequate sample size' is a finding of no effect with inadequate power to detect an effect. Another example of 'Inadequate sample size' is use of a parametric analysis with low numbers, which invalidates the assumptions for use of a parametric analysis."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Janice Tufte, Joanne Dehnbostel, Mario Tristan, Khalid Shahin"}, {"code": "approval", "valueString": "2022-07-22 vote 7-0 by Mario Tristan, Paul Whaley, Philippe Rocca-Serra, Harold Lehmann, Jesus Lopez-Alcalde, Janice Tuft, Eric Harvey"}], "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "inadequate numbers for analysis"}]}], "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "bias related to selection of the statistical framework"}], "definition": "An analysis bias due to inappropriate choice of the analytic framework before the analysis is applied.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Mario Tristan, Joanne Dehnbostel, Muhammad Afzal"}, {"code": "comment", "valueString": "An analytic framework is the model, scaffolding, or organizational representation of concepts used in analyzing the data. The concepts included in an analytic framework may involve data, variables, formulas, assumptions, and adjustments."}, {"code": "negative-vote", "valueString": "2022-05-13 vote 6-0 by Eric Harvey, raradhikaag@gmail.com, Jesus Lopez-Alcalde, Mario Tristan, Paola Rosati, Janice Tufte [[but then the term changed in webmeeting 2022-05-13]]\n2022-05-20 vote 4-2 by Joanne Dehnbostel, Eric M Harvey, Mario Tristan, Jesus Lopez-Alcalde, Paul Whaley, Harold Lehmann"}, {"code": "expert-comments", "valueString": "2022-05-20 comments:\nseems to be entirely too much overlap with the \"inappropriate analytic framework\" term\n\nI like this term and definition but I am not sure it is adequately differentiated from \"inappropriate analytical framework\". I think the term needs changing in some way."}, {"code": "approval", "valueString": "2022-05-27 vote 5-0 by Mario Tristan, Jesus Lopez-Alcalde, Eric M Harvey, Harold Lehmann, Joanne Dehnbostel"}]}]}, {"code": "SEVCO:00294", "display": "bias related to execution of the analysis", "concept": [{"code": "SEVCO:00305", "display": "incomplete analysis", "definition": "An analysis bias due to absence of a component of the analytic process.", "property": [{"code": "comment", "valueString": "Missing components may include addressing missing data, addressing potential confounders, checking model assumptions, or robustness checks for model misspecification."}, {"code": "editors", "valueString": "Harold Lehmann, Joanne Dehnbostel, Brian S. Alper, Kenneth Wilkins, Muhammad Afzal, Khalid Shahin"}, {"code": "negative-vote", "valueString": "2022-08-12 vote 4-1 by Paul Whaley, Mario Tristan, Harold Lehmann, Janice Tufte, Eric Harvey\n2022-08-19 vote 5-1 by Paul Whaley, Mario Tristan, Harold Lehmann, Janice Tufte, Eric Harvey, Philippe Rocca-Serra\n2022-08-25 vote 8-1 by nisha mathew, Jesus Lopez-Alcalde, Cau\u00ea Monaco, Paul Whaley, Mario Tristan, Harold Lehmann, Janice Tufte, Eric Harvey, Philippe Rocca-Serra"}, {"code": "expert-comments", "valueString": "2022-08-12 comment: Ambiguous as to whether the data is incomplete or the analytic process incomplete. Also seems to be ambiguous as to whether the analysis is of a selected subset of the existing data (thus relating to selection bias?), or of data that is not representative of the totality of theoretically available data (thus relating to external validity?).\n\n2022-08-19 comment: tension between bias and process. Shouldn't it be \"incomplete analysis related bias\"? omission seems to indicate a wilful act. \"absence\" may be more neutral when considering a 'canonical / state of the art / standardised ' protocol.\n\n\"An analysis bias due to absence of a component deemed necessary in a state-of- art (possibly regulator-approved ) analytic process.\""}, {"code": "approval", "valueString": "2022-09-09 vote 6-0 by Philippe Rocca-Serra, Harold Lehmann, Jesus Lopez-Alcalde, Khalid Shahin, Janice Tufte, Eric Harvey"}], "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "incomplete analysis process"}]}, {"code": "SEVCO:00306", "display": "inappropriate handling of uninterpretable data", "definition": "An analysis bias due to omission of uninterpretable values, or their replacement with inappropriate values.", "property": [{"code": "editors", "valueString": "Harold Lehmann, Joanne Dehnbostel, Brian S. Alper, Kenneth Wilkins, Muhammad Afzal"}, {"code": "negative-vote", "valueString": "2022-08-12 vote 4-1 by Paul Whaley, Mario Tristan, Harold Lehmann, Janice Tufte, Eric Harvey"}, {"code": "expert-comments", "valueString": "2022-08-12 comment: I'm not sure I would understand the definition if I had not read the term, suggest rephrasing - \"omission of accommodation for\" is perhaps the problem part."}, {"code": "comment", "valueString": "Inappropriate values may include use of non-representative imputation treating uninterpretable data like missing data. \n\nIn evaluation of diagnostic tests, omission of or inappropriate classification of test results would be Inappropriate handling of uninterpretable data."}, {"code": "approval", "valueString": "2022-09-16 vote 5-0 by Mario Tristan, Janice Tufte, Eric Harvey, Yaowaluk Ngoenwiwatkul, nisha mathew"}]}, {"code": "SEVCO:00307", "display": "inappropriate handling of missing data", "definition": "An analysis bias due to use of non-representative values in place of missing data.", "property": [{"code": "comment", "valueString": "Handling of missing data may address data missing at levels of single observations or groupings by encounter, participant, site, or subpopulation."}, {"code": "editors", "valueString": "Harold Lehmann, Joanne Dehnbostel, Brian S. Alper, Kenneth Wilkins"}, {"code": "approval", "valueString": "2022-08-12 vote 5-0 by Paul Whaley, Mario Tristan, Harold Lehmann, Janice Tufte, Eric Harvey"}]}, {"code": "SEVCO:00308", "display": "inappropriate handling of variables", "definition": "An analysis bias due to processing a variable in an incorrect role or with an incorrect datatype.", "property": [{"code": "comment", "valueString": "Typical variable roles are population, exposure, confounder, and outcome.\n\nA variable datatype may be numerical (continuous or discrete) or categorical (ordinal or nominal)."}, {"code": "editors", "valueString": "Harold Lehmann, Joanne Dehnbostel, Brian S. Alper, Kenneth Wilkins"}, {"code": "approval", "valueString": "2022-09-16 vote 5-0 by Mario Tristan, Janice Tufte, Eric Harvey, Yaowaluk Ngoenwiwatkul, nisha mathew"}, {"code": "change-for-vote", "valueString": "Consider types to include Inappropriate handling of confounders, and Inappropriate handling of measurement error"}]}, {"code": "SEVCO:00300", "display": "bias in adjustment for selection bias", "definition": "An analysis bias due to inappropriate application of adjustment techniques for correction of bias in the selection of participants for analysis.", "property": [{"code": "comment", "valueString": "Bias in the selection of participants for analysis could occur due to Participant Selection Bias (SEVCO:00003) or participant-level Bias related to selection of the data for analysis (SEVCO:00376).\n\n\"It is in principle possible to correct for selection biases, for example by using inverse probability weights to create a pseudo-population in which the selection bias has been removed, or by modelling the distributions of the missing participants or follow up times and outcome events and including them using missing data methodology.\" (Sterne JA, Hern\u00e1n MA, Reeves BC, et al. ROBINS-I: a tool for assessing risk of bias in non-randomised studies of interventions. BMJ. 2016 Oct 12;355:i4919. doi: 10.1136/bmj.i4919. PMID: 27733354; PMCID: PMC5062054.  Supplementary Table A.)"}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Janice Tufte, Muhammad Afzal"}, {"code": "external-definitions", "valueString": "\"It is in principle possible to correct for selection biases, for example by using\ninverse probability weights to create a pseudo-population in which the\nselection bias has been removed, or by modelling the distributions of the\nmissing participants or follow up times and outcome events and including\nthem using missing data methodology.\" (Sterne JA, Hern\u00e1n MA, Reeves BC, et al. ROBINS-I: a tool for assessing risk of bias in non-randomised studies of interventions. BMJ. 2016 Oct 12;355:i4919. doi: 10.1136/bmj.i4919. PMID: 27733354; PMCID: PMC5062054.  Supplementary Table A.)"}, {"code": "approval", "valueString": "2022-09-30 vote 5-0 by Jesus Lopez-Alcalde, Harold Lehmann, Janice Tufte, Eric Harve, Morufu Olalekan Raimi"}]}, {"code": "SEVCO:00309", "display": "data transition bias", "definition": "An analysis bias due to differences between recorded data and data used for analysis.", "property": [{"code": "comment", "valueString": "Data Transition Bias may include distorted results due to errors in transcription, translation, erroneous mapping, or transposition between the recorded data (values, labels, and other metadata) and the data used for analysis. Data Transition Bias may occur due to any problem encountered during the Extraction, Transformation, and Loading (ETL) process in data exchange."}, {"code": "editors", "valueString": "Harold Lehmann, Brian S. Alper, Joanne Dehnbostel, Kenneth Wilkins"}, {"code": "approval", "valueString": "2022-11-04 vote 5-0 by Philippe Rocca-Serra, Jesus Lopez-Alcalde, Janice Tufte, Harold Lehmann, Eric Harvey"}]}, {"code": "SEVCO:00311", "display": "inappropriate handling of missing confounder data", "definition": "An analysis bias due to use of non-representative values in place of missing data for variables in the role of confounder.", "property": [{"code": "comment", "valueString": "Handling of missing confounder data may address data missing at levels of single observations or groupings by encounter, participant, site, or subpopulation. Inappropriate handling of missing confounder data can result in misleading adjusted analyses."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Muhammad Afzal, Joanne Dehnbostel, Kenneth Wilkins"}, {"code": "approval", "valueString": "2022-09-16 vote 5-0 by Mario Tristan, Janice Tufte, Eric Harvey, Yaowaluk Ngoenwiwatkul, nisha mathew"}]}, {"code": "SEVCO:00298", "display": "computational implementation bias", "definition": "An analysis bias due to miscalculations in the processing of the data.", "property": [{"code": "comment", "valueString": "This bias is intended to cover a broad range of errors in curating the data and performing the calculations specified or implied by the analytic plan, including but not limited to: memory allocation and other environmental specifications, data ingestion pipeline, statistical package choice and vetting, and syntax, semantics and logic of coding. this bias can be applied to both manual or computer based computation."}, {"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Joanne Dehnbostel, Janice Tufte, Harold Lehmann, Khalid Shahin, Muhammad Afzal, Neeraj Ojha"}, {"code": "negative-vote", "valueString": "2022-08-12 vote 4-1 by Paul Whaley, Mario Tristan, Harold Lehmann, Janice Tufte, Eric Harvey\n2022-08-19 vote 4-2 by Paul Whaley, Mario Tristan, Harold Lehmann, Janice Tufte, Eric Harvey, Philippe Rocca-Serra"}, {"code": "expert-comments", "valueString": "2022-08-12 comment: Not sure about including data entry errors among errors in software code - the latter is a computational error, the former is not. Also, the definition does not specify computational processing.\n2022-08-19 comment: the class label is ambiguous: is it \"computation error caused bias\" or it is 'contradictions caused bias? The latter term does not add clarity.\nAlso, only data entry errors resulting from computational errors would fall under this type of bias, but not direct entry of values."}, {"code": "approval", "valueString": "2022-09-09 vote 6-0 by Philippe Rocca-Serra, Harold Lehmann, Jesus Lopez-Alcalde, Khalid Shahin, Janice Tufte, Eric Harvey"}], "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "bug"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "statistical programming error"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "programming error"}]}], "definition": "An analysis bias due to inappropriate decisions pertaining to preparation of data for analysis and/or conduct of the analysis.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Joanne Dehnbostel, Janice Tufte, Harold Lehmann, Paul Whaley, Yuan Gao"}, {"code": "comment", "valueString": "\"Bias related to selection of the analysis\" is used when the wrong analysis is done (the analysis is planned wrongly). \"Bias in processing of data\" is used when the analysis is done wrong (the analysis is executed wrongly)."}, {"code": "approval", "valueString": "2022-11-04 vote 5-0 by Philippe Rocca-Serra, Jesus Lopez-Alcalde, Janice Tufte, Harold Lehmann, Eric Harvey"}], "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "bias in processing of data"}]}, {"code": "SEVCO:00324", "display": "reported analysis not following pre-specified analysis plan", "definition": "An analysis bias in which the reported analysis does not match the pre-specified analysis plan.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte"}, {"code": "approval", "valueString": "2023-03-10 vote 5-0 by Joanne Dehnbostel, Mario Tristan, Harold Lehmann, Eric Harvey, Jesus Lopez-Alcalde"}]}, {"code": "SEVCO:00303", "display": "collider bias", "property": [{"code": "external-definitions", "valueString": "A structural classification of bias distinguishes between biases resulting from conditioning on common effects (\u201cselection bias\u201d) --- A Structural Approach to Selection Bias, https://journals.lww.com/epidem/Fulltext/2004/09000/A_Structural_Approach_to_Selection_Bias.20.aspx\n\nCollider bias occurs when an exposure and outcome (or factors causing these) each influence a common third variable and that variable or collider is controlled for by design or analysis. In contrast, confounding occurs when an exposure and outcome have a shared common cause that is not controlled for. -- JAMA 2022 Mar 14 https://jamanetwork.com/journals/jama/fullarticle/2790247\n\nhttps://catalogofbias.org/biases/collider-bias/ Collider bias = A distortion that modifies an association between an exposure and outcome, caused by attempts to control for a common effect of the exposure and outcome"}, {"code": "comment", "valueString": "Collider bias occurs when an exposure and outcome (or factors causing these) each influence a common third variable and that variable or collider is controlled for by design or analysis. In contrast, confounding occurs when an exposure and outcome have a shared common cause that is not controlled for. (JAMA 2022 Mar 14 https://jamanetwork.com/journals/jama/fullarticle/2790247)\n\nThe \"third variable\" affected by both variables of interest can also be a \"third variable\" affected by an \"intermediary variable\" which is affected by both variables of interest.\n\nAn analysis bias is defined as a bias related to the analytic process applied to the data.\n\nA bias is defined as a systematic distortion in research results (estimation of effect, association, or inference). Distortions in research results means differences between the reported results (findings, conclusions, effect estimates) and the actuality (the truth, the estimand [the quantity targeted for estimation])."}, {"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Harold Lehmann, Joanne Dehnbostel, Paul Whaley"}, {"code": "negative-vote", "valueString": "2022-07-01 vote 3-2 by Harold Lehmann, Paul Whaley, Jesus Lopez-Alcalde, Eric Harvey, Philippe Rocca-Serra"}, {"code": "expert-comments", "valueString": "2022-07-01 comments: Is this the same as a confounding variable? If not, please differentiate.\n\nthe first comment seems a bit confusing: does collider bias occurs when the study design controls for a variable which is influenced by both the exposure and the outcome?\n\nI'm not sure this is correct. My understanding is that collision comes into play when effect modifiers are treated as confounders (and possibly when confounders are treated as modifiers? I don't know if it is symmetric). This reads as though it is an analysis unadjusted for confounders, with the factor causing both the cause and effect variables.\n\nConfounding: A < B > C and A > C\nModification: A > B > C and A > C\nCollision: Conditioning on B under modification rather than confounding."}, {"code": "approval", "valueString": "2022-07-08 vote 5-0 by Jesus Lopez-Alcalde, Eric Harvey, Paul Whaley, Janice Tufte, Harold Lehmann"}], "definition": "An analysis bias in which an estimation of association between two variables is distorted by controlling for a third variable affected by both variables of interest (or factors causing the variables of interest)."}, {"code": "SEVCO:00314", "display": "preliminary analysis bias", "definition": "An analysis bias related to analysis of data before the complete dataset is available.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Muhammad Afzal, Kenneth Wilkins"}, {"code": "approval", "valueString": "2022-12-23 vote 6-0 by Joanne Dehnbostel, Harold Lehmann, Yuan Gao, Jesus Lopez-Alcalde, Mario Tristan, Eric Harvey"}], "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "interim analysis bias"}]}, {"code": "SEVCO:00295", "display": "data-dredging bias", "definition": "An analysis bias involving use of data analyses that are not pre-specified and fully disclosed, to select analyses with desirable results.", "property": [{"code": "comment", "valueString": "Types of data analysis that lead to data-dredging bias include but are not limited to repeated subgroup analyses, repeated adjusted analyses, repeated analyses with different analytic models, and repeated analyses across many outcomes for many variations of defining outcomes, any of which can be done to select (\"cherry-pick\") the analyses that provide a desired result.  The desired result may be statistically significant findings or other specific results.\n\nThe terms \"p-hacking\" and \"Fishing expedition\" are commonly used terms to describe data-dredging practices that lead to bias and are often used to imply bias."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Janice Tufte, Paul Whaley, Kenneth Wilkins"}, {"code": "external-definitions", "valueString": "from Catalog of Bias (https://catalogofbias.org/biases/data-dredging-bias/): Data-dredging bias = A distortion that arises from presenting the results of unplanned statistical tests as if they were a fully prespecified course of analyses.\n\nfrom BMJ Evidence-Based Medicine (https://ebm.bmj.com/content/27/4/209): Background: what is data dredging bias?\nData-dredging bias encompasses a number of more specific questionable practices (eg, fishing, p-hacking) all of which involve probing data using unplanned analyses and then reporting salient results without accurately describing the processes by which the results were generated.\n\nfrom Wikipedia (https://en.wikipedia.org/wiki/Data_dredging): Data dredging (also known as data snooping or p-hacking) is the misuse of data analysis to find patterns in data that can be presented as statistically significant, thus dramatically increasing and understating the risk of false positives."}, {"code": "expert-comments", "valueString": "2022-12-09 comment:  Ioannidis, J. P. A. (2019) P values linked to null hypothesis significance testing (NHST) is the most widely (mis)used method of statistical inference. Empirical data suggest that across the biomedical literature (1990\u20132015), when abstracts use P values 96% of them have P values of 0.05 or less. The same percentage (96%) applies for full-text articles. \n2022-12-16 comments: Delete comma in definition (before \"that\"). \np-hacking and fishing expedition aren't synonyms but data processes leading to bias. \"p-hacking induced bias\" maybe"}, {"code": "negative-vote", "valueString": "2022-12-09 votes 4-0 by Yuan Gao, Mario Tristan, Eric Harvey, Harold Lehmann\n2022-12-16 votes 6-1 by Philippe Rocca-Serra, Janice Tufte, Yuan Gao, Jesus Lopez-Alcalde, Mario Tristan, Eric Harvey, Harold Lehmann"}, {"code": "approval", "valueString": "2022-12-23 vote 6-0 by Joanne Dehnbostel, Harold Lehmann, Yuan Gao, Jesus Lopez-Alcalde, Mario Tristan, Eric Harvey"}], "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "p-hacking"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "fishing expedition"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "data snooping bias"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "p-hacking bias"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "fishing expedition bias"}]}, {"code": "SEVCO:00348", "display": "inadequate sensitivity analysis", "definition": "An analysis bias due to inadequate approach to determine the implications of modeling assumptions, missing data, or distorted data for the interpretation of research results.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "inadequate robustness analysis"}], "property": [{"code": "external-definitions", "valueString": "ROBIS 4.5 Were the findings robust, e.g. as demonstrated through funnel plot or sensitivity analyses?"}, {"code": "comment", "valueString": "Sensitivity analysis is the process of accounting for the implications of missing or distorted data or modeling assumptions. The purpose of sensitivity analysis is to assess the robustness of findings given plausible variations in the context.\n\nMethods of sensitivity analysis to account for missing data include but are not limited to best-case scenario, worst-case scenario, and last-observation-carried-forward. Methods of sensitivity analysis to account for distorted data include but are not limited to intention-to-treat analysis, per-protocol analysis, and completer analysis.   Methods of sensitivity analysis to account for modeling assumptions include but are not limited to variations in prior probabilities and changes in the statistical model.\n\nThe targets and types of sensitivity analyses needed depend on the research question, the research design, the data, modeling assumptions (both verifiable and unverifiable from the data), and the context of the results interpretation. The adequacy of sensitivity analysis is assessed on the basis of the targets and types of sensitivity analyses reported.\n\nThe term 'inadequate sensitivity analysis' matches the ROBIS signaling question 4.5 ''Were the findings robust, e.g. as demonstrated through funnel plot or sensitivity analyses?'\n\nA funnel plot may be used to detect missing data due to publication bias. Although funnel plot asymmetry has been equated with publication bias, the funnel plot displays a tendency for the intervention effects estimated in smaller studies to differ from those estimated in larger studies, and such small-study effects may be due to reasons other than publication bias. (Egger M, Smith GD, Schneider M, Minder C. Bias in meta-analysis detected by a simple, graphical test. BMJ 1997; 315: 629-634.) Consider also [inadequate accounting for heterogeneity](https://fevir.net/resources/CodeSystem/27270#SEVCO:00347).\n\nAn inadequate sensitivity analysis does not result in a bias in the effect estimates, but may result in a bias in the interpretations derived from the effect estimates."}, {"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Saphia Mokrane, Homa Keshavarz, Joanne Dehnbostel, Harold Lehmann, Airton Stein"}, {"code": "negative-vote", "valueString": "2024-07-05 vote 4-1 by C P Ooi, Sheyu Li, Lenny Vasanthan, Eric Harvey, Harold Lehmann\n2024-07-12 vote 6-1 by Paul Whaley, Cau\u00ea Monaco, Sheyu Li, Philippe Rocca-Serra, Lenny Vasanthan, Saphia Mokrane, Eric Harvey\n2024-07-19 vote 5-1 by Carlos Alva-Diaz, Sheyu Li, Harold Lehmann, Homa Keshavarz, Lenny Vasanthan, Eric Harvey"}, {"code": "expert-comments", "valueString": "2024-07-05 comments re: \"inadequate sensitivity analysis\" = \"A synthesis bias due to inadequate approach to determine the magnitude or implications of missing or distorted data.\"1N) My understanding of the main purpose of sensitivity analysis can be testing the robustness of the findings and determining  its impact factors. \n2) (The paragraph on funnel plot sounds more textbooky/prescriptive information than we have generally provided, but I'm not against including it.)\n\n2024-07-12 comment re: \"inadequate sensitivity analysis\" = \"An analysis bias due to inadequate approach to determine the implications of missing data, distorted data, or modeling assumptions.\"1N) Need explanation regarding the term 'inadequate', which reflects clinical impact of this inadequate. \n\n2024-07-19 comments re: \"inadequate sensitivity analysis\" = \"An analysis bias due to inadequate approach to determine the implications of missing data, distorted data, or modeling assumptions.\"1N)\nThe sensitivity analyses achieves multiple targets including but not limited to the quoted ones. But all try to make sure the robustness of the findings given heterogeneous research approaches. For the definition, it is good to quote the definition of sensitivity analysis, especially its purpose. \n\nAlso, inadequate sensitivity analysis is rather a bias, but a failure to reach to purpose of sensitivity analysis. \n2Y)\nI am not suggesting changes, but I had to ask chatGPT today about sensitivity analysis. This was its response:\n\nSensitivity analysis is a technique used in the context of analyzing real-world data to assess how the results of a study or model are affected by changes in the input parameters or assumptions. It helps to understand the robustness of the findings and identify which variables have the most significant impact on the outcomes. Sensitivity analysis is particularly useful in fields such as economics, healthcare, environmental science, and engineering, where models often rely on uncertain or variable data inputs.\n\nKey Aspects of Sensitivity Analysis\nPurpose:\n\nTo evaluate the stability and reliability of the results.\nTo identify critical variables that significantly influence the outcomes.\nTo assess the impact of uncertainty in input parameters on the conclusions.\nApplications:\n\nIn healthcare, sensitivity analysis can be used to determine how different clinical assumptions affect health outcomes or cost-effectiveness in medical studies.\nIn environmental science, it can help assess the effect of varying environmental parameters on pollution models.\nIn economics, it evaluates how changes in economic indicators impact financial models or forecasts.\nTypes of Sensitivity Analysis:\n\nDeterministic Sensitivity Analysis: This involves systematically changing one parameter at a time while keeping others constant to observe the effect on the outcome.\nProbabilistic Sensitivity Analysis: This involves changing multiple parameters simultaneously, often using statistical distributions to model uncertainty and variability in the inputs.\nScenario Analysis: Examining different possible future scenarios by varying several parameters together to understand potential outcomes under different conditions.\nLocal Sensitivity Analysis: Focuses on small changes around a baseline value of the parameters to assess local impact.\nGlobal Sensitivity Analysis: Assesses the impact of varying all parameters over their entire range to understand the overall influence on the model.\nre: \"inadequate sensitivity analysis\" = \"An analysis bias due to inadequate approach to determine the implications of missing data, distorted data, or modeling assumptions.\""}, {"code": "approval", "valueString": "2024-07-26 vote 5-0 by Harold Lehmann, Homa Keshavarz, Lenny Vasanthan, Eric Harvey, Airton Tetelbom Stein"}]}, {"code": "SEVCO:00322", "display": "final model not corresponding to multivariable analysis", "definition": "An analysis bias in which the predictors and coefficients in the final model do not match the predictors and coefficients reported in the multivariable analysis.", "property": [{"code": "external-definitions", "valueString": "from PROBAST:\n4.9 Do predictors and their assigned weights in the final model correspond to the results from the reported multivariable analysis? (Model development studies only)\n\nPredictors and coefficients of the final developed model, including intercept or baseline components, should be fully reported to allow others to correctly apply the model to other individuals. Mismatch between the presented final model and the reported results from the multivariable analysis (such as the intercept and predictor coefficients) is frequent. A review of prediction models in cancer in 2010 found that only 13 of 38 final prediction model equations (34%) used the same predictors and coefficients as the final presented multivariable analyses, 8 used the same predictors but different coefficients, 11 used neither the same coefficients nor the same predictors, and 6 used an unclear method to derive the final prediction model from the presented results of the multivariable analysis (121).\n\nBias can arise when the presented final model and the results reported from the multivariable analysis do not match. One way this can occur is when nonsignificant predictors are dropped from a larger model to arrive at a final presented model but the predictor coefficients from the larger model are used to define the final model, which are no longer correct. When predictors are dropped from a larger model, it is important to reestimate all predictor coefficients of the smaller model because the latter has become the final model. These newly estimated predictor coefficients are likely different even if nonsignificant or irrelevant predictors from the larger model are dropped.\n\nWhen a study reports a final model in which both predictors and regression coefficients correspond to the reported results of the multivariable regression analysis or model, this question should be answered as Y. If the final model is based only on a selection of predictors from the reported multivariable regression analysis without refitting the smaller model, it should be answered as N or PN. When no information is given on the multivariable modeling from which predictors and regression coefficients are derived, it should be answered as NI.\n\nThis signaling question is not about detecting improper methods of selecting predictors for the final model; such methods are addressed in signaling question 4.5."}, {"code": "comment", "valueString": "This type of bias is applicable to model development studies and model selection within other study designs."}, {"code": "editors", "valueString": "Kenneth Wilkins, Brian S. Alper"}, {"code": "approval", "valueString": "2023-12-08 vote 5-0 by Brian S. Alper, Harold Lehmann, Javier Bracchiglione, Yasser Sami Amer, Eric Harvey"}]}, {"code": "SEVCO:00310", "display": "cognitive interpretive bias affecting analysis", "definition": "A bias related to the analytic process due to the subjective nature of human interpretation.", "concept": [{"code": "SEVCO:00379", "display": "cognitive interpretive bias affecting analysis selection", "concept": [{"code": "SEVCO:00315", "display": "availability bias affecting analysis selection", "definition": "A Cognitive Interpretive Bias due to the use of information which is most readily available, rather than information which is most representative, affecting analysis selection.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Janice Tufte, Joanne Dehnbostel, Kenneth Wilkins"}, {"code": "external-definitions", "valueString": "Catalogue of Bias:\nAvailability bias\nA distortion that arises from the use of information which is most readily available, rather than that which is necessarily most representative."}, {"code": "negative-vote", "valueString": "2022-08-12 vote 4-1 by Paul Whaley, Mario Tristan, Harold Lehmann, Janice Tufte, Eric Harvey\n2022-08-19 vote 5-1 by Paul Whaley, Mario Tristan, Harold Lehmann, Janice Tufte, Eric Harvey, Philippe Rocca-Serra"}, {"code": "expert-comments", "valueString": "2022-08-12 comment: Clarify as to whether this is exclusively about cognitive availability? Seems ambiguous in current phrasing. Would suggest comment for application to make clear specific circumstances in which this applies.\n\n2022-08-19 comment: The definition is ambiguous about whether limits on access to the information is cognitive (e.g. familiarity) or otherwise. Also, the definition specifies \"information\" when the thing being selected is a technique for analysing information."}, {"code": "comment", "valueString": "Selection of inappropriate data or variables for analysis is an availability bias when the appropriate data or variables are not readily available to the analyst and therefore the appropriate analysis is not selected.\n\nSelection of an inappropriate analysis due to familiarity with the analytic techniques is an availability bias when the appropriate technique is unfamiliar and therefore not selected. \n\nThe term \"Availability bias affecting analysis selection\" is about selection of the analysis and not about missing data."}, {"code": "approval", "valueString": "2022-08-26 vote 7-0 by nisha mathew, Philippe Rocca-Serra, Jesus Lopez-Alcalde, Harold Lehmann, Mario Tristan, Cau\u00ea Monaco, Eric Harvey"}]}], "property": [{"code": "comment", "valueString": "Bias related to selection of the analysis is defined as an analysis bias due to inappropriate choice of analysis methods before the analysis is applied.\n\nThe Cognitive Interpretive Bias affecting analysis selection can be mitigated by masking the analyst as to the assignments for the groups, and by specification of the analysis prior to data availability."}, {"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Harold Lehmann, Joanne Dehnbostel"}, {"code": "approval", "valueString": "2022-07-29 vote 5-0 by Janice Tufte, Philippe Rocca-Serra, Jesus Lopez-Alcalde, Harold Lehmann, Eric Harvey"}], "definition": "A bias related to selection of the analysis due to the subjective nature of human interpretation."}, {"code": "SEVCO:00380", "display": "cognitive interpretive bias affecting execution of the analysis", "concept": [{"code": "SEVCO:00296", "display": "lack of blinding of data analysts", "definition": "A cognitive interpretive bias affecting execution of the analysis due to the analyst's awareness of the participants' status with respect to the variables defining the comparison groups.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Harold Lehmann, Janice Tufte, Joanne Dehnbostel, Paul Whaley"}, {"code": "approval", "valueString": "2022-12-02 vote 5-0 by Mario Tristan, Mahnoor Ahmed, Muhammad Afzal, Janice Tufte, Eric Harvey"}, {"code": "expert-comments", "valueString": "2022-12-02 comment: Should it be participants' statuses --- EWG discussion notes that \"status\" can be used for the plural"}], "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "lack of masking of data analysts"}]}], "definition": "A bias in processing of data due to the subjective nature of human interpretation.", "property": [{"code": "comment", "valueString": "Bias in processing of data is defined as an analysis bias due to inappropriate decisions pertaining to preparation of data for analysis and/or conduct of the analysis.\n\nThis bias may be mitigated by the partial masking or blinding of the individuals conducting the analysis."}, {"code": "editors", "valueString": "Kenneth Wilkins, Joanne Dehnbostel, Janice Tufte, Paul Whaley, Yuan Gao, Harold Lehmann, Brian S. Alper"}, {"code": "approval", "valueString": "2022-12-02 vote 6-0 by Mario Tristan,  Yuan Gao, Mahnoor Ahmed, Muhammad Afzal, Janice Tufte, Eric Harvey"}]}], "property": [{"code": "comment", "valueString": "The Cognitive Interpretive Bias affecting analysis can be mitigated by masking the analyst as to the assignments for the groups, and by specification of the analysis prior to data availability."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Kenneth Wilkins, Joanne Dehnbostel, Janice Tufte"}, {"code": "approval", "valueString": "2022-11-18 vote 6-0 by Mahnoor Ahmed, Yuan Gao, Harold Lehmann, Jesus Lopez-Alcalde, Paul Whaley, Eric Harvey"}]}, {"code": "SEVCO:00392", "display": "inappropriate weighting bias", "definition": "An analysis bias in which the weights used in model construction do not align with the target of estimation or estimand.", "property": [{"code": "comment", "valueString": "This bias often occurs with the omission of sampling weights in a model or in the process of trying to mitigate misrepresentation of a population due to sampling.\nOne example is use of an unweighted model with National Health and Nutrition Examination Survey (NHANES) data.\nThis bias occurs when attempting to reweight imbalanced classes in a model to make them representative of the source population, when weights drive estimation away from the target."}, {"code": "approval", "valueString": "2023-10-13 vote 6-0 by Louis Leff, Jesus Lopez-Alcalde, Harold Lehmann, Eric Harvey, Paul Whaley, Janice Tufte"}, {"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins"}]}, {"code": "SEVCO:00026", "display": "synthesis bias", "definition": "A bias in the conduct of an analysis combining two or more studies or datasets.", "property": [{"code": "comment", "valueString": "A synthesis bias results from methods used to select, manipulate or interpret data for evidence synthesis."}, {"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Kenneth Wilkins"}, {"code": "approval", "valueString": "2024-05-17 vote 5-0 by Saphia Mokrane, Lenny Vasanthan, Sheyu Li, Eric Harvey, Harold Lehmann"}], "concept": [{"code": "SEVCO:00346", "display": "bias related to selection of the analytic framework for synthesis", "definition": "A synthesis bias resulting from an analytic approach that is not suitable for the included studies.", "property": [{"code": "external-definitions", "valueString": "ROBIS 4.3 Was the synthesis appropriate given the nature and similarity in the research questions, study designs and outcomes across included studies?"}, {"code": "comment", "valueString": "The term 'synthesis bias related to selection of the analytic framework' used for a systematic review or synthesis is equivalent to the term  [bias related to selection of the analytic framework](#SEVCO:00378) used for a single study. An analytic framework is the model, scaffolding, or organizational representation of concepts used in analyzing the data. The concepts included in an analytic framework may involve data, variables, formulas, assumptions, and adjustments.\nIf the analytic framework selected for synthesis does not match the data and research question, there is a risk of distorted results which constitutes bias.\nThe term 'bias related to selection of the analytic framework for synthesis' matches the ROBIS signaling question 4.3 'Was the synthesis appropriate given the nature and similarity in the research questions, study designs and outcomes across included studies?'"}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Kenneth Wilkins, Joanne Dehnbostel"}, {"code": "negative-vote", "valueString": "2024-06-07 vote 5-1 by Sean Grant, Sheyu Li, Lenny Vasanthan, Harold Lehmann, Eric Harvey, Carlos Alva-Diaz\n2024-06-14 vote 8-1 by Carlos Alva-Diaz, Yaowaluk Ngoenwiwatkul, Homa Keshavarz, Sean Grant, Sheyu Li, Eric Harvey, Lenny Vasanthan, Harold Lehmann, Janice Tufte"}, {"code": "expert-comments", "valueString": "2024-06-07 comment:  The term itself is new to me: is there a more established term?\n\n2024-06-14  comments re: \"bias related to selection of the analytic framework for synthesis\" = \"A synthesis bias resulting from an analytic approach that is not suitable for the included studies.\"1N) As above, I understand the concept though I am not clear how this is a \"bias\"? \"Not suitable\" also sounds like poor study execution rather than a bias.\n2) Have we been consistent in other Comments for application in matching the signaling questions?"}, {"code": "approval", "valueString": "2024-06-21 vote 8-0 by Cau\u00ea Monaco, Lenny Vasanthan, Homa Keshavarz, Yaowaluk Ngoenwiwatkul, Harold Lehmann, Sean Grant, Eric Harvey, Carlos Alva-Diaz"}]}, {"code": "SEVCO:00347", "display": "inadequate accounting for heterogeneity", "definition": "A synthesis bias due to inadequate approach to determine the magnitude, cause, or implications of variation among studies.", "property": [{"code": "external-definitions", "valueString": "ROBIS 4.4 Was between-study variation (heterogeneity) minimal or addressed in the synthesis?"}, {"code": "comment", "valueString": "Adequate accounting for variation among studies includes measuring the variation among studies, determining if substantial variation is systematic or random, and addressing the implications of substantial variation if present.\nThe term 'inadequate accounting for heterogeneity' matches the ROBIS signaling question 4.4 'Was between-study variation (heterogeneity) minimal or addressed in the synthesis?'\n\n[Bias](https://fevir.net/resources/CodeSystem/27270#SEVCO:00001) is defined as a systematic distortion in research results (estimation of effect, association, or inference). Distortions in research results means differences between the reported results (findings, conclusions, effect estimates) and the actuality (the truth, the estimand [the quantity targeted for estimation]). [Synthesis bias](https://fevir.net/resources/CodeSystem/27270#SEVCO:00026) is defined as a bias in the conduct of an analysis combining two or more studies or datasets. An inadequate approach to the accounting for heterogeneity in the conduct of an evidence synthesis can introduce or obscure a systematic distortion in research results."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Homa Keshavarz, Joanne Dehnbostel"}, {"code": "negative-vote", "valueString": "2024-06-21 vote 5-2 by Cau\u00ea Monaco, Lenny Vasanthan, Homa Keshavarz, Yaowaluk Ngoenwiwatkul, Harold Lehmann, Sean Grant, Eric Harvey\n2024-06-28 vote 6-1 by Harold Lehmann, Lenny Vasanthan, Homa Keshavarz, Sean Grant, Philippe Rocca-Serra, Eric Harvey, Sheyu Li"}, {"code": "expert-comments", "valueString": "2024-06-21 comments re: \"bias related to accounting for heterogeneity\" = \"A synthesis bias due to inadequate accounting for variation among studies.\"1N) Missing text: \"The term \" matches...\"2N) Not clear how this is a \"bias\" rather than a low-quality review?\n\n2024-06-28 comment re: \"inadequate accounting for heterogeneity\" = \"A synthesis bias due to inadequate approach to determine the magnitude, cause, or implications of variation among studies.\"This again does not sound like a \"bias\" to me. Perhaps it contributes to a bias, though it sounds more like poor execution of an evidence synthesis rather than a \"bias\""}, {"code": "approval", "valueString": "2024-07-05 vote 6-0 by Cau\u00ea Monaco, C P Ooi, Sheyu Li, Lenny Vasanthan, Eric Harvey, Harold Lehmann"}]}, {"code": "SEVCO:00349", "display": "inadequate accounting for bias in constituent studies", "definition": "A synthesis bias due to inadequate approach to determine the risks of bias in the studies selected for synthesis or the implications of those risks.", "property": [{"code": "external-definitions", "valueString": "ROBIS 3.4 Was risk of bias (or methodological quality) formally assessed using appropriate criteria?\nROBIS 3.5 Were efforts made to minimise error in risk of bias assessment?\nROBIS 4.6 Were biases in primary studies minimal or addressed in the synthesis?"}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Homa Keshavarz, Airton Stein"}, {"code": "approval", "valueString": "2024-07-26 vote 5-0 by Harold Lehmann, Homa Keshavarz, Lenny Vasanthan, Eric Harvey, Airton Tetelbom Stein"}], "concept": [{"code": "SEVCO:00353", "display": "inadequate criteria for methodologic quality assessment", "definition": "A synthesis bias due to inadequate criteria to determine the risks of bias in the studies selected for synthesis.", "property": [{"code": "comment", "valueString": "The term 'inadequate criteria for methodologic quality assessment' matches the ROBIS signaling question 3.4 'Was risk of bias (or methodological quality) formally assessed using appropriate criteria?'"}, {"code": "external-definitions", "valueString": "ROBIS 3.4 Was risk of bias (or methodological quality) formally assessed using appropriate criteria?"}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Homa Keshavarz, Airton Stein"}, {"code": "approval", "valueString": "2024-07-26 vote 5-0 by Harold Lehmann, Homa Keshavarz, Lenny Vasanthan, Eric Harvey, Airton Tetelbom Stein"}]}, {"code": "SEVCO:00354", "display": "inadequate process for methodologic quality assessment", "definition": "A synthesis bias due to inadequate process to determine the risks of bias in the studies selected for synthesis.", "property": [{"code": "external-definitions", "valueString": "ROBIS 3.5 Were efforts made to minimise error in risk of bias assessment?"}, {"code": "comment", "valueString": "The term 'inadequate process for methodologic quality assessment' matches the ROBIS signaling question 3.5 'Were efforts made to minimise error in risk of bias assessment?'"}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Homa Keshavarz, Airton Stein"}, {"code": "approval", "valueString": "2024-07-26 vote 5-0 by Harold Lehmann, Homa Keshavarz, Lenny Vasanthan, Eric Harvey, Airton Tetelbom Stein"}]}, {"code": "SEVCO:00396", "display": "inadequate adjusting for bias in constituent studies", "definition": "A synthesis bias due to inadequate approach to determine the implications of bias in the studies selected for synthesis.", "property": [{"code": "comment", "valueString": "The term 'inadequate adjusting for bias in constituent studies' matches the ROBIS signaling question 4.6 'Were biases in primary studies minimal or addressed in the synthesis?'"}, {"code": "external-definitions", "valueString": "ROBIS 4.6 Were biases in primary studies minimal or addressed in the synthesis?"}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Homa Keshavarz, Airton Stein"}, {"code": "approval", "valueString": "2024-07-26 vote 5-0 by Harold Lehmann, Homa Keshavarz, Lenny Vasanthan, Eric Harvey, Airton Tetelbom Stein"}]}]}, {"code": "SEVCO:00369", "display": "inadequate process for data extraction", "definition": "A synthesis bias due to inadequate process to select and abstract the data from the included studies or datasets.", "property": [{"code": "external-definitions", "valueString": "ROBIS 3.1 Were efforts made to minimise error in data collection?"}, {"code": "comment", "valueString": "The term 'inadequate process for data extraction' matches the ROBIS signaling question 3.1 'Were efforts made to minimise error in data collection?'"}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Airton Stein, Joanne Dehnbostel"}, {"code": "approval", "valueString": "2024-08-02 vote 5-0 by Harold Lehmann, Homa Keshavarz, Lenny Vasanthan, Airton Tetelbom Stein, Eric Harvey"}]}, {"code": "SEVCO:00351", "display": "inadequate study characteristics available for results interpretation", "definition": "A synthesis bias due to inadequate availability of information regarding design, data collection, analysis or reporting for the study results or datasets collected for synthesis.", "property": [{"code": "external-definitions", "valueString": "ROBIS 3.2 Were sufficient study characteristics available for both review authors and readers to be able to interpret the results?"}, {"code": "comment", "valueString": "The term 'inadequate study characteristics available for results interpretation' matches the ROBIS signaling question 3.2 'Were sufficient study characteristics available for both review authors and readers to be able to interpret the results?'"}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Airton Stein, Joanne Dehnbostel"}, {"code": "approval", "valueString": "2024-08-02 vote 5-0 by Harold Lehmann, Homa Keshavarz, Lenny Vasanthan, Airton Tetelbom Stein, Eric Harvey"}]}, {"code": "SEVCO:00352", "display": "bias related to selection of the data for synthesis", "definition": "A synthesis bias due to inappropriate choice of study results included in the synthesis.", "property": [{"code": "external-definitions", "valueString": "ROBIS 3.3 Were all relevant study results collected for use in the synthesis?"}, {"code": "comment", "valueString": "Selection of study results may occur before or after data extraction and transformation. The process of extracting results from a study involves identifying, collecting, and recording the findings (quantitative or qualitative) that are relevant for synthesis. The process of transformation may include unit of measure changes, other data harmonization, or statistical transformations so the data can be integrated into a meta-analysis.\nAnother reason for not including a relevant study result is the failure to contact the study investigators for missing data.\nIf the data selected for synthesis does not match the data that is available, there is a risk of distorted results which constitutes bias.\nThe term 'bias related to selection of the data for synthesis' matches the ROBIS signaling question 3.3 'Were all relevant study results collected for use in the synthesis?'"}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Airton Stein"}, {"code": "negative-vote", "valueString": "2024-08-09 vote 6-1 by Harold Lehmann, Homa Keshavarz, Sheyu Li, Sean Grant, Eric Harvey, Lenny Vasanthan, Airton Tetelbom Stein\n2024-08-16 vote 5-1 by Cau\u00ea Monaco, Bhagvan Kommadi, Jennifer Hunter, Eric Harvey, Harold Lehmann, Airton Tetelbom Stein"}, {"code": "expert-comments", "valueString": "2024-08-09 comment re: \"bias related to selection of the data for synthesis\" = \"A synthesis bias due to inappropriate choice of study results included in the synthesis before the synthesis is applied.\"1N)\nOnce again, what is the difference between this bias and selection bias?  Similar comments with above. \n\n\n2024-08-16 comment re: \"bias related to selection of the data for synthesis\" = \"A synthesis bias due to inappropriate choice of study results included in the synthesis.\"1N)\nI'm unsure that \"and appropriate for synthesis\" is correct. For instance, an included study may have measured the outcome of interest but not reported the results in a way that can be used in the planned meta-analysis (e.g., only the p value is reported, or no SDM/SE is reported). Even though the results cannot be used (i.e., are not appropriate) for the meta-analysis, there is still a risk of distorted results which constitutes bias. Perhaps I am mistaken, and this bias only refers to errors of judgement by the reviewers.\n\nDo we need to mention some examples relevant to selection bias arising after data extraction? e.g., failing to undertake appropriate statistical transformations so that the reported results can be used in a meta-analysis.\n\nAnother reason for not including a relevant study result is the failure to contact the study investigators for missing data. Does this need to be mentioned here or is it covered under a different term? If this term is supposed to map to  ROBIS 3.3., then this is another example of not collecting relevant results.\n\n2024-08-23 comment re: \"bias related to selection of the data for synthesis\" = \"A synthesis bias due to inappropriate choice of study results included in the synthesis.\"1Y)\nIt might be good to mention conditions when the study selection happens after data extraction and transformation.\n\nOne question - if anyone is working on an update of a review and if the previous author team havent selected the appropriate data in their included studies and the current team have published an update without updating the study results of the previously included studies, how do we handle that here?"}, {"code": "approval", "valueString": "2024-08-23 vote 9-0 by Carlos Alva-Diaz, Elma OMERAGIC, Lenny Vasanthan, Harold Lehmann, Philippe Rocca-Serra, Eric Harvey, Sean Grant, Airton Tetelbom Stein, Homa Keshavarz"}]}]}, {"code": "SEVCO:00320", "display": "inappropriate evaluation of predictive model performance measures", "definition": "An analysis bias in which the method for analysis of a performance measure (such as calibration or discrimination) is not adequate or suitable for the predictive model.", "property": [{"code": "comment", "valueString": "According to PROBAST explanation, to fully gauge the predictive performance of a model, reviewers must assess both model calibration and discrimination (such as the c-index) addressing the entire range of the model-predicted probabilities. (https://www.acpjournals.org/doi/10.7326/M18-1377)"}, {"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Muhammad Afzal, Kenneth Wilkins"}, {"code": "approval", "valueString": "2023-10-06 vote 5-0 by Jesus Lopez-Alcalde, Harold Lehmann, Eric Harvey, Paul Whaley, Janice Tufte"}], "concept": [{"code": "SEVCO:00393", "display": "inappropriate evaluation of calibration of predictive model", "definition": "An analysis bias in which the method for analysis of calibration is not adequate or suitable for the predictive model.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Muhammad Afzal, Kenneth Wilkins"}, {"code": "approval", "valueString": "2023-10-06 vote 5-0 by Jesus Lopez-Alcalde, Harold Lehmann, Eric Harvey, Paul Whaley, Janice Tufte"}, {"code": "expert-comments", "valueString": "2023-10-06 comment: Is the bias because an analyst prefers one model over another when there might be a more appropriate one ( perhaps the analyst is not familiar with?)"}]}, {"code": "SEVCO:00394", "display": "inappropriate evaluation of discrimination of predictive model", "definition": "An analysis bias in which the method for analysis of discrimination is not adequate or suitable for the predictive model.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Muhammad Afzal, Kenneth Wilkins"}, {"code": "approval", "valueString": "2023-10-13 vote 5-0 by Louis Leff, Jesus Lopez-Alcalde, Harold Lehmann, Eric Harvey, Paul Whaley"}]}, {"code": "SEVCO:00321", "display": "model overfitting", "definition": "An analysis bias, specific to predictive model development studies, in which strategies to mitigate overfitting are not adequately applied.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Muhammad Afzal, Kenneth Wilkins, Harold Lehmann"}, {"code": "comment", "valueString": "Predictive model performance measures (calibration and discrimination) may be misinterpreted if there are no strategies to mitigate overfitting.  This applies to development studies without external validation studies. Strategies to mitigate overfitting may include penalization/regularization, k-fold cross validation, train-test/validation split, etc.\n\nFrom the PROBAST explanation (https://www.acpjournals.org/doi/10.7326/M18-1377):  \"quantifying the predictive performance of a model on the same data from which the model was developed (apparent performance) tends to give optimistic estimates of performance due to overfitting\u2014that is, the model is too much adapted to the development data set. This optimism is higher when any of the following are present: too few outcome events in total, too few outcome events relative to the number of candidate predictors (small EPV), dichotomization of continuous predictors, use of predictor selection strategies based on univariable analyses, or use of traditional stepwise predictor selection strategies (for example, forward or backward selection) in multivariable analysis in small data sets (small EPV)\""}, {"code": "negative-vote", "valueString": "2023-10-06 vote 3-1 by Jesus Lopez-Alcalde, Eric Harvey, Paul Whaley, Janice Tufte"}, {"code": "expert-comments", "valueString": "2023-10-06 comments: I am not sure about having a preferred term that actually consists of two terms - overfit and optimism. Is one a synonym of the other?\nOptimism- being too over optimistic and fitting things into the model that really were not defined early on? (adding inappropriate data that can skew the outcomes?)"}, {"code": "approval", "valueString": "2023-10-20 vote 5-0 by Muhammad Afzal, Eric Harvey, Harold Lehmann, Louis Leff, Joanne Dehnbostel"}]}]}]}, {"code": "SEVCO:00023", "concept": [{"code": "SEVCO:00024", "display": "selective reporting bias", "definition": "A reporting bias due to inappropriate selection of the results or research findings that are reported.", "concept": [{"code": "SEVCO:00330", "display": "selective outcome reporting", "definition": "A selective reporting bias due to inappropriate selection of which outcomes are reported within results or research findings.", "concept": [{"code": "SEVCO:00336", "display": "selective outcome measure reporting", "property": [{"code": "comment", "valueString": "Selective outcome measure reporting may be considered a type of selective outcome reporting in which the measurement method for determination of the outcome is interpreted as a distinct outcome.\nA selective reporting bias is a reporting bias due to inappropriate selection of the results or research findings that are reported.\nA <a href=\"https://fevir.net/resources/CodeSystem/27270#SEVCO:00023\" target=\"_blank\">reporting bias</a> is a bias due to distortions in the selection of or representation of information in study results or research findings."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Paul Whaley"}, {"code": "approval", "valueString": "2023-01-13 vote 5-0 by Harold Lehmann, Joanne Dehnbostel, Paul Whaley, Janice Tufte, Eric Harvey"}], "definition": "A selective reporting bias due to inappropriate selection of which outcome measures are reported for an outcome.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "selective outcome measure reporting within outcome domain"}]}], "property": [{"code": "comment", "valueString": "A selective reporting bias is a reporting bias due to inappropriate selection of the results or research findings that are reported.\nA <a href=\"https://fevir.net/resources/CodeSystem/27270#SEVCO:00023\" target=\"_blank\">reporting bias</a> is a bias due to distortions in the selection of or representation of information in study results or research findings."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Paul Whaley, Muhammad Afzal"}, {"code": "approval", "valueString": "2023-01-13 vote 5-0 by Harold Lehmann, Joanne Dehnbostel, Paul Whaley, Janice Tufte, Eric Harvey"}], "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "outcome reporting bias"}]}, {"code": "SEVCO:00331", "display": "selective subgroup reporting", "definition": "A selective reporting bias due to inappropriate selection of subsets of groups of participants for which results or research findings are reported.", "property": [{"code": "comment", "valueString": "A selective reporting bias is a reporting bias due to inappropriate selection of the results or research findings that are reported.\nA <a href=\"https://fevir.net/resources/CodeSystem/27270#SEVCO:00023\" target=\"_blank\">reporting bias</a> is a bias due to distortions in the selection of or representation of information in study results or research findings.\nSelective subgroup reporting relates to choice of attributes of participants within cohorts, for example reporting limited to male patients."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Kenneth Wilkins, Paul Whaley, Joanne Dehnbostel"}, {"code": "approval", "valueString": "2023-01-27 vote 7-0 by Janice Tufte, Harold Lehmann, Mario Tristan, Jesus Lopez-Alcalde, Yuan Gao, Paul Whaley, Eric Harvey"}], "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "subgroup reporting bias"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "subgroup analysis reporting bias"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "selective subgroup analysis reporting"}]}, {"code": "SEVCO:00331a", "display": "selective comparison reporting", "definition": "A selective reporting bias due to inappropriate selection of comparison groups for which results or research findings are reported.", "property": [{"code": "comment", "valueString": "A selective reporting bias is a reporting bias due to inappropriate selection of the results or research findings that are reported.\nA <a href=\"https://fevir.net/resources/CodeSystem/27270#SEVCO:00023\" target=\"_blank\">reporting bias</a> is a bias due to distortions in the selection of or representation of information in study results or research findings.\nSelective comparison reporting relates to choice of cohort definitions, for example an intention-to-treat analysis (as-randomized analysis) vs. an as-treated analysis."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Kenneth Wilkins, Paul Whaley, Joanne Dehnbostel"}, {"code": "negative-vote", "valueString": "2023-01-20 vote 2-1 by Yuan Gao, Paul Whaley, Eric Harvey"}, {"code": "expert-comments", "valueString": "2023-01-20 comment: I don't see enough of a connection between the term (selective comparison) and the definition, which does not seem to talk about comparisons."}, {"code": "approval", "valueString": "2023-01-27 vote 6-0 by Janice Tufte, Harold Lehmann, Mario Tristan, Jesus Lopez-Alcalde, Yuan Gao, Eric Harvey"}]}, {"code": "SEVCO:00333", "display": "selective analysis reporting from repeated analyses at multiple times", "definition": "A selective reporting bias due to inappropriate selection of which analyses are reported for an outcome that was analyzed at multiple points in time in a longitudinal study.", "property": [{"code": "comment", "valueString": "A selective reporting bias is a reporting bias due to inappropriate selection of the results or research findings that are reported.\nA <a href=\"https://fevir.net/resources/CodeSystem/27270#SEVCO:00023\" target=\"_blank\">reporting bias</a> is a bias due to distortions in the selection of or representation of information in study results or research findings."}, {"code": "editors", "valueString": "Brian S. Alper, Paul Whaley, Janice Tufte, Joanne Dehnbostel"}, {"code": "approval", "valueString": "2023-01-27 vote 6-0 by Janice Tufte, Harold Lehmann, Mario Tristan, Jesus Lopez-Alcalde, Yuan Gao, Eric Harvey"}]}, {"code": "SEVCO:00334", "display": "selective analysis reporting from multiple analytic models", "definition": "A selective reporting bias due to inappropriate selection of which analyses are reported for an outcome that was analyzed in multiple ways.", "property": [{"code": "comment", "valueString": "A selective reporting bias is a reporting bias due to inappropriate selection of the results or research findings that are reported.\nA <a href=\"https://fevir.net/resources/CodeSystem/27270#SEVCO:00023\" target=\"_blank\">reporting bias</a> is a bias due to distortions in the selection of or representation of information in study results or research findings.\nAdjustment reporting bias, or selective reporting of adjusted estimates, is a type of selective analysis reporting from multiple analytic models."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Kenneth Wilkins"}, {"code": "approval", "valueString": "2023-02-10 vote 6-0 by Cau\u00ea Monaco, Paul Whaley, Janice Tufte, Brian S. Alper, Jesus Lopez-Alcalde, Eric Harvey"}]}, {"code": "SEVCO:00335", "display": "selective threshold reporting bias", "definition": "A selective reporting bias due to inappropriate selection of which thresholds (used for definitions of the variables) are reported.", "property": [{"code": "comment", "valueString": "A selective reporting bias is a reporting bias due to inappropriate selection of the results or research findings that are reported.\nA <a href=\"https://fevir.net/resources/CodeSystem/27270#SEVCO:00023\" target=\"_blank\">reporting bias</a> is a bias due to distortions in the selection of or representation of information in study results or research findings."}, {"code": "editors", "valueString": "Brian S. Alper, Paul Whaley, Harold Lehmann, Joanne Dehnbostel, Kenneth Wilkins"}, {"code": "negative-vote", "valueString": "2023-02-10 vote 5-1 by Cau\u00ea Monaco, Paul Whaley, Janice Tufte, Brian S. Alper, Jesus Lopez-Alcalde, Eric Harvey"}, {"code": "expert-comments", "valueString": "2023-02-10 comment: I'm not clear how the definition relates specifically to reporting bias."}, {"code": "approval", "valueString": "2023-02-24 vote 7-0 by Harold Lehmann, Yasser Sami Amer, Mario Tristan, Paul Whaley, Jesus Lopez-Alcalde, Janice Tufte, Eric Harvey"}], "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "selective cutoff reporting bias"}]}], "property": [{"code": "external-definitions", "valueString": "MASTER-31. There was no discernible data dredging or selective reporting of the outcomes"}, {"code": "comment", "valueString": "A <a href=\"https://fevir.net/resources/CodeSystem/27270#SEVCO:00023\" target=\"_blank\">reporting bias</a> is a bias due to distortions in the selection of or representation of information in study results or research findings."}, {"code": "editors", "valueString": "Brian S. Alper, Paul Whaley, Harold Lehmann, Joanne Dehnbostel, Muhammad Afzal, Yuan Gao, Janice Tufte"}, {"code": "approval", "valueString": "2023-01-06 vote 5-0 by Harold Lehmann, Yuan Gao, Janice Tufte, Eric Harvey, Mario Tristan"}]}, {"code": "SEVCO:00025", "display": "cognitive interpretive bias in reporting", "definition": "A distortion in the representation of study results or research findings due to the subjective nature of human interpretation.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "spin bias"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "cognitive interpretive bias for reporting"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "selective interpretation reporting bias"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "selective representation reporting bias"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "cognitive interpretive reporting bias"}], "concept": [{"code": "SEVCO:00338", "display": "interpretation of results not addressing potential for bias", "definition": "A cognitive interpretive bias in reporting whereby the reported interpretation of results does not adequately address potential for bias.", "property": [{"code": "comment", "valueString": "Reporting bias is defined as a bias due to distortions in the selection of or representation of information in study results or research findings.\nCognitive interpretive bias in reporting is defined as a distortion in the representation of study results or research findings due to the subjective nature of human interpretation.\nInterpretation of results not addressing potential for bias occurs when there is an absence of risk of bias assessment or incomplete inclusion of a risk of bias assessment in the interpretation of findings."}, {"code": "editors", "valueString": "Brian S. Alper, Paul Whaley, Kenneth Wilkins, Harold Lehmann, Joanne Dehnbostel"}, {"code": "approval", "valueString": "2023-03-03 vote 6-0 by A.G. Radhika, Cau\u00ea Monac, Janice Tufte, Harold Lehmann, Yasser Sami Amer, Eric Harvey"}], "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "interpretation of results not addressing risk of bias"}]}, {"code": "SEVCO:00328", "display": "results emphasized based on statistical significance", "definition": "A cognitive interpretive bias in reporting whereby results with statistical significance are given exaggerated attention.", "property": [{"code": "comment", "valueString": "This bias may occur in several ways. Results may be interpreted as \"positive\" or \"conclusive\" if below the significance threshold and \"negative\" or \"inconclusive\" if above the significance threshold without proper interpretation of the meaning of the significance threshold.  Results may be selectively emphasized in overall summarization of the results based on whether or not they are under the significance threshold. Results may be interpreted based on statistical significance instead of clinical significance, or results may misrepresent statistical significance and clinical significance as synonymous."}, {"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Joanne Dehnbostel"}, {"code": "approval", "valueString": "2023-04-07 vote 5-0 by Paul Whaley, Jesus Lopez-Alcalde, Janice Tufte, Eric Harvey, Harold Lehmann"}, {"code": "expert-comments", "valueString": "2023-04-07 comments:\nI support this term as written, although I would suggest that we consider adding that assessment of statistical significance without assessing clinical significance often  leads to this bias.\nI might suggest adding to Comment for application: \"Another mis-interpretation is when statistical significance confused with clinical significance.\""}]}, {"code": "SEVCO:00340", "display": "confirmation bias in reporting", "definition": "A cognitive interpretive bias in reporting due to the influence of an individual\u2019s ideas, beliefs or hypotheses.", "property": [{"code": "comment", "valueString": "Reporting bias is defined as a bias due to distortions in the selection of or representation of information in study results or research findings.\nCognitive interpretive bias in reporting is defined as a distortion in the representation of study results or research findings due to the subjective nature of human interpretation."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Kenneth Wilkins"}, {"code": "approval", "valueString": "2023-03-10 vote 8-0 by Joanne Dehnbostel, Mario Tristan, Harold Lehmann, Jesus Lopez-Alcalde, A.G. Rradhika, Janice Tufte, Eric Harvey, Cau\u00ea Monaco"}]}, {"code": "SEVCO:00329", "display": "external validity bias", "property": [{"code": "external-definitions", "valueString": "derived from ROBIS https://www.bristol.ac.uk/media-library/sites/social-community-medicine/robis/ROBIS%201.2%20Clean.pdf"}, {"code": "comment", "valueString": "Reporting bias is defined as a bias due to distortions in the selection of or representation of information in study results or research findings.\nCognitive interpretive bias in reporting is defined as a distortion in the representation of study results or research findings due to the subjective nature of human interpretation.\nIn the assessment of systematic reviews, this type of bias can be phrased as \"Relevance of studies to research question not appropriately considered\"."}, {"code": "editors", "valueString": "Brian S. Alper, Paul Whaley, Joanne Dehnbostel, Muhammad Afzal"}, {"code": "approval", "valueString": "2023-4-14 by Janice Tufte, Eric Harvey, Harold Lehmann, Joanne Dehnbostel, Jesus Lopez-Alcalde"}], "definition": "A cognitive interpretive bias in reporting due to a mismatch between what the observed data represent and the results that were reported."}], "property": [{"code": "external-definitions", "valueString": "CoB: Spin bias = The intentional or unintentional distorted interpretation of research results, unjustifiably suggesting favourable or unfavourable findings that can result in misleading conclusions (https://catalogofbias.org/biases/spin-bias/)"}, {"code": "comment", "valueString": "Reporting bias is defined as a bias due to distortions in the selection of or representation of information in study results or research findings.\nCognitive interpretive bias in reporting is about interpretation of the results rather than the choice of which results are presented (which would be Selective Reporting Bias).\nCognitive interpretive biases in reporting include selective theory reporting, confirmation bias, bias of rhetoric, novelty bias, popularity bias, and positive results bias."}, {"code": "editors", "valueString": "Brian S. Alper, Paul Whaley, Harold Lehmann, Janice Tufte, Joanne Dehnbostel"}, {"code": "negative-vote", "valueString": "2023-02-10 vote 4-1 by Cau\u00ea Monaco, Paul Whaley, Jesus Lopez-Alcalde, Janice Tuft, Eric Harvey"}, {"code": "expert-comments", "valueString": "2023-02-10 comment: I think the definition is sound but the comment for application should be extended to make it clearer that this is about interpretation of the results rather than the choice of which results are presented."}, {"code": "approval", "valueString": "2023-02-24 vote 7-0 by Harold Lehmann, Yasser Sami Amer, Mario Tristan, Paul Whaley, Jesus Lopez-Alcalde, Janice Tufte, Eric Harvey"}]}, {"code": "SEVCO:00327", "display": "early dissemination bias", "definition": "A reporting bias due to publication or reporting of results or research findings that change in subsequent reports.", "property": [{"code": "comment", "valueString": "One form of Early dissemination bias is the reporting of results in preprints or early versions during the peer review and publication process not matching the subsequent reports.\nAnother form of Early dissemination bias is the reporting of interim results (even if fully peer reviewed) when a study is ongoing and more data will be analyzed for the final results.\nThis bias may result from failure to disclose that the results are preliminary or subject to change.\nThis definition is not meant to indicate that preprints are inherently biased."}, {"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Kenneth Wilkins, Muhammad Afzal, Paul Whaley"}, {"code": "negative-vote", "valueString": "2023-04-07 vote 3-1 by Eric Harvey, Harold Lehmann, Paul Whaley, Jesus Lopez-Alcalde"}, {"code": "expert-comments", "valueString": "2023-04-14 comments:\nShould we make clear in Comment for Application that preprints represent *potential* bias, because preprinting does not prima facie mean bias?\nIt seems to me that the bias falls where the results do ot carefully convey that they are preliminary or early AND not to be read as final results -maybe could be word smithed Do you mean someone is reporting without full disclosure\n2023-04-07 comments:\nI would suggest \"One form of potential Premature...\", since prima facie, premature reporting does not *have* to be biased.\nI feel that \"reporting bias\" has the same issue of being semantically loaded as \"publication bias\" - the problem is premature dissemination of results, via reporting them, publishing them, putting them in a press release, etc. So maybe \"premature dissemination bias\" could be considered as the preferred term? And then we could even consider \"early dissemination bias\" as that feels more objective than \"premature\", now that it is phrased this way."}, {"code": "approval", "valueString": "2023-04-14 by Janice Tufte, Eric Harvey, Harold Lehmann, Jesus Lopez-Alcalde, Joanne Dehnbostel"}], "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "preliminary reporting bias"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "early reporting bias"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "interim reporting bias"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "early publication bias"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "interim publication bias"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "premature publication bias"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "preliminary publication bias"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "premature reporting bias"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "premature dissemination bias"}]}, {"code": "SEVCO:00384", "display": "fabrication bias", "definition": "A reporting bias resulting from intentional misrepresentation of any part of the study.", "property": [{"code": "comment", "valueString": "Examples include plagiarism, unjustified authorship, data manipulation, and intentional misrepresentation of figures and charts. Applying this code is a serious allegation of wrongdoing."}, {"code": "editors", "valueString": "Harold Lehmann, Kenneth Wilkins, Joanne Dehnbostel, Khalid Shahin"}, {"code": "approval", "valueString": "2023-04-21 vote 5-0 by Brian S. Alper, Janice Tufte, Harold Lehmann, Cau\u00ea Monaco, Eric Harvey"}], "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "fraud"}]}, {"code": "SEVCO:00359", "display": "unsubstantiated interpretation of results", "definition": "A reporting bias in which the interpretation of results is not adequately supported by the data collected.", "property": [{"code": "comment", "valueString": "Reporting bias is defined as a bias due to distortions in the selection of or representation of information in study results or research findings."}, {"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Caue Monaco, Li Wang, Harold Lehmann"}, {"code": "approval", "valueString": "2023-12-22 vote 5-0 Eric Harvey, Caue Monaco, Janice Tufte, Paul Whaley, Joanne Dehnbostel"}]}, {"code": "SEVCO:00271", "display": "one-sided reference bias", "definition": "A reporting bias in which included citations are limited to those that represent only some of the perspectives.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "selective citation bias"}], "property": [{"code": "external-definitions", "valueString": "Catalogue of Bias (https://catalogofbias.org/biases/one-sided-reference-bias/) One-sided reference bias\nWhen authors restrict their references to only those works that support their position.\nOne-sided reference bias occurs when a study author cites only publications that demonstrate one side of the picture of available evidence. This bias may arise when researchers cite publications that support their preconceptions or hypotheses, ignoring evidence that does not support their view. This can happen in any study report, but a particular problem arises when this occurs in literature reviews, which are supposed to represent a comprehensive collection of all relevant information, along with description and appraisal of quality and content. The result can be a misrepresentation of the current totality of evidence and can lead to spurious claims or needless additional research.\nCatalogue of Bias Collaboration, Spencer EA, Brassey J, Heneghan C. One-sided reference bias. In: Catalogue of Bias 2017 https://www.catalogofbias.org/biases/one-sided-reference-bias"}, {"code": "editors", "valueString": "Joanne Dehnbostel, Brian S. Alper, Kenneth Wilkins, Sheyu Li, Janice Tufte, Harold Lehmann"}, {"code": "expert-comments", "valueString": "2024-05-17 comment: \"Perspective\" needs to be clarified in the Comment for application. For instance, \"perspective\" could mean patient vs provider vs society OR in favor of drug A vs in favor of drug B. [In general, considering that there's always discussion about a term, there should be some Comment for application.]\n\n2024-05-24 comment: Can we consider rephrasing the definition to -  A study selection bias in which included studies are limited to those that represent \"only \" one perspective"}, {"code": "negative-vote", "valueString": "2024-05-17 vote 4-1 by Saphia Mokrane, Lenny Vasanthan, Sheyu Li, Eric Harvey, Harold Lehmann\n2024-05-24 vote 7-0 by Homa Keshavarz, Sheyu Li, Eric Harvey, Lenny Vasanthan, Harold Lehmann, Janice Tufte, Saphia Mokrane"}, {"code": "comment", "valueString": "The term \"perspective\" covers a variety of contexts, such as a side of an argument or point of view."}, {"code": "approval", "valueString": "2024-05-31 vote 5-0 by Saphia Mokrane, Lenny Vasanthan, Sheyu Li, Eric Harvey, Homa Keshavarz"}]}, {"code": "SEVCO:00325", "display": "inadequate reporting of methods", "definition": "A reporting bias due to insufficient reporting of methods to determine the validity of the results.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Muhammad Afzal"}, {"code": "expert-comments", "valueString": "2023-03-17 vote on \"Inadequate Reporting Bias\" 2-1 by Eric Harvey, Jesus Lopez-Alcalde, Janice Tufte\n2023-03-17 comment on \"Inadequate Reporting Bias\": Inadequate reporting of methods is covered by another term. Recommend changing this term to \"inadequate reporting of results\" or deleting this term if terms covering \"reporting results biases\" have already been established."}, {"code": "approval", "valueString": "2023-03-31 vote 5-0 by Harold Lehmann, Eric Harvey, Janice Tufte, Paola Rosati, Jesus Lopez-Alcalde"}], "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "inadequate reporting to assess analytic strategy"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "inadequate methods reporting bias"}]}, {"code": "SEVCO:00326", "display": "inadequate explanation of participant withdrawals", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Muhammad Afzal, Janice Tufte"}, {"code": "approval", "valueString": "2023-03-31 vote 5-0 by Harold Lehmann, Eric Harvey, Janice Tufte, Paola Rosati, Jesus Lopez-Alcalde"}, {"code": "expert-comments", "valueString": "2023-03-31 comment: Somewhere in this entry should be a link to the \"withdrawal\" SEVCO term. Or terms."}], "definition": "A reporting bias due to insufficient reporting of reasons for withdrawals of participants after study enrollment.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "inadequate explanation of participant attrition"}]}], "display": "reporting bias", "definition": "A bias due to distortions in the selection of or representation of information in study results or research findings.", "property": [{"code": "external-definitions", "valueString": "CoB: Reporting biases = A systematic distortion that arises from the selective disclosure or withholding of information by parties involved in the design, conduct, analysis, or dissemination of a study or research findings (https://catalogofbias.org/biases/reporting-biases/) also notes: The Dictionary of Epidemiology defines reporting bias as the \u201cselective revelation or suppression of information (e.g., about past medical history, smoking, sexual experiences) or of study results.\u201d\nThe Cochrane Handbook states it arises \u201cwhen the dissemination of research findings is influenced by the nature and direction of results.\u201d\nThe James Lind Library states \u201cbiased reporting of research occurs when the direction or statistical significance of results influence whether and how research is reported.\u201d\nQUIPS: The Statistical Analysis and Reporting domain addresses the appropriateness of the study\u2019s statistical analysis and completeness of reporting. It helps the assessor judge whether results are likely to be spurious or biased because of analysis or reporting. To make this judgment, the assessor considers the data presented to determine the adequacy of the analytic strategy and model-building process and investigates concerns about selective reporting. Selective reporting is an important issue in prognostic factor reviews because studies commonly report only factors positively associated with outcomes. A study would be considered to have low risk of bias if the statistical analysis is appropriate for the data, statistical assumptions are satisfied, and all primary outcomes are reported.\nROB2 = This domain addresses bias that arises because the reported result is selected (based on its direction, magnitude or statistical significance) from among multiple intervention effect estimates that were calculated by the trial investigators. We call this bias in selection of the reported result. Consideration of risk of bias requires distinction between:\n\u2022 An outcome domain. This is a state or endpoint of interest, irrespective of how it is measured (e.g. severity\nof depression);\n\u2022 An outcome measurement. This is a specific way in which an outcome domain is measured (e.g. measurement of depression using the Hamilton rating scale 6 weeks after starting intervention); and \n\u2022 An outcome analysis. This is a specific result obtained by analysing one or more outcome measurements (e.g. the difference in mean change in Hamilton rating scale scores from baseline to 6 weeks between experimental and comparator groups). This domain does not address bias due to selective non-reporting (or incomplete reporting) of outcome domains that were measured and analysed by the trial investigators (115). For example, deaths of trial participants may be recorded by the trialists, but the reports of the trial might contain no mortality data, or state only that the intervention effect estimate for mortality was not statistically significant. Such bias puts the result of a synthesis at risk because results are omitted based on their direction, magnitude or statistical significance. It should therefore be addressed at the review level, as part of an integrated assessment of the risk of reporting bias (116).\nROBINS-I = Bias in selection of the reported result"}, {"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Muhammad Afzal, Yuan Gao"}, {"code": "comment", "valueString": "Bias is defined as a systematic distortion in research results (estimation of effect, association, or inference). Distortions in research results means differences between the reported results (findings, conclusions, effect estimates) and the actuality (the truth, the estimand [the quantity targeted for estimation])."}, {"code": "approval", "valueString": "2022-10-21 vote 7-0 by Philippe Rocca-Serra, Harold Lehmann, Joanne Dehnbostel, Mario Tristan, Brian Alper, Janice Tufte, Eric Harvey"}]}, {"code": "SEVCO:00028", "display": "qualitative research bias", "definition": "A bias specific to the design, conduct, analysis or reporting of qualitative research.", "property": [{"code": "external-definitions", "valueString": "MMAT = \u201cQualitative research is an approach for exploring and understanding the meaning individuals or groups ascribe to a social or human problem\u201d (Creswell, 2013b, p. 3)."}, {"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Kenneth Wilkins, Caue Monaco, Li Wang"}, {"code": "comment", "valueString": "Qualitative research is a research approach that studies subjective aspects of social phenomenon, human behavior, and human perception. Qualitative research may encompass any non-quantitative method of analysis. Qualitative research often explores the meaning individuals or groups assign to concepts.\n\nBias is defined as a systematic distortion in research results (estimation of effect, association, or inference). Distortions in research results means differences between the reported results (findings, conclusions, effect estimates) and the actuality (the truth, the estimand [the quantity targeted for estimation]). In qualitative research, the actuality may include multiple meanings that individuals or groups assign to concepts, and there is no quantitative estimand."}, {"code": "negative-vote", "valueString": "2023-12-08 vote 5-1 by Cau\u00ea Monaco, Harold Lehmann, Javier Bracchiglione, Janice Tufte, Yasser Sami Amer, Eric Harvey"}, {"code": "expert-comments", "valueString": "2023-12-08 comments:  Are the initial letters of each word really meant to be capitalized? Or they are this way by error?\nAs SEVCO states, bias relates to differences between the reported results and the actuality (the truth, the estimand). Qualitative research usually does not adopt a positivist approach, therefore, it does not assume there is necessarily one truth to be found. I think at some point (maybe in comments for application) this should be described.\n\n2023-12-15 comment: Qualitative research covers more than, \"subjective aspects of social phenomenon and human behavior\". For instance, I'm not sure this Comment covers usability or pain perception. How about, \"human perception\"?"}, {"code": "approval", "valueString": "2023-12-22 Vote 5-0 Caue Monaco, Eric Harvey, Janice Tufte, Paul Whaley, Joanne Dehnbostel"}], "concept": [{"code": "SEVCO:00356", "display": "bias in qualitative research design", "definition": "A qualitative research bias in which the qualitative approach used in a study is not appropriate for the research question and problem.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Li Wang, Caue Monaco"}, {"code": "comment", "valueString": "Bias is defined as a systematic distortion in research results (estimation of effect, association, or inference). Distortions in research results means differences between the reported results (findings, conclusions, effect estimates) and the actuality (the truth, the estimand [the quantity targeted for estimation]). In qualitative research, the actuality may include multiple meanings that individuals or groups assign to concepts, and there is no quantitative estimand.\n\nThe qualitative approach used in a study should be appropriate for the research question and problem.\n\nCommon qualitative research approaches include (this list is not exhaustive): \n\nEthnography - The aim of the study is to describe and interpret the shared cultural behavior of a group of individuals.\nPhenomenology - The study focuses on the subjective experiences and interpretations of a phenomenon encountered by individuals.\nNarrative research - The study analyzes life experiences of an individual or a group.\nGrounded theory - Generation of theory from data in the process of conducting research (data collection occurs first).\nCase study - In-depth exploration and/or explanation of issues intrinsic to a particular case. A case can be anything from a decision-making process, to a person, an organization, or a country.\nQualitative description - There is no specific methodology, but a qualitative data collection and analysis, e.g., in-depth interviews or focus groups, and hybrid thematic analysis (inductive and deductive). \n\nReference - Hong QN, Pluye P, F\u00e0bregues S, Bartlett G, Boardman F, Cargo M, Dagenais P, Gagnon M-P, Griffiths F, Nicolau B, O\u2019Cathain A, Rousseau M-C, Vedel I. Mixed Methods Appraisal Tool (MMAT), version 2018. Registration of Copyright (#1148552), Canadian Intellectual Property Office, Industry Canada. Accessed at: http://mixedmethodsappraisaltoolpublic.pbworks.com/w/file/fetch/127916259/MMAT_2018_criteria-manual_2018-08-01_ENG.pdf"}, {"code": "expert-comments", "valueString": "2023-12-15 comment: (Ethnography could include grounded theory, so these are not a great pair.)\n\n2024-01-05 comment:\nI think there are some major problems with the definition and comment for application:\n- First, the definition is almost the same as the term, using basically the same words (so, it adds no new knowledge to the reader).\n- Second, the comment for application provides a more detailed approach to a definition than the definition itself (\"The qualitative approach used in a study should be appropriate for the research question and problem\").\n- Third, among the common qualitative research approaches included, there are some in which the term \"bias\" may not be so applicable. Hierarchically, this term comes from \"bias\", which is defined as \"A systematic distortion in research results (estimation of effect, association, or inference). Distortions in research results means differences between the reported results (findings, conclusions, effect estimates) and the actuality (the truth, the estimand [the quantity targeted for estimation])\". So, we need an assumption of \"actuality\" for bias to exist. \nSome of the qualitative approaches described do not have that assumption. For example, phenomenology focuses on \"subjective experiences\", and grounded theory \"generates a theory\", which is not an \"actuality\" by itself. I think this comment is applicable to all of the terms related to qualitative bias."}, {"code": "negative-vote", "valueString": "2024-01-05 vote 4-1 by Javier Bracchiglione, Joanne Dehnbostel, Janice Tufte, Eric Harvey, Cau\u00ea Monaco"}, {"code": "approval", "valueString": "2024-01-19 vote 5-0 by Harold Lehmann, Brian S. Alper, Homa Keshavarz, Javier Bracchiglione, Eric Harvey"}]}, {"code": "SEVCO:00357", "display": "bias in qualitative data collection methods", "definition": "A qualitative research bias in which the data sources, the methods of data collection, and the forms of data are not adequate or appropriate to address the research question.", "property": [{"code": "comment", "valueString": "Bias is defined as a systematic distortion in research results (estimation of effect, association, or inference). Distortions in research results means differences between the reported results (findings, conclusions, effect estimates) and the actuality (the truth, the estimand [the quantity targeted for estimation]). In qualitative research, the actuality may include multiple meanings that individuals or groups assign to concepts, and there is no quantitative estimand.\n\nThe data sources (e.g., archives, documents), the methods of data collection (e.g., in depth interviews, group interviews, and/or observations), and the forms of the data (e.g., tape recording, video material, diary, photo, and/or field notes) should be adequate and appropriate to address the research question. The term 'bias in qualitative data collection methods' may be supplemental to other terms for types of detection bias or types of selection bias."}, {"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Caue Monaco, Li Wang"}, {"code": "negative-vote", "valueString": "2024-01-05 vote 3-1 by Javier Bracchiglione, Janice Tufte, Eric Harvey, Cau\u00ea Monaco"}, {"code": "expert-comments", "valueString": "2024-01-05 comment: see 'bias in qualitative research design'"}, {"code": "approval", "valueString": "2024-01-19 vote 5-0 by Harold Lehmann, Brian S. Alper, Homa Keshavarz, Javier Bracchiglione, Eric Harvey"}]}, {"code": "SEVCO:00358", "display": "bias in qualitative analysis", "definition": "A qualitative research bias in which the analysis approach is not appropriate for the research question and qualitative approach.", "property": [{"code": "comment", "valueString": "Bias is defined as a systematic distortion in research results (estimation of effect, association, or inference). Distortions in research results means differences between the reported results (findings, conclusions, effect estimates) and the actuality (the truth, the estimand [the quantity targeted for estimation]). In qualitative research, the actuality may include multiple meanings that individuals or groups assign to concepts, and there is no quantitative estimand.\n\nThe analysis approach should be appropriate for the research question and qualitative approach (design). The term 'bias in qualitative analysis' may be supplemental to other terms for types of analysis bias.\nWhen interpretation is an integral part of qualitative analysis, bias in the interpretive analysis should use the term 'bias in qualitative analysis' rather than 'cognitive interpretive bias in reporting'."}, {"code": "editors", "valueString": "Brian S. Alper, Li Wang, Caue Monaco, Joanne Dehnbostel"}, {"code": "expert-comments", "valueString": "2023-12-15 comments: I suppose a \"guard rail\" would be, \"Were the methods described adequately, that they could be reproduced\", which is different from the bias itself\n\nI am not sure why sometimes terms include the word \"inadequate\" and sometimes \"inappropriate\"\n2024-01-05 comment: see 'bias in qualitative research design'"}, {"code": "negative-vote", "valueString": "2024-01-05 vote 3-1 by Javier Bracchiglione, Janice Tufte, Eric Harvey, Cau\u00ea Monaco"}, {"code": "approval", "valueString": "2024-01-19 vote 5-0 by Harold Lehmann, Brian S. Alper, Homa Keshavarz, Javier Bracchiglione, Eric Harvey"}]}, {"code": "SEVCO:00360", "display": "incoherence among qualitative data, analysis, and interpretation", "definition": "A qualitative research bias in which there is any mismatch among hypothesis, data collected, data analysis, and results interpretation.", "property": [{"code": "comment", "valueString": "The term mismatch applies to an inappropriate or wrong or inadequate relationship."}, {"code": "editors", "valueString": "Harold Lehmann, Joanne Dehnbostel, Muhammad Afzal, Kenneth Wilkins, Khalid Shahin, Xing Song"}, {"code": "negative-vote", "valueString": "2024-01-19 vote 3-1 by Harold Lehmann, Homa Keshavarz, Javier Bracchiglione, Eric Harvey"}, {"code": "expert-comments", "valueString": "2024-01-19 comment: I think the definition should not start with \"There are...\". Maybe it should be more straightforward: \"Mismatch among (...)\"2024-02-02 comment: Does the phrase \"in the study report\" add value to the definition or add an unnecessary clause?\n2024-02-16 comment: The definition sounds coherent, but, as it is, I would argue that other previous concepts (e.g. \"study eligibility criteria not appropriate for review question\") could also be interpreted by this term."}, {"code": "approval", "valueString": "2024-03-08 vote 5-0 Homa Keshavarz, Eric Harvey, Harold Lehmann, Javier Bracchiglione, Lenny Vasanthan"}]}]}, {"code": "SEVCO:00029", "display": "mixed methods research bias", "definition": "A bias specific to the alignment of design, conduct, analysis or reporting of qualitative research and quantitative research within the same research project.", "property": [{"code": "external-definitions", "valueString": "MMAT: Mixed methods (MM) research involves combining qualitative (QUAL) and quantitative (QUAN) methods. In this tool, to be considered MM, studies have to meet the following criteria (Creswell and Plano Clark, 2017): (a) at least one QUAL method and one QUAN method are combined; (b) each method is used rigorously in accordance to the generally accepted criteria in the area (or tradition) of research invoked; and (c) the combination of the methods is carried out at the minimum through a MM design (defined a priori, or emerging) and the integration of the QUAL and QUAN phases, results, and data"}, {"code": "comment", "valueString": "Mixed methods research is a research approach that combines both qualitative and quantitative research methods within a single study or research project. This methodology aims to provide a more comprehensive understanding of a research problem by integrating the strengths of both qualitative and quantitative research.\nExamples of mixed methods research include combining surveys with in-depth interviews, using quantitative data to identify patterns and trends followed by qualitative data to explore the underlying reasons and meanings, or incorporating qualitative findings to help interpret and validate quantitative results.\nOverall, mixed methods research provides a more holistic understanding of a research question by acknowledging and leveraging the strengths of both qualitative and quantitative approaches."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann"}, {"code": "approval", "valueString": "2024-02-23 vote 5-0 by Homa Keshavarz, Harold Lehmann, Javier Bracchiglione, Lenny Vasanthan, Eric Harvey"}, {"code": "negative-vote", "valueString": "2024-01-19 vote 3-1 by Harold Lehmann, Homa Keshavarz, Javier Bracchiglione, Eric Harvey"}, {"code": "expert-comments", "valueString": "2024-01-19 comment: I would say a bias is not applied to the \"coordination\" (this sounds more like an administrative issue)"}], "concept": [{"code": "SEVCO:00361", "display": "bias in mixed methods research design", "definition": "A mixed methods research bias in which the mixed methods approach used in a study is not appropriate for the research question and problem.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "inadequate rationale for mixed methods design"}], "property": [{"code": "comment", "valueString": "This signaling question in the Mixed Methods Assessment Tool (MMAT) is 5.1. Is there an adequate rationale for using a mixed methods design to address the research question? \n\nCommon mixed methods designs include:\n\nConvergent design\nThe QUAL and QUAN components are usually (but not necessarily) concomitant. The purpose is to examine the same phenomenon by interpreting QUAL and QUAN results (bringing data analysis together at the interpretation stage), or by integrating QUAL and QUAN datasets (e.g., data on same cases), or by transforming data (e.g., quantization of qualitative data).\n\nSequential explanatory design\nResults of the phase 1 - QUAN component inform the phase 2 - QUAL component. The purpose is to explain QUAN results using QUAL findings. E.g., the QUAN results guide the selection of QUAL data sources and data collection, and the QUAL findings contribute to the interpretation of QUAN results.\n\nSequential exploratory design\nResults of the phase 1 - QUAL component inform the phase 2 - QUAN component. The purpose is to explore, develop and test an instrument (or taxonomy), or a conceptual framework (or theoretical model). E.g., the QUAL findings inform the QUAN data collection, and the QUAN results allow a statistical generalization of the QUAL findings.\n\nKey references: Creswell et al. (2011); Creswell and Plano Clark, (2017); O'Cathain (2010)\n\nReference - Hong QN, Pluye P, F\u00e0bregues S, Bartlett G, Boardman F, Cargo M, Dagenais P, Gagnon M-P, Griffiths F, Nicolau B, O\u2019Cathain A, Rousseau M-C, Vedel I. Mixed Methods Appraisal Tool (MMAT), version 2018. Registration of Copyright (#1148552), Canadian Intellectual Property Office, Industry Canada. Accessed at: http://mixedmethodsappraisaltoolpublic.pbworks.com/w/file/fetch/127916259/MMAT_2018_criteria-manual_2018-08-01_ENG.pdf"}, {"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Joanne Dehnbostel"}, {"code": "approval", "valueString": "2024-02-23 vote 5-0 by Homa Keshavarz, Harold Lehmann, Brian S. Alper, Lenny Vasanthan, Eric Harvey"}]}, {"code": "SEVCO:00362", "display": "ineffective integration of qualitative and quantitative study components", "definition": "A mixed methods research bias in which the qualitative research and quantitative research components are not adequately combined.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Kenneth Wilkins"}, {"code": "approval", "valueString": "2024-02-23 vote 5-0 by Homa Keshavarz, Harold Lehmann, Brian S. Alper, Lenny Vasanthan, Eric Harvey"}]}, {"code": "SEVCO:00363", "display": "inappropriate interpretation of integration of qualitative and quantitative findings", "definition": "A mixed methods research bias in which the process of combining the results of the constituent analyses is flawed.", "property": [{"code": "comment", "valueString": "This criterion is related to meta-inference, which is defined as the overall interpretations derived from integrating qualitative and\nquantitative findings (Teddlie and Tashakkori, 2009). Meta-inference occurs during the interpretation of the findings from the\nintegration of the qualitative and quantitative components, and shows the added value of conducting a mixed methods study\nrather than having two separate studies. (Pluye et al 2018)"}, {"code": "editors", "valueString": "Harold Lehmann, Joanne Dehnbostel, Caue Monaco, Muhammad Afzal, Homa Keshavarz, Brian S. Alper, Kenneth Wilkins"}, {"code": "external-definitions", "valueString": "Pluye, P., Bengoechea, E.G., Granikov, V., Kaur, N., & Tang, D.L. (2018). A World of Possibilities in Mixed Methods: Review of the Combinations of Strategies Used to Integrate Qualitative and Quantitative Phases, Results and Data. INTERNATIONAL JOURNAL OF MULTIPLE RESEARCH APPROACHES. https://www.semanticscholar.org/paper/A-World-of-Possibilities-in-Mixed-Methods%3A-Review-Pluye-Bengoechea/21f292d0cb5cc07a982b240b17ff077fe4646632\n\nTeddlie, C. and Tashakkori, A. (2009) Foundations of Mixed Methods Research: Integrating Quantitative and Qualitative Approaches in the Social and Behavioral Sciences. Sage, London."}, {"code": "negative-vote", "valueString": "2024-01-19 vote 3-0 by Harold Lehmann, Eric Harvey, Homa Keshavarz BUT then the definition was changed in conference"}, {"code": "approval", "valueString": "2024-02-23 vote 5-0 by Homa Keshavarz, Harold Lehmann, Brian S. Alper, Lenny Vasanthan, Eric Harvey"}]}, {"code": "SEVCO:00364", "display": "inadequate handling of inconsistency between qualitative and quantitative findings", "definition": "A mixed methods research bias in which discrepancies in the results from the qualitative and quantitative components are not adequately addressed.", "property": [{"code": "comment", "valueString": "When integrating the findings from the qualitative and quantitative components, divergences and inconsistencies (also called conflicts, contradictions, discordances, discrepancies, and dissonances) can be found. It is not sufficient to only report the divergences; they need to be explained. Different strategies to address the divergences have been suggested such as reconciliation, initiation, bracketing and exclusion (Pluye et al., 2009b). (Reference - Hong QN, Pluye P, F\u00e0bregues S, Bartlett G, Boardman F, Cargo M, Dagenais P, Gagnon M-P, Griffiths F, Nicolau B, O\u2019Cathain A, Rousseau M-C, Vedel I. Mixed Methods Appraisal Tool (MMAT), version 2018. Registration of Copyright (#1148552), Canadian Intellectual Property Office, Industry Canada. Accessed at: http://mixedmethodsappraisaltoolpublic.pbworks.com/w/file/fetch/127916259/MMAT_2018_criteria-manual_2018-08-01_ENG.pdf)"}, {"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Joanne Dehnbostel"}, {"code": "approval", "valueString": "2024-02-23 vote 5-0 by Homa Keshavarz, Harold Lehmann, Xing Song, Lenny Vasanthan, Eric Harvey"}]}]}, {"code": "SEVCO:00030", "display": "bias in validation assessment", "definition": "A bias in the design, conduct or reporting of studies or analyses intended to evaluate the reliability and/or performance of a procedure for a specific predictive, classification, measurement, or communication purpose.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "validation bias"}], "property": [{"code": "external-definitions", "valueString": "PROBAST = ROB, which was defined to occur when shortcomings in study design, conduct, or analysis lead to systematically distorted estimates of model predictive performance. PROBAST enables a focused and transparent approach to assessing the ROB and applicability of studies that develop, validate, or update prediction models for individualized predictions. Prediction models are sometimes described as risk prediction models, predictive models, prediction indices or rules, or risk scores."}, {"code": "comment", "valueString": "Bias in validation assessment is often used for predictive model research and diagnostic research where optimal research design includes derivation studies and external validation studies.\n\nA 'validation study' has a validation goal where validation goal {SEVCO:01098} is defined as a study goal with the intent to determine the reliability and/or performance of a procedure for a specific predictive, classification, measurement, or communication purpose.\n\nProcedures that may be assessed in validation studies include predictive algorithms, measurement instruments, and educational materials. Internal validation is tested in populations from the source used for derivation of the procedure. External validation is tested in populations that differ from the source used for derivation of the procedure."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Kenneth Wilkins"}, {"code": "approval", "valueString": "2023-10-27 vote 5-0 by Brian S. Alper, Eric Harvey, Yasser Sami Amer, Janice Tufte, Harold Lehmann"}], "concept": [{"code": "SEVCO:00368", "display": "bias in external validation assessment", "definition": "A bias in validation assessment using a sample source that differs from those used in the derivation of the procedure.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "inadequate external validation assessment"}], "property": [{"code": "comment", "valueString": "Validation assessment is often used for predictive model research and diagnostic research where optimal research design includes derivation studies and external validation studies.\n\nA 'validation study' has a validation goal where validation goal {SEVCO:01098} is defined as a study goal with the intent to determine the reliability and/or performance of a procedure for a specific predictive, classification, measurement, or communication purpose.\n\nProcedures that may be assessed in validation studies include predictive algorithms, measurement instruments, and educational materials. Internal validation is tested in populations from the source used for derivation of the procedure. External validation is tested in populations that differ from the source used for derivation of the procedure.\n\nBias in validation assessment is defined as a bias in the design, conduct or reporting of studies or analyses intended to evaluate the reliability and/or performance of a procedure for a specific predictive, classification, measurement, or communication purpose.\n\nBias in external validation assessment may be used for absence of any external validation assessment or inadequacy in external validation assessment."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Muhammad Afzal"}, {"code": "approval", "valueString": "2023-11-26 vote 5-0 by Harold Lehmann, Muhammad Afzal, Janice Tufte, Jesus Lopez-Alcalde, Eric Harvey"}]}, {"code": "SEVCO:00367", "display": "bias in internal validation assessment", "definition": "A bias in validation assessment specific to a validation assessment that uses the same sample source that was used in the derivation of the procedure.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "inadequate internal validation assessment"}], "property": [{"code": "comment", "valueString": "Validation assessment is often used for predictive model research and diagnostic research where optimal research design includes derivation studies and external validation studies.\n\nA 'validation study' has a validation goal where validation goal {SEVCO:01098} is defined as a study goal with the intent to determine the reliability and/or performance of a procedure for a specific predictive, classification, measurement, or communication purpose.\n\nProcedures that may be assessed in validation studies include predictive algorithms, measurement instruments, and educational materials. Internal validation is tested in populations from the source used for derivation of the procedure. \n\nModel derivation is often based on a portion of data available from a sample source, and internal validation is performed using the same sample data but a different set of data. \n\nWhereas external validation is tested in populations that differ from the source used for derivation of the procedure, internal validation is tested in the same population.\n\nBias in validation assessment is defined as a bias in the design, conduct or reporting of studies or analyses intended to evaluate the reliability and/or performance of a procedure for a specific predictive, classification, measurement, or communication purpose.\n\nBias in internal validation assessment may be used for absence of any internal validation assessment or inadequacy in internal validation assessment. A common cause of bias in internal validation assessment is validation using the same data that was used for derivation."}, {"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Harold Lehmann, Muhammad Afzal"}, {"code": "approval", "valueString": "2023-12-01 vote 5-0 by Xing Song, Javier Bracchiglione, Harold Lehmann, Eric Harvey, Caue Monaco"}]}]}, {"code": "SEVCO:00018", "display": "DEFERRED: choice-of-question bias", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "choice of question bias"}], "property": [{"code": "external-definitions", "valueString": "https://www.ijcmr.com/uploads/7/7/4/6/77464738/_ijcmr_628_may_23.pdf \"What biases can occur during the planning phase of an RCT?\n\nI. Biases that can arise, even before the trial is conducted 1. Choice-of-Question Bias It is one of the most unrecognized types of bias that occur in RCTs. This bias is concealed within the question that the study intends to answer. This bias may not have a stronger impact on the strength of the study but it may affect the generalizability of the study outcomes.6 This bias can take many forms: i. Hidden agenda bias:\n\nIt occurs when a trial is mounted, not in order to answer a question, but rather to demonstrate a pre-required answer. ii. Cost and convenience bias: It occurs when a study is done on a basis of what we can afford to study, or what is convenient to study, rather than what we really want to study. It can seriously compromise what we choose to study. iii. Funding availability Bias: It occurs where studies tend to concentrate on questions that are more readily fundable, often for a vested or commercial interest.7\n\n\n\n\n\nChoice-of-question bias Perhaps one of the least recognized forms of bias in an RCT is hidden in the choice of the question that the trial intends to answer. This would not necessarily affect the internal validity of a trial, but may have profound effects on its external validity, or generalizability. This bias can take many forms. Hidden agenda bias occurs when a trial is mounted, not in order to answer a question, but in order to demonstrate a pre-required answer. The unspoken converse may be \u2018Don\u2019t do a trial if it won\u2019t show you what you want to find\u2019. This could be called the vested interest bias. 14 Closely related to this is the self fulfiling prophecy bias in which the very carrying out of a trial ensures the desired result. The cost and convenience bias can seriously compromise what we choose to study. When we study what we can afford to study, or what is convenient to study, rather than what we really want to study, or should study, we take resources away from what we know is important. Closely related to this is the funding availability bias where studies tend to concentrate on questions that are more readily fundable, often for a vested or commercial interest. We should always look for the secondary gains search bias which can influence the choice of study, the methodology used, and the ascertainment and dissemination of the results.\"\nChapter 3, p.36 of Wiley text\nChapter Title: Bias in randomized controlled trials\n\nJadad AR, Enkin MW. Randomized Controlled Trials Questions, Answers, and Musings Second edition. Published by Blackwell Publishing 2007. Print ISBN:9781405132664. Online ISBN:9780470691922. doi: 10.1002/9780470691922."}, {"code": "editors"}, {"code": "deprecated", "valueString": "2023-11-03"}], "concept": [{"code": "SEVCO:00251", "display": "predetermined result bias", "definition": "Self-fulfilling prophecy bias, Shape the result bias"}, {"code": "SEVCO:00256", "display": "wrong design bias"}, {"code": "SEVCO:00257", "display": "population choice bias"}, {"code": "SEVCO:00258", "display": "intervention choice bias"}, {"code": "SEVCO:00259", "display": "comparator choice bias"}, {"code": "SEVCO:00260", "display": "outcome choice bias"}, {"code": "SEVCO:00391", "display": "predictor choice bias", "definition": "from PROBAST 2.3 Are all predictors available at the time the model is intended to be used? (for the explanatory variable)"}]}, {"code": "SEVCO:00370", "display": "early study termination bias", "concept": [{"code": "SEVCO:00371", "display": "early study termination bias due to competing interests", "definition": "An early study termination bias due to the decision to end the study being influenced by financial, commercial, legal, political, social, professional, or intellectual  interests.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Muhammad Afzal, Mario Tristan, Khalid Shahin"}, {"code": "approval", "valueString": "2022-04-01 vote 6-0 by Brian S. Alper, Joanne Dehnbostel, Jesus Lopez-Alcalde, Harold Lehmann, Cau\u00ea Monaco, Mario Tristan"}]}, {"code": "SEVCO:00372", "display": "early study termination bias due to unplanned use of interim analysis", "definition": "An early study termination bias due to awareness of study results without following a preplanned protocol for how interim results will influence the decision to terminate the study.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Muhammad Afzal, Mario Tristan, Khalid Shahin, Joanne Dehnbostel"}, {"code": "approval", "valueString": "2022-04-01 vote 5-0 by Joanne Dehnbostel, Jesus Lopez-Alcalde, Harold Lehmann, Cau\u00ea Monaco, Mario Tristan"}]}, {"code": "SEVCO:00373", "display": "early study termination bias due to inappropriate statistical stopping rule", "definition": "An early study termination bias due to use of an inappropriate model or threshold in the analysis used for determination to end the study.", "property": [{"code": "comment", "valueString": "An example of an inappropriate statistical stopping rule is one that does not account for multiple analyses (i.e. does not use a lower p value threshold) for a conclusion of benefit warranting early termination of the study."}, {"code": "editors", "valueString": "Brian S. Alper, Muhammad Afzal, Mario Tristan, Khalid Shahin, Joanne Dehnbostel"}, {"code": "approval", "valueString": "2022-04-01 vote 6-0 by Joanne Dehnbostel, Jesus Lopez-Alcalde, Harold Lehmann, Cau\u00ea Monaco, Mario Tristan, Robin Ann Yurk"}]}, {"code": "SEVCO:00374", "display": "early study termination bias due to external factors", "definition": "An early study termination bias due to a decision to end the study based on factors other than the results of interim analysis.", "property": [{"code": "comment", "valueString": "Examples of external factors may include cessation of funding, and safety or efficacy results reported by other studies."}, {"code": "editors", "valueString": "Brian S. Alper, Muhammad Afzal, Mario Tristan, Khalid Shahin, Joanne Dehnbostel"}, {"code": "approval", "valueString": "2022-04-01 vote 6-0 by Joanne Dehnbostel, Jesus Lopez-Alcalde, Harold Lehmann, Cau\u00ea Monaco, Mario Tristan, Robin Ann Yurk"}]}], "definition": "A bias due to the decision to end the study earlier than planned.", "property": [{"code": "comment", "valueString": "Child terms (types of Early Study Termination Bias) may be used to report the reasons for bias in the decision to end the study earlier than planned. Bias resulting from the early study termination may be described with other terms in the code system."}, {"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Muhammad Afzal, Mario Tristan, Khalid Shahin, Harold Lehmann, Joanne Dehnbostel"}, {"code": "negative-vote", "valueString": "2022-04-01 vote 4-1 by Jesus Lopez-Alcalde, Harold Lehmann, Cau\u00ea Monaco, Robin Ann Yurk, Mario Tristan"}, {"code": "expert-comments", "valueString": "2022-04-01 comment: Term Definition:  Simplify so it reads.\nA bias in the reported results due to early termination of a study resulting in incomplete data collection."}, {"code": "approval", "valueString": "2022-04-08 vote 6-0 by nelle.stocquart, nisha mathew, Mario Tristan, Robin Ann Yurk, Harold Lehmann, Joanne Dehnbostel"}], "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "bias due to early study termination"}]}, {"code": "SEVCO:00398", "display": "cognitive bias influencing study design", "definition": "A bias in the study design due to the subjective nature of human decision-making.", "property": [{"code": "comment", "valueString": "[Study design](https://fevir.net/resources/CodeSystem/27270#SEVCO:01000) is defined as \"a plan specification for how and what kinds of data will be gathered as part of an investigation which may produce testable explanations, conclusions and predictions or test a hypothesis.\" \nThis plan specification is the result of human decision-making. Any human decision-making may be influenced by cognitive bias, recognized or not."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Airton Stein, Joanne Dehnbostel, Homa Keshavarz, Khalid Shahin, Cau\u00ea Monaco"}, {"code": "open-for-voting", "valueString": "2024-12-06"}, {"code": "external-definitions", "valueString": "This term was added after evaluation of [A comprehensive item bank of internal validity issues of relevance to in vitro toxicology studies](https://www.tandfonline.com/doi/full/10.1080/2833373X.2024.2418045) which included a concept of 'Metabias' defined as 'A general distorting influence on investigator decision-making that may bias the results or findings of a study'"}, {"code": "negative-vote", "valueString": "2024-12-06 vote 7-1 by Homa Keshavarz, Bhagvan Kommadi, Sheyu Li, Cau\u00ea Monaco, Javier Bracchiglione, Lara Kahaleh, Saphia Mokrane, Airton Tetelbom Stein\n2024-12-13 vote 4-1 by Saphia Mokrane, Lara Kahaleh, Bhagvan Kommadi, Paul Whaley, Airton Tetelbom Stein"}, {"code": "expert-comments", "valueString": "2024-12-06 comment re: \"cognitive bias influencing study design\" = \"A bias in the study design due to the subjective nature of human decision-making.\"1No)\nThe comments are very confusing. \n\n2024-12-13 comment re: \"cognitive bias influencing study design\" = \"A bias in the study design due to the subjective nature of human decision-making.\"1No)\nNot intuitive or self explanatory"}]}, {"code": "SEVCO:00399", "display": "late study termination bias", "definition": "A bias due to the decision to end the study later than planned.", "property": [{"code": "comment", "valueString": "When the study is allowed to continue longer than a pre-planned stopping point, then there is a risk of bias in that the results from the study may differ from the results that would occur according to the study plan. When the study termination is pre-planned to vary by events or results of interim analyses (e.g., in an adaptive design), this is not a 'late study termination bias'."}, {"code": "open-for-voting", "valueString": "2024-12-06"}, {"code": "external-definitions", "valueString": "This term was added after evaluation of [A comprehensive item bank of internal validity issues of relevance to in vitro toxicology studies](https://www.tandfonline.com/doi/full/10.1080/2833373X.2024.2418045) which included a concept of 'Timing of study termination bias' defined as a bias due to the decision to end the study earlier or later than planned, and modified from the original SEVCO term \u201c[early study termination bias](https://fevir.net/resources/CodeSystem/27270#SEVCO:00370),\u201d defined as \u201ca bias due to the decision to end the study earlier than planned\u201d"}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Airton Stein, Joanne Dehnbostel, Homa Keshavarz, Khalid Shahin, Cau\u00ea Monaco"}, {"code": "negative-vote", "valueString": "2024-12-06 vote 7-1 by Homa Keshavarz, Sheyu Li, Cau\u00ea Monaco, Javier Bracchiglione, Lara Kahaleh, Bhagvan Kommadi, Saphia Mokrane, Airton Tetelbom Stein"}, {"code": "expert-comments", "valueString": "2024-12-06 comment re: \"late study termination bias\" = \"A bias due to the decision to end the study later than planned.\"1No)\nThis bias highly relies on the reason of the late termination, which warrants discussion. It is also helpful to differentiate two situations, i.e., post-trial follow up (analysis based on the follow up data after the termination of the trial) and delayed termination based on the adaptive design (it is not a real delay)."}]}]}, {"code": "SEVCO:00027", "display": "conflict of interest", "definition": "A risk factor for bias in which persons influencing research design, conduct, analysis or reporting have motivations that could compromise their impartiality.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "conflicted interests"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "conflicts of interest"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "competing interest"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "competing interests"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "duality of interest"}], "property": [{"code": "external-definitions", "valueString": "MASTER-28. Conflict of interests were declared and absent"}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Kenneth Wilkins, Javier Bracchiglione, Janice Tufte, Muhammad Afzal, Caue Monaco"}, {"code": "negative-vote", "valueString": "2023-11-10 vote 4-1 by Brian S. Alper, Harold Lehmann, Janice Tufte, Eric Harvey, Javier Bracchiglione"}, {"code": "expert-comments", "valueString": "2023-11-10 comment: I do not think the term should be limited to goals and motivations this seems judgmental and manipulative. COI can be based on intellectual property and or current research work along the same subject where a researcher or partner is too involved with a project or paper on the same subject"}, {"code": "comment", "valueString": "Motivations may be explicit or implicit. Motivations may be unconscious or unrecognized. Conflict of interest is sometimes phrased \"potential conflict of interest\" or \"perceived conflict of interest\"."}, {"code": "approval", "valueString": "2023-12-01 vote 6-0 by Cau\u00ea Monaco, Xing Song, Javier Bracchiglione, Harold Lehmann, Janice Tufte, Eric Harvey"}], "concept": [{"code": "SEVCO:00355", "display": "financial conflict of interest", "definition": "A risk factor for bias in which persons influencing research design, conduct, analysis or reporting have financial motivations that could compromise their impartiality.", "property": [{"code": "comment", "valueString": "Motivations may be explicit or implicit. Motivations may be unconscious or unrecognized. The financial motivations may be direct (e.g. salary or consulting fees) or indirect (e.g. stock interests or spousal financial interests). Conflict of interest is sometimes phrased \"potential conflict of interest\" or \"perceived conflict of interest\"."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Kenneth Wilkins, Javier Bracchiglione, Janice Tufte, Muhammad Afzal, Caue Monaco"}, {"code": "approval", "valueString": "2023-12-01 vote 6-0 by Cau\u00ea Monaco, Xing Song, Javier Bracchiglione, Harold Lehmann, Janice Tufte, Eric Harvey"}, {"code": "expert-comments", "valueString": "2023-12-01 comment: I agree with the definition of the term, but I think it will be better to further explicit what \"financial\" means in the comments for application (e.g. salary, stocks, paid assistance to congress)"}]}, {"code": "SEVCO:00252", "display": "nonfinancial conflict of interest", "definition": "A risk factor for bias in which persons influencing research design, conduct, analysis or reporting have non-financial motivations that could compromise their impartiality.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "non-financial conflict of interest"}], "property": [{"code": "comment", "valueString": "Motivations may be explicit or implicit. Motivations may be unconscious or unrecognized. The non-financial motivations may be related to social, political, professional, ideological, or other factors. Conflict of interest is sometimes phrased \"potential conflict of interest\" or \"perceived conflict of interest\"."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Kenneth Wilkins, Javier Bracchiglione, Janice Tufte, Muhammad Afzal, Caue Monaco"}, {"code": "approval", "valueString": "2023-12-01 vote 6-0 by Cau\u00ea Monaco, Xing Song, Javier Bracchiglione, Harold Lehmann, Janice Tufte, Eric Harvey"}, {"code": "expert-comments", "valueString": "2023-12-01 comment: I agree with the definition of the term, but I think it will be better to further explicit what \"non-financial\" means in the comments for application (e.g. intellectual)"}]}]}, {"code": "SEVCO:00007", "display": "rating of bias risk", "definition": "The result of a qualitative assessment of the likelihood and potential impact of systematic distortion in research results.", "property": [{"code": "comment", "valueString": "[Bias](https://fevir.net/resources/CodeSystem/27270#SEVCO:00001) is defined as a systematic distortion in research results (estimation of effect, association, or inference). Distortions in research results means differences between the reported results (findings, conclusions, effect estimates) and the actuality (the truth, the estimand [the quantity targeted for estimation]).\n\nAll terms defined here are qualitative classifications of the risk of bias. Although a risk of bias can conceptually be quantified, there is no common agreed method on how to quantify a risk of bias."}, {"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Carlos Alva-Diaz, Homa Keshavarz"}, {"code": "approval", "valueString": "2024-09-20 vote 6-0 by Javier Bracchiglione, C P Ooi, Bhagvan Kommadi, Lenny Vasanthan, Eric Harvey, Airton Tetelbom Stein"}, {"code": "negative-vote", "valueString": "2024-08-30 vote 7-0 by Saphia Mokrane, Sheyu Li, Lenny Vasanthan, Eric Harvey, Janice Tufte, Homa Keshavarz, Airton Tetelbom Stein BUT THEN DEFINITION CHANGED to add \"The result of \" based on feedback on child terms."}], "concept": [{"code": "SEVCO:00186", "display": "low risk of bias", "definition": "The result of a qualitative assessment that there is a low likelihood and potential impact of systematic distortion in research results.", "property": [{"code": "comment", "valueString": "A 'low risk of bias' rating denotes a judgment that there are no serious concerns for bias. The 'potential impact of systematic distortion in research results' may include the impact on the clinical interpretation or conclusion of the study findings."}, {"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Homa Keshavarz"}, {"code": "external-definitions", "valueString": "In the Cochrane Handbook (https://training.cochrane.org/handbook/current/chapter-08#section-8-7):\nOnce the signalling questions are answered, the next step is to reach a risk-of-bias judgement, and assign one of three levels to each domain:\n\nLow risk of bias;\nSome concerns; or\nHigh risk of bias."}, {"code": "negative-vote", "valueString": "2024-09-06 vote 5-1 by Carlos Alva-Diaz, Cau\u00ea Monaco, Sheyu Li, janice tufte, Eric Harvey, Javier Bracchiglione"}, {"code": "expert-comments", "valueString": "2024-09-06 comment re: \"low risk of bias\" = \"A qualitative assessment that there is a low likelihood and potential impact of systematic distortion in research results.\"1N)\nA qualitative judgement that the the systematic distortion is unlikely to impact the clinical interpretation or conclusion of the study findings. \n\nThe rating of low, moderate, and high are subjective judgement or the result of an assessment based on a particular context. It is thus not a asessment per se. As a clinician, I would prefer to the term ending up with a clinical interpretation or decision. But other conclusion can be possible even for clinical research."}, {"code": "approval", "valueString": "2024-09-20 vote 8-0 by Carlos Alva-Diaz, Saphia Mokrane, Javier Bracchiglione, C P Ooi, Bhagvan Kommadi, Lenny Vasanthan, Eric Harvey, Airton Tetelbom Stein"}]}, {"code": "SEVCO:00187", "display": "moderate risk of bias", "definition": "The result of a qualitative assessment that there is some likelihood and potential impact of systematic distortion in research results, and this likelihood and potential impact is between low and high.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "some concerns for risk of bias"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "medium risk of bias"}], "property": [{"code": "external-definitions", "valueString": "In the Cochrane Handbook (https://training.cochrane.org/handbook/current/chapter-08#section-8-7):\nOnce the signalling questions are answered, the next step is to reach a risk-of-bias judgement, and assign one of three levels to each domain:\n\nLow risk of bias;\nSome concerns; or\nHigh risk of bias."}, {"code": "comment", "valueString": "The 'potential impact of systematic distortion in research results' may include the impact on the clinical interpretation or conclusion of the study findings.\n\nThe term 'unclear risk of bias' is not explicitly defined because it could be used to represent 'moderate risk of bias' or [undetermined risk of bias](https://fevir.net/resources/CodeSystem/27270#SEVCO:00192)."}, {"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Joanne Dehnbostel, Harold Lehmann, Carlos Alva-Diaz"}, {"code": "negative-vote", "valueString": "2024-09-06 vote 5-2 by Airton Tetelbom Stein, Carlos Alva-Diaz, Cau\u00ea Monaco, Sheyu Li, janice tufte, Eric Harvey, Javier Bracchiglione"}, {"code": "expert-comments", "valueString": "2024-09-06 comments re: \"moderate risk of bias\" = \"A qualitative assessment that there is some likelihood and potential impact of systematic distortion in research results, but this likelihood and potential impact is neither low nor high.\"1N)\nI think that the term' undetermined risk of bias' is opposed to any other positive assertions of concern (low, moderate or high risk of bias). \n2N)\nSame with above. But it is a bit confusing for stating as 'neither low nor high', which leads people have to refer to the definition of low to high."}, {"code": "approval", "valueString": "2024-09-20 vote 6-0 by Carlos Alva-Diaz, Saphia Mokrane, Javier Bracchiglione, C P Ooi, Bhagvan Kommadi, Lenny Vasanthan"}]}, {"code": "SEVCO:00188", "display": "high risk of bias", "definition": "The result of a qualitative assessment that there is a high likelihood and potential impact of systematic distortion in research results.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "serious risk of bias"}], "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Homa Keshavarz"}, {"code": "comment", "valueString": "A 'high risk of bias' rating denotes a judgment that there are serious concerns for bias. The 'potential impact of systematic distortion in research results' may include the impact on the clinical interpretation or conclusion of the study findings."}, {"code": "external-definitions", "valueString": "In the Cochrane Handbook (https://training.cochrane.org/handbook/current/chapter-08#section-8-7):\nOnce the signalling questions are answered, the next step is to reach a risk-of-bias judgement, and assign one of three levels to each domain:\n\nLow risk of bias;\nSome concerns; or\nHigh risk of bias."}, {"code": "negative-vote", "valueString": "2024-09-06 vote 6-1 by Airton Tetelbom Stein, Carlos Alva-Diaz, Cau\u00ea Monaco, Sheyu Li, janice tufte, Eric Harvey, Javier Bracchiglione"}, {"code": "expert-comments", "valueString": "2024-09-06 comment re: \"high risk of bias\" = \"A qualitative assessment that there is a high likelihood and potential impact of systematic distortion in research results.\"1N)\nA qualitative judgement that the the systematic distortion is unlikely to impact the clinical interpretation or conclusion of the study findings. \n\nThe rating of low, moderate, and high are subjective judgement or the result of an assessment based on a particular context. It is thus not a asessment per se. As a clinician, I would prefer to the term ending up with a clinical interpretation or decision. But other conclusion can be possible even for clinical research."}, {"code": "approval", "valueString": "2024-09-20 vote 6-0 by Carlos Alva-Diaz, Saphia Mokrane, Javier Bracchiglione, C P Ooi, Bhagvan Kommadi, Lenny Vasanthan"}]}, {"code": "SEVCO:00190", "display": "critical risk of bias", "definition": "The result of a qualitative assessment that there is such a high likelihood and potential impact of systematic distortion in research results that the findings are not valid.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "extreme risk of bias"}], "property": [{"code": "comment", "valueString": "The colloquial term 'fatal flaw' is sometimes used to report a critical risk of bias, signifying no further use of the study being assessed."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Kenneth Wilkins, Airton Stein, Muhammad Afzal"}, {"code": "approval", "valueString": "2024-09-20 vote 7-0 by Carlos Alva-Diaz, Saphia Mokrane, Javier Bracchiglione, C P Ooi, Bhagvan Kommadi, Lenny Vasanthan, Eric Harvey"}]}, {"code": "SEVCO:00192", "display": "undetermined risk of bias", "definition": "There is insufficient information to make a qualitative assessment regarding the likelihood and potential impact of systematic distortion in research results.", "property": [{"code": "comment", "valueString": "Unlike the terms [low risk of bias](https://fevir.net/resources/CodeSystem/27270#SEVCO:00186), [moderate risk of bias](https://fevir.net/resources/CodeSystem/27270#SEVCO:00187), and [high risk of bias](https://fevir.net/resources/CodeSystem/27270#SEVCO:00188), the term 'undetermined risk of bias' does not express a positive assertion of concern. \n\nThe term 'unclear risk of bias' is not explicitly defined because it could be used to represent 'undetermined risk of bias' or [moderate risk of bias](https://fevir.net/resources/CodeSystem/27270#SEVCO:00187). Some guidance has suggested to use 'unclear risk of bias' to mean 'undetermined risk of bias' but others have interpreted it to mean [moderate risk of bias](https://fevir.net/resources/CodeSystem/27270#SEVCO:00187).\n\nThe 'potential impact of systematic distortion in research results' may include the impact on the clinical interpretation or conclusion of the study findings."}, {"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Joanne Dehnbostel, Harold Lehmann, Carlos Alva-Diaz"}, {"code": "negative-vote", "valueString": "2024-09-06 vote 5-2 by Airton Tetelbom Stein, Carlos Alva-Diaz, Cau\u00ea Monaco, Sheyu Li, janice tufte, Eric Harvey, Javier Bracchiglione"}, {"code": "expert-comments", "valueString": "2024-09-06 comments re: \"undetermined risk of bias\" = \"A qualitative assessment that there is insufficient information to make a qualitative assessment regarding the likelihood and potential impact of systematic distortion in research results.\"1N)\nThe term' undetermined risk of bias' is opposed to any other positive assertions of concern (low, moderate or high risk of bias). \n\nI think that a better explication is\n\n\"As opposed to the term low, moderate or high risk of bias, the term 'undetermined risk of bias' does not express a positive assertion of concern.\"\n2N)\nSame with above. \n3Y)\nis this a cop out though possibly?\n4Y)\nI would suggest \"unclear risk of bias\" as an alternative term.\n\n\n2024-09-20 comment re: \"undetermined risk of bias\" = \"There is insufficient information to make a qualitative assessment regarding the likelihood and potential impact of systematic distortion in research results.\"Yes\nAs I understand, at least the Cochrane RoB1 tool guidance specified that \"unclear risk of bias\" referred to undetermined and not moderate. Its use, however, was often seen as moderate risk of bias, but this was not the guidance. I don't know if you are thinking of other tools that also specify \"unclear risk of bias\" as a category."}, {"code": "approval", "valueString": "2024-09-20 vote 6-0 by Carlos Alva-Diaz, Saphia Mokrane, Javier Bracchiglione, C P Ooi, Bhagvan Kommadi, Lenny Vasanthan"}]}]}, {"code": "SEVCO:00193", "display": "rating of factor presence", "definition": "The result of a qualitative assessment of the likelihood of a situation or event.", "property": [{"code": "comment", "valueString": "For approaches to assessment of the risk of bias (which includes bias presence and potential impact) in which multiple factors are separately considered, the 'rating of factor presence' may be applied to each of the factors considered."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Carlos Alva-Diaz, Homa Keshavarz"}, {"code": "approval", "valueString": "2024-10-04 vote 5-0 by Joanne Dehnbostel, Saphia Mokrane, Airton Tetelbom Stein, Homa Keshavarz, Eric Harvey"}, {"code": "expert-comments", "valueString": "2024-09-27 comment re: \"rating of presence of cause of bias\" = \"The result of a qualitative assessment of the likelihood of a situation leading to systematic distortion in research results.\"1Yes)\nPossible alternatives: \"rating of presence of biasing factor\" \"judgment regarding presence of factor introducing possible bias\" \"presence or absence of possible biasing factor\"\n2 No) Rating of presence of cause of bias just doesn't read well. Rating of factor presence was better, rating of bias presence would work. Likelihood of bias presence would also work."}, {"code": "negative-vote", "valueString": "2024-09-27 vote 5-1 by Joanne Dehnbostel, Brian S. Alper, Carlos Alva-Diaz, Homa Keshavarz, Arnav Agarwal, Airton Tetelbom Stein"}], "concept": [{"code": "SEVCO:00194", "display": "factor present", "definition": "The result of a qualitative assessment that a situation exists or an event has occurred.", "property": [{"code": "open-for-voting"}, {"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Homa Keshavarz"}, {"code": "approval", "valueString": "2024-10-04 vote 5-0 by Joanne Dehnbostel, Saphia Mokrane, Airton Tetelbom Stein, Homa Keshavarz, Eric Harvey"}]}, {"code": "SEVCO:00195", "display": "factor likely present", "definition": "The result of a qualitative assessment that a situation probably exists or an event has probably occurred.", "property": [{"code": "comment"}, {"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Homa Keshavarz"}, {"code": "approval", "valueString": "2024-10-04 vote 5-0 by Joanne Dehnbostel, Saphia Mokrane, Airton Tetelbom Stein, Homa Keshavarz, Eric Harvey\nYes"}]}, {"code": "SEVCO:00196", "display": "factor likely absent", "definition": "The result of a qualitative assessment that a situation probably does not exist or an event has probably not occurred.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Homa Keshavarz"}, {"code": "approval", "valueString": "2024-10-04 vote 5-0 by Joanne Dehnbostel, Saphia Mokrane, Airton Tetelbom Stein, Homa Keshavarz, Eric Harvey"}]}, {"code": "SEVCO:00197", "display": "factor absent", "definition": "The result of a qualitative assessment that a situation does not exist or an event has not occurred.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Homa Keshavarz"}, {"code": "approval", "valueString": "2024-10-04 vote 5-0 by Joanne Dehnbostel, Saphia Mokrane, Airton Tetelbom Stein, Homa Keshavarz, Eric Harvey"}]}, {"code": "SEVCO:00199", "display": "undetermined factor presence or absence", "definition": "There is insufficient information to make a qualitative assessment regarding whether a situation exists or an event has occurred.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "factor presence or absence undetermined"}], "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Homa Keshavarz, Harold Lehmann"}, {"code": "negative-vote", "valueString": "2024-10-11 vote 7-2 by Javier Bracchiglione, Saphia Mokrane, Harold Lehmann, Arnav Agarwal, Lenny Vasanthan, Joanne Dehnbostel, Airton Tetelbom Stein, Homa Keshavarz, Eric Harvey"}, {"code": "expert-comments", "valueString": "2024-10-11 comments re: \"factor presence or absence unclear\" = \"There is insufficient information to make a qualitative assessment regarding whether a situation exists or an event has occurred.\"1No)\nTo be consistent with the previous terms under \"rating of factor presence\", I would suggest rephrasing the term, as for example : \"factor unclearly present of absent\" \nSuggestion for the definition : \"The result of a qualitative assessment of the presence or the absence of a situation or an event due to insufficient information to make the assessment.\" \n2No)\n\"Situation\" is especially vague; \"event\" mildly suggestive. Sounds like we need a Comment for application---either here or in the parent term---that puts these terms into perspective. E.g., \"Assessment of presence of a factor depends on the definition of the factor. Assessing such presence depends on whether a situation"}, {"code": "comment", "valueString": "The presence or absence of a factor may be undetermined because a qualitative assessment was attempted and concluded that there was insufficient information to rate the factor presence, or because a qualitative assessment was not done."}, {"code": "approval", "valueString": "2024-10-18 vote 5-0 by Saphia Mokrane, Homa Keshavarz, Airton Tetelbom Stein, Lenny Vasanthan, Eric Harvey"}]}]}, {"code": "SEVCO:00200", "display": "rating of bias direction", "definition": "The result of a qualitative assessment of the direction of influence on research results.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel"}, {"code": "comment", "valueString": "The meaning of direction of influence on research results changes with the type of estimation. For an estimation of comparative effect, the direction may be favoring a side being compared or towards no effect. For an estimation of prevalence, the direction may be overestimation or underestimation.\nBias is defined as a systematic distortion of research results."}, {"code": "approval", "valueString": "2024-11-08 vote 6-0 by Saphia Mokrane, Homa Keshavarz, Lara Kahaleh, Bhagvan Kommadi, Airton Tetelbom Stein, Eric Harvey"}, {"code": "external-definitions", "valueString": "https://training.cochrane.org/handbook/current/chapter-08\n\nRoB 2 includes optional judgements of the direction of the bias for each domain and overall. For some domains, the bias is most easily thought of as being towards or away from the null. For example, high levels of switching of participants from their assigned intervention to the other intervention may have the effect of reducing the observed difference between the groups, leading to the estimated effect of adhering to intervention (see Section 8.2.2) being biased towards the null. For other domains, the bias is likely to favour one of the interventions being compared, implying an increase or decrease in the effect estimate depending on which intervention is favoured. Examples include manipulation of the randomization process, awareness of interventions received influencing the outcome assessment and selective reporting of results. If review authors do not have a clear rationale for judging the likely direction of the bias, they should not guess it and can leave this response blank.\n\nCite this chapter as: Higgins JPT, Savovi\u0107 J, Page MJ, Elbers RG, Sterne JAC. Chapter 8: Assessing risk of bias in a randomized trial [last updated October 2019]. In: Higgins JPT, Thomas J, Chandler J, Cumpston M, Li T, Page MJ, Welch VA (editors). Cochrane Handbook for Systematic Reviews of Interventions version 6.5. Cochrane, 2024. Available from www.training.cochrane.org/handbook.\n\nhttps://onlinelibrary-wiley-com.ezproxy3.library.arizona.edu/doi/10.1111/acem.12255"}], "concept": [{"code": "SEVCO:00201", "display": "risk of bias favoring experimental exposure", "definition": "The result of a qualitative assessment that a bias, if present, would influence the effect estimate in a direction that suggests greater benefit or less harm from the experimental exposure compared to the comparator exposure.", "property": [{"code": "comment", "valueString": "The experimental exposure is the exposure of interest, whether the study is interventional or observational, the exposure of interest is an intervention or an exposure, or the outcome of interest is desirable or undesirable. The desirability of the outcome of interest determines whether an increase or decrease in the value of the effect estimate is considered beneficial or harmful."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Airton Stein"}, {"code": "approval", "valueString": "2024-11-22 vote 6-0 by Saphia Mokrane, Sheyu Li, Homa Keshavarz, Eric Harvey, Lara Kahaleh, Airton Tetelbom Stein"}]}, {"code": "SEVCO:00202", "display": "risk of bias favoring comparator exposure", "definition": "The result of a qualitative assessment that a bias, if present, would influence the effect estimate in a direction that suggests greater benefit or less harm from the comparator exposure compared to the experimental exposure.", "property": [{"code": "comment", "valueString": "The experimental exposure is the exposure of interest, whether the study is interventional or observational, the exposure of interest is an intervention or an exposure, or the outcome of interest is desirable or undesirable. The desirability of the outcome of interest determines whether an increase or decrease in the value of the effect estimate is considered beneficial or harmful."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Airton Stein"}, {"code": "approval", "valueString": "2024-11-22 vote 5-0 by Sheyu Li, Homa Keshavarz, Eric Harvey, Lara Kahaleh, Airton Tetelbom Stein"}]}, {"code": "SEVCO:00203", "display": "risk of bias towards the null hypothesis", "definition": "The result of a qualitative assessment that a bias, if present, would increase the likelihood of failing to reject the null hypothesis.", "property": [{"code": "external-definitions", "valueString": "\"there are many exceptions to the heuristic for which bias towards the null cannot be assumed.\" Yland JJ, Wesselink AK, Lash TL, Fox MP. Misconceptions About the Direction of Bias From Nondifferential Misclassification. Am J Epidemiol. 2022 Jul 23;191(8):1485-1495. doi: 10.1093/aje/kwac035. Erratum in: Am J Epidemiol. 2022 Nov 19;191(12):2123. doi: 10.1093/aje/kwac129. PMID: 35231925; PMCID: PMC9989338. https://pmc.ncbi.nlm.nih.gov/articles/PMC9989338/"}, {"code": "comment", "valueString": "A risk of bias towards the null hypothesis increases the likelihood of a type 2 error (mistaken failure to reject the null hypothesis when the null hypothesis is false)."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Airton Stein, Homa Keshavarz"}, {"code": "approval", "valueString": "2024-11-22 vote 6-0 by Saphia Mokrane, Sheyu Li, Homa Keshavarz, Eric Harvey, Lara Kahaleh, Airton Tetelbom Stein"}]}, {"code": "SEVCO:00204", "display": "risk of bias away from the null hypothesis", "definition": "The result of a qualitative assessment that a bias, if present, would increase the likelihood of rejecting the null hypothesis.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "risk of bias against the null hypothesis"}], "property": [{"code": "comment", "valueString": "A risk of bias away from the null hypothesis increases the likelihood of a type 1 error (mistaken rejection of the null hypothesis when the null hypothesis is true)."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Airton Stein, Homa Keshavarz"}, {"code": "approval", "valueString": "2024-11-22 vote 6-0 by Saphia Mokrane, Sheyu Li, Homa Keshavarz, Eric Harvey, Lara Kahaleh, Airton Tetelbom Stein"}]}, {"code": "SEVCO:00205", "display": "risk of bias direction unpredictable", "definition": "The result of a qualitative assessment that a bias, if present, cannot be classified as to whether the bias would lead to an increase or a decrease in the estimate.", "property": [{"code": "editors", "valueString": "Brian S. Alper"}, {"code": "approval", "valueString": "2024-11-22 vote 5-0 by Saphia Mokrane, Sheyu Li, Homa Keshavarz, Lara Kahaleh, Airton Tetelbom Stein"}]}]}, {"code": "SEVCO:00206", "display": "rating of potential influence on research results", "definition": "The result of a qualitative assessment of, if a cause of bias were present, the potential impact on the research results.", "property": [{"code": "comment", "valueString": "For approaches to assessment of the risk of bias (which includes bias presence and potential impact) in which multiple factors are separately considered, the 'rating of potential influence' may be applied to each of the factors considered."}, {"code": "editors", "valueString": "Brian S. Alper, Airton Stein, Joanne Dehnbostel"}, {"code": "approval", "valueString": "2024-10-25 vote 7-0 by Saphia Mokrane, Harold Lehmann, Lenny Vasanthan, Bhagvan Kommadi, Homa Keshavarz, Eric Harvey, Airton Tetelbom Stein"}, {"code": "expert-comments", "valueString": "2024-10-18 comment re: \"rating of potential influence\" = \"The result of a qualitative assessment of, if a cause of bias were present, the potential impact on the research results.\"1Yes)\nthe 'rating of potential influence'' => the 'rating of potential influence'"}, {"code": "negative-vote", "valueString": "2024-10-18 vote 5-0 by Saphia Mokrane, Homa Keshavarz, Airton Tetelbom Stein, Lenny Vasanthan, Eric Harvey BUT THEN THE TERM CHANGED"}], "concept": [{"code": "SEVCO:00207", "display": "high potential to influence research results", "definition": "High certainty that a cause of bias, if present, has an impact on the research results.", "property": [{"code": "comment", "valueString": "The rating of potential influence on research results is a qualitative assessment; there is no agreed-upon quantitative scale of certainty. The rating of 'high potential to influence research results' matches an answer of Yes (from an option list of Yes/Likely Yes/Likely No/No) in the ROB2 risk of bias assessment tool."}, {"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel"}, {"code": "negative-vote", "valueString": "2024-11-01 vote 5-0 by Harold Lehmann, Saphia Mokrane, Eric Harvey, Homa Keshavarz, Airton Tetelbom Stein BUT THEN COMMENT ADDED"}, {"code": "expert-comments", "valueString": "2024-11-01 comment:\n1Yes)\nConsider a Comment for application that says something like, \"There is no agreed-upon quantitative scale on which to base this qualitative assessment.\""}, {"code": "approval", "valueString": "2024-11-08 vote 6-0 by Saphia Mokrane, Homa Keshavarz, Lara Kahaleh, Bhagvan Kommadi, Airton Tetelbom Stein, Eric Harvey"}]}, {"code": "SEVCO:00208", "display": "some potential to influence research results", "definition": "Low to moderate certainty that a cause of bias, if present, has an impact on the research results.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Muhammad Afzal, Khalid Shahin"}, {"code": "expert-comments", "valueString": "2024-11-01 comment:\n1Yes)\nConsider a Comment for application that says something like, \"There is no agreed-upon quantitative scale on which to base this qualitative assessment.\"\n\n2024-11-08 comment re: \"some potential to influence research results\" = \"Low to moderate certainty that a cause of bias, if present, has an impact on the research results.\"1Yes)\ninstead of some, it can be worded as significant potential\n\n\n2024-11-15  comment re: \"significant potential to influence research results\" = \"Low to moderate certainty that a cause of bias, if present, has an impact on the research results.\"1No)\nSignificant can be interpreted as substantial or important -- that does not match the described use of 'Likely Yes' as distinct from 'Yes' in response to whether there is a potential to impact research results."}, {"code": "negative-vote", "valueString": "2024-11-01 vote 5-0 by Harold Lehmann, Saphia Mokrane, Eric Harvey, Homa Keshavarz, Airton Tetelbom Stein BUT THEN COMMENT ADDED \n2024-11-08 vote 6-0 by Saphia Mokrane, Homa Keshavarz, Lara Kahaleh, Bhagvan Kommadi, Airton Tetelbom Stein, Eric Harvey BUT THEN TERM CHANGED DUE TO COMMENT\n2024-11-15 vote 6-1 by Brian S. Alper, Cau\u00ea Monaco, Airton Tetelbom Stein, Homa Keshavarz, Lenny Vasanthan, Yaowaluk Ngoenwiwatkul, Eric Harvey"}, {"code": "comment", "valueString": "The rating of potential influence on research results is a qualitative assessment; there is no agreed-upon quantitative scale of certainty. The rating of 'some potential to influence research results' matches an answer of Likely Yes (from an option list of Yes/Likely Yes/Likely No/No) in the ROB2 risk of bias assessment tool."}, {"code": "approval", "valueString": "2024-11-22 vote 6-0 by Saphia Mokrane, Sheyu Li, Homa Keshavarz, Eric Harvey, Airton Tetelbom Stein, Lara Kahaleh"}]}, {"code": "SEVCO:00209", "display": "limited potential to influence research results", "definition": "Low to moderate certainty that a cause of bias, if present, does NOT have an impact on the research results.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel"}, {"code": "comment", "valueString": "The rating of potential influence on research results is a qualitative assessment; there is no agreed-upon quantitative scale of certainty. The rating of 'limited potential to influence research results' matches an answer of Likely No (from an option list of Yes/Likely Yes/Likely No/No) in the ROB2 risk of bias assessment tool."}, {"code": "negative-vote", "valueString": "2024-11-01 vote 4-1 by Harold Lehmann, Saphia Mokrane, Eric Harvey, Homa Keshavarz, Airton Tetelbom Stein"}, {"code": "expert-comments", "valueString": "2014-11-01 comment re: \"Low to moderate certainty that a cause of bias, if present, has little to no impact on the research results.\":\n1No)\nDefinition is too similar to 'some potential'"}, {"code": "approval", "valueString": "2024-11-08 vote 5-0 by 2024-11-08 vote 6-0 by Saphia Mokrane, Homa Keshavarz, Lara Kahaleh, Bhagvan Kommadi, Airton Tetelbom Stein, Eric Harvey"}]}, {"code": "SEVCO:00210", "display": "no potential to influence research results", "definition": "High certainty that a cause of bias, if present, has NO impact on the research results.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel"}, {"code": "comment", "valueString": "The rating of potential influence on research results is a qualitative assessment; there is no agreed-upon quantitative scale of certainty. The rating of 'no potential to influence research results' matches an answer of No (from an option list of Yes/Likely Yes/Likely No/No) in the ROB2 risk of bias assessment tool."}, {"code": "expert-comments", "valueString": "2024-11-01 comment re:  \"no potential to influence research results\" = \"High certainty that a cause of bias, if present, has no impact on the research results.\"1No)\nWeird that both \"High potential\" and \"No potential\" start with \"High certainty...\" The negation in the definition here is too buried"}, {"code": "negative-vote", "valueString": "2024-11-01 vote 4-1 by Harold Lehmann, Saphia Mokrane, Eric Harvey, Homa Keshavarz, Airton Tetelbom Stein"}, {"code": "approval", "valueString": "2024-11-08 vote 6-0 by Saphia Mokrane, Homa Keshavarz, Lara Kahaleh, Bhagvan Kommadi, Airton Tetelbom Stein, Eric Harvey"}]}]}, {"code": "STATO:0000039", "display": "statistic", "definition": "An information content entity that is a formalization of relationships between variables and value specification.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "statistic type"}], "property": [{"code": "comment", "valueString": "The 'statistic' does not include the numerical value for which the statistic is used--that would be the statistic value, and the 'statistic' does not include the model characteristics."}, {"code": "editors", "valueString": "Brian S. Alper, Philippe Rocca-Serra, Harold Lehmann, Joanne Dehnbostel, Muhammad Afzal, Janice Tufte, Bhagvan Kommadi, Khalid Shahin"}, {"code": "approval", "valueString": "revision 6/6 as of 10/4/2021: Alejandro Piscoya, Bhagvan Kommadi, Brian S. Alper, Janice Tufte, Louis Leff, Sorana D. Bolboaca; original approval 6/6 as of 9/27/2021: Harold Lehmann, Bhagvan Kommadi, Louis Leff, Janice Tufte, Joanne Dehnbostel, Mario Tristan"}], "concept": [{"code": "STATO:0000668", "display": "absolute value", "definition": "A statistic that represents the distance of a value from zero.", "property": [{"code": "comment", "valueString": "The | symbol is used around the value to denote the absolute value, e.g. |x|, such that if x = -3, then |x| = 3."}, {"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Harold Lehmann"}, {"code": "approval", "valueString": "2024-04-15 vote 5-0 by Harold Lehmann, Janice Tufte, Eric Harvey, Homa Keshavarz, Lenny Vasanthan"}]}, {"code": "STATO:0000047", "display": "count", "property": [{"code": "comment", "valueString": "A count can only be denoted by non-negative integer values."}, {"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Muhammad Afzal, Janice Tufte, Kenneth Wilkins"}, {"code": "approval", "valueString": "6/6 as of 9/27/2021: Harold Lehmann, Bhagvan Kommadi, Louis Leff, Janice Tufte, Joanne Dehnbostel, Mario Tristan"}], "definition": "A statistic that represents the number of instances or occurrences of something."}, {"code": "STATO:0000669", "display": "sum", "definition": "A statistic that represents the result of adding all the values in a collection of values.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "total"}], "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel,Muhammad Afzal, Janice Tufte, Bhagvan Kommadi, Khalid Shahin"}, {"code": "approval", "valueString": "6/6 as of 10/4/2021: Alejandro Piscoya, Bhagvan Kommadi, Brian S. Alper, Janice Tufte, Louis Leff, Sorana D. Bolboaca"}]}, {"code": "STATO:0000151", "display": "maximum observed value", "definition": "A statistic that represents the largest non-null value in a collection of values that can be ordered by magnitude.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel,Muhammad Afzal, Janice Tufte, Bhagvan Kommadi, Khalid Shahin"}, {"code": "approval", "valueString": "6/6 as of 10/4/2021: Alejandro Piscoya, Bhagvan Kommadi, Brian S. Alper, Janice Tufte, Louis Leff, Sorana D. Bolboaca"}]}, {"code": "STATO:0000150", "display": "minimum observed value", "definition": "A statistic that represents the smallest non-null value in a collection of values that can be ordered by magnitude.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel,Muhammad Afzal, Janice Tufte, Bhagvan Kommadi, Khalid Shahin"}, {"code": "approval", "valueString": "6/6 as of 10/4/2021: Alejandro Piscoya, Bhagvan Kommadi, Brian S. Alper, Janice Tufte, Louis Leff, Sorana D. Bolboaca"}]}, {"code": "STATO:0000666", "display": "maximum possible value", "definition": "A statistic that represents the largest value that could occur.", "property": [{"code": "comment", "valueString": "This term may be used to denote the upper limit of a scale or score."}, {"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel,Muhammad Afzal, Janice Tufte, Bhagvan Kommadi, Khalid Shahin"}, {"code": "approval", "valueString": "6/6 as of 10/4/2021: Alejandro Piscoya, Bhagvan Kommadi, Brian S. Alper, Janice Tufte, Louis Leff, Sorana D. Bolboaca"}]}, {"code": "STATO:0000667", "display": "minimum possible value", "definition": "A statistic that represents the smallest value that could occur.", "property": [{"code": "comment", "valueString": "This term may be used to denote the lower limit of a scale or score."}, {"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel,Muhammad Afzal, Janice Tufte, Bhagvan Kommadi, Khalid Shahin"}, {"code": "approval", "valueString": "6/6 as of 10/4/2021: Alejandro Piscoya, Bhagvan Kommadi, Brian S. Alper, Janice Tufte, Louis Leff, Sorana D. Bolboaca"}]}, {"code": "STATO:0000029", "concept": [{"code": "STATO:0000573", "display": "mean", "property": [{"code": "comment", "valueString": "A=sum[Ai] / n where i ranges from 1 to n and Ai represents the value of individual observations."}, {"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Muhammad Afzal, Janice Tufte,  Kenneth Wilkins, Philippe Rocca-Serra"}, {"code": "approval", "valueString": "6/6 as of 10/27/2021: Janice Tufte, Louis Leff, Vignesh Subbian, Robin Ann Yurk, Harold Lehmann, Muhammad Afzal, Pentti Nieminen"}, {"code": "statistical-purpose", "valueString": "Measure of Central Tendency"}], "definition": "A measure of central tendency calculated as the sum of a set of values divided by the number of values in the set.", "designation": [{"language": "fi", "use": {"system": "http://snomed.info/sct", "code": "900000000000003001", "display": "Fully specified name"}, "value": "keskiarvo"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "arithmetic mean"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "average"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "average value"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "statistical mean"}], "concept": [{"code": "STATO:0000664", "display": "mean of differences", "definition": "A mean of values in which each value is the subtraction of one quantity from another.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "mean of paired differences"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "average of differences"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "mean difference"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "average difference"}], "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Khalid Shahin, Janice Tufte, Muhammad Afzal, Kenneth Wilkins"}, {"code": "negative-vote", "valueString": "2021-12-01 vote 6-1 by Louis Leff, Paola Rosati, Robin Ann Yurk, Joanne Dehnbostel, Jesus Lopez-Alcalde, Janice Tufte, C P Ooi"}, {"code": "expert-comments", "valueString": "2021-12-01 comment: 'Difference in means' may be more appropriate. 'Mean value from one population subtract the mean value of another population' may be clearer reflecting the definition"}, {"code": "comment", "valueString": "The primary use of this term is in analyzing within-individual differences."}, {"code": "approval", "valueString": "2021-12-15 vote 5-0 by Robin Ann Yurk, Harold Lehmann, Janice Tufte, Paola Rosati, Brian S. Alper"}, {"code": "statistical-purpose", "valueString": "Measure of Central Tendency"}, {"code": "external-definitions", "valueString": "http://purl.obolibrary.org/obo/STATO_0000664"}]}, {"code": "STATO:0000658", "display": "mean time-to-event", "definition": "A mean of values in which each value is the duration of time between the start of observation and the occurrence of an event.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "mean TTE"}], "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Muhammad Afzal, Yuan Gao"}, {"code": "approval", "valueString": "2022-10-19 vote 5-0 by Joanne Dehnbostel, Muhammad Afzal, Janice Tufte, Mario Tristan, Eric Harvey"}]}]}, {"code": "STATO:0000396", "display": "geometric mean", "property": [{"code": "comment", "valueString": "For n observations with values x1, x2, \u2026 xn, the product of all the values P = x1 * x2 \u2026 xn [also expressed as P = (x1)(x2)...(xn)].  The nth root of the product = (P)^(1/n)."}, {"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Muhammad Afzal, Janice Tufte,  Kenneth Wilkins, Philippe Rocca-Serra"}, {"code": "approval", "valueString": "6/6 as of 10/27/2021: Janice Tufte, Louis Leff, Vignesh Subbian, Robin Ann Yurk, Harold Lehmann, Muhammad Afzal, Pentti Nieminen"}, {"code": "statistical-purpose", "valueString": "Measure of Central Tendency"}], "definition": "A measure of central tendency calculated as the nth root of the product of all of the observations in a data set (n being the number of all observations)."}, {"code": "STATO:0000574", "display": "median", "concept": [{"code": "STATO:0000659", "display": "median time-to-event", "definition": "A median of values in which each value is the duration of time between the start of observation and the occurrence of an event.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "median TTE"}], "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Muhammad Afzal, Yuan Gao"}, {"code": "approval", "valueString": "2022-10-19 vote 5-0 by Joanne Dehnbostel, Muhammad Afzal, Janice Tufte, Mario Tristan, Eric Harvey"}]}], "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Kenneth Wilkins, Joanne Dehnbostel, Muhammad Afzal, Janice Tufte"}, {"code": "comment", "valueString": "The median value is equal to the middle value of a set of ordered data with an odd number of values. The median value is calculated as the mean of the two middle values of a set of ordered data with an even number of values. The median is sometimes called the second quartile or fiftieth percentile."}, {"code": "negative-vote", "valueString": "6-1 on 2021-11-01 by Louis Leff, Vignesh Subbian, Pentti Nieminen, Bhagvan Kommadi, Janice Tufte, Sorana D. Bolboaca, Robin Ann Yurk\n2021-12-01 vote 5-1 by Philippe Rocca-Serra, Paola Rosati, Robin Ann Yurk, Joanne Dehnbostel, Jesus Lopez-Alcalde, Janice Tufte"}, {"code": "expert-comments", "valueString": "2021-11-01 comment: the definition is appropriate. Suggest use Alternative terms: center value, statistical median or middle value. I don't recommend using fiftieth percentile or second quartile\n2021-12-01 comment: I would change definition to: A measure of central tendency equal to the middle value of a set of ordered data with an odd number of values. It could be calculated also as  the mean of the two middle values of a set of ordered data with an even number of values. ((Perhaps simpler as: A measure of central tendency equal to the middle value of a set of ordered data. In a set of ordered data with an even number of values, the middle value is calculated as the mean of the two middle values.))"}, {"code": "approval", "valueString": "2021-12-15 vote 6-0 by Robin Ann Yurk, Muhammad Afzal, Harold Lehmann, Janice Tufte, Paola Rosati, Khalid Shahin"}, {"code": "statistical-purpose", "valueString": "Measure of Central Tendency"}], "definition": "A measure of central tendency equal to the middle value (or mean of the two middle values) of a set of ordered data.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "center value"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "statistical median"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "middle value"}]}, {"code": "STATO:0000033", "display": "mode", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Kenneth Wilkins, Joanne Dehnbostel, Muhammad Afzal, Janice Tufte"}, {"code": "approval", "valueString": "7/7 on 2021-11-01 by Louis Leff, Vignesh Subbian, Pentti Nieminen, Bhagvan Kommadi, Janice Tufte, Sorana D. Bolboaca, Robin Ann Yurk"}, {"code": "statistical-purpose", "valueString": "Measure of Central Tendency"}], "definition": "A measure of central tendency that is the most frequently occurring value in a data set. If no value is repeated, there is no mode. If more than one value occurs with the same greatest frequency, each of these values is a mode.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "statistical mode"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "most common value"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "most frequent value"}]}, {"code": "STATO:0000397", "display": "harmonic mean", "definition": "A measure of central tendency calculated by dividing the total number of observations by the sum of the reciprocals of each observed value.", "property": [{"code": "external-definitions", "valueString": "STATO:\nThe harmonic mean is a kind of mean which is calculated by dividing the total number of observations by the reciprocal of each number in a series. Harmonic Mean = N/(1/a1+1/a2+1/a3+1/a4+.......+1/aN) where a(i)= Individual score and N = Sample size (Number of scores)"}, {"code": "comment", "valueString": "Harmonic Mean = N/(1/a1+1/a2+1/a3+1/a4+...+1/aN) where a(i)= Individual observed value and N = Sample size (Number of observations)"}, {"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Muhammad Afzal"}, {"code": "approval", "valueString": "2022-10-19 vote 6-0 by Joanne Dehnbostel, Muhammad Afzal, Janice Tufte, Mario Tristan, Eric Harvey, Yuan Gao"}]}], "display": "measure of central tendency", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Muhammad Afzal, Janice Tufte,  Kenneth Wilkins, Philippe Rocca-Serra"}, {"code": "approval", "valueString": "6/6 as of 10/27/2021: Janice Tufte, Louis Leff, Vignesh Subbian, Robin Ann Yurk, Harold Lehmann, Muhammad Afzal, Pentti Nieminen"}], "definition": "A statistic that represents a central value for a set of data.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "central tendency measure"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "centrality measure"}]}, {"code": "STATO:0000291", "display": "quantile", "definition": "A statistic that represents the value for which the number of data points at or below it constitutes a specific portion of the total number of data points.", "property": [{"code": "external-definitions", "valueString": "STATO-a quantile is a data item which corresponds to specific elements x in the range of a variate X. the k-th n-tile P_k is that value of x, say x_k, which corresponds to a cumulative frequency of Nk/n (Kenney and Keeping 1962). If n=4, the quantity is called a quartile, and if n=100, it is called a percentile."}, {"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Harold Lehmann, Muhammad Afzal"}, {"code": "comment", "valueString": "Quantile is a type of statistic but not used without specification of the portion it represents. Typically, the specification of the portion it represents includes both the number of equal portions (e.g., percentile for 100 equal portions, or quartile for 4 equal portions) and selection of one of these portions (e.g., 25th percentile or first quartile).\n\nFor common uses in communicating statistic values, more specific types of quantiles (such as percentile, decile, or quartile) would be used instead of the term *quantile*."}, {"code": "negative-vote", "valueString": "2024-04-15 vote 2-1 by Lenny Vasanthan, Harold Lehmann, Eric Harvey\n2024-04-22 vote 5-1 by Lenny Vasanthan, Homa Keshavarz, Eric Harvey, Harold Lehmann, Sheyu Li, Khalid Shahin"}, {"code": "expert-comments", "valueString": "2024-04-15 comment: \nCan we add information about quartiles also here. \neg. Quartile is a type of quantile that divides the distribution into four equal halves (Q1, Q2, Q3, Q4)\n\n2024-04-22 comment:\nIt is confusing in the comments whether the quantile refers to 25% percentile, 50% percentile and 75% percentile. What is the difference between quantile and percentile?"}, {"code": "approval", "valueString": "2024-04-29 vote 6-0 by Lenny Vasanthan, Brian S. Alper, Harold Lehmann, Eric Harvey, Homa Keshavarz, Sean Grant"}], "concept": [{"code": "STATO:0000293", "display": "percentile", "definition": "A quantile in which the specific portion of the number of data points is expressed as a percentage.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "centile"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "%ile"}], "property": [{"code": "external-definitions", "valueString": "STATO-a percentile is a quantile which splits data into sections accrued of 1% of data, so the first percentile delineates 1% of the data, the second quartile delineates 2% of the data and the 99th percentile, 99 % of the data"}, {"code": "comment", "valueString": "Quantile is defined as a statistic that represents the value for which the number of data points at or below it constitutes a specific portion of the total number of data points.\n\nPercentile is a type of statistic but not used to define a statistic value without specification of the portion it represents. For example, one may report a fortieth percentile (40%ile) but one does not report a percentile without specification of which percentile. 40% of the data is at or below the 40%ile.\n\nMost statistic values can be reported in FHIR Evidence Resources with a statisticType element including the SEVCO term as a CodeableConcept. To report a specific percentile (such as the fortieth percentile), one may use the attributeEstimate element containing a type element with the SEVCO term for percentile as a CodeableConcept and a level element with the corresponding value (such as 40)."}, {"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Harold Lehmann, Muhammad Afzal"}, {"code": "expert-comments", "valueString": "2024-04-22 comment:\nIt is unclear if it is OK to say 50% percentile, or it is recommended to say 50% percentile."}, {"code": "negative-vote", "valueString": "2024-04-22 vote 5-1 by Lenny Vasanthan, Homa Keshavarz, Eric Harvey, Harold Lehmann, Sheyu Li, Khalid Shahin"}, {"code": "approval", "valueString": "2024-04-29 vote 6-0 by Lenny Vasanthan, Brian S. Alper, Harold Lehmann, Eric Harvey, Homa Keshavarz, Sean Grant"}]}, {"code": "STATO:0000292", "display": "decile", "definition": "A quantile in which the specific portion of the number of data points is expressed as a number of tenths.", "property": [{"code": "external-definitions", "valueString": "STATO-a decile is a quantile where n=10 and which splits data into sections accrued of 10% of data, so the first decile delineates 10% of the data, the second decile delineates 20% of the data and the nineth decile, 90 % of the data"}, {"code": "comment", "valueString": "Quantile is defined as a statistic that represents the value for which the number of data points at or below it constitutes a specific portion of the total number of data points.\n\nDecile is a type of statistic but not used to define a statistic value without specification of the portion it represents. For example, one may report a fourth decile but one does not report a decile without specification of which decile. 40% of the data is at or below the fourth decile.\n\nMost statistic values can be reported in FHIR Evidence Resources with a statisticType element including the SEVCO term as a CodeableConcept. To report a specific decile (such as the fourth decile), one may use the attributeEstimate element containing a type element with the SEVCO term for decile as a CodeableConcept and a level element with the corresponding value (such as 4)."}, {"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Harold Lehmann, Muhammad Afzal"}, {"code": "approval", "valueString": "2024-04-22 vote 6-0 by Lenny Vasanthan, Homa Keshavarz, Eric Harvey, Harold Lehmann, Sheyu Li, Khalid Shahin\n2024-04-29 vote 6-0 by Lenny Vasanthan, Brian S. Alper, Harold Lehmann, Eric Harvey, Homa Keshavarz, Sean Grant"}]}, {"code": "STATO:0000152", "display": "quartile", "definition": "A quantile in which the specific portion of the number of data points is expressed as a number of fourths.", "property": [{"code": "external-definitions", "valueString": "STATO-a quartile is a quantile which splits data into sections accrued of 25% of data, so the first quartile delineates 25% of the data, the second quartile delineates 50% of the data and the third quartile, 75% of the data"}, {"code": "comment", "valueString": "Quantile is defined as a statistic that represents the value for which the number of data points at or below it constitutes a specific portion of the total number of data points.\n\nQuartile is a type of statistic but not used to define a statistic value without specification of the portion it represents. For example, one may report a third quartile but one does not report a quartile without specification of which quartile. 75% of the data is at or below the third quartile. The second quartile is also called the median.\n\nTo report the first quartile, use the SEVCO term for <a href=\"https://fevir.net/resources/CodeSystem/27270#TBD:first-quartile\" target=\"_blank\">first quartile</a>. To report the second quartile, use the SEVCO term for <a href=\"https://fevir.net/resources/CodeSystem/27270#STATO:0000574\" target=\"_blank\">median</a>. To report the third quartile, use the SEVCO term for <a href=\"https://fevir.net/resources/CodeSystem/27270#TBD:third-quartile\" target=\"_blank\">third quartile</a>. To report the fourth quartile, use the SEVCO term for maximum observed value."}, {"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Harold Lehmann, Muhammad Afzal"}, {"code": "approval", "valueString": "2024-04-22 vote 6-0 by Lenny Vasanthan, Homa Keshavarz, Eric Harvey, Harold Lehmann, Sheyu Li, Khalid Shahin\n2024-04-29 vote 6-0 by Lenny Vasanthan, Brian S. Alper, Harold Lehmann, Eric Harvey, Homa Keshavarz, Sean Grant"}], "concept": [{"code": "STATO:0000167", "display": "first quartile", "definition": "A quantile for which the number of data points at or below it constitutes a 25% of the total number of data points.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Harold Lehmann, Muhammad Afzal"}, {"code": "approval", "valueString": "2024-04-29 vote 6-0 by Lenny Vasanthan, Brian S. Alper, Harold Lehmann, Eric Harvey, Homa Keshavarz, Sean Grant"}]}, {"code": "STATO:0000170", "display": "third quartile", "definition": "A quantile for which the number of data points at or below it constitutes a 75% of the total number of data points.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Harold Lehmann, Muhammad Afzal"}, {"code": "approval", "valueString": "2024-04-29 vote 6-0 by Lenny Vasanthan, Brian S. Alper, Harold Lehmann, Eric Harvey, Homa Keshavarz, Sean Grant"}]}]}]}, {"code": "STATO:0000613", "display": "difference", "definition": "A statistic that is a subtraction of one quantity from another.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "delta"}], "property": [{"code": "editors", "valueString": "Harold Lehmann, Brian S. Alper, Muhammad Afzal, Khalid Shahin, Philippe Rocca-Serra, Kenneth Wilkins, Joanne Dehnbostel, Janice Tufte"}, {"code": "approval", "valueString": "2021-12-01 vote 5-0 by Philippe Rocca-Serra, Paola Rosati, Joanne Dehnbostel, Jesus Lopez-Alcalde, Janice Tufte"}], "concept": [{"code": "STATO:0000614", "display": "absolute difference", "definition": "A statistic that is a subtraction of one quantity from another, with no modification of the resulting value.", "property": [{"code": "comment", "valueString": "As a type of statistic, \"Absolute Difference\" is the actual difference between two quantities and can be positive or negative depending on the order of subtraction. The term \"Absolute Difference\" should not be confused with the mathematical term 'absolute value' which is a numerical value without a negative sign."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Kenneth Wilkins, Joanne Dehnbostel, Muhammad Afzal, Khalid Shahin, Janice Tufte"}, {"code": "approval", "valueString": "2021-12-01 vote 5-0 by Philippe Rocca-Serra, Paola Rosati, Joanne Dehnbostel, Jesus Lopez-Alcalde, Janice Tufte"}], "concept": [{"code": "STATO:0000616", "display": "count difference", "definition": "A statistic that is a subtraction of one count from another.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "difference in counts"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "number difference"}], "property": [{"code": "editors", "valueString": "Harold Lehmann, Brian S. Alper, Muhammad Afzal, Khalid Shahin, Philippe Rocca-Serra, Kenneth Wilkins, Joanne Dehnbostel, Janice Tufte"}, {"code": "negative-vote", "valueString": "2021-12-01 vote 5-1 by Philippe Rocca-Serra, Paola Rosati, Robin Ann Yurk, Joanne Dehnbostel, Jesus Lopez-Alcalde, Janice Tufte\n2021-12-08 vote 6-1 by Philippe Rocca-Serra, Paola Rosati, Robin Ann Yurk, Joanne Dehnbostel, Jesus Lopez-Alcalde, Janice Tufte, Harold Lehmann"}, {"code": "expert-comments", "valueString": "2021-12-01 comment: Suggest include as an Alternative term under difference and remove this term as unclear on distinction as a separate term.\n2021-12-08 comment: Suggest removing this term and adding as an Alternative term to Difference {(atlernative term and Comment for application added in response}}"}, {"code": "comment", "valueString": "The term Count Difference is used to specify the Absolute Difference is with respect to a count or number of items (such as number of events, platelet counts, sample size e.g. number of people in the group) to distinguish from differences in other types of statistics (mean difference, median difference, risk difference, etc.)"}, {"code": "approval", "valueString": "2021-12-15 vote 6-0 by Robin Ann Yurk, Janice Tufte, Paola Rosati, Harold Lehmann, Joanne Dehnbostel, Muhammad Afzal"}]}, {"code": "STATO:0000457", "display": "difference in means", "definition": "A statistic that is a subtraction of one mean from another.", "property": [{"code": "editors", "valueString": "Harold Lehmann, Brian S. Alper, Muhammad Afzal, Khalid Shahin, Philippe Rocca-Serra, Kenneth Wilkins, Joanne Dehnbostel, Janice Tufte"}, {"code": "approval", "valueString": "2021-12-01 vote 6-0 by Philippe Rocca-Serra, Paola Rosati, Robin Ann Yurk, Joanne Dehnbostel, Jesus Lopez-Alcalde, Janice Tufte\n2021-12-01 Steering group added comment for application and decided not to send out for vote again."}, {"code": "comment", "valueString": "The primary use of this term is in analyzing between-group differences."}], "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "difference of means"}]}, {"code": "STATO:0000617", "display": "difference in medians", "definition": "A statistic that is a subtraction of one median from another.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "difference of medians"}], "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Khalid Shahin, Janice Tufte, Muhammad Afzal, Kenneth Wilkins"}, {"code": "approval", "valueString": "2021-12-01 vote 6-0 by Philippe Rocca-Serra, Paola Rosati, Robin Ann Yurk, Joanne Dehnbostel, Jesus Lopez-Alcalde, Janice Tufte"}]}, {"code": "STATO:0000424", "display": "risk difference", "definition": "A measure of association that is the subtraction of the risk of an event in one group from the risk of the same event in another group.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "absolute risk difference"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "RD"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "ARD"}], "property": [{"code": "external-definitions", "valueString": "STATO: risk difference = The risk difference is the difference between the observed risks (proportions of individuals with the outcome of interest) in the two groups.\nThe risk difference is straightforward to interpret: it describes the actual difference in the observed risk of events between experimental and control interventions."}, {"code": "editors", "valueString": "Brian S. Alper, Muhammad Afzal, Joanne Dehnbostel, Harold Lehmann, Janice Tufte"}, {"code": "statistical-purpose", "valueString": "Measure of Association"}, {"code": "approval", "valueString": "2022-06-08 vote 5-0 by Harold Lehmann, Mario Tristan, Eric M Harvey, Muhammad Afzal, Paola Rosati"}]}, {"code": "STATO:0000665", "display": "difference-in-differences", "definition": "A statistic that is a subtraction of one difference from another.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "difference in differences"}], "property": [{"code": "comment", "valueString": "The term 'Difference-in-differences' may be used to assess the incremental benefit or harm of an intervention or exposure, where the effect of the exposure is measured as a difference (for example, pre-post testing comparison of values before and after the exposure) in two groups being compared."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Muhammad Afzal, Janice Tufte"}, {"code": "approval", "valueString": "2022-06-08 vote 6-0 by Robin Ann Yurk, Harold Lehmann, Mario Tristan, Eric M Harvey, Muhammad Afzal, Paola Rosati"}, {"code": "expert-comments", "valueString": "2022-06-08 comment: do you want to add to comment for application, pre-post testing or as an Alternative term?"}]}]}, {"code": "STATO:0000615", "display": "relative difference", "definition": "A statistic that is a difference between 1 and a ratio of the two quantities being compared.", "property": [{"code": "comment", "valueString": "Relative Difference = 1 - ( a / b ).   Because 1 - ( a / b ) is not equal to 1 - ( b / a ), Relative Difference may be expressed as \"Relative Difference with respect to b\" when referring to 1 - ( a / b ).\n\nThe relative difference can also be defined as a statistic that is a ratio of the absolute difference (of the two quantities being compared) to the reference value (one of the quantities being compared). Relative Difference = ( b - a ) / ( b ) where b is the reference value and this may also be called \"Relative Difference with respect to b\""}, {"code": "editors", "valueString": "Brian S. Alper, Muhammad Afzal, Kenneth Wilkins, Joanne Dehnbostel"}, {"code": "external-definitions", "valueString": "Example of a relative difference (relative to placebo) that is not a relative mean difference or a relative risk difference:\n\nRelative median difference (%) = [(active median - placebo median) / placebo median] x 100. \nThis can be transformed to:\nRelative median difference = (active median / placebo median) - 1."}, {"code": "negative-vote", "valueString": "2022-06-15 vote 2-2 by Jesus Lopez-Alcalde, Robin Ann Yurk, Paola Rosati, Janice Tufte\n2022-06-22 vote 4-2 by Mario Tristan, Eric M Harvey, Jesus Lopez-Alcalde, Robin Ann Yurk, Paola Rosati, Janice Tufte"}, {"code": "expert-comments", "valueString": "2022-06-15 comments: Suggest combining this set of terms(relative difference, relative mean difference and relative risk difference  and summarizing the comment for applications so it is one term.\n\nTo me this definition is unclear...sorry, what it means? Is it weird to a have a ratio of a difference to a reference value? Sorry, but I am unable to understand this definition.\n\nrelative and absolute difference seems confusing to me"}, {"code": "approval", "valueString": "2022-06-29 vote 5-0 by Jesus Lopez-Alcalde, Philippe Rocca-Serra, Mario Tristan, Harold Lehmann, Eric Harvey"}], "concept": [{"code": "STATO:0000625", "display": "relative mean difference", "definition": "A statistic that is a difference between 1 and a ratio of the two mean values being compared.", "property": [{"code": "comment", "valueString": "Relative Mean Difference = 1 - ( a / b ) where a and b are mean values.\n\nThe relative mean difference can also be defined as a statistic that is a ratio of the difference in means to the reference mean value. Relative Mean Difference = ( b - a ) / ( b ) where b is the reference mean value and a is another mean value."}, {"code": "editors", "valueString": "Brian S. Alper, Muhammad Afzal, Kenneth Wilkins, Joanne Dehnbostel"}, {"code": "negative-vote", "valueString": "2022-06-15 vote 3-1 by Jesus Lopez-Alcalde, Robin Ann Yurk, Paola Rosati, Janice Tufte\n2022-06-22 vote 5-1 by Mario Tristan, Eric M Harvey, Jesus Lopez-Alcalde, Robin Ann Yurk, Paola Rosati, Janice Tufte"}, {"code": "expert-comments", "valueString": "2022-06-15 comment: Suggest combining this set of terms(relative difference, relative mean difference and relative risk difference  and summarizing the comment for applications so it is one term.  \n2022-06-29 comment: Relative Mean Difference is_a kind of Relative difference where the quantities being compared are two means, one of which is or acts as reference mean value  (additional comment: define 'reference mean value' if it refers to something more specific"}, {"code": "approval", "valueString": "2022-06-29 vote 6-0 by Jesus Lopez-Alcalde, Philippe Rocca-Serra, Mario Tristan, Janice Tufte, Harold Lehmann, Eric Harvey"}]}, {"code": "STATO:0000626", "display": "relative risk difference", "definition": "A statistic that is a difference between 1 and a ratio of the two risk values being compared.", "property": [{"code": "comment", "valueString": "Relative Risk Difference = 1 - ( a / b ) where a and b are risk values.\n\nThe relative risk difference can also be defined as a statistic that is a ratio of the risk difference to the risk used as a reference. Relative Risk Difference = ( b - a ) / ( b ) where b is the reference risk value and a is another risk value."}, {"code": "editors", "valueString": "Brian S. Alper, Muhammad Afzal, Kenneth Wilkins, Joanne Dehnbostel"}, {"code": "negative-vote", "valueString": "2022-06-15 vote 3-1 by Jesus Lopez-Alcalde, Robin Ann Yurk, Paola Rosati, Janice Tufte\n2022-06-22 vote 5-1 by Mario Tristan, Eric M Harvey, Jesus Lopez-Alcalde, Robin Ann Yurk, Paola Rosati, Janice Tufte"}, {"code": "expert-comments", "valueString": "2022-06-15 comment: Suggest combining this set of terms(relative difference, relative mean difference and relative risk difference  and summarizing the comment for applications so it is one term."}, {"code": "approval", "valueString": "2022-06-22 vote 6-0 by Mario Tristan, Eric M Harvey, Jesus Lopez-Alcalde, Robin Ann Yurk, Paola Rosati, Janice Tufte"}]}]}, {"code": "STATO:0000100", "concept": [{"code": "STATO:0000618", "display": "Cohen\u2019s d statistic", "definition": "A standardized mean difference which is calculated as a difference between two means, divided by a square root of an average of the variances of the two groups.", "property": [{"code": "comment", "valueString": "A standardized mean difference is a statistic that is a difference between two means, divided by a statistical measure of dispersion. In SEVCO, the term Standardized Mean Difference is a description of the concept without an explicit type of statistical measure of dispersion. If the statistical measure of dispersion is specified, then a type (child term) of Standardized Mean Difference is preferred.\n\nIn Cohen's d statistic, the statistical measure of dispersion is specified as the square root of an average of the variances of the two groups being compared. The variances of the two groups are based on within-group standard deviations.\n\nFor sample sizes < 50, a correction factor is used."}, {"code": "external-definitions", "valueString": "STATO: standardized mean difference (Cohen's d statistic, SMD) = standardized mean difference is data item computed by forming the difference between two means, divided by an estimate of the within-group standard deviation.\nIt is used to provide an estimatation of the effect size between two treatments when the predictor (independent variable) is categorical and the response(dependent) variable is continuous"}, {"code": "editors", "valueString": "Harold Lehmann, Brian S. Alper, Kenneth Wilkins, Muhammad Afzal, Joanne Dehnbostel"}, {"code": "negative-vote", "valueString": "2022-07-06 vote 3-1 by Paola Rosati, Harold Lehmann, Robin Ann Yurk, Eric Harvey"}, {"code": "expert-comments", "valueString": "2022-07-06  comment: Consider listing SMD statistic as an Alternative term or selecting one of the two terms to be the term to evaluate as the definition are similar and the other term to be the Alternative term."}, {"code": "approval", "valueString": "2022-07-20 vote 5-0 by Philippe Rocca-Serra, Mario Tristan, Jesus Lopez-Alcalde, Harold Lehmann, Eric Harvey"}]}, {"code": "STATO:0000135", "display": "strictly standardized mean difference", "property": [{"code": "external-definitions", "valueString": "STATO: strictly standardized mean difference (SSMS) is a standardized mean difference which corresponds to the ratio of mean to the standard deviation of the difference between two groups. SSMD directly measures the magnitude of difference between two groups. SSMD is widely used in High Content Screen for hit selection and quality control. When the data is preprocessed using log-transformation as normally done in HTS experiments, SSMD is the mean of log fold change divided by the standard deviation of log fold change with respect to a negative reference. In other words, SSMD is the average fold change (on the log scale) penalized by the variability of fold change (on the log scale). For quality control, one index for the quality of an HTS assay is the magnitude of difference between a positive control and a negative reference in an assay plate. For hit selection, the size of effects of a compound (i.e., a small molecule or an siRNA) is represented by the magnitude of difference between the compound and a negative reference. SSMD directly measures the magnitude of difference between two groups. Therefore, SSMD can be used for both quality control and hit selection in HTS experiments."}, {"code": "comment", "valueString": "A standardized mean difference is a statistic that is a difference between two means, divided by a statistical measure of dispersion. In SEVCO, the term Standardized Mean Difference is a description of the concept without an explicit type of statistical measure of dispersion. If the statistical measure of dispersion is specified, then a type (child term) of Standardized Mean Difference is preferred.\n\nIn Strictly standardized mean difference, the statistical measure of dispersion is specified as the standard error of the difference between means [SEVCO TBD:0000063]."}, {"code": "editors", "valueString": "Harold Lehmann, Brian S. Alper, Kenneth Wilkins, Joanne Dehnbostel"}, {"code": "approval", "valueString": "2022-07-20 vote 6-0 by Janice Tufte, Philippe Rocca-Serra, Mario Tristan, Jesus Lopez-Alcalde, Harold Lehmann, Eric Harvey"}], "definition": "A standardized mean difference which is calculated as a difference between two means, divided by the standard error of the difference between the two means.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "ssmd"}]}, {"code": "STATO:0000319", "display": "Hedges\u2019s g", "property": [{"code": "external-definitions", "valueString": "STATO: Hedges's g = Hedges's g is an estimator of effect size, which is similar to Cohen's d and is a measure based on a standardized difference. However, the denominator, corresponding to a pooled standard deviation, is computed differently from Cohen's d coefficient, by applying a correction factor (which involves a Gamma function)."}, {"code": "comment", "valueString": "A standardized mean difference is a statistic that is a difference between two means, divided by a statistical measure of dispersion. In SEVCO, the term Standardized Mean Difference is a description of the concept without an explicit type of statistical measure of dispersion. If the statistical measure of dispersion is specified, then a type (child term) of Standardized Mean Difference is preferred.\n\nIn Hedges\u2019s g, the statistical measure of dispersion is specified as the pooled standard deviation. There is a correction factor for small sample sizes."}, {"code": "editors", "valueString": "Harold Lehmann, Brian S. Alper, Kenneth Wilkins, Joanne Dehnbostel"}, {"code": "approval", "valueString": "2022-07-20 vote 5-0 by Philippe Rocca-Serra, Mario Tristan, Jesus Lopez-Alcalde, Harold Lehmann, Eric Harvey"}], "definition": "A standardized mean difference which is calculated as a difference between two means, divided by the pooled standard deviation."}, {"code": "STATO:0000320", "display": "Glass\u2019s delta", "property": [{"code": "external-definitions", "valueString": "STATO: Glass's delta is an estimator of effect size which is similar to Cohen's d but where the denominator corresponds only to the standard deviation of the control group (or second group). It is considered less bias than the Cohen's d for estimating effect sizes based on means and distances between means."}, {"code": "comment", "valueString": "A standardized mean difference is a statistic that is a difference between two means, divided by a statistical measure of dispersion. In SEVCO, the term Standardized Mean Difference is a description of the concept without an explicit type of statistical measure of dispersion. If the statistical measure of dispersion is specified, then a type (child term) of Standardized Mean Difference is preferred.\n\nIn Glass's delta, the statistical measure of dispersion is specified as the standard deviation of the control group. There is a correction factor for small sample sizes."}, {"code": "editors", "valueString": "Harold Lehmann, Brian S. Alper, Kenneth Wilkins, Joanne Dehnbostel"}, {"code": "approval", "valueString": "2022-07-20 vote 5-0 by Philippe Rocca-Serra, Mario Tristan, Jesus Lopez-Alcalde, Harold Lehmann, Eric Harvey"}], "definition": "A standardized mean difference which is calculated as a difference between two means (of an experimental group and a control group), divided by the standard deviation of the control group."}], "display": "standardized mean difference", "property": [{"code": "external-definitions", "valueString": "STATO: standardized mean difference (Cohen's d statistic, SMD) = standardized mean difference is data item computed by forming the difference between two means, divided by an estimate of the within-group standard deviation.\nIt is used to provide an estimatation of the effect size between two treatments when the predictor (independent variable) is categorical and the response(dependent) variable is continuous"}, {"code": "comment", "valueString": "In English, \"standardized\" is often used to express relative comparison to any reference value. However, in SEVCO, \"standardized\" is used to express relative comparison to a statistical measure of dispersion.\nIn SEVCO, the term Standardized Mean Difference is a description of the concept without an explicit type of statistical measure of dispersion. If the statistical measure of dispersion is specified, then a type (child term) of Standardized Mean Difference is preferred.\n\nFor example, in Cohen's d statistic, the statistical measure of dispersion is specified as the square root of an average of the variances of the two groups being compared."}, {"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Harold Lehmann, Muhammad Afzal, Joanne Dehnbostel, Khalid Shahin"}, {"code": "negative-vote", "valueString": "2022-07-06 vote 3-1 by Paola Rosati, Harold Lehmann, Robin Ann Yurk, Eric Harvey"}, {"code": "expert-comments", "valueString": "2022-07-06 comment: Consider listing Cohen's D statistic as an Alternative term or selecting one of the two terms to be the term to evaluate as the definition are similar."}, {"code": "approval", "valueString": "2022-07-20 vote 6-0 by Janice Tufte, Philippe Rocca-Serra, Mario Tristan, Jesus Lopez-Alcalde, Harold Lehmann, Eric Harvey"}], "definition": "A statistic that is a difference between two means, divided by a statistical measure of dispersion.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "smd"}]}]}, {"code": "STATO:0000634", "display": "reciprocal of difference", "definition": "A statistic that is a quotient of one and a difference.", "property": [{"code": "comment", "valueString": "A difference is a statistic that is a subtraction of one quantity from another."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel"}, {"code": "approval", "valueString": "2022-07-20 vote 5-0 by Philippe Rocca-Serra, Mario Tristan, Jesus Lopez-Alcalde, Harold Lehmann, Eric Harvey"}], "concept": [{"code": "STATO:0000635", "display": "number needed to treat", "definition": "A statistic that represents the number of units that needs to be treated to prevent one additional undesired outcome. The Number Needed to Treat is calculated as the reciprocal of a treatment effect estimate, where the effect estimate is expressed as a risk difference.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "number needed to treat to benefit"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "NNT"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "NNTB"}], "property": [{"code": "comment", "valueString": "The Number Needed to Treat (NNT) value is often rounded up to the next highest whole integer."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte"}, {"code": "external-definitions", "valueString": "Centre for Evidence-Based Medicine\nNumber Needed to Treat (NNT)\nThe Number Needed to Treat (NNT) is the number of patients you need to treat to prevent one additional bad outcome (death, stroke, etc.).\nhttps://www.cebm.ox.ac.uk/resources/ebm-tools/number-needed-to-treat-nnt"}, {"code": "approval", "valueString": "2022-07-20 vote 7-0 by Cau\u00ea Monaco, Janice Tufte, Philippe Rocca-Serra, Mario Tristan, Jesus Lopez-Alcalde, Harold Lehmann, Eric Harvey"}]}, {"code": "STATO:0000637", "display": "number needed to screen to detect", "definition": "A statistic that represents the number of units that needs to be tested to identify one additional case. The Number Needed to Screen to Detect is calculated as the reciprocal of a difference in rate of detected cases with and without screening.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "NNS"}], "property": [{"code": "comment", "valueString": "The Number Needed to Screen (NNS) value is often rounded up to the next highest whole integer.  The Number Needed to Screen to Detect is distinct from the Number Needed to Screen to Prevent as the formulas to calculate are different, even though both may be abbreviated as NNS."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte"}, {"code": "approval", "valueString": "2022-08-03 vote 5-0 by Jesus Lopez-Alcalde, Janice Tufte, Eric Harvey, Philippe Rocca-Serra, Harold Lehmann"}]}, {"code": "STATO:0000636", "display": "number needed to screen to prevent", "definition": "A statistic that represents the number of units that needs to be tested to prevent one additional adverse outcome, assuming that positive testing will lead to preventive intervention. The Number Needed to Screen to Prevent is calculated as the Number Needed to Treat divided by the prevalence.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "NNS"}], "property": [{"code": "comment", "valueString": "The Number Needed to Screen (NNS) value is often rounded up to the next highest whole integer.  The Number Needed to Screen to Detect is distinct from the Number Needed to Screen to Prevent as the formulas to calculate are different, even though both may be abbreviated as NNS.\n\nThe formula may be adjusted for test performance characteristics (e.g. dividing by the sensitivity) or assumptions regarding acceptance or adherence of interventions."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte"}, {"code": "external-definitions", "valueString": "BMJ 1998;317: 307 Number needed to screen: development of a statistic for disease screening\nNumber needed to screen is defined as the number of people that need to be screened for a given duration to prevent one death or adverse event.\nNumber needed to screen was then calculated by dividing the number needed to treat for treating risk factors by the prevalence of disease that was unrecognised or untreated. \nhttps://www.bmj.com/content/317/7154/307.long"}, {"code": "approval", "valueString": "2022-08-03 vote 5-0 by Jesus Lopez-Alcalde, Janice Tufte, Eric Harvey, Philippe Rocca-Serra, Harold Lehmann"}]}, {"code": "STATO:0000638", "display": "number needed to harm", "definition": "A statistic that represents the number of units that, if treated or exposed to the intervention, to lead to one additional undesired outcome. The Number Needed to Harm is calculated as the reciprocal of a treatment effect estimate, where the effect estimate is expressed as a risk difference.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "number needed to treat to harm"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "NNH"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "NNTH"}], "property": [{"code": "comment", "valueString": "The Number Needed to Harm (NNH) value is often rounded down to the next lowest whole integer."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte"}, {"code": "external-definitions", "valueString": "Centre for Evidence-Based Medicine\nNumber needed to treat (NNT): The number of patients who need to be treated to prevent one bad outcome. It is the inverse of the ARR: NNT=1/ARR. Numbers needed to harm (NNH)-the number of patients who, if they received the experimental treatment, would lead to one additional person being harmed compared with patients who receive the control treatment; calculated as 1/ARI.\nhttps://www.cebm.ox.ac.uk/resources/ebm-tools/glossary"}, {"code": "approval", "valueString": "2022-07-20 vote 7-0 by Cau\u00ea Monaco, Janice Tufte, Philippe Rocca-Serra, Mario Tristan, Jesus Lopez-Alcalde, Harold Lehmann, Eric Harvey"}]}]}, {"code": "STATO:0000184", "concept": [{"code": "STATO:0000639", "display": "percentage", "definition": "A ratio that is multiplied by 100, and has the same units of measurement in the numerator and the denominator.", "property": [{"code": "comment", "valueString": "When a percentage is a fraction of hundred or proportion per hundred, then the percentage is the proportion multiplied by 100. However, a percentage can be greater than 100% so the definition is a ratio that is multiplied by 100.\nProportion is SEVCO code of TBD:0000018, Ratio is SEVCO code of STATO:0000184"}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Kenneth Wilkins, Janice Tufte, Muhammad Afzal, Khalid Shahin"}, {"code": "external-definitions", "valueString": "NCIt-A fraction or ratio with 100 understood as the denominator. Alt definition One hundred times the quotient of one quantity divided by another, with the same units of measurement.\nOECD-A percentage is a special type of proportion where the ratio is multiplied by a constant, 100, so that the ratio is expressed per 100.\nSCO-A fraction or ratio with 100 understood as the denominator.\nUMLS-A unit for expressing a number as a fraction of hundred (on the basis of a rate or proportion per hundred)-NCI"}, {"code": "negative-vote", "valueString": "2022-01-05 vote 5-1 by Harold Lehmann, Robin Ann Yurk, Janice Tufte, C P Ooi, Louis Leff, Jesus Lopez-Alcalde"}, {"code": "expert-comments", "valueString": "2022-01-05 comment: Instead of \"A ratio\" I would propose \"A proportion that is multiplied by 100, [...]\""}, {"code": "approval", "valueString": "2022-01-07 vote 7-0 by Harold Lehmann, Robin Ann Yurk, Janice Tufte, C P Ooi, Louis Leff, Jesus Lopez-Alcalde, Mario Tristan"}], "concept": [{"code": "STATO:0000705", "display": "measurement accuracy", "definition": "A percentage in which the numerator represents the absolute value of one minus the difference between the true value and the observed value, and the denominator represents the true value.", "property": [{"code": "external-definitions", "valueString": "from https://www.sciencedirect.com/topics/engineering/measurement-accuracy\nMeasurement Accuracy\nMeasurement accuracy is defined as the closeness of agreement between a measured quantity value and a true quantity value of a measurand (i.e., the quantity intended to be measured) (ISO-JCGM 200, 2008), and is often limited by calibration errors."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Muhammad Afzal, Joanne Dehnbostel"}, {"code": "approval", "valueString": "2022-08-24 vote 5-0 by Jesus Lopez-Alcalde, Harold Lehmann, Mario Tristan, Cau\u00ea Monaco, Eric Harvey"}]}]}, {"code": "STATO:0000607", "display": "proportion", "definition": "A ratio in which the numerator represents a part, fraction or share of the amount represented by the denominator.", "property": [{"code": "external-definitions", "valueString": "STATO: observed risk [as a data item STATO_0000423] = the proportion of individuals in a population with the outcome of interest\n\nNCIt: A part, fraction, share, or number considered in relation to the whole amount or number.\n\nOECD Definition:\nA proportion is a special type of ratio in which the denominator includes the numerator.\n\nAn example is the proportion of deaths that occurred to males which would be deaths to males divided by deaths to males plus deaths to females (i.e. the total population).\n\nOCRe: A proportion is a measure of the frequency of some phenomenon of interest within an average population"}, {"code": "comment", "valueString": "The value of a proportion must be between 0 and 1 (inclusive). Proportions may represent the frequency of some phenomenon of interest within a population, or may represent a subset of a whole."}, {"code": "editors", "valueString": "Harold Lehmann, Brian S. Alper, Joanne Dehnbostel, Kenneth Wilkins, Muhammad Afzal, Khalid Shahin"}, {"code": "negative-vote", "valueString": "2021-12-29 vote 3-1 by Robin Ann Yurk, Harold Lehmann, Janice Tufte, C P Ooi"}, {"code": "expert-comments", "valueString": "2021-12-29 comment: I agree with the term definition.  However, for the comment, I would edit to include the OCRe defintion:  A proportion is a measure of the frequency of some phenomenon of interest within a population."}, {"code": "approval", "valueString": "2022-01-07 vote 7-0 by Harold Lehmann, Robin Ann Yurk, Janice Tufte, C P Ooi, Louis Leff, Jesus Lopez-Alcalde, Mario Tristan"}], "concept": [{"code": "STATO:0000413", "display": "incidence", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "cumulative incidence"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "incidence proportion"}], "property": [{"code": "external-definitions", "valueString": "STATO: Incidence is the ratio of the number of new cases of a disease divided by the number of persons at risk for the disease.\n\nNCIt The relative frequency of occurrence of something.\n\nOBCS A data item that refers to the number of new events that have occurred in a specific time interval divided by the population at risk at the beginning of the time interval. The result gives the likelihood of developing an event in that time interval.\n\nUMLS The number of new cases of a given disease during a given period in a specified population. It also is used for the rate at which new events occur in a defined population. It is differentiated from PREVALENCE, which refers to all cases in the population at a given time.\u00a0(MSH)\nThe relative frequency of occurrence of something.\u00a0(NCI)\nThe number of new cases of a disease diagnosed each year.\u00a0(NCI)\n\nCDC: https://www.cdc.gov/csels/dsepd/ss1978/lesson3/section2.html\nIncidence refers to the occurrence of new cases of disease or injury in a population over a specified period of time. Although some epidemiologists use incidence to mean the number of new cases in a community, others use incidence to mean the number of new cases per unit of population.\n\nTwo types of incidence are commonly used \u2014 incidence proportion and incidence rate.\n\nIncidence proportion or risk\n\nSynonyms for incidence proportion\n\nAttack rate\nRisk\nProbability of developing disease\nCumulative incidence\n\n\nDefinition of incidence proportion\n\nIncidence proportion is the proportion of an initially disease-free population that develops disease, becomes injured, or dies during a specified (usually limited) period of time. Synonyms include attack rate, risk, probability of getting disease, and cumulative incidence. Incidence proportion is a proportion because the persons in the numerator, those who develop disease, are all included in the denominator (the entire population)."}, {"code": "comment", "valueString": "Outside of the Scientific Evidence Code System (SEVCO), there is substantial inconsistency in the terms and definitions used for incidence and related concepts.\n\nWithin SEVCO, Incidence is a proportion in which the numerator represents new events. The denominator may represent the entire population or may represent that population at risk (i.e., those without prior events). \n\nDisease incidence is the ratio of the number of new cases of a disease divided by the number of persons at risk for the disease. Incidence is a proportion because the persons in the numerator, those who develop disease, are all included in the denominator (the entire population).\n\nWhen a time period or a duration of time is used to define the period of time in which the incidence is measured, the statistic type is Incidence. Examples include 1-year incidence, in-hospital incidence, and cumulative incidence.\n\nWhen time is considered as a variable in the formalization of the statistic, such as incidence per unit of time, then the statistic type is Incidence Rate (SEVCO code of TBD:0000024)"}, {"code": "negative-vote", "valueString": "2022-01-05 vote 2-2 by Robin Ann Yurk, janice tufte, Jesus Lopez-Alcalde, Harold Lehmann"}, {"code": "expert-comments", "valueString": "2022-01-05 comments: I propose \"The number of new occurrences of an event (for example, infection) in a population at risk over a particular period of time.\n\nDoesn't denominator need to include a time component? Even if not, the time component should be referenced in the Comment. Also, do note that, in public health, the numerator *attempts* to be a subset of the denominator, but that relationship cannot be assured. (E.g., fertility incidence may be number of births (vital statistics) with denominator of number of women of child bearing age (census).\n\n2022-06-15 Expert Working Group/Steering Committee removed 'Risk' as Alternative term as we created a separate term for 'Risk' (TBD:0000185)"}, {"code": "editors", "valueString": "Brian S. Alper, Muhammad Afzal, Joanne Dehnbostel, Janice Tufte"}, {"code": "approval", "valueString": "2022-01-12 vote 6-0 by Harold Lehman, Mario Tristan, janice tufte, Andrew Beck, Robin Ann Yurk, Paul Harris"}], "definition": "A proportion in which the numerator represents new events."}, {"code": "STATO:0000412", "display": "prevalence", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "period prevalence"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "point prevalence"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "lifetime prevalence"}], "property": [{"code": "external-definitions", "valueString": "STATO: prevalence is a ratio formed by the number of subjects diagnosed with a disease divided by the total population size.\n\nPeriod prevalence:\nThe ratio (for a given time period) of the number of occurrences of a disease or event to the number of units at risk in the population.\na prevalence rate that occurs at a specific period of time\n\n\nPoint prevalence:\nNCIt The ratio (for a given time period) of the number of occurrences of a disease or event to the number of units at risk in the population.\nOBCS a prevalence rate that occurs at a specific point of time\n\nUMLS:\nThe total number of cases of a given disease in a specified population at a designated time. It is differentiated from INCIDENCE, which refers to the number of new cases in the population at a given time.\u00a0(MSH)\nThe ratio (for a given time period) of the number of occurrences of a disease or event to the number of units at risk in the population.\u00a0(NCI)\nProportion of the people having a certain disease or condition in a given population\u00a0(CHV)\n\nCDC https://www.cdc.gov/csels/dsepd/ss1978/lesson3/section2.html\nPoint prevalence = Number of current cases (new and preexisting) at a specified point in time / Population at the same specified point in time\nPeriod prevalence = Number of current cases (new and preexisting) over a specified period of time / Average or mid-interval population\n\nDefinition of prevalence\nPrevalence, sometimes referred to as prevalence rate, is the proportion of persons in a population who have a particular disease or attribute at a specified point in time or over a specified period of time. Prevalence differs from incidence in that prevalence includes all cases, both new and preexisting, in the population at the specified time, whereas incidence is limited to new cases only.\n\nPoint prevalence refers to the prevalence measured at a particular point in time. It is the proportion of persons with a particular disease or attribute on a particular date.\n\nPeriod prevalence refers to prevalence measured over an interval of time. It is the proportion of persons with a particular disease or attribute at any time during the interval."}, {"code": "comment", "valueString": "Prevalence is the proportion of persons in a population who have a particular disease or attribute at a specified point in time or over a specified period of time.\nPrevalence differs from incidence in that prevalence includes all cases, both new and preexisting, in the population at the specified time, whereas incidence is limited to new cases only.\nIn Bayesian calculations, the prevalence value is often used as the pre-test probability or prior probability value, but these probability values are not always based on or derived from the prevalence value."}, {"code": "editors", "valueString": "Brian S. Alper, Muhammad Afzal, Joanne Dehnbostel, Janice Tufte, Kenneth Wilkins, Harold Lehmann"}, {"code": "negative-vote", "valueString": "2022-01-12 vote 6-1 by Robin Ann Yurk, janice tufte, Jesus Lopez-Alcalde, Harold Lehmann, Mario Tristan, Andrew Beck, Paul Harris\n2022-01-19 vote 2-1 by Harold Lehmann, Robin Ann Yurk, Alejandro Piscoya\n2022-01-26 vote 7-1 by Janice Tufte, Harold Lehmann, Philippe Rocca-Serra, Paola Rosati, Mario Tristan, Robin Ann Yurk, Brian S. Alper, Jesus Lopez-Alcalde"}, {"code": "expert-comments", "valueString": "2022-01-12 comments: I propose \"A proportion in which the numerator represents all events (new and preexisting).\" I think it is very important to detail \"new and preexisting\"2022-01-03 comment: The comment here is better than for incidence (why not copy this comment into \"Incidence,\" and edit?). But it still feels like the denominator should be called out in the definition.\n2022-01-19 comment:  I would edit the term definition to include ...as part of a denominator of a broader population.\n2022-01-26 comments: (1) suggestion: alter the definition to: A proportion in which the numerator represents all events of interest (e.g. both new and preexisting cases of a disease) in the population, which is represented by the denominator.\n(2) I would delete this sentence from the comment for application. \" Prevalence is a proportion because the persons in the numerator, those who develop or have disease, are all included in the denominator (the entire population)\"(3) Probability should be a type of Proportion but distinct from Prevalence. Probability relates to the likelihood of something, but in that sense incidence and prevalence are both probabilities.  If Prevalence and Probability were considered synonyms then one would still not call it the same as \"Pre-test\" or \"Prior\" probability.  The term pre-test probability could be a type of (child of) probability.\n\n2022-02-02 comment: I would remove the statement ..In Bayesian calculations, as the pre-test probability is a formula with new variables."}, {"code": "approval", "valueString": "2022-02-02 vote 5-0 by Paola Rosati, Mario Tristan, Robin Ann Yurk, Janice Tufte, Brian S. Alper"}], "definition": "A proportion in which the numerator represents all events of interest (for example, both new and preexisting cases of a disease) in the population, which is represented by the denominator."}, {"code": "STATO:0000233", "display": "sensitivity", "property": [{"code": "external-definitions", "valueString": "STATO: true positive rate (recall, sensitivity) = sensitivity is a measurement datum qualifying a binary classification test and is computed by substracting the false negative rate to the integral numeral 1\nNCIt diagnostic sensitivity The probability that a test will produce a true positive result when used on effected subjects as compared to a reference or \"gold standard\". The sensitivity of a test can be determined by calculating: number of true positive results divided by the sum of true positive results plus number of false negative results.\nOBCS-\na data item that measures the proportion of actual positives which are correctly identified as such (e.g. the percentage of sick people who are correctly identified as having the condition).\nOCRe\nAn index of performance of a discriminant test calculated as the percentage of correct positives in all true positives\nSTATO\nsensitivity is a measurement datum qualifying a binary classification test and is computed by subtracting the false negative rate to the integral numeral 1\nNICE glossary-Sensitivity of a test-How well a test detects what it is testing for. It is the proportion of people with the disease or condition that are correctly identified by the study test. For example, a test with a sensitivity of 96% will, on average, correctly identify 96 people in every 100 who truly have the condition, but incorrectly identify as not having the condition 4 people in every 100 who truly have it. It is different from positive predictive value.\n\nMeSH scope note-sensitivity and specificity-Scope Note\nBinary classification measures to assess test results. Sensitivity or recall rate is the proportion of true positives. Specificity is the probability of correctly determining the absence of a condition. (From Last, Dictionary of Epidemiology, 2d ed)"}, {"code": "comment", "valueString": "In a population of people with and without a disease, and a test which is positive (suggesting the disease) or negative (suggesting not having the disease), the sensitivity is the proportion of true positives (all people with the disease who test positive) within all people with the disease (true positives plus false negatives). Sn = TP / (TP + FN).\nIn information retrieval, recall is the proportion of items correctly retrieved within all relevant items.\nTrue positive rate (TPR) is listed as an Alternative term because of common usage, but TPR is not a Rate as defined in SEVCO."}, {"code": "editors", "valueString": "Harold Lehmann, Brian S. Alper, Joanne Dehnbostel, Kenneth Wilkins, Muhammad Afzal"}, {"code": "negative-vote", "valueString": "2022-01-19 vote 3-1 by Paul Harris, Harold Lehmann, Robin Ann Yurk, Alejandro Piscoya"}, {"code": "expert-comments", "valueString": "2022-01-19 comment: I would remove recall from Alternative terms and comment for applications, as it is a specialized informatics measures and list it as a separate term. (EWG discussion: This comment is not persuasive. If the same statistic type (formula) has different names in different contexts we still want one common code for the concept. This consolidation of terms is the purpose of a standardized terminology or controlled vocabulary where we are controlling the code for the concept, not the name for common use.)"}, {"code": "approval", "valueString": "2022-01-26 vote 10-0 by Paul Harris, Harold Lehmann, Robin Ann Yurk, Alejandro Piscoya, Janice Tufte, Philippe Rocca-Serra, Paola Rosati, Mario Tristan, Brian S. Alper, Jesus Lopez-Alcalde"}], "definition": "A proportion in which the numerator represents the detected items within the denominator that represents all items with the targeted attribute.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "recall"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "true positive rate"}]}, {"code": "STATO:0000134", "display": "specificity", "property": [{"code": "external-definitions", "valueString": "STATO: true negative rate (specificity) = specificity is a measurement datum qualifying a binary classification test and is computed by substracting the false positive rate to the integral numeral 1\n\n\nNCIt The probability that a test will produce a true negative result when used on non-effected subjects as compared to a reference or \"gold standard\". The specificity of a test can be determined by calculating: number of true negative results divided by the sum of true negative results plus number of false positive results.\n\nOBCS a data item that refers to the proportion of negatives in a binary classification test which are correctly identified\n\nOCRe An index of performance of a discriminant test calculated as the percentage of negatives in all true negatives\n\nNICE glossary-Specificity (of a test)\nHow well a test correctly identifies people who do not have what it is testing for. It is the proportion of people without the disease or condition that are correctly identified by the study test. For example, a test with a specificity of 96% will, on average, correctly identify 96 people in every 100 who truly do not have the condition, but incorrectly identify as having the condition 4 people in every 100 who truly do not have it. It is different from negative predictive value.\n\nMeSH scope note-sensitivity and specificity-Scope Note\nBinary classification measures to assess test results. Sensitivity or recall rate is the proportion of true positives. Specificity is the probability of correctly determining the absence of a condition. (From Last, Dictionary of Epidemiology, 2d ed)"}, {"code": "comment", "valueString": "In a population of people with and without a disease, and a test which is positive (suggesting the disease) or negative (suggesting not having the disease), the specificity is the proportion of true negatives (all people without the disease who test negative) within all people without the disease (true negatives plus false positives). Sp = TN / (TN + FP).\nTrue Negative Rate (TNR) is listed as an Alternative term because of common usage, but TNR is not a Rate as defined in SEVCO."}, {"code": "editors", "valueString": "Harold Lehmann, Brian S. Alper, Joanne Dehnbostel, Kenneth Wilkins, Muhammad Afzal"}, {"code": "approval", "valueString": "2022-01-19 vote 5-0 by Paul Harris, Harold Lehmann, Robin Ann Yurk, Alejandro Piscoya, Janice Tufte"}], "definition": "A proportion in which the numerator represents the non-detected items within the denominator that represents all items without the targeted attribute.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "true negative rate"}]}, {"code": "STATO:0000416", "display": "positive predictive value", "definition": "A proportion in which the numerator represents the correctly detected items within the denominator that represents all items detected.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "precision (as used in information retrieval)"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "PPV"}], "property": [{"code": "external-definitions", "valueString": "NCIt The probability that an individual is affected with the condition when a positive test result is observed. Predictive values should only be calculated from cohort studies or studies that legitimately reflect the number of people in the population who have the condition of interest at that time since predictive values are inherently dependent upon the prevalence. PPVDT can be determined by calculating: number of true positive results divided by the sum of true positive results plus number of false positive results."}, {"code": "comment", "valueString": "In a population of people with and without a disease, and a test which is positive (suggesting the disease) or negative (suggesting not having the disease), the positive predictive value is the proportion of true positives (all people with the disease who test positive) within all the people with a positive test (true positives plus false positives). PPV = TP / (TP + FP).\nIn information retrieval, 'precision' is the proportion of items correctly retrieved within all retrieved items.\nIn Bayesian calculations, the 'Positive Predictive Value' is equivalent to the 'post-test probability' or 'posterior probability' following a positive test."}, {"code": "negative-vote", "valueString": "2022-01-26 vote 7-1 by Robin Ann Yurk, Janice Tufte, Harold Lehmann, Philippe Rocca-Serra, Paola Rosati, Mario Tristan, Brian S. Alper, Jesus Lopez-Alcalde"}, {"code": "expert-comments", "valueString": "2022-01-26 comments: (1) I would remove precision from Alternative terms\n(2) minor change=quote terms of interest: In information retrieval, `precision` is the proportion of items correctly retrieved within all retrieved items.\nThe terms `post-test probability` and `posterior probability` are used in Bayesian calculations.\n(3) Post-test probability is not fully synonymous with positive predictrive value.  A negative predictive value is also the \"post-test\" probability of a true negative if the test has a negative result.  And a test with a continuous rather than binary result could have a post-test probability that is neither positive nor negative predictive value.  Post-test probability (and posterior probability) should become a child of probability.\n2022-02-02 comment: I would remove the alternate term Precision and the comment for application for precision."}, {"code": "editors", "valueString": "Harold Lehmann, Kenneth Wilkins, Phillippe Rocca-Serra, Joanne Dehnbostel"}, {"code": "approval", "valueString": "2022-02-02 vote 5-0 by Paola Rosati, Mario Tristan, Robin Ann Yurk, Janice Tufte, Brian S. Alper"}]}, {"code": "STATO:0000619", "display": "negative predictive value", "definition": "A proportion in which the numerator represents the correctly non-detected items within the denominator that represents all items not detected.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "NPV"}], "property": [{"code": "external-definitions", "valueString": "NCIt The probability that an individual is not affected with the condition when a negative test result is observed. This measure of accuracy should only be used if the data on the prevalence of condition of interest in given population is available. NPVDT can be determined by calculating: number of true negative results divided by the sum of true negative results plus number of false negative results."}, {"code": "comment", "valueString": "In a population of people with and without a disease, and a test which is positive (suggesting the disease) or negative (suggesting not having the disease), the negative predictive value is the proportion of true negatives (all people without the disease who test negative) within all the people with a negative test (true negatives plus false negatives). NPV = TN / (TN + FN)."}, {"code": "editors", "valueString": "Harold Lehmann, Ken Wilkins, Phillippe Rocca-Serra, Joanne Dehnbostel"}, {"code": "approval", "valueString": "2022-01-26 vote 8-0 by Robin Ann Yurk, Janice Tufte, Harold Lehmann, Philippe Rocca-Serra, Paola Rosati, Mario Tristan, Brian S. Alper, Jesus Lopez-Alcalde"}]}, {"code": "STATO:0000621", "display": "diagnostic yield", "definition": "A proportion in which the numerator represents the correctly detected items within the denominator that represents all items tested.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Kenneth Wilkins"}, {"code": "external-definitions", "valueString": "\"Diagnostic yield was defined as the number of participants with positive findings for advanced neoplasia relative to all participants\" in https://pubs.rsna.org/doi/10.1148/radiol.12112486\nOther 'definitions' found include synonymous use with sensitivity, and 'diagnostic yield' describing the statistic array of TP, FP, TN, and FN data.\n\nhttps://medical-dictionary.thefreedictionary.com/diagnostic+yield\nDiagnostic yield The likelihood that a test or procedure will provide the information needed to establish a diagnosis."}, {"code": "approval", "valueString": "2022-08-10 vote 5-0 by Philippe Rocca-Serra, Mario Tristan, Harold Lehmann, Eric Harvey, Paola Rosati"}, {"code": "expert-comments", "valueString": "2022-08-10 comment:  I would simply suggest to simplify the definition to:\n\nA proportion obtained by dividing the number of correctly detected items (numerator) by the number of all items tested (denominator)"}]}, {"code": "STATO:0000620", "display": "risk", "definition": "A proportion in which the numerator represents the cases in which an event or characteristic occurs and the denominator represents all possible cases.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "probability"}], "property": [{"code": "comment", "valueString": "In the English language, 'risk' may be used synonymously with 'hazard', 'chance', 'likelihood', 'relative likelihood', 'probability' and many other terms. In SEVCO the term 'risk' is explicitly defined for how it is used in other terms such as 'Risk Ratio' and 'Relative Risk Difference'  The statistical definition of 'risk' does not have a negative or undesirable connotation.\n\nRisk may be conditioned on many factors.  In such cases the statistic type is Risk and the statistic may be reported as a conditional risk (for example, predicted risk).\n\nWhen a time period or a duration of time is used to define the period of time in which the risk is measured, the statistic type is Risk. Examples include 1-year risk, in-hospital risk, and cumulative risk.\n\nIn frequentist statistics, the risk is a ratio of the number of events to the number of possible cases. In subjective Bayesian statistics, the risk is a proportion as a whole that represents degree of belief, where 0 represents certainty that an event will not occur and 1 represents certainty that the event will occur."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Muhammad Afzal, Janice Tufte"}, {"code": "negative-vote", "valueString": "2022-06-22 vote 4-1 by Eric Harvey, Janice Tufte, Mario Tristan, Muhammad Afza, Eric M Harvey"}, {"code": "expert-comments", "valueString": "2022-06-22 comment: It is confusing to consider \"conditional probability\" as an Alternative term for \"risk.\" \n\nGenerally; \n\"Conditional probability\" refers to a probability whose value is dependent upon the occurrence of some process/event. In contrast, \"risk\" refers to the probability that an event will occur. \n\nMathematically;\n\"Conditional probability\" is a measure of the probability of an event occurring, given that another event has already occurred. Let us have two events, A and B, and we want to know P(A) given P(B); notationally, P(A|B). Here the word 'given' defines a subset of the population of events because it applies condition on B. For example, if we care about the incidence of COVID-19 in men only, we might want to know P(COVID-19 | male). This means that first, pick out all the males, and second, figure out the probability they will get COVID-19. More formally, what P(A|B) says is: pick out the events to which both P(A) and P(B) apply and consider them as part of the subset of events to which only P(B) applies: hence P(A/B) = P(A and B)/P(B).\nIn simple words, what we are doing with P(A|B) = P(A and B) | P(B) is selecting out the same subset of the event population in both the\nthe numerator and the denominator: in this case, only men.\nWhile \"risk\" by definition involves no condition. Taking the same example, we can say, \"what is the risk of COVID-19?\" here, we refer to the whole population; however, we can apply can make a condition over it like \"what is the risk of COVID-19 in males?\" This risk may be taken as \"conditional risk,\" and it could be taken as an Alternative term to conditional probability.  \nConclusion: Let us define two terms, \"risk\" and \"conditional risk,\" as a subset of \"risk.\" Then \"conditional probability\" shall be taken as an Alternative term to \"conditional risk.\"\nOne more important point about the current definition of \"Risk,\" i.e., \nRisk = A proportion in which the numerator represents the probability that an event or characteristic occurs and the denominator represents the probability that the event or characteristic occurs or does not occur.\nIf we write symbolically, it will look like this; P(A)/P(A or B), where A indicates \"positive,\" which is the occurrence of something, and B indicates \"negative,\" which is the non-occurrence of the same. We can write it formally as P(A) / P(AUB). In set theory, when there is \"OR,\" in other words, \"Union\" infer the True value when either of them is True. It means A is true, or B is true, or both are true; we will get the true result. Interestingly, occurrence and non-occurrence are mutually exclusive, so two situations arise.\nI) when the event occurs: P(A) / P(AUB)  --> P(A)/P(A) = 1\nII) when the event does not occur: P(A) / P(AUB)  --> P(A)/P(B)  = Odds\nTherefore the definition needs to be revised for the correct meaning of the denominator. I believe the denominator refers to the whole population where some people are at risk and some are not, while the numerator refers to only those at risk."}, {"code": "approval", "valueString": "2022-06-29 vote 6-0 by Jesus Lopez-Alcalde, Philippe Rocca-Serra, Mario Tristan, Janice Tufte, Harold Lehmann, Eric Harvey"}]}]}, {"code": "STATO:0000627", "display": "odds", "definition": "A ratio in which the numerator represents the probability that an event will occur and the denominator represents the probability that an event will not occur.", "property": [{"code": "external-definitions", "valueString": "OCRe:\nOdds is a quotient in which the relative likelihood that an event will occur is divided by the the relative likelihood that it won't. In probability theory and statistics, where the variable \"p\" is the probability in favor of the event, and the probability against the event is 1-p, \"the odds\" of the event are the quotient of the two, or p / (1-p)"}, {"code": "comment", "valueString": "'Odds' and 'Odds ratio' are different terms. 'Odds' is a ratio of probabilities. 'Odds ratio' is a ratio of two different odds.\n\nOdds are calculated as p / (1-p) where p is the probability of event occurrence.  When p = 0, the odds = 0. When p = 1, the odds may be expressed as not calculable or as \"odds against = 0\".\n\nOdds may be expressed as p:(1-p). Odds may be expressed as p:q where q = 1-p. Odds may be expressed as a:b where a and b are multiples of p and (1-p). Examples of different expressions of the same odds include 3:2, 3/2, 0.6:0.4, 0.6/0.4, and 1.5.\n\nOdds may be expressed as \"odds for\" or \"odds in favor\" (e.g. 1:5 for a \"3\" on a 6-sided die) or \"odds against\" (e.g. 5:1 against a \"3\" on a 6-sided die).\n\nThe term \"betting odds\" used in gambling that involves financial amounts in the formulation is not an \"Odds\" in the definition of the Scientific Evidence Code System."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Khalid Shahin, Kenneth Wilkins, Muhammad Afzal"}, {"code": "negative-vote", "valueString": "2022-02-16 vote 4-2 by Janice Tufte, Paola Rosati, Eric Moyer,  Harold Lehmann, Robin Ann Yurk, Jesus Lopez-Alcalde\n2022-02-23 vote 5-2 by nisha mathew, Harold Lehman, Paola Rosati, Sunu Alice Cherian, Robin Ann Yurk,  Joanne Dehnbostel, Sumalatha A\n2022-03-09 vote 3-1 by Robin Ann Yurk, Janice Tufte, Eric Moyer, nisha mathew\n2022-03-16 vote 8-1 by Robin Ann Yurk, Janice Tufte, Eric Moyer, nisha mathew, Harold Lehmann, Philippe Rocca-Serra, Louis Leff, Paola Rosati, Mario Tristan"}, {"code": "expert-comments", "valueString": "2022-02-16 comments: The term definition and comment for application are clear and well written.  It would help to have a discussion on the Parent and Child relationships for this term as right now you only have Statistic, Ratio, Odds.  In statistics for the scientific code system is Statistic, Ratio, Odds Ratio a better sequence and put the Odds under comment for application.  \n\nThis term needs two Alternative terms: \"Odds For\" and \"Odds in Favor.\" The definition needs to deal with the cases p=1 and p=0. (I can think of 3 questions regarding these cases. (1) Are they defined? (2) Is p=1 the same as 8. (3) Does 3:0=1:0?)\n\nWe should mention that this term does not include gambling odds. (As I understand it, gambling odds are the ratio of stake to winnings with several representations and frequently have a \"rounding\" factor to ensure a profit for the bookmaker).\n\nAnother issue is whether to represent \"Odds Against\" in the vocabulary. It could come up when annotating an immutable pre-existing source that gives odds as odds against; for example, an NLP system that scans published works to output labels for sections of the text.\n\nA term related to \"Odds\" missing from the parent branch, \"Ratio,\" is \"Log Odds.\"\n(Not unique to this term, but I noticed it here) The children of \"Statistic\" should inherit the application comment from \"Statistic\" about distinguishing between the statistic and statistic value. That way, a reader will not need to read the whole tree to know that 1.5 is not \"Odds\"; it is \"Odds statistic value.\" (However, I do not see a place for \"Odds statistic value\" in the tree.)\n\nFinally, the repetition of \"Odds may be expressed as\" is awkward.\n\n2022-02-23 comments: \"Odds may be expressed as p:(1-p). Odds may be expressed as p:q where q = 1-p. \" Sounds redundant.\nAlternative terms: Probablity likelihood, chance ---{{Group meeting decided that 'probability' and 'likelihood' are terms we may consider adding to the SEVCO but they are not Alternative terms for odds, 'chance' is considered a lay term and not a specific statistical term for the code system}}\nOdds is a computational function such as addition, subtraction, multiplication.  Odds Ratio may be better term for the term definition.  This comment is based on your term definition and comment for application.  \n\n2022-03-09 comment: Edit the term definition:  A ratio of probabilities in which the numerator represents the probability of the number of times an event will occur and the denominator represents the probability of the number of time an event will not occur.  (Steering group 2022-03-09 considers the suggested change does not add clarification or improved understanding.)\n\n2022-03-16 comment: I would delete likelihood from the term definition as in statistics it introduces a different formula such as likelihood ratio.\nMy suggestion is to simplify to a ration in which the numerator represents the number of times an event will occur and the denominator represents the number of times an event will not occur. (Steering group 2022-03-16 again considers the suggested change to include \"number of times\" not persuasive, but changed \"relative likelihood\" to \"probability\" in the definition to avoid the potential confusion with likelihood ratio.)"}, {"code": "approval", "valueString": "2022-03-22 vote 5-0 by Muhammad Afzal, Jesus Lopez-Alcalde, Philippe Rocca-Serra, Mario Tristan, Robin Ann Yurk"}]}, {"code": "STATO:0000645", "display": "rate", "definition": "A ratio in which the numerator represents any quantity and the denominator represents an interval of time.", "property": [{"code": "comment", "valueString": "When the numerator represents a count, the rate is an Event Rate."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Kenneth Wilkins, Muhammad Afzal"}, {"code": "external-definitions", "valueString": "NCIt\nRate = A measurement of degree, speed, or frequency relative to time.\n\nOBCS\nrate= A quality of a single process inhering in a bearer by virtue of the bearer's occurrence per unit time.\n\nOCRe\nRate = A rate is a quantity per unit of time."}, {"code": "negative-vote", "valueString": "2022-03-30 vote 4-2 by Cau\u00ea Monaco, Muhammad Afzal, Jesus Lopez-Alcalde, Philippe Rocca-Serra, Mario Tristan, Robin Ann Yurk\n2022-04-06 vote 3-2 by Mario Tristan, Robin Ann Yurk, Paola Rosati, Jesus Lopez-Alcalde, nisha mathew"}, {"code": "expert-comments", "valueString": "2022-03-30 comments: A rate does not necessarily represent time. \"In math, a rate is a special ratio in which the two terms are in different units\"Edit term definition:  A proportion represented by a rate of an event count for another quantified measure.\n My comments are more focused on in the term definition and comment you have incomplete definitions or comments as you only describe in the term definition the denominator and in the comment you only describe the numerator.\nImprovement Suggestion:  By definition, a rate would have both a numerator and denominator so it is important for your to include in a definition both numerator and denominator.\n\nThe term definition should read:  A ratio in which the numerator represents an event count and the denominator represents the total sum of the events considered as a count and non count.\n\nThe underlying concept for Rate is that the Denominator is a measure of time.   So we need a definition where the numerator is X and the denominator is a measure time.\n \nOur approach to definitions has been:\n \nRatio = A statistic that is a quotient of two quantities.  [[By definition any statistic that is a ratio has a numerator and a denominator.   Any statistic that has a numerator and a denominator is a Ratio, and may be given a more specific term when it is a type of Ratio.]]   The Ratio definition inherits the Statistic definition so we do not re-define statistic.\n \nRate = A ratio in which the denominator represents a duration of time.     This means that when we constrain the definition of ratio to limit to statistics where the denominator represents a duration of time, then the type of Ratio is a Rate.   There is a logic to this approach to setting a definition, but your comment shows that it feel lacking because it does not mention the numerator.  There is no constraint or modification being applied to the numerator.\n \nPerhaps we can try \u201cRate = A ratio in which the numerator represents any quantity and the denominator represents a duration of time.\u201d\n \nWould that help clarify this item?\n\n2022-04-06 comments: I would insert in the term definition, the numerator represents a quantity defined as a unit which is a smaller part of the denominator divided by the total sum of units in the denominator.\n\nthe concepts,  \"frequency of events\" and  \"over a specified period of time\"  are not reflected in this definition \n\n2022-04-27 comment: Edit term definition:  A proportion represented by a rate of an event count or another quantified measure divided by the total sum of units.  {{Discussion by Expert Working Group: The proposed definition describes a Proportion, but a Rate is NOT a Proportion.}}"}, {"code": "approval", "valueString": "2022-05-12 vote 9-0 by Eric Harvey, raradhikaag@gmail.com, Jesus Lopez-Alcalde, Mario Tristan, Harold Lehmann, Paola Rosati, Muhammad Afzal, nisha mathew, Janice Tufte"}], "concept": [{"code": "STATO:0000670", "display": "incidence rate", "definition": "A rate in which the number of new events per total at risk is divided by an interval of time.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "incidence density"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "average hazard rate"}], "property": [{"code": "comment", "valueString": "Incidence is defined as a proportion in which the numerator represents new events and the denominator represents the total at risk for events. Rate is defined as a ratio in which the numerator represents any quantity and the denominator represents an interval of time. The interval of time used for the denominator may be data-dependent when the duration of observation varies across the observations.\n\nIn the method for calculating incidence rate (described at https://www.cdc.gov/csels/dsepd/ss1978/lesson3/section2.html), the numerator is the \"Number of new cases of disease or injury during the specified period\" and the denominator is the \"Time each person was observed, totaled for all persons\""}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Kenneth Wilkins, Muhammad Afzal"}, {"code": "external-definitions", "valueString": "NCIt \nIncidence Rate = The frequency of new occurrences of an event during a specified time period.\n\nCDC: https://www.cdc.gov/csels/dsepd/ss1978/lesson3/section2.html\nIncidence refers to the occurrence of new cases of disease or injury in a population over a specified period of time. Although some epidemiologists use incidence to mean the number of new cases in a community, others use incidence to mean the number of new cases per unit of population.\n\nTwo types of incidence are commonly used \u2014 incidence proportion and incidence rate.\n\nSynonyms for incidence rate\n\nPerson-time rate\n\n\nDefinition of incidence rate\n\nIncidence rate or person-time rate is a measure of incidence that incorporates time directly into the denominator. A person-time rate is generally calculated from a long-term cohort follow-up study, wherein enrollees are followed over time and the occurrence of new cases of disease is documented. Typically, each person is observed from an established starting time until one of four \u201cend points\u201d is reached: onset of disease, death, migration out of the study (\u201clost to follow-up\u201d), or the end of the study. Similar to the incidence proportion, the numerator of the incidence rate is the number of new cases identified during the period of observation. However, the denominator differs. The denominator is the sum of the time each person was observed, totaled for all persons. This denominator represents the total time the population was at risk of and being watched for disease. Thus, the incidence rate is the ratio of the number of cases to the total time the population is at risk of disease.\n\n\nAlternative terms for incidence rate (incidence density, average hazard) noted at https://www.sjsu.edu/faculty/gerstman/eks/formula_sheet.pdf"}, {"code": "negative-vote", "valueString": "2022-05-11 vote 7-1 by Eric Harvey, raradhikaag@gmail.com, Jesus Lopez-Alcalde, Mario Tristan, Janice Tufte, Harold Lehmann, Paola Rosati, Robin Ann Yurk"}, {"code": "expert-comments", "valueString": "2022-05-11 comment: Suggest improving current term definition with the definition in comment for application.  The Alternative terms I am not sure fit here--you may want to add more detail for the alternate terms to the comment for application.\n2022-05-25 comment: The definition defines the ideal (\"at risk\"); very often, however, incidence rates are calculated more grossly. While they are semantically wrong, they are quantitatively correct. Classic: birth incidence. The proper denominator would be fertile women, but *could * be calculated \"per woman\" or even \"per capita\"."}, {"code": "approval", "valueString": "2022-05-25 vote 6-0 by Jesus Lopez-Alcalde, Brian S. Alper, Joanne Dehnbostel, Eric M Harvey, Mario Tristan, Harold Lehmann"}]}, {"code": "STATO:0000671", "display": "hazard rate", "definition": "A conditional instantaneous rate in which the numerator represents an incidence conditioned on survival to a specified time, and the denominator represents a time interval with a duration approaching zero.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "hazard"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "hazard function"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "instantaneous hazard rate"}], "property": [{"code": "comment", "valueString": "In the definition of Hazard Rate, the term \"survival\" is not literally about life and death but is used to represent existence without experiencing the event. \"Hazard\" as a statistical term is not specific to \"bad\" or \"dangerous\" events.\nA hazard rate is expressed as a unitless numerator per unit of time, occurring at a specified time, and conditioned on survival to that time. \nA hazard rate is mathematically the negative derivative of the log of the survival function. The survival function is the probability of surviving past a specified point in time, expressed as Pr{ T >= t }. \nA hazard rate is also mathematically defined as lim(dt -> 0) [ Pr{ ( t <= T < t + dt ) | ( T >= t ) } / dt ]."}, {"code": "editors", "valueString": "Harold Lehmann, Kenneth Wilkins, Joanne Dehnbostel, Brian S. Alper"}, {"code": "external-definitions", "valueString": "A Dictionary of Epidemiology (5 ed.) by Miquel Porta\nHazard rate = A theoretical measure of the probability of occurrence of an event per unit time at risk; e.g., death or new disease, at a point in time,\u00a0t, defined mathematically as the limit, as ?t approaches zero, of the probability that an individual well at time\u00a0t\u00a0will experience the event by\u00a0t\u00a0+ ?t, divided by ?t.\n\nformula expressed at https://data.princeton.edu/wws509/notes/c7s1"}, {"code": "negative-vote", "valueString": "2022-04-06 vote 4-3 by Mario Tristan, Robin Ann Yurk, Cau\u00ea Monaco, Harold Lehmann, Paola Rosati, Jesus Lopez-Alcalde, nisha mathew"}, {"code": "expert-comments", "valueString": "2022-04-06 comments: An instantaneous rate in which the numerator represents an incidence and the denominator represents a time interval conditioned on survival to a specified time with a duration approaching zero\n\nA hazard is any danger or peril. It does not necessarily represent a survival/death relationship.\n\nI would add a vote choice:  No Comment-Specialized Term or Not Applicable or some other choice as this is specialized formula."}, {"code": "approval", "valueString": "2022-05-12 vote 8-0 by Eric Harvey, raradhikaag@gmail.com, Jesus Lopez-Alcalde, Mario Tristan, Harold Lehmann, Paola Rosati, Muhammad Afzal, nisha mathew"}]}, {"code": "STATO:0000672", "display": "event rate", "definition": "The number of occurrences per unit of time.", "property": [{"code": "comment", "valueString": "An event rate is a ratio in which the numerator represents a count and the denominator represents an interval of time.\nWhen the numerator represents a count: \n--If the denominator includes an interval of time, the type of ratio is an Event Rate. \n--If the denominator includes a count without an interval of time, the type of ratio is an Event Frequency. \n--If the denominator includes a count and an interval of time, the type of ratio is an Event Frequency Rate. \n--If the denominator includes an interval of space, the type of ratio is a Number Density"}, {"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Muhammad Afzal, Kenneth Wilkins, Harold Lehmann"}, {"code": "expert-comments", "valueString": "2022-04-27 comment: The term definition and comment for application are comprehensive.  However, for your comment for application I would only use the following...\nAn event rate is a ratio in which the numerator represents a count and the denominator represents an interval of time.\nWhen the numerator represents a count: \n--If the denominator includes an interval of time, the type of ratio is an Event Rate. \n{{Expert Working Group discussion: the comment providing instructions for choosing among 4 related and confusing terms is considered useful for guidance, and purposefully mentions other terms that may be more appropriate.}}"}, {"code": "approval", "valueString": "2022-05-12 vote 8-0 by Eric Harvey, raradhikaag@gmail.com, Jesus Lopez-Alcalde, Mario Tristan, Harold Lehmann, Paola Rosati, Muhammad Afzal, nisha mathew"}]}, {"code": "STATO:0000673", "display": "event frequency rate", "definition": "A ratio in which the numerator represents an event frequency and the denominator represents an interval of time.", "property": [{"code": "comment", "valueString": "When the numerator represents a count: \n--If the denominator includes an interval of time, the type of ratio is an Event Rate. \n--If the denominator includes a count without an interval of time, the type of ratio is an Event Frequency. \n--If the denominator includes a count and an interval of time, the type of ratio is an Event Frequency Rate. \n--If the denominator includes an interval of space, the type of ratio is a Number Density"}, {"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Muhammad Afzal, Kenneth Wilkins, Harold Lehmann"}, {"code": "approval", "valueString": "2022-05-12 vote 9-0 by Eric Harvey, raradhikaag@gmail.com, Jesus Lopez-Alcalde, Mario Tristan, Harold Lehmann, Paola Rosati, Muhammad Afzal, nisha mathew, Janice Tufte"}]}]}, {"code": "STATO:0000674", "display": "event frequency", "definition": "A ratio in which the numerator represents a count and the denominator represents a count (without involving an interval of time).", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "frequentist probability"}], "property": [{"code": "comment", "valueString": "When the numerator represents a count: \n--If the denominator includes an interval of time, the type of ratio is an Event Rate. \n--If the denominator includes a count without an interval of time, the type of ratio is an Event Frequency. \n--If the denominator includes a count and an interval of time, the type of ratio is an Event Frequency Rate. \n--If the denominator includes an interval of space, the type of ratio is a Number Density"}, {"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Muhammad Afzal, Kenneth Wilkins, Harold Lehmann"}, {"code": "approval", "valueString": "2022-05-12 vote 9-0 by Eric Harvey, raradhikaag@gmail.com, Jesus Lopez-Alcalde, Mario Tristan, Harold Lehmann, Paola Rosati, Muhammad Afzal, nisha mathew, Janice Tufte"}]}, {"code": "STATO:0000675", "display": "density", "definition": "A ratio in which the numerator represents any quantity and the denominator represents an interval of space (distance, area, or volume).", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Muhammad Afzal, Kenneth Wilkins, Harold Lehmann"}, {"code": "approval", "valueString": "2022-05-08 vote 7-0 by Mario Tristan, Janice Tufte, Harold Lehmann, Paola Rosati, Muhammad Afzal, nisha mathew, Eric M Harvey"}, {"code": "expert-comments", "valueString": "2022-05-08 comment: Examples would be nice, since \"linear density\" is not a traditional measure"}], "concept": [{"code": "STATO:0000676", "display": "number density", "definition": "A ratio in which the numerator represents a count and the denominator represents an interval of space (distance, area, or volume).", "property": [{"code": "comment", "valueString": "When the numerator represents a count: \n--If the denominator includes an interval of time, the type of ratio is an Event Rate. \n--If the denominator includes a count without an interval of time, the type of ratio is an Event Frequency. \n--If the denominator includes a count and an interval of time, the type of ratio is an Event Frequency Rate. \n--If the denominator includes an interval of space, the type of ratio is a Number Density"}, {"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Muhammad Afzal, Kenneth Wilkins, Harold Lehmann"}, {"code": "negative-vote", "valueString": "2022-05-12 vote 8-1 by Eric Harvey, raradhikaag@gmail.com, Jesus Lopez-Alcalde, Mario Tristan, Harold Lehmann, Paola Rosati, Muhammad Afzal, nisha mathew, Janice Tufte"}, {"code": "expert-comments", "valueString": "2022-05-12 comment: I wonder if we could define better \"Number Density\" as Density ratio {{2022-05-18 discussion found 2 instances of the term 'Number density' matching our definition, and the term 'density ratio' defines a density divided by a density which does not match this concept.}}"}, {"code": "external-definitions", "valueString": "Wikipedia https://en.wikipedia.org/wiki/Number_density \nThe number density (symbol: n or ?N) is an intensive quantity used to describe the degree of concentration of countable objects (particles, molecules, phonons, cells, galaxies, etc.) in physical space: three-dimensional volumetric number density, two-dimensional areal number density, or one-dimensional linear number density. Population density is an example of areal number density.\n\nIUPAC Gold Book https://goldbook.iupac.org/terms/view/N04262\nnumber density, n\nNumber of particles divided by the volume they occupy."}, {"code": "approval", "valueString": "2022-05-27 vote 10-0 by Khalid Shahin, Joanne Dehnbostel, Eric Harvey, raradhikaag@gmail.com, Jesus Lopez-Alcalde, Mario Tristan, Harold Lehmann, Muhammad Afzal, nisha mathew, Janice Tufte"}]}]}, {"code": "STATO:0000704", "display": "concentration", "definition": "A ratio in which the numerator is a measure of the solute and the denominator is a measure of the solvent.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Muhammad Afzal, Kenneth Wilkins, Harold Lehmann"}, {"code": "approval", "valueString": "2022-05-08 vote 6-0 by Mario Tristan, Harold Lehmann, Paola Rosati, Muhammad Afzal, nisha mathew, Eric M Harvey"}]}], "display": "ratio", "property": [{"code": "editors", "valueString": "Harold Lehmann, Kenneth Wilkins, Brian S. Alper, Joanne Dehnbostel, Janice Tufte, Muhammad Afzal"}, {"code": "external-definitions", "valueString": "STATO: A ratio is a data item which is formed with two numbers r and s is written r/s, where r is the numerator and s is the denominator. The ratio of r to s is equivalent to the quotient r/s.\nNCIt:  The quotient of one quantity divided by another, with the same units of measurement.\nUMLS: Quotient of quantities of the same kind for different components within the same system.\nOECD: A ratio is a number that expresses the relative size of two other numbers.\nOCRe: A ratio is a quotient of quantities of the same kind for different components within the same system.\nSCO: A ratio is a relationship between two numbers of the same kind expressed arithmetically as a dimensionless quotient of the two which explicitly indicates how many times the first number contains the second.\nQuotient of quantities of the same kind for different components within the same system."}, {"code": "comment", "valueString": "Although some definitions for Ratio include \"with the same units of measurement\" and some definitions for Ratio include \"a dimensionless quotient\", not all definitions have these concepts, and there are ratios with units of measurement that are different for numerator and denominator such as event rate, body mass index, and cost-effectiveness ratio."}, {"code": "negative-vote", "valueString": "2021-12-22 vote 3-1 by Robin Ann Yurk, Harold Lehmann, Janice Tufte, Jesus Lopez-Alcalde\n2021-12-29 vote 3-1 by Robin Ann Yurk, Harold Lehmann, Janice Tufte, C P Ooi"}, {"code": "expert-comments", "valueString": "2021-12-22 comment: I suggest adding \"with the same measurement units\"2021-12-29 comment: I agree with the term definition.  However, the comment could be improved and I would not include BMI as an example as an index may not necessarily be a ratio but a more complex statistic or calculation\n2022-01-05 comment: Comment,  I would remove body mass index from the comment section as an example as an index is a unique statistical defnition."}, {"code": "approval", "valueString": "2022-01-05 vote 6-0 by Harold Lehmann, Robin Ann Yurk, Janice Tufte, C P Ooi, Louis Leff, Jesus Lopez-Alcalde"}], "definition": "A statistic that is a quotient of two quantities."}, {"code": "STATO:0000610", "display": "measure of association", "definition": "A statistic that quantitatively represents a relationship between two or more variables.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Kenneth Wilkins, Muhammad Afzal, Neeraj Ojha"}, {"code": "expert-comments", "valueString": "2022-02-24 comment: There are measures of association between more than two variables, for example, an estimator of interaction information. So, this should be \"two or more variables\" (or just \"variables\"). \n\nAlso, I don't like the term \"represents\", I'd prefer to say \"A statistic that quantifies a relationship between variables.\""}, {"code": "approval", "valueString": "2022-03-16 vote 7-0 by Mario Tristan, Paola Rosati, Louis Leff, nisha mathew, Philippe Rocca-Serra, Harold Lehmann, Janice Tufte"}], "concept": [{"code": "STATO:0000622", "display": "ratio-based measure of association", "definition": "A measure of association expressed as a ratio.", "property": [{"code": "editors", "valueString": "Harold Lehmann, Kenneth Wilkins, Brian S. Alper, Joanne Dehnbostel, Janice Tufte, Muhammad Afzal"}, {"code": "expert-comments", "valueString": "2022-02-24 comment: I think we should replace \"represents\" with \"quantifies\" and remove the restriction to two variables.\n\n\"A statistic that is a ratio and quantifies a relationship between variables.\"\nSecond, I think you want a more restrictive definition than a statistic that is a ratio. For example, the uncertainty coefficient, I(X;Y)/H(Y), is a ratio and a measure of association, but I don't think you'd consider it a ratio-based measure of association (maybe you would, in which case this is OK).\n\nYou should also consider whether monotonic transformations of ratios count as ratio-based measures. It is common for people to take logarithms of ratios.\n\nI'm not sure what the utility is of this category. When does someone need it? Could we just put all its children Measure of Association?"}, {"code": "comment", "valueString": "This categorical (parent) term can be used for a statistic that is a ratio, quantifies a relationship between two variables, and is not found in the child terms."}, {"code": "approval", "valueString": "2022-12-28 vote 7-0 by Janice Tufte, Mario Tristan, Joanne Dehnbostel, Harold Lehman, Yuan Gao, Jesus Lopez-Alcalde, Eric Harvey"}], "concept": [{"code": "STATO:0000677", "display": "hazard ratio", "definition": "A measure of association that is the ratio of the hazard rate of an event in one group to the hazard rate of the same event in another group.", "property": [{"code": "statistical-purpose", "valueString": "Measure of Association"}, {"code": "external-definitions", "valueString": "NCIt:\nHazard ratio = A measure of how often a particular event happens in one group compared to how often it happens in another group, over time. In cancer research, hazard ratios are often used in clinical trials to measure survival at any point in time in a group of patients who have been given a specific treatment compared to a control group given another treatment or a placebo. A hazard ratio of one means that there is no difference in survival between the two groups. A hazard ratio of greater than one or less than one means that survival was better in one of the groups.\n\nhttps://www.statisticshowto.com/hazard-ratio/\nThe hazard ratio is a comparison between the probability of events in a treatment group, compared to the probability of events in a control group.\n\nHazard Ratio in Clinical Trials (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC478551/)\nThe hazard ratio is an estimate of the ratio of the hazard rate in the treated versus the control group. The hazard rate is the probability that if the event in question has not already occurred, it will occur in the next time interval, divided by the length of that interval. The time interval is made very short, so that in effect the hazard rate represents an instantaneous rate.\n\nThe Hazards of Hazard Ratios (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3653612/)\nThe hazard ratio (HR) is the main, and often the only, effect measure reported in many epidemiologic studies. For dichotomous, non\u2013time-varying exposures, the HR is defined as the hazard in the exposed groups divided by the hazard in the unexposed groups. For all practical purposes, hazards can be thought of as incidence rates and thus the HR can be roughly interpreted as the incidence rate ratio. The HR is commonly and conveniently estimated via a Cox proportional hazards model, which can include potential confounders as covariates."}, {"code": "comment", "valueString": "Hazard rate (SEVCO TBD:0000025) is defined as: A conditional instantaneous rate in which the numerator represents an incidence conditioned on survival to a specified time, and the denominator represents a time interval with a duration approaching zero.\n\nThe groups being compared are often the exposed group versus the unexposed group, but hazard ratio can also be applied to comparisons of one exposure relative to another exposure.\n\nA hazard ratio of one means there is no difference between two groups in terms of their hazard rates, based on whether or not they were exposed to a certain substance or factor, or how they responded to two interventions being compared. A hazard ratio of greater than one implies an association of greater risk, and a hazard ratio of less than one implies an association of lower risk.\n\nThe hazard ratio can be calculated from studies in which the proportion of exposed participants who had the event is known, the proportion of unexposed participants who had the event is known, and the timing of events for each participant is known or estimable, such as a cohort study or clinical trial."}, {"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Joanne Dehnbostel, Muhammad Afzal"}, {"code": "approval", "valueString": "2022-06-08 vote 5-0 by Harold Lehmann, Mario Tristan, Eric M Harvey, Muhammad Afzal, Paola Rosati"}]}, {"code": "STATO:0000680", "display": "incidence rate ratio", "definition": "A measure of association that is the ratio of two incidence rates.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "IRR"}], "property": [{"code": "statistical-purpose", "valueString": "Measure of Association"}, {"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Joanne Dehnbostel, Muhammad Afzal"}, {"code": "comment", "valueString": "Incidence Rate (SEVCO TBD:0000024) is defined as: A rate in which the number of new events per total at risk is divided by an interval of time.\n\nThe incidence rates may refer to the same event comparing two different groups, or the same group comparing two different events."}, {"code": "approval", "valueString": "2022-06-08 vote 5-0 by Harold Lehmann, Mario Tristan, Eric M Harvey, Muhammad Afzal, Paola Rosati"}], "concept": [{"code": "STATO:0000681", "display": "standardized incidence ratio", "definition": "An incidence rate ratio in which the numerator is the incidence rate in a group and the denominator is the incidence rate for a reference population.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "SIR"}], "property": [{"code": "statistical-purpose", "valueString": "Measure of Association"}, {"code": "comment", "valueString": "The incidence rate used for the denominator may be an expected incidence rate for a reference population. The reference population may refer to a general population of the geographic area from which the cohort was selected."}, {"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Joanne Dehnbostel, Muhammad Afzal"}, {"code": "approval", "valueString": "2022-06-08 vote 5-0 by Harold Lehmann, Mario Tristan, Eric M Harvey, Muhammad Afzal, Paola Rosati"}, {"code": "expert-comments", "valueString": "2022-06-08 comment: ... and the denominator is the incidence rate or expected incidence rate for a reference population.\n\nComment for application: The reference population may refer to a general population of the geographic area from which the cohort was selected."}]}]}, {"code": "STATO:0000182", "display": "odds ratio", "property": [{"code": "editors", "valueString": "Harold Lehmann, Kenneth Wilkins, Brian S. Alper, Joanne Dehnbostel, Janice Tufte"}, {"code": "external-definitions", "valueString": "STATO: odds ratio (OR) = Odds ratio is a ratio that measures effect size, that is the strength of association between 2 dichotomous variables, one describing an exposure and one describing an outcome.\nIt represents the odds that an outcome will occur given a particular exposure, compared to the odds of the outcome occurring in the absence of that exposure ( the probability of the event occuring divided by the probability of an event not occurring). The odds ratio is a ratio of describing the strength of association or non-independence between two binary data values by forming the ratio of the odds for the first group and the odds for the second group. Odds ratio are used when one wants to compare the odds of something occurring to two different groups.\n\nUMLS: The ratio of two odds. The exposure-odds ratio for case control data is the ratio of the odds in favor of exposure among cases to the odds in favor of exposure among noncases. The disease-odds ratio for a cohort or cross section is the ratio of the odds in favor of disease among the exposed to the odds in favor of disease among the unexposed. The prevalence-odds ratio refers to an odds ratio derived cross-sectionally from studies of prevalent cases. (MSH)\nA measure of the odds of an event happening in one group compared to the odds of the same event happening in another group. In cancer research, odds ratios are most often used in case-control (backward looking) studies to find out if being exposed to a certain substance or other factor increases the risk of cancer. For example, researchers may study a group of individuals with cancer (cases) and another group without cancer (controls) to see how many people in each group were exposed to a certain substance or factor. They calculate the odds of exposure in both groups and then compare the odds. An odds ratio of one means that both groups had the same odds of exposure and, therefore, the exposure probably does not increase the risk of cancer. An odds ratio of greater than one means that the exposure may increase the risk of cancer, and an odds ratio of less than one means that the exposure may reduce the risk of cancer. (NCI)\nThe ratio of the odds of an event occurring in one group to the odds of it occurring in another group, or to a sample-based estimate of that ratio. (NCI)\n\nNICE: Compares the odds (probability) of something happening in 1 group with the odds of it happening in another. An odds ratio of 1 shows that the odds of the event happening (for example, a person developing a disease or a treatment working) is the same for both groups. An odds ratio of greater than 1 means that the event is more likely in the first group than the second. An odds ratio of less than 1 means that the event is less likely in the first group than in the second group."}, {"code": "statistical-purpose", "valueString": "Measure of Association"}, {"code": "approval", "valueString": "2022-03-16 vote 8-0 by Mario Tristan, Paola Rosati, Louis Leff, nisha mathew, Philippe Rocca-Serra, Harold Lehmann, Janice Tufte, Eric Moyer"}], "definition": "A measure of association that is the ratio of two odds."}, {"code": "STATO:0000678", "display": "prevalence ratio", "definition": "A measure of association that is the ratio of two prevalences.", "property": [{"code": "statistical-purpose", "valueString": "Measure of Association"}, {"code": "external-definitions", "valueString": "https://www.ctspedia.org/do/view/CTSpedia/PrevalenceRatio#:~:text=Reference-,Definition%20of%20Prevalence%20Ratio,the%20proportion%20with%20the%20exposure.\nThe ratio of the proportion of the persons with disease over the proportion with the exposure.\n\nCalculation is described here:\nhttps://sphweb.bumc.bu.edu/otlt/MPH-Modules/PH717-QuantCore/PH717-Module3-Frequency-Association/PH717-Module3-Frequency-Association12.html"}, {"code": "comment", "valueString": "Prevalence (SEVCO STATO:0000412) is defined as: A proportion in which the numerator represents all events of interest (for example, both new and preexisting cases of a disease) in the population, which is represented by the denominator.\n\nThe Prevalence Ratio indicates the magnitude of the prevalence of an event/outcome in one group of subjects/individuals (with characteristics/attribute) relative to another group (with different characteristics/attributes), such as the prevalence of the disease among the exposed persons to the prevalence of the disease among the unexposed persons."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Kenneth Wilkins, Muhammad Afzal, Janice Tufte"}, {"code": "approval", "valueString": "2022-06-08 vote 5-0 by Harold Lehmann, Mario Tristan, Eric M Harvey, Muhammad Afzal, Paola Rosati"}, {"code": "expert-comments", "valueString": "2022-06-08 comment: Comment for application: The prevalence Ratio indicates how large is the prevalence of an event/outcome in one group of subjects/individuals (with characteristics/attribute) relative to another group (without the characteristics/attributes), such as the prevalence of the disease among the exposed persons to the prevalence of the disease among the unexposed persons."}]}, {"code": "STATO:0000245", "display": "risk ratio", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "relative risk"}], "property": [{"code": "external-definitions", "valueString": "STATO: relative risk (risk ratio) = Relative risk is a measurement datum which denotes the risk of an 'event' relative to an 'exposure'. Relative risk is calculated by forming the ratio of the probability of the event occurring in the exposed group versus the probability of this event occurring in the non-exposed group.\n\nNCIt\tRelative Risk\tA measure of the risk of a certain event happening in one group compared to the risk of the same event happening in another group. In cancer research, risk ratios are used in prospective (forward looking) studies, such as cohort studies and clinical trials. A risk ratio of one means there is no difference between two groups in terms of their risk of cancer, based on whether or not they were exposed to a certain substance or factor, or how they responded to two treatments being compared. A risk ratio of greater than one or of less than one usually means that being exposed to a certain substance or factor either increases (risk ratio greater than one) or decreases (risk ratio less than one) the risk of cancer, or that the treatments being compared do not have the same effects\n\nOBCS\trelative risk  A data item that equals the incidence in exposed individuals divided by the incidence in unexposed individuals. The relative risk can be calculated from studies in which the proportion of patients exposed and unexposed to a risk is known, such as a cohort study.\n\nCDC https://www.cdc.gov/csels/dsepd/ss1978/lesson3/section5.html:\nA risk ratio (RR), also called relative risk, compares the risk of a health event (disease, injury, risk factor, or death) among one group with the risk among another group. It does so by dividing the risk (incidence proportion, attack rate) in group 1 by the risk (incidence proportion, attack rate) in group 2. The two groups are typically differentiated by such demographic factors as sex (e.g., males versus females) or by exposure to a suspected risk factor (e.g., did or did not eat potato salad). Often, the group of primary interest is labeled the exposed group, and the comparison group is labeled the unexposed group."}, {"code": "statistical-purpose", "valueString": "Measure of Association"}, {"code": "comment", "valueString": "The groups being compared are often the exposed group versus the unexposed group, but risk ratio can also be applied to comparisons of one exposure relative to another exposure.\n\nA risk ratio of one means there is no difference between two groups in terms of their risk, based on whether or not they were exposed to a certain substance or factor, or how they responded to two interventions being compared. A risk ratio of greater than one implies an association of greater risk, and a risk ratio of less than one implies an association of lower risk.\n\nThe risk ratio can be calculated from studies in which the proportion of exposed participants who had the event is known and the proportion of unexposed participants who had the event is known, such as a cohort study or clinical trial."}, {"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Joanne Dehnbostel, Muhammad Afzal"}, {"code": "approval", "valueString": "2022-06-08 vote 6-0 by Robin Ann Yurk, Harold Lehmann, Mario Tristan, Eric M Harvey, Muhammad Afzal, Paola Rosati"}], "definition": "A measure of association that is the ratio of the risk of an event in one group to the risk of the same event in another group."}, {"code": "STATO:0000411", "display": "likelihood ratio positive", "definition": "A measure of association that is the ratio of the probability of the test giving a positive result when testing an affected subject and the probability of the test giving a positive result when a subject is not affected.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "positive likelihood ratio"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "+LR"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "LR+"}], "property": [{"code": "external-definitions", "valueString": "STATO: positive likelihood ratio (likelihood ratio for positive results) = the likelihood ratio of positive results is a ratio which is form by dividing the sensitivity value of a test by the difference between 1 and specificity of the test. This can be expressed also as dividing the probability of the test giving a positive result when testing an affected subject versus the probability of the test giving a positive result when a subject is not affected.\n\nAHRQ https://effectivehealthcare.ahrq.gov/products/test-performance-metrics/appendixes:\nThe positive and negative likelihood ratios (LR+ and LR-, respectively) quantify the change in the certainty of the \u201cdiagnosis\u201d conferred by test results. More specifically, the likelihood ratios transform the pretest odds to the posttest odds of a given (positive or negative) diagnosis:\n\nposttest odds = pretest odds x LR\n\nFor a positive result with the medical test, the positive likelihood ratio would be used in the above relationship; for a negative result with the medical test portable monitor, the negative likelihood ratio would be used.\n\nIf a given medical test has very good ability to predict the \u201ctrue disease status,\u201d its positive likelihood ratio will be high (i.e., will greatly increase the odds of a positive diagnosis) and its negative likelihood ratio will be low (i.e., will diminish substantially the likelihood of the positive diagnosis). A completely non-informative portable monitor would have likelihood ratios equal to 1 (i.e., does not transform the pre-test odds substantially in the equation above). Typically, a positive likelihood ratio of 10 or more and a negative likelihood ratio of 0.1 or less are considered to represent informative tests.3 We note that other, more lenient boundaries for LR+ and LR- can be used3 and that the choice of the boundaries is a subjective decision. It is interesting to note that studies with high LR+ and low LR- can be readily identified in the square sensitivity/100 percent-specificity plot, as shown in the Appendix Figure above."}, {"code": "statistical-purpose", "valueString": "Measure of Association"}, {"code": "comment", "valueString": "The probability of the test giving a positive result when testing an affected subject is also called the sensitivity [SEVCO term STATO:0000233] or true positive rate. The probability of the test giving a positive result when a subject is not affected is called the false positive rate and is calculated as 1 minus the specificity [SEVCO term STATO:0000134]. The Likelihood Ratio Positive (LR+) is calculated as Sensitivity / (1 - Specificity).\n\nThe Likelihood Ratio Positive may also be calculated as the posterior probability (positive predictive value) divided by the prior probability (prevalence).\n\nWhen the test result is a specific value on a continuous scale, the Likelihood Ratio Positive is the ratio of the likelihood of the test giving the specific value when testing an affected subject and the likelihood of the test giving the specific value when a subject is not affected. \n\nIn the context of a probability distribution function, e.g. normal distribution, the x axis is the value and y axis is the likelihood."}, {"code": "editors", "valueString": "Harold Lehmann, Brian S. Alper, Joanne Dehnbostel, Muhammad Afzal"}, {"code": "approval", "valueString": "2022-08-10 vote 5-0 by Robin Ann Yurk, Mario Tristan, Harold Lehmann, Eric Harvey, Paola Rosati"}]}, {"code": "STATO:0000410", "display": "likelihood ratio negative", "definition": "A measure of association that is the ratio of the probability of the test giving a negative result when testing an affected subject and the probability of the test giving a negative result when a subject is not affected.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "negative likelihood ratio"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "LR-"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "-LR"}], "property": [{"code": "external-definitions", "valueString": "STATO: negative likelihood ratio (likelihood ratio for negative results) = the likelihood ratio of negative results is a ratio which is formed  by dividing the difference between 1 and sensitivity of the test by the specificity value of a test.. This can be expressed also as dividing the probability of a person who has the disease testing negative by the probability of a person who does not have the disease testing negative.\n\nAHRQ https://effectivehealthcare.ahrq.gov/products/test-performance-metrics/appendixes:\nThe positive and negative likelihood ratios (LR+ and LR-, respectively) quantify the change in the certainty of the \u201cdiagnosis\u201d conferred by test results. More specifically, the likelihood ratios transform the pretest odds to the posttest odds of a given (positive or negative) diagnosis:\n\nposttest odds = pretest odds x LR\n\nFor a positive result with the medical test, the positive likelihood ratio would be used in the above relationship; for a negative result with the medical test portable monitor, the negative likelihood ratio would be used.\n\nIf a given medical test has very good ability to predict the \u201ctrue disease status,\u201d its positive likelihood ratio will be high (i.e., will greatly increase the odds of a positive diagnosis) and its negative likelihood ratio will be low (i.e., will diminish substantially the likelihood of the positive diagnosis). A completely non-informative portable monitor would have likelihood ratios equal to 1 (i.e., does not transform the pre-test odds substantially in the equation above). Typically, a positive likelihood ratio of 10 or more and a negative likelihood ratio of 0.1 or less are considered to represent informative tests.3 We note that other, more lenient boundaries for LR+ and LR- can be used3 and that the choice of the boundaries is a subjective decision. It is interesting to note that studies with high LR+ and low LR- can be readily identified in the square sensitivity/100 percent-specificity plot, as shown in the Appendix Figure above."}, {"code": "statistical-purpose", "valueString": "Measure of Association"}, {"code": "comment", "valueString": "The probability of the test giving a negative result when testing an affected subject is also called the false negative rate and is calculated as 1 minus the sensitivity [SEVCO term STATO:0000233]. The probability of the test giving a negative result when a subject is not affected is called the specificity [SEVCO term STATO:0000134] or true negative rate. The Likelihood Ratio Negative (LR-) is calculated as (1 - Sensitivity ) / Specificity.\n\nThe Likelihood Ratio Negative may also be calculated as the posterior probability (1 - negative predictive value) divided by the prior probability (prevalence)."}, {"code": "editors", "valueString": "Harold Lehmann, Brian S. Alper, Joanne Dehnbostel, Muhammad Afzal"}, {"code": "approval", "valueString": "2022-08-10 vote 5-0 by Robin Ann Yurk, Mario Tristan, Harold Lehmann, Eric Harvey, Paola Rosati"}]}, {"code": "TBD:0000029", "display": "positive clinical utility index", "property": [{"code": "statistical-purpose", "valueString": "Measure of Association"}, {"code": "external-definitions", "valueString": "Mitchell AJ 2011 https://www.psycho-oncology.info/686.pdf https://link.springer.com/article/10.1007/s10654-011-9561-x\npositive clinical utility index = sensitivity x PPV\n\n\nAsberg 2019 A new index of clinical utility for diagnostic tests at https://www.tandfonline.com/doi/full/10.1080/00365513.2019.1677938 \n\nWe propose a new clinical utility index (CUI), which is the expected gain in utility (EGU) of the test divided by the EGU of an ideal test, both adjusted for EGU of the optimal clinical action without testing. The index expresses the relative benefit of using the test compared to using an optimal test when making a clinical decision. \nExpected gain in utility (EGU) of a clinical option, at a certain probability of disease (p), is the difference between its expected utility and the expected utility of another option, for instance doing nothing [4]. The EGU of the option W at probability p is EGUp(W) = p\u00d7BW \u2013 (1 - p)\u00d7CW ......CUI is then a complicated equation."}, {"code": "change-for-vote", "valueString": "2022-08-10 discussion: Considering 2 source definitions that are incompatible and limited usage overall, decision made to defer this term to future consideration for SEVCO."}], "definition": "DEFERRED"}, {"code": "TBD:0000030", "display": "negative clinical utility index", "property": [{"code": "statistical-purpose", "valueString": "Measure of Association"}, {"code": "external-definitions", "valueString": "see Positive Clinical Utility Index"}, {"code": "change-for-vote", "valueString": "2022-08-10 discussion: Considering 2 source definitions that are incompatible and limited usage overall, decision made to defer this term to future consideration for SEVCO."}], "definition": "DEFERRED"}, {"code": "STATO:0000415", "display": "diagnostic accuracy", "property": [{"code": "external-definitions", "valueString": "STATO: \"accuracy (Rand accuracy, Rand index) = in the context of binary classification, accuracy is defined as the proportion of true results (both true positives and true negatives) to the total number of cases examined (the sum of true positive, true negative, false positive and false negative).\n\nIt can be understood as a measure of the proximity of measurement results to the true value.\""}, {"code": "statistical-purpose", "valueString": "Measure of Association"}, {"code": "comment", "valueString": "Where results are reported as positive or negative, correct results are reported as true, and incorrect results are reported as false, the diagnostic accuracy is calculated as ( True Positives + True Negatives ) / ( True Positives + True Negatives + False Positives + False Negatives ).\nFor continuous values, Measurement Accuracy (SEVCO term: TBD:MeasAccu) would be used instead of Diagnostic Accuracy."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Muhammad Afzal, Joanne Dehnbostel"}, {"code": "approval", "valueString": "2022-08-24 vote 6-0 by Jesus Lopez-Alcalde, Harold Lehmann, Mario Tristan, Cau\u00ea Monaco, Eric Harvey, Janice Tufte"}], "definition": "A measure of association that is the ratio of the number of correct results to the total number tested.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "categorical accuracy"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "classification accuracy"}]}, {"code": "STATO:0000679", "display": "diagnostic odds ratio", "definition": "A measure of association that is the ratio of the odds of a positive test in those with disease relative to the odds of a positive test in those without disease.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "DOR"}], "property": [{"code": "statistical-purpose", "valueString": "Measure of Association"}, {"code": "external-definitions", "valueString": "AHRQ https://effectivehealthcare.ahrq.gov/products/test-performance-metrics/appendixes: \nThe diagnostic odds ratio (DOR) describes the odds of a positive test in those with disease relative to the odds of a positive test in those without disease.4 It can be computed in terms of sensitivity and specificity as well as in terms of positive and negative likelihood ratios (DOR = LR+/LR-). Thus this single measure includes information about both sensitivity and specificity and tends to be reasonably constant despite diagnostic threshold. However, it is impossible to use diagnostic odds ratios to weigh sensitivity and specificity separately, and to distinguish between tests with high sensitivity and low specificity and tests with low sensitivity and high specificity.\n\nAnother disadvantage is that it is difficult for clinicians to understand and apply, limiting its clinical value. This is partly because they are not often exposed to diagnostic odds ratios. A diagnostic odds ratio is similar to an odds ratio that measures strength of association in an observational study or effect size in a trial. However, contrary to the typical effect size magnitudes of such odds ratios (often between 0.5 and 2), diagnostic odds ratios can attain much larger values (often greater than 100)."}, {"code": "comment", "valueString": "The Diagnostic Odds Ratio may be calculated as the Likelihood Ratio Positive divided by the Likelihood Ratio Negative. The Diagnostic Odds Ratio is an overall measure of the discriminatory power of a test and does not distinguish between the power to detect (rule in) or exclude (rule out)."}, {"code": "editors", "valueString": "Harold Lehmann, Brian S. Alper, Joanne Dehnbostel, Kenneth Wilkins"}, {"code": "approval", "valueString": "2022-08-31 vote 6-0 by Janice Tufte, nisha mathew, Muhammad Afza, Harold Lehmann, Philippe Rocca-Serra, Eric Harvey"}]}, {"code": "STATO:0000524", "display": "phi coefficient", "definition": "A measure of association, ranging from -1 to 1, that measures the strength and direction of the linear relationship between two binary variables.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "mean square contingency coefficient"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "Yule phi"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "Matthews correlation coefficient"}], "property": [{"code": "external-definitions", "valueString": "STATO: Matthews correlation coefficient (MCC) = Matthews Correlation Coefficient (or MCC) is a correlation coefficient which is a measure of the quality of binary (two-class) classifications, introduced by biochemist Brian W. Matthews in 1975."}, {"code": "statistical-purpose", "valueString": "Measure of Correlation"}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Muhammad Afzal"}, {"code": "comment", "valueString": "For a 2\u00d72 contingency table \n\n<table align='center'>\n   <thead>\n      <tr>\n         <th></th>\n         <th>Variable 1 Value 1</th>\n         <th>Variable 1 Value 2</th>\n      </tr>\n   </thead>\n   <tbody>\n      <tr>\n         <td>Variable 2 Value 1</td>\n         <td align='center'>A</td>\n         <td align='center'>B</td>\n      </tr>\n      <tr>\n         <td>Variable 2 Value 2</td>\n         <td align='center'>C</td>\n         <td align='center'>D</td>\n      </tr>\n   </tbody>\n</table>\n\nwhere A, B, C, and D represent the observation frequencies (the cell count), the formula for the phi coefficient ($\\Phi$) is:\n\n$$\\Phi = \\frac{AD - BC}{\\sqrt{(A+B)(C+D)(A+C)(B+D)}}$$"}, {"code": "approval", "valueString": "2023-01-25 vote 6-0 by Mario Tristan, Jesus Lopez-Alcalde, Joanne Dehnbostel,  Harold Lehmann, Yuan Gao, Eric Harvey"}]}]}, {"code": "STATO:0000623", "display": "measure of agreement", "definition": "A measure of association of two variables representing measurements of the same attribute of an entity.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel"}, {"code": "comment", "valueString": "The term 'Measure of Agreement' is primarily used as a class for types of measure of agreement listed in the hierarchy but may be used as the code for a measure of agreement that is not listed."}, {"code": "approval", "valueString": "2022-12-21 vote 5-0 by Mario Tristan, Philippe Rocca-Serra, Eric Harvey, Janice Tuft, Harold Lehmann"}], "concept": [{"code": "STATO:0000682", "display": "kappa", "definition": "A measure of agreement among categorical assessments, corrected for chance agreement.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "kappa statistic"}], "property": [{"code": "statistical-purpose", "valueString": "Measure of Agreement"}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Kenneth Wilkins, Muhammad Afzal"}, {"code": "external-definitions", "valueString": "OBCS kappa statistic = a generic term for several similar measures of agreement used with categorical data; typically used in assessing the degree to which two or more raters, examining the same data, agree on assigning data to categories"}, {"code": "comment", "valueString": "In the literature, the same eponymic term (e.g., 'Cohen's kappa') is used with different formulas. In SEVCO, we define each term with a single formula, and recommend annotators to choose the SEVCO term based on the formula.\n\nThis is a widely used term to measure inter-rater reliability. Refer to measures of association to see other terms: for example, intra-class correlation coefficient (ICC)."}, {"code": "approval", "valueString": "2022-09-14 (After deleting one \"yes\" vote at the request of the voter) vote 6-0 by Nisha Mathew, Philippe Rocca-Serra, Harold Lehmann, Eric Harvey, Jesus Lopez-Alcalde, Khalid Shahin"}, {"code": "expert-comments", "valueString": "2022-09-14 Comment  \"I recommend adding ....is a measure of interrater reliability or is this an Interrater reliability testing an alternate term.\""}], "concept": [{"code": "STATO:0000683", "display": "simple chance-corrected agreement coefficient", "definition": "A Kappa statistic in which the expected agreement by chance is based on an assumption that all possible categories for assignment are equally likely.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "Bennett\u2019s Kappa"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "Brennan-Prediger agreement coefficient"}], "property": [{"code": "statistical-purpose", "valueString": "Measure of Agreement"}, {"code": "comment", "valueString": "A Kappa statistic is a measure of agreement among categorical assessments, corrected for chance agreement.\n\nIn the simple chance-corrected agreement coefficient, the expected chance agreement is modeled as the inverse of the number of categories (1/q) where q is the number of possible categories for assignment.\n\nThe simple chance-corrected agreement coefficient is calculated as ( p[a] - 1/q ) / ( 1 - 1/q ) where p[a] is the observed percent agreement and q is the number of possible categories for assignment."}, {"code": "external-definitions", "valueString": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5965565\nGwet KL. Testing the Difference of Correlated Agreement Coefficients for Statistical Significance. Educ Psychol Meas. 2016 Aug;76(4):609-637. doi: 10.1177/0013164415596420. Epub 2015 Jul 28. PMID: 29795880; PMCID: PMC5965565.\n\nBrennan and Prediger (1981) proposed a simple chance-corrected agreement coefficient, which generalizes to multiple raters and multiple categories, the G-index previously proposed by Holley and Guilford (1964) for two raters and two categories. What is known as the Holley\u2013Guilford G-index was previously proposed independently by various authors under different names. Among them are Guttman (1945), Bennett, Alpert, and Goldstein (1954), and Maxwell (1977). For an interrater reliability experiment involving r raters who classify n subjects into one of q possible categories, the Brennan-Prediger coefficient is given by\n\n?[BP] = ( p[a] - 1/q ) / ( 1 - 1/q ),\nwhere the percent agreement p[a] is defined by Equation (3 -- see https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5965565/#disp-formula3-0013164415596420), and the percent chance agreement is a constant representing the inverse of the number of categories."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Muhammad Afzal, Kenneth Wilkins"}, {"code": "approval", "valueString": "2022-09-14 vote 6-0 by Nisha Mathew, Philippe Rocca-Serra, Harold Lehmann, Eric Harvey, Jesus Lopez-Alcalde, Khalid Shahin"}]}, {"code": "STATO:0000630", "display": "Cohen\u2019s kappa", "definition": "A Kappa statistic in which the expected agreement by chance is based on an assumption that the likelihood of each category for assignment is based on the proportion observed, and the number of raters is 2.", "property": [{"code": "statistical-purpose", "valueString": "Measure of Agreement"}, {"code": "external-definitions", "valueString": "OBCS Cohen's kappa measurement (inter-rater agreement, inter-annotator agreement; inter-rater agreement, inter-annotator agreement) = a statistical measure of agreement for categorical data; a measure of inter-rater agreement or inter-annotator agreement"}, {"code": "comment", "valueString": "A Kappa statistic is a measure of agreement among categorical assessments, corrected for chance agreement.\n\nIn Cohen's kappa, the expected chance agreement is modeled as the summation of the differences, between the square of the expected probability of the category and the quotient of its variance divided by 2 (the number of raters), for each category.\n\nCohen's kappa is calculated as ( p[a] - p[e] ) / ( 1 - p[e] ) where p[a] is the observed percent agreement and p[e] is the expected chance agreement."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Muhammad Afzal, Kenneth Wilkins"}, {"code": "approval", "valueString": "2022-09-14 vote 6-0 by Nisha Mathew, Philippe Rocca-Serra, Harold Lehmann, Eric Harvey, Jesus Lopez-Alcalde, Khalid Shahin"}]}, {"code": "STATO:0000631", "display": "modified Cohen\u2019s kappa for more than 2 raters", "definition": "A Kappa statistic in which the expected agreement by chance is based on an assumption that the likelihood of each category for assignment is based on the proportion observed, and the number of raters is more than 2.", "property": [{"code": "statistical-purpose", "valueString": "Measure of Agreement"}, {"code": "external-definitions", "valueString": "OBCS Cohen's kappa measurement (inter-rater agreement, inter-annotator agreement; inter-rater agreement, inter-annotator agreement) = a statistical measure of agreement for categorical data; a measure of inter-rater agreement or inter-annotator agreement"}, {"code": "comment", "valueString": "A Kappa statistic is a measure of agreement among categorical assessments, corrected for chance agreement.\n\nIn the modified Cohen's kappa for more than 2 raters, the expected chance agreement is modeled as the summation of the differences, between the square of the expected probability of the category and the quotient of its variance divided by the number of raters, for each category.\n\nThe modified Cohen's kappa for more than 2 raters is calculated as ( p[a] - p[e] ) / ( 1 - p[e] ) where p[a] is the observed percent agreement and p[e] is the expected chance agreement."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Muhammad Afzal, Kenneth Wilkins"}, {"code": "approval", "valueString": "2022-09-14 vote 5-0 by Nisha Mathew, Philippe Rocca-Serra, Harold Lehmann, Eric Harvey, Jesus Lopez-Alcalde"}]}, {"code": "STATO:0000629", "display": "Scott\u2019s pi", "definition": "A Kappa statistic where the expected agreement between two raters is expressed in terms of the square of arithmetic means of marginal proportions of each assessment category.", "property": [{"code": "statistical-purpose", "valueString": "Measure of Agreement"}, {"code": "comment", "valueString": "Scott's pi is a kappa statistic for two raters that assumes the likelihood of each category for assignment is based on the same distribution of rater responses, leading to the use of squared arithmetic means of the marginal proportion of each assessment category as its estimate of \"chance agreement.\"\nPr(expected) is calculated using squared \"joint proportions\" which are squared arithmetic means of the marginal proportions of each assessment category, in contrast to Cohen's Kappa which uses squared geometric means.\n\nScott's pi = ( p[a] - p[e] ) / ( 1 - p[e] ) where p[a] is the observed percent agreement and p[e] is the expected chance agreement expressed as the squared joint proportions of the marginal sums."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Muhammad Afzal, Kenneth Wilkins"}, {"code": "expert-comments", "valueString": "2022-09-21 comment: I think there should be a formula included in the comment for application as with all the other Kappa terms\n2022-09-28 adjustment: Steering Group changed the first sentence of Comment for application to better represent the assumption."}, {"code": "approval", "valueString": "2022-10-19 vote 6-0 by Joanne Dehnbostel, Muhammad Afzal, Jesus Lopez-Alcalde, Mario Tristan, Eric Harvey, Harold Lehmann"}]}]}, {"code": "STATO:0000632", "display": "misclassification rate", "definition": "A ratio of the number of incorrect results to the total number tested.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "classification error"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "misclassification error"}], "property": [{"code": "comment", "valueString": "Where results are reported as positive or negative, incorrect results are reported as false, and correct results are reported as true, the misclassification rate is calculated as ( False Positives + False Negatives ) / ( True Positives + True Negatives + False Positives + False Negatives )."}, {"code": "editors", "valueString": "Brian S. Alper, Muhammad Afzal, Joanne Dehnbostel"}, {"code": "approval", "valueString": "2022-10-19 vote 5-0 by Joanne Dehnbostel, Muhammad Afzal, Janice Tufte, Mario Tristan, Eric Harvey"}]}, {"code": "STATO:0000628", "display": "F1-score", "definition": "A ratio representing the harmonic mean of recall and precision.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "F1 score"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "F1 measure"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "F measure"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "F score"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "F-score"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "F-measure"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "F1-measure"}], "property": [{"code": "statistical-purpose", "valueString": "Measure of Agreement"}, {"code": "external-definitions", "valueString": "OCRe F measure [not used due to inaccuracy in the definition]"}, {"code": "comment", "valueString": "The F1-score is used as a measure of quality for classification algorithms and information retrieval strategies, where 1 represents the best precision and recall and 0 represents the worst precision and recall.\n\nA harmonic mean of a set of quantities is the reciprocal of the arithmetic mean of the reciprocals of each quantity.  The F score is thus calculated as 1 / (the arithmetic mean of the reciprocals), or:\n\nF = 1 / ( ( (1/recall) + (1/precision) ) / 2 )\n\nF = 2*( (precision*recall) / (precision+recall) )\n\nRecall is sensitivity STATO:0000233\nPrecision (PPV) is SEVCO TBD:0000022\n\n[[F-beta will be defined elsewhere in the code system.]]"}, {"code": "editors", "valueString": "Harold Lehmann, Kenneth Wilkins, Muhammad Afzal, Joanne Dehnbostel, Brian S. Alper"}, {"code": "approval", "valueString": "2022-10-19 vote 6-0 by Joanne Dehnbostel, Muhammad Afzal, Jesus Lopez-Alcalde, Mario Tristan, Eric Harvey, Harold Lehmann"}]}]}, {"code": "STATO:0000611", "display": "measure of correlation", "definition": "A measure of association between ordinal or continuous variables.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "correlation"}], "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Muhammad Afzal, Yuan Gao, Kenneth Wilkins, Harold Lehmann"}, {"code": "negative-vote", "valueString": "2022-10-26 vote 6-1 by Yuan Gao, Philippe Rocca-Serra, Eric Harvey, Paola Rosati, Harold Lehmann, Joanne Dehnbostel, Janice Tufte"}, {"code": "expert-comments", "valueString": "2022-10-26 comments: there are measures of correlation which characterise non-linear relation between 2 variables . so I was wondering if there was a need to specify \"measure of linear correlation\" , where a subclass would be 'correlation coefficient). The type 'measure of correlation' becoming a parent class for the 'measure of non-linear correlation'\nShould we say, \"A value of 0 means no linear association, a value of +1 mean perfect positive linear (a positive slope) association, and a value of -1 means perfect negative association (a negative slope).\""}, {"code": "comment", "valueString": "A value of 0 means no association. A positive value means a positive association (as one variable increases, the other variable increases). A negative value means a negative association (as one variable increases, the other variable decreases). \nFor correlation coefficients, the possible values range from +1 (perfect positive association) to -1 (perfect negative association)."}, {"code": "approval", "valueString": "2022-11-16 vote 5-0 by Brian S. Alper, Philippe Rocca-Serra, Harold Lehman, Jesus Lopez-Alcalde, Eric Harvey"}], "concept": [{"code": "STATO:0000301", "display": "covariance", "property": [{"code": "external-definitions", "valueString": "STATO: \"covariance = The covariance is a measurement data item about the strength of correlation between a set (2 or more) of random variables.\nThe covariance is obtained by forming:\ncov(X,Y)=E([X-E(X)][Y-E(Y)] where E(X), E(Y) is the expected value (mean) of variable X and Y respectively.\n\ncovariance is symmetric so cov(X,Y)=cov(Y,X).\n\nThe covariance is usefull when looking at the variance of the sum of the 2 random variables since:\nvar(X+Y) = var(X) +var(Y) +2cov(X,Y)\n\nThe covariance cov(x,y) is used to obtain the coefficient of correlation cor(x,y) by normalizing (dividing) cov(x,y) but the product of the standard deviations of x and y.\""}, {"code": "statistical-purpose", "valueString": "Measure of Correlation"}, {"code": "comment", "valueString": "A measure of correlation is a measure of association between ordinal or continuous variables.\n\nCovariance is used in the calculation of other measures of correlation. Covariance can only be calculated for interval or continuous variables.\n\nBecause the covariance is not normalized by the variances of the variables, the magnitude of the covariance is not informative without consideration of the magnitude of the respective variances. Covariance is informative regarding whether both variables vary in the same direction (positive covariance) or in the opposite direction (negative covariance).\n\nCovariance for a sample is calculated as the mean of the products of deviations from the sample mean for the variables.\nCov(X,Y) = S (($x_i \u2013 \\overline{x}$) ($y_i \u2013 \\overline{y}$)) / (n-1) where $x_i$ is one the observed values of X, $\\overline{x}$ is the sample mean of X,  $y_i$ is one the observed values of Y, and $\\overline{y}$ is the sample mean of Y.\n\nCovariance as the population-level quantity is given by the expected value of the product of deviations from the mean for the variables.\nCov(X, Y) = E [ (X - \u00b5) (Y - ?) ] where \u00b5 = E(X) and ? = E(Y)\n\nCovariance is a continuous value with a range of negative infinity to positive infinity."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Kenneth Wilkins, Yuan Gao, Khalid Shahin, Muhammad Afzal"}, {"code": "approval", "valueString": "2022-11-23 vote 5-0 by Mario Tristan, Yuan Gao, Jesus Lopez-Alcalde, Eric Harvey, Harold Lehmann"}], "definition": "A measure of correlation that is not normalized by the variances of the variables."}, {"code": "STATO:0000280", "display": "Pearson correlation coefficient", "property": [{"code": "external-definitions", "valueString": "STATO: \"Pearson's correlation coefficient (Pearson product-moment correlation coefficient; Pearson's r; r statistics) = The Pearson's correlation coefficient is a correlation coefficient which evaluates two continuous variables for association strength in a data sample. It assumes that both variables are normally distributed and linearity exists. \nThe coefficient is calculated by dividing their covariance with the product of their individual standard deviations. It is a normalized measurement of how the two are linearly related.\""}, {"code": "statistical-purpose", "valueString": "Measure of Correlation"}, {"code": "comment", "valueString": "A measure of correlation is a measure of association between ordinal or continuous variables. Pearson correlation coefficient is designed to be used between continuous variables.\nPearson correlation coefficient for a sample ($r$) is calculated as $r = \\dfrac{\\widehat{cov}(x,y)}{s_x*s_y}$ where $ \\widehat{cov}(x,y)$ is the estimated covariance, and $s_x$ and $s_y$ are the sample standard deviations.\nPearson correlation coefficient for a population ($\\rho$) is defined as $\\rho= \\dfrac{cov(X,Y)}{\\sigma_X*\\sigma_Y}$ where cov(X,Y) is covariance of X and Y and $\\sigma_X$ and $\\sigma_Y$ are the population standard deviations.\n\nAssumptions for computing Pearson's correlation coefficient include a linear relationship between 2 continuous variables and each of the variables approximates a normal distribution.\n\nCovariance is [defined in SEVCO](https://fevir.net/resources/CodeSystem/27270#STATO:0000301)."}, {"code": "editors", "valueString": "Kenneth Wilkins, Muhammad Afzal, Yuan Gao, Khalid Shahin, Joanne Dehnbostel, Brian S. Alper, Harold Lehmann"}, {"code": "approval", "valueString": "2022-12-07 vote 5-0 by Muhammad Afzal, Mario Tristan, Eric Harvey, Yuan Gao, Mahnoor Ahmed"}], "definition": "A measure of correlation, ranging from -1 to 1, that measures the strength and direction of the linear relationship between values of two continuous variables.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "product moment"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "product moment correlation"}]}, {"code": "STATO:0000201", "display": "Spearman rank-order correlation coefficient", "property": [{"code": "external-definitions", "valueString": "STATO: \"Spearman's rank correlation coefficient (Spearman's rho) = Spearman's rank correlation coefficient is a correlation coefficient which is a nonparametric measure of statistical dependence between two ranked variables. It assesses how well the relationship between two variables can be described using a monotonic function. If there are no repeated data values, a perfect Spearman correlation of +1 or -1 occurs when each of the variables is a perfect monotone function of the other.\nSpearman's coefficient may be used when the conditions for computing Pearson's correlation are not met (e.g linearity, normality of the 2 continuous variables) but may require a ranking transformation of the variables\""}, {"code": "statistical-purpose", "valueString": "Measure of Correlation"}, {"code": "editors", "valueString": "Kenneth Wilkins, Muhammad Afzal, Yuan Gao, Joanne Dehnbostel, Brian S. Alper, Harold Lehmann, Noor Ahmed"}, {"code": "comment", "valueString": "A measure of correlation is a measure of association between ordinal or continuous variables. Spearman rank-order correlation coefficient is designed to be used between ordinal and/or continuous variables.\n\nThe Spearman rank-order correlation coefficient can identify monotonic (i.e. consistently non-increasing or consistently non-decreasing) relationships, whether the relationships are linear or non-linear.\n\nThe Spearman rank-order correlation coefficient between two variables is equal to the [Pearson correlation coefficient](https://fevir.net/resources/CodeSystem/27270#STATO:0000280) between the rank values of those two variables.\n\nThe Spearman rank-order correlation coefficient is the nonparametric counterpart to the Pearson correlation coefficient and may be used when the assumptions for computing Pearson's correlation coefficient (include a linear relationship between 2 continuous variables and each of the variables approximates a normal distribution) are not met. The Spearman rank-order correlation coefficient is appropriate when either variable has outliers, is ordinal, or is not normally distributed; when the variances of the two variables are unequal; or when the apparent relationship between the variables is non-linear. The assumptions for computing Spearman rank-order correlation coefficient include a monotonic relationship between 2 continuous or ordinal variables."}, {"code": "expert-comments", "valueString": "2022-12-07 comment: The fundamental difference between the two correlation coefficients is that the Pearson coefficient works with a linear relationship between the two variables whereas the Spearman Coefficient works with monotonic relationships as well."}, {"code": "approval", "valueString": "2022-12-14 vote 5-0 by Jesus Lopez-Alcalde, Yuan Gao, Mario Tristan, Eric Harvey, Harold Lehmann"}], "definition": "A measure of correlation, ranging from -1 to 1, that measures the strength and direction of the relationship between ranks by value of two ordinal or continuous variables, and is calculated as the Pearson correlation coefficient between the rank values.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "Spearman's rank correlation coefficient"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "Spearman's rho"}]}, {"code": "STATO:0000240", "display": "Kendall correlation coefficient", "property": [{"code": "external-definitions", "valueString": "STATO: Kendall's correlation coefficient (Kendall's tau (t) coefficient; Kendall rank correlation coefficient) = Kendall's correlation coefficient is a correlation coefficient between 2 ordinal variables (natively or following a ranking procedure) and may be used when the conditions for computing Pearson's correlation are not met (e.g linearity, normality of the 2 continuous variables)"}, {"code": "statistical-purpose", "valueString": "Measure of Correlation"}, {"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Harold Lehmann, Joanne Dehnbostel"}, {"code": "comment", "valueString": "A measure of correlation is a measure of association between ordinal or continuous variables. Kendall's correlation coefficient is designed to be used between ordinal variables (or continuous variables converted to ordinal variables).\n\nThe Kendall's correlation coefficient can identify monotonic (i.e. consistently non-increasing or consistently non-decreasing) relationships, whether the relationships are linear or non-linear.\n\nThe Kendall's correlation coefficient between two variables is calculated by determining the concordance or discordance of each pair of ranked values (whether or not two raters are concordant in one value being ranked equal or higher to the other value), and then dividing the difference between the number of concordant values ($n_c$) and the number of discordant values ($n_d$) by the number of pairs of ranked values ($\\frac{1}{2}n(n-1)$).\n\n$$\\tau =  \\dfrac{n_c - n_d}{\\frac{1}{2}n(n-1)}$$\n\n\nThe Kendall's correlation coefficient is a nonparametric statistic and may be used when the assumptions for computing Pearson's correlation coefficient (include a linear relationship between 2 continuous variables and each of the variables approximates a normal distribution) are not met. The Kendall's correlation coefficient is appropriate when either variable has outliers, is ordinal, or is not normally distributed; when the variances of the two variables are unequal; or when the apparent relationship between the variables is non-linear. The assumptions for computing Kendall's correlation coefficient include a monotonic relationship between 2 ordinal variables."}, {"code": "negative-vote", "valueString": "2022-12-21 vote 5-0 by Joanne Dehnbostel, Mario Trista, Philippe Rocca-Serra, Eric Harvey, Harold Lehmann\n2023-01-04 definition change by Steering Committee"}, {"code": "approval", "valueString": "2023-01-25 vote 6-0 by Mario Tristan, Jesus Lopez-Alcalde, Joanne Dehnbostel,  Harold Lehmann, Yuan Gao, Eric Harvey"}], "definition": "A measure of correlation, ranging from -1 to 1, that measures the strength and direction of the relationship between ranks by value of two ordinal or continuous variables, and is calculated based on the difference in the number of concordant and discordant pairs of rankings divided by the number of all possible pairs of rankings.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "Kendall's tau coefficient"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "Kendall's tau"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "Kendall's t"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "Kendall rank correlation coefficient"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "Kendall's tau-b"}]}, {"code": "STATO:0000612", "display": "Goodman and Kruskal\u2019s gamma", "definition": "A measure of correlation, ranging from -1 to 1, that measures the strength and direction of the relationship between ranks by value of two ordinal or continuous variables, and is calculated based on the difference in the number of concordant and discordant pairs of rankings divided by the total number of pairs of rankings, where ties are not counted among the pairs of rankings.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "Goodman-Kruskal gamma"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "gamma statistic"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "gamma coefficient"}], "property": [{"code": "statistical-purpose", "valueString": "Measure of Correlation"}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel"}, {"code": "external-definitions", "valueString": "https://stats.stackexchange.com/questions/18112/how-do-the-Goodman-Kruskal-gamma-and-the-Kendall-tau-or-Spearman-rho-correlation"}, {"code": "approval", "valueString": "2023-01-25 vote 5-0 by Mario Tristan, Jesus Lopez-Alcalde, Joanne Dehnbostel,  Harold Lehmann, Eric Harvey"}]}]}, {"code": "STATO:0000565", "display": "regression coefficient", "property": [{"code": "external-definitions", "valueString": "STATO: regression coefficient = a regression coefficient is a data item generated by a type of data transformation called a regression, which aims to model a response variable by expression the predictor variables as part of a function where variable terms are modified by a number. A regression coefficient is one such number."}, {"code": "statistical-purpose", "valueString": "Measure of Association"}, {"code": "comment", "valueString": "A value of zero means no association. The sign (positive or negative) reflects the direction of association."}, {"code": "editors", "valueString": "Harold Lehmann, Brian S. Alper, Kenneth Wilkins, Muhammad Afzal"}, {"code": "approval", "valueString": "2023-02-07 vote 5-0 by Cau\u00ea Monaco, Harold Lehmann, Mario Tristan, Jesus Lopez-Alcalde, Eric Harvey"}], "definition": "A measure of association that is used as the coefficient of an independent variable in a regression model, of the dependent variable, which is linear in its parameters."}, {"code": "STATO:0000685", "display": "measure of calibration", "definition": "A measure of association between a variable representing known or true values and a variable representing measured or predicted values.", "property": [{"code": "comment", "valueString": "Calibration is often used for measurement devices. The known or true values may be called the reference standard.\nCalibration is also used for predictive models and other contexts comparing computed or expected probabilities with empirical frequencies.\nA measure of calibration indicates the degree to which the computed values are underestimated or overestimated."}, {"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Harold Lehmann, Kenneth Wilkins"}, {"code": "approval", "valueString": "2023-12-18 vote 6-0 by Janice Tufte, Eric Harvey, Caue Monaco, Philippe Rocca-Serra, Harold Lehmann, Jesus Lopez-Alcalde"}], "concept": [{"code": "STATO:0000686", "display": "mean calibration", "definition": "A measure of calibration that is the average of a function of the difference between the expected values and the observed values.", "property": [{"code": "statistical-purpose", "valueString": "Measure of Calibration"}, {"code": "editors", "valueString": "Harold Lehmann, Kenneth Wilkins, Muhammad Afzal, Brian S. Alper"}, {"code": "comment", "valueString": "For predictive modeling of non-continuous variables, the mean calibration is a measure of calibration that is the average of a function of the difference between the expected probabilities and the observed frequencies.\nThe expected values may be computed (as in predictive models) or may be derived from reference data (as typical for a measurement device).\nWhen the function is the square of the difference and the variables are binary (0 or 1), the measure is called the Brier score."}, {"code": "approval", "valueString": "2024-01-22 vote 5-0 by Harold Lehmann, Homa Keshavarz, Eric Harvey, Janice Tufte, Cau\u00ea Monaco"}]}, {"code": "STATO:0000688", "display": "calibration intercept", "definition": "A measure of calibration that is the difference between the mean expected value and the mean observed value.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "calibration-in-the-large"}], "property": [{"code": "statistical-purpose", "valueString": "Measure of Calibration"}, {"code": "comment", "valueString": "For calibration of binary outcome variables (0 or 1), the calibration intercept is computed from a statistical model where the log odds of the predicted probabilities is a linear function of the empirical frequencies.\nFor calibration of count outcome variables (0, 1, 2, 3, ...), the calibration intercept may be computed from a statistical model where the log of the predicted mean counts is a linear function of the empirical frequencies determined by unique combinations of the covariates.\nThere are other types of outcome variables for which the calibration-in-the-large measure may be obtained.\nThe notion of calibration in the large is that the intercept is a gross assessment of whether the average prediction matches the average outcome, however, this interpretation is exquisitely sensitive to the choice of referent factors within the prediction model."}, {"code": "editors", "valueString": "Harold Lehmann, Ken Wilkins, Muhammad Afzal, Joanne Dehnbostel, Khalid Shahin"}, {"code": "negative-vote", "valueString": "2024-02-05 vote 4-0 by Xing Song, Eric Harvey, Harold Lehmann, Homa Keshavarz"}, {"code": "expert-comments", "valueString": "2024-02-05 comment: The definition looks good to me. Only comment is that the first comment about \"calibration of binary variable\" made it is sounds like this concept is only for binary outcomes, while I think calibration is a generic measure for all generalized linear models."}, {"code": "approval", "valueString": "2024-02-12 vote 5-0 by Lenny Vasanthan, Xing Song, Eric Harvey, Harold Lehmann, Homa Keshavarz"}]}, {"code": "STATO:0000687", "display": "calibration slope", "definition": "A measure of calibration that is the rate of change in the appropriately transformed value per unit change of the correspondingly transformed predicted value.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "calibration-in-the-small"}], "property": [{"code": "statistical-purpose", "valueString": "Measure of Correlation"}, {"code": "comment", "valueString": "For calibration of binary outcome variables (0 or 1), the calibration slope is computed from a statistical model where the log odds of the predicted probabilities is a linear function of the empirical frequencies (logistical regression). The transformation is log odds (logit, the link function for a generalized linear model for the expected value of the outcome).\n \nFor calibration of count outcome variables (0, 1, 2, 3, ...), the calibration slope may be computed from a statistical model where the log of the predicted mean counts is a linear function of the empirical frequencies determined by unique combinations of the covariates. The transformation is log, the link function, of the counts.\n \nThere are other types of outcome variables for which the calibration slope may be obtained.\n \nSlopes further away from 1.0 indicate, at upper and lower values, over- or under-confidence in the prediction."}, {"code": "editors", "valueString": "Harold Lehmann, Ken Wilkins, Muhammad Afzal, Joanne Dehnbostel, Khalid Shahin"}, {"code": "approval", "valueString": "2024-03-11 vote 6-0 by Eric Harvey, Xing Song, Lenny Vasanthan, Elma OMERAGIC, Homa Keshavarz, Harold Lehmann"}, {"code": "expert-comments", "valueString": "2024-02-12 comment: Again, the first comment about \"calibration of binary variable\" made it is sounds like this concept is only for binary outcomes. Logistic regression could be used as an example for this concept."}, {"code": "negative-vote", "valueString": "2024-02-12 vote 5-0 by Lenny Vasanthan, Xing Song, Eric Harvey, Harold Lehmann, Homa Keshavarz BUT THEN term definition changed in response to the comment"}]}]}]}, {"code": "STATO:0000028", "concept": [{"code": "STATO:0000035", "display": "range", "property": [{"code": "external-definitions", "valueString": "STATO: range = the range is a measure of variation which describes the difference between the lowest score and the highest score in a set of numbers (a data set)"}, {"code": "statistical-purpose", "valueString": "Measure of Dispersion"}, {"code": "comment", "valueString": "A measure of dispersion is a statistic that represents the variation or spread among data values in a dataset or data distribution.\nThe maximum observed value is a statistic that represents the largest non-null value in a collection of values that can be ordered by magnitude.\nThe minimum observed value is a statistic that represents the smallest non-null value in a collection of values that can be ordered by magnitude.\nA range (as a statistic) is represented as a single value (the difference between maximum and minimum observed values) while, in common language, the term range is often expressed with two values (from the minimum to maximum values, or from the lower limit to the higher limit)."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Muhammad Afzal"}, {"code": "approval", "valueString": "2023-02-20 vote 5-0 by Philippe Rocca-Serra, Janice Tufte, Harold Lehmann, Mario Tristan, Eric Harvey"}], "definition": "A measure of dispersion calculated as the difference between the maximum observed value and the minimum observed value."}, {"code": "STATO:00000164", "display": "interquartile range", "definition": "A measure of dispersion calculated as the difference between the 75th percentile and the 25th percentile.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "middle range"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "midspread"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "IQR"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "median IQR"}], "property": [{"code": "external-definitions", "valueString": "STATO: \"inter quartile range = The interquartile range is a data item which corresponds to the difference between the upper quartile (3rd quartile) and lower quartile (1st quartile).\nThe interquartile range contains the second quartile or median.\nThe interquartile range is a data item providing a measure of data dispersion\""}, {"code": "statistical-purpose", "valueString": "Measure of Dispersion"}, {"code": "comment", "valueString": "A measure of dispersion is a statistic that represents the variation or spread among data values in a dataset or data distribution.\n\nThe 75th percentile is the median of the portion of the dataset or distribution with values greater than the median value.\n\nThe 25th percentile is the median of the portion of the dataset or distribution with values lesser than the median value.\n\nAn interquartile range (as a statistic) is represented as a single value (the difference between 75th and 25th percentiles) while, in common language, the term interquartile  range is often expressed with two values (the 25th percentile and the 75th percentile)."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Muhammad Afzal"}, {"code": "approval", "valueString": "2023-02-20 vote 5-0 by Philippe Rocca-Serra, Janice Tufte, Harold Lehmann, Mario Tristan, Eric Harvey"}]}, {"code": "STATO:0000237", "display": "standard deviation", "definition": "A measure of dispersion that represents the average of the distances from the mean of the dataset to each data point in the dataset.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "SD"}], "property": [{"code": "external-definitions", "valueString": "STATO: standard deviation (s) = The standard deviation of a random variable, statistical population, data set, or probability distribution is a measure of variation which correspond to the average distance from the mean of the data set to any given point of that dataset. It also corresponds to the square root of its variance."}, {"code": "statistical-purpose", "valueString": "Measure of Dispersion"}, {"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Muhammad Afzal, Khalid Shahin, Kenneth Wilkins"}, {"code": "comment", "valueString": "Standard deviation for sample is a standard deviation in which the dataset is a sample. Standard deviation for population, when used as a statistical model parameter, is not a standard deviation as a type of statistic."}, {"code": "approval", "valueString": "2023-05-15 vote 6-0 by Muhammad Afzal, Brian S. Alper, Jesus Lopez-Alcalde, Janice Tufte, Eric Harvey, Harold Lehmann"}], "concept": [{"code": "STATO:0000684", "display": "standard deviation for sample", "definition": "A standard deviation that is the square root of the quotient of the summation across data points of the square of the distance from each data point to the sample mean, and the degrees of freedom (where the degrees of freedom is sample size minus one).", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "sample standard deviation"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "sample SD"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "S"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "s"}], "property": [{"code": "statistical-purpose", "valueString": "Measure of Dispersion"}, {"code": "comment", "valueString": "Standard deviation is defined as a measure of dispersion that represents the average of the distances from the mean of the dataset to each data point in the dataset.\nStandard deviation for sample is a standard deviation in which the dataset is a sample.\nThe formula for the standard deviation for sample ($s$) is:\n$$s = \\sqrt \\frac{\\sum\\\\{\\substack{n\\\\i=1}} (x_i - \\overline{x})^2}{n - 1}$$\nwhere $n$ is the sample size (the number of independent observations, indexed by $i$), $x$ is observed value, and $\\overline{x}$ is the sample mean.\nThe formula to calculate degrees of freedom depends on the model. For the degrees of freedom for a sample standard deviation, given the sample mean, it is n-1, because the nth observation is no longer independent, given the n-1 other observations and the sample mean."}, {"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Muhammad Afzal, Khalid Shahin, Kenneth Wilkins"}, {"code": "approval", "valueString": "2023-05-15 vote 5-0 by Muhammad Afzal, Brian S. Alper, Jesus Lopez-Alcalde, Eric Harvey, Harold Lehmann"}]}]}, {"code": "STATO:0000113", "display": "variance", "definition": "A measure of dispersion that represents the square of the standard deviation.", "property": [{"code": "external-definitions", "valueString": "STATO: variance (s2) = variance is a data item about a random variable or probability distribution. it is equivalent to the square of the standard deviation.  It is one of several descriptors of a probability distribution, describing how far the numbers lie from the mean (expected value).The variance is the second moment of a distribution."}, {"code": "statistical-purpose", "valueString": "Measure of Dispersion"}, {"code": "comment", "valueString": "Standard deviation is defined as a measure of dispersion that represents the average of the distances from the mean of the dataset to each data point in the dataset.\n\nVariance for sample is a variance in which the dataset is a sample. Variance for population, when used as a probability distribution parameter, is not a variance as a type of statistic."}, {"code": "editors", "valueString": "Brian S. Alper, Muhammad Afzal, Joanne Dehnbostel"}, {"code": "approval", "valueString": "2023-11-20 vote 5-0 by Brian S. Alper, Jesus Lopez-Alcalde, Harold Lehmann, Muhammad Afzal, Eric Harvey"}], "concept": [{"code": "STATO:0000643", "display": "variance for sample", "definition": "A variance that is the quotient of the summation across data points of the square of the distance from each data point to the sample mean, and the degrees of freedom (where the degrees of freedom is sample size minus one).", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "sample variance"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "s^2"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "V"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "Var"}], "property": [{"code": "statistical-purpose", "valueString": "Measure of Dispersion"}, {"code": "comment", "valueString": "Variance is defined as a measure of dispersion that represents the square of the standard deviation. Standard deviation is defined as a measure of dispersion that represents the average of the distances from the mean of the dataset to each data point in the dataset.\n\nVariance for sample is a variance in which the dataset is a sample.\nThe formula for the variance for sample ($s^2$) is:\n$$s^2 = \\frac{\\sum\\\\{\\substack{n\\\\i=1}} (x_i - \\overline{x})^2}{n - 1}$$\nwhere $n$ is the sample size (the number of independent observations, indexed by $i$), $x$ is observed value, and $\\overline{x}$ is the sample mean.\nThe formula to calculate degrees of freedom depends on the model. For the degrees of freedom for a sample variance, given the sample mean, it is n-1, because the nth observation is no longer independent, given the n-1 other observations and the sample mean."}, {"code": "editors", "valueString": "Kenneth Wilkins, Brian S. Alper, Muhammad Afzal"}, {"code": "approval", "valueString": "2023-11-20 vote 5-0 by Brian S. Alper, Jesus Lopez-Alcalde, Harold Lehmann, Muhammad Afzal, Eric Harvey"}]}]}, {"code": "STATO:0000624", "display": "Gini index", "definition": "A measure of dispersion that is half the relative mean absolute difference between all pairs of observed values.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "Gini coefficient"}], "property": [{"code": "statistical-purpose", "valueString": "Measure of Dispersion"}, {"code": "comment", "valueString": "The Gini index is typically used as a measure of inequality for income, wealth, or resource distribution."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Muhammad Afzal, Kenneth Wilkins"}, {"code": "negative-vote", "valueString": "2023-11-20 vote 5-0 by Brian S. Alper, Jesus Lopez-Alcalde, Harold Lehmann, Muhammad Afzal, Eric Harvey BUT comment of \"between all pairs of observed values?\" led to recognition of incorrect definition"}, {"code": "approval", "valueString": "2023-12-04 vote 5-0 by Yasser Sami Amer, Xing Song, Eric Harvey, Harold Lehmann, Brian S. Alper"}]}, {"code": "STATO:0000562", "display": "standard error", "definition": "A measure of dispersion applied to estimates across hypothetical repeated random samples.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "SE"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "standard error of the estimate"}], "property": [{"code": "external-definitions", "valueString": "STATO: It is a measure of how precise is an estimate of the statistical parameter is. Standard error is the estimated standard deviation of an estimate. It measures the uncertainty associated with the estimate. Compared with the standard deviations of the underlying distribution, which are usually unknown, standard errors can be calculated from observed data."}, {"code": "editors", "valueString": "Harold Lehmann, Kenneth Wilkins, Brian S. Alper, Xing Song, Joanne Dehnbostel, Muhammad Afzal"}, {"code": "comment", "valueString": "A standard error is used to quantify the uncertainty around a statistical estimate due to random sampling error."}, {"code": "approval", "valueString": "2023-12-18 vote 7-0 by Xing Song, Muhammad Afzal, Yasser Sami Amer, Eric Harvey, Harold Lehmann, Janice Tufte, Caue Monaco"}], "concept": [{"code": "STATO:0000037", "display": "standard error of the mean", "definition": "A measure of dispersion applied to means across hypothetical repeated random samples.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "SEM"}], "property": [{"code": "external-definitions", "valueString": "STATO: The standard error of the mean (SEM) is data item denoting the standard deviation of the sample-mean's estimate of a population mean. It is calculated by dividing the sample standard deviation (i.e., the sample-based estimate of the standard deviation of the population) by the square root of n , the size (number of observations) of the sample."}, {"code": "comment", "valueString": "A standard error is used to quantify the uncertainty around a statistical estimate due to random sampling error.\nThe standard error of the mean is calculated by dividing the sample standard deviation (STATO:0000237) by the square root of n, the size (number of observations) of the sample."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Muhammad Afzal, Xing Song, Kenneth Wilkins, Joanne Dehnbostel"}, {"code": "approval", "valueString": "2024-01-22 vote 5-0 by Homa Keshavarz, Eric Harvey, Cau\u00ea Monaco, Harold Lehmann, Yasser Sami Amer"}]}, {"code": "STATO:0000647", "display": "standard error of the proportion", "definition": "A measure of dispersion applied to proportions across hypothetical repeated random samples.", "property": [{"code": "comment", "valueString": "A standard error is used to quantify the uncertainty around a statistical estimate due to random sampling error.\n\nThe formula for the standard error of the sample proportion ($SE(\\hat{p})$) is:\n$$SE(\\hat{p}) = \\sqrt \\frac{\\hat{p}(1-\\hat{p})} {n}$$\nwhere $\\hat{p}$ is the sample proportion and $n$ is the size (number of observations) of the sample."}, {"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Xing Song, Harold Lehmann, Joanne Dehnbostel, Muhammad Afzal"}, {"code": "approval", "valueString": "2024-01-22 vote 5-0 by Homa Keshavarz, Eric Harvey, Brian S. Alper, Harold Lehmann, Yasser Sami Amer"}]}, {"code": "STATO:0000648", "display": "standard error of the difference between independent means", "definition": "A measure of dispersion applied to differences between means of independent groups across hypothetical repeated random samples.", "property": [{"code": "comment", "valueString": "A standard error is used to quantify the uncertainty around a statistical estimate due to random sampling error.\n\nIn cases where the samples are assumed to have unequal population variances for X, the formula for the standard error of the sample difference between means $(SE_{unequal}(\\overline{x}_{1} - \\overline{x}_{2}))$ is:\n$$SE_{unequal}(\\overline{x}_{1} - \\overline{x}_{2}) = \\sqrt{\\frac{s^2_1}{n_1}+\\frac{s^2_2}{n_2}}$$\nwhere $\\overline{x}_{1}$ and $\\overline{x}_{2}$ are the sample means, $s^2_1$ and $s^2_2$ are the sample standard deviations, and $n_1$ and $n_2$ are the sizes (number of observations) of the samples.\n\nIn cases where the samples are assumed to have the same (equal) population variance for X, the formula for the standard error of the sample difference between means $(SE_{equal}(\\overline{x}_{1} - \\overline{x}_{2}))$ is:\n$$SE_{equal}(\\overline{x}_{1} - \\overline{x}_{2}) = \\sqrt{\\frac{n_1 s^2_1 + n_2 s^2_2}{n_1 + n_2 - 2}}$$\nwhere $\\overline{x}_{1}$ and $\\overline{x}_{2}$ are the sample means, $s^2_1$ and $s^2_2$ are the sample standard deviations, and $n_1$ and $n_2$ are the sizes (number of observations) of the samples. In cases where the samples are assumed to have the same (equal) population variance for X, the standard error of the sample difference between means is also called the pooled standard deviation."}, {"code": "editors", "valueString": "Harold Lehmann, Kenneth Wilkins, Brian S. Alper"}, {"code": "approval", "valueString": "2024-02-12 vote 5-0 by Lenny Vasanthan, Xing Song, Eric Harvey, Harold Lehmann, Homa Keshavarz"}, {"code": "expert-comments", "valueString": "2024-02-12 comment: We may consider including the term of \"pooled standard deviation\" to describe the SE_equal(x1-x2), SE when assuming equal variance."}]}, {"code": "STATO:0000649", "display": "standard error of the difference between independent proportions", "definition": "A measure of dispersion applied to differences between proportions arising from independent groups across hypothetical repeated random samples.", "property": [{"code": "comment", "valueString": "A standard error is used to quantify the uncertainty around a statistical estimate due to random sampling error.\n\nThe formula for the standard error of the sample difference between proportions $(SE(\\hat{p}_1 - \\hat{p}_2))$ is:\n$$SE(\\hat{p}_1 - \\hat{p}_2) =  \\sqrt {\\frac{\\hat{p}_1(1-\\hat{p}_1)} {n_1} + \\frac{\\hat{p}_2(1-\\hat{p}_2)} {n_2}}$$\nwhere $\\hat{p}_1$ and $\\hat{p}_2$ are the sample proportions and $n_1$ and $n_2$ are the sizes (number of observations) of the samples."}, {"code": "editors", "valueString": "Harold Lehmann, Kenneth Wilkins, Brian S. Alper"}, {"code": "approval", "valueString": "2024-02-12 vote 5-0 by Lenny Vasanthan, Xing Song, Eric Harvey, Harold Lehmann, Homa Keshavarz"}, {"code": "expert-comments", "valueString": "2024-02-12 comment: In hypothesis testing for p1 = p2, I think the typical way of calculating standard error of proportion difference, is using the formula with pooled proportion, should we also include that in the comment?"}]}]}, {"code": "STATO:0000455", "display": "credible interval", "definition": "The range in which the value of the parameter of interest is likely to reside, typically within a posterior probability distribution.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "region of highest posterior density"}], "property": [{"code": "external-definitions", "valueString": "STATO: In Bayesian statistics context, a credible interval is an interval of a posterior distribution which is such that the density at any point inside the interval is greater than the density at any point outside and that the area under the curve for that interval is equal to a prespecified probability level. For any probability level there is generally only one such interval, which is also often known as the highest posterior density region. Unlike the usual confidence interval associated with frequentist inference, here the intervals specify the range within which parameters lie with a certain probability. The Bayesian counterparts of the confidence interval used in Frequentists Statistics.\n\nUMLS: \"Interval (C1272706)\nDefinition: The period of time or the distance separating two instances, events, or occurrences.\nSemantic Types: Temporal Concept\"\nOBCS: A quantitative confidence value that is used in Bayesian analysis to describe the range in which a posterior probability estimate is likely to reside.\n\nOECD: calculated interval-The interval containing possible values for a suppressed cell in a table, given the table structure and the values published.\n\nSCO: interval-An interval is a set of real numbers that includes all numbers between any two numbers in the set."}, {"code": "comment", "valueString": "The credible interval is used in Bayesian analysis and plays an analogous role to the confidence interval in frequentist statistics."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Kenneth Wilkins, Muhammad Afzal"}, {"code": "approval", "valueString": "2023-11-27 vote 5-0 by Xing Song, Yasser Sami Amer, Harold Lehmann, Jesus Lopez-Alcalde, Eric Harvey"}]}, {"code": "STATO:0000196", "display": "confidence interval", "definition": "The estimated range of values that encompasses the point estimate and quantifies the uncertainty about that estimate in terms of a prespecified level of coverage, expected to include the true value between upper and lower bounds, across hypothetically repeated random samples, with all assumptions regarding the sampling distribution across random samples having been fully met.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Ken Wilkins, Joanne Dehnbostel, Robin Ann Yurk, Janice Tufte"}, {"code": "external-definitions", "valueString": "STATO: A confidence interval is a data item which defines an range of values in which a measurement or trial falls corresponding to a given probability. also confidence interval calculation is a data transformation which determines a confidence interval for a given statistical parameter\n\nNCIt: A range of values for a parameter that may contain the parameter and the degree of confidence that it is in fact there. A measure of the precision of an estimated value. The interval represents the range of values, consistent with the data, that is believed to encompass the \"true\" value with high probability (usually 95%). The confidence interval is expressed in the same units as the estimate. Wider intervals indicate lower precision; narrow intervals, greater precision. [CONSORT Statement]\n\nOBCS: A quantitative confidence value that refers to an interval give values within which there is a high probability (95 percent by convention) that the true population value can be found. The calculation of a confidence interval considers the standard deviation of the data and the number of observations. Thus, a confidence interval narrows as the number of observations increases, or its variance (dispersion) decreases.\n\nCDISC Glossary: A measure of the precision of an estimated value. The interval represents the range of values, consistent with the data, that is believed to encompass the \"true\" value with high probability (usually 95%). The confidence interval is expressed in the same units as the estimate. Wider intervals indicate lower precision; narrow intervals, greater precision. [CONSORT Statement]\n\nNICE: \"Confidence interval\nA way of expressing how certain we are about the findings from a study, using statistics. It gives a range of results that is likely to include the 'true' value for the population. A wide confidence interval (CI) indicates a lack of certainty about the true effect of the test or treatment - often because a small group of patients has been studied. A narrow CI indicates a more precise estimate (for example, if a large number of patients have been studied).\n\nThe CI is usually stated as '95% CI', which means that the range of values has a 95 in a 100 chance of including the 'true' value. For example, a study may state that 'based on our sample findings, we are 95% certain that the 'true' population blood pressure is not higher than 150 and not lower than 110'. In such a case the 95% CI would be 110 to 150.\"\nOECD: A confidence interval is an interval which has a known and controlled probability (generally 95% or 99%) to contain the true value.\n\n\"Rothman textbook: confidence interval, which provides a range of values for the association, under the hypothesis that only random variation has created discrepancies between the true value of the association under study and the value observed in the data (Altman et al., 2000; see Chapters 13 through 16) Altman DG, Machin D, Bryant TN, Gardner MJ, eds. Statistics with confidence, 2nd ed. London: BMJ Books, 2000\n\""}, {"code": "comment", "valueString": "The prespecified level of coverage is commonly 0.95 or 95%. \n\nConfidence cannot be directly interpreted as a probability. This is in contrast to credibility for credible intervals. Confidence only conveys uncertainty indirectly by reflecting a long term relative frequency across hypothetically repeated sample estimates.\n\nWidth of a confidence interval can convey precision. This precision can be increased by increasing the sample size in most cases assuming variability in sample is only due to random sample-to-sample variation."}, {"code": "approval", "valueString": "2023-11-27 vote 5-0 by Xing Song, Yasser Sami Amer, Harold Lehmann, Jesus Lopez-Alcalde, Eric Harvey"}]}, {"code": "STATO:0000418", "display": "measure of heterogeneity", "definition": "A statistic that represents the variation or spread among values in the set of estimates across studies.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "measure of statistical heterogeneity"}], "property": [{"code": "external-definitions", "valueString": "STATO: a measure of heterogeneity in meta-analysis is a data item which aims to describe the variation in study outcomes between studies.\nCochrane Handbook 10.10.4 (August 2023)\nAnalysing data and undertaking meta-analyses \nVariability in the intervention effects being evaluated in the different studies is known as statistical heterogeneity, and is a consequence of clinical or methodological diversity, or both, among the studies. Statistical heterogeneity manifests itself in the observed intervention effects being more different from each other than one would expect due to random error (chance) alone. We will follow convention and refer to statistical heterogeneity simply as heterogeneity.\nhttps://training.cochrane.org/handbook/current/chapter-10#section-10-10-4\nThere are types of heterogeneity (or diversity) other than statistical heterogeneity which are important factors in whether or not evidence can be pooled. Clinical heterogeneity may refer to variations in the population, intervention, comparator, or outcome. Methodological heterogeneity may refer to variations in study design."}, {"code": "comment", "valueString": "There are several types of heterogeneity (or diversity) which are important factors which determine whether or not evidence should be pooled. Qualitative descriptors of explainable sources of heterogeneity include clinical heterogeneity and methodological heterogeneity. Clinical heterogeneity may refer to variations in the population, intervention, comparator, or outcome. Methodological heterogeneity may refer to variations in study design. Statistical heterogeneity, which is a quantitative measure of heterogeneity, whether explained or not, is described here.\n\nA measure of dispersion is defined as a statistic that represents the variation or spread among data values in a dataset or data distribution. In the context of a meta-analysis, a measure of heterogeneity is a measure of dispersion in which the dataset is the set of estimates across studies."}, {"code": "editors", "valueString": "Brian Alper, Harold Lehmann, Muhammad Afzal, Joanne Dehnbostel, Khalid Shahin, Kenneth Wilkins"}, {"code": "approval", "valueString": "2024-03-11 vote 5-0 by Eric Harvey, Xing Song, Lenny Vasanthan, Harold Lehmann, Homa Keshavarz\n2024-05-06 vote 5-0 by Harold Lehmann, Cau\u00ea Monaco, Homa Keshavarz, Eric Harvey, Lenny Vasanthan"}, {"code": "expert-comments", "valueString": "2024-04-29 Comment for application revised during the Statistic Terminology Working Group meeting"}], "concept": [{"code": "STATO:0000419", "display": "Cochran's Q", "definition": "A measure of heterogeneity, based on the chi-square statistic, for reporting an analytic finding regarding whether two or more multinomial distributions are equal, accounting for chance variability.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "chi square for heterogeneity"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "chi\u00b2 heterogeneity statistic"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "\ud835\udf12\u00b2 for homogeneity"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "\ud835\udf12\u00b2 test statistic for homogeneity"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "\ud835\udf12\u00b2 heterogeneity statistic"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "chi-square test statistic for heterogeneity"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "chi-square test statistic for homogeneity"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "\ud835\udf12\u00b2 for heterogeneity"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "\ud835\udf12\u00b2 test statistic for heterogeneity"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "chi square for homogeneity"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "Cochran Q"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "Cochran Q statistic"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "Cochran's Q statistic"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "Cochran Q test statistic"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "Cochran's Q test statistic"}], "property": [{"code": "comment", "valueString": "A measure of heterogeneity is defined as a statistic that represents the variation or spread among values in the set of estimates across studies.\nChi square for homogeneity assesses whether observed differences in results are compatible with chance alone.\nA chi square for homogeneity is a hypothesis testing measure that is testing the hypothesis of heterogeneity. A chi square for homogeneity is distinct from a chi square for independence (also called Pearson's chi square). A chi square test for homogeneity is based on testing whether the distributions across two or more populations are the same."}, {"code": "editors", "valueString": "Kenneth Wilkins, Brian S. Alper, Harold Lehmann, Muhammad Afzal, Joanne Dehnbostel"}, {"code": "external-definitions", "valueString": "STATO: Cochran's Q test is a statistical test used for unreplicated randomized block design experiments with a binary response variable and paired data. In the analysis of two-way randomized block designs where the response variable can take only two possible outcomes (coded as 0 and 1), Cochran's Q test is a non-parametric statistical test to verify whether k treatments have identical effects.\n\nfrom Cochrane Handbook https://training.cochrane.org/handbook/current/chapter-10\nMore formally, a statistical test for heterogeneity is available. This Chi2 (\u03c72, or chi-squared) test is included in the forest plots in Cochrane Reviews. It assesses whether observed differences in results are compatible with chance alone. A low P value (or a large Chi2 statistic relative to its degree of freedom) provides evidence of heterogeneity of intervention effects (variation in effect estimates beyond chance).\nCare must be taken in the interpretation of the Chi2 test, since it has low power in the (common) situation of a meta-analysis when studies have small sample size or are few in number. This means that while a statistically significant result may indicate a problem with heterogeneity, a non-significant result must not be taken as evidence of no heterogeneity. This is also why a P value of 0.10, rather than the conventional level of 0.05, is sometimes used to determine statistical significance. A further problem with the test, which seldom occurs in Cochrane Reviews, is that when there are many studies in a meta-analysis, the test has high power to detect a small amount of heterogeneity that may be clinically unimportant.\n\nHoaglin DC. Misunderstandings about Q and 'Cochran's Q test' in meta-analysis. Stat Med. 2016 Feb 20;35(4):485-95. doi: 10.1002/sim.6632. Epub 2015 Aug 24. PMID: 263037 and discussions"}, {"code": "negative-vote", "valueString": "2024-05-13 vote 3-1 by Eric Harvey, Harold Lehmann, Saphia Mokrane, Sheyu Li\n2024-05-06 vote 5-2 by Cau\u00ea Monaco, Homa Keshavarz, Eric Harvey, Lenny Vasanthan, Harold Lehmann, Sean Grant, Sheyu Li"}, {"code": "expert-comments", "valueString": "2024-05-13 comments\nCochran's Q may be the most accepted name. I would thus suggest changing the term. Actually, Cochran's Q is Chi square contributed and theoretically there can be other Chi square distributed in testing heterogeneity or homogeneity (although current Cochran's Q may be the only one). \n\n2024-04-29 comments:\n1) Add to \"comment for application\" the following from the Cochrane Handbook: \"Chi square for homogeneity assesses whether observed differences in results are compatible with chance alone.\"\n2) Is it chi square or Chi square? \n\nIs it Chi square for homogeneity or Chin square for heterogeneity? \n\nX2 test is a very common statistic. To avoid confusion, should we add some detailed statistical explanation regarding the difference between this x2 test and other x2 tests?"}, {"code": "approval", "valueString": "2024-05-28 vote 7-0 by Carlos Alva-Diaz, Homa Keshavarz, Sheyu Li, Harold Lehmann, Saphia Mokrane, Eric Harvey, Lenny Vasanthan"}]}, {"code": "STATO:0000420", "display": "I-squared", "definition": "A measure of heterogeneity that estimates the proportion of variability across studies that is in excess of the expected variability due to chance.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "I2"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "I\u00b2"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "I-square"}], "property": [{"code": "external-definitions", "valueString": "STATO: I-squared = The quantity called I2, describes the percentage of total variation across studies that is due to heterogeneity rather than chance. I2 can be readily calculated from basic results obtained from a typical meta-analysis as I2 = 100%\u00d7(Q - df)/Q, where Q is Cochran's heterogeneity statistic and df the degrees of freedom. Negative values of I2 are put equal to zero so that I2 lies between 0% and 100%. A value of 0% indicates no observed heterogeneity, and larger values show increasing heterogeneity. Unlike Cochran's Q, it does not inherently depend upon the number of studies considered. A confidence interval for I\u00b2 is constructed using either i) the iterative non-central chi-squared distribution method of Hedges and Piggott (2001); or ii) the test-based method of Higgins and Thompson (2002). The non-central chi-square method is currently the method of choice (Higgins, personal communication, 2006) \u2013 it is computed if the 'exact' option is selected. (STATO:0000420)\n\nHedges, L. V., & Pigott, T. D. (2001). The power of statistical tests in meta-analysis. Psychological methods, 6(3), 203\u2013217.https://pubmed.ncbi.nlm.nih.gov/11570228/\n\nHiggins, J. P., & Thompson, S. G. (2002). Quantifying heterogeneity in a meta-analysis. Statistics in medicine, 21(11), 1539\u20131558. https://doi.org/10.1002/sim.1186 https://pubmed.ncbi.nlm.nih.gov/12111919/"}, {"code": "comment", "valueString": "A measure of heterogeneity is defined as a statistic that represents the variation or spread among values in the set of estimates across studies. $I^2$ = 100%\u00d7(Q - df)/Q, where Q is Cochran's heterogeneity statistic and df is the degrees of freedom. $I^2$ is strictly non-negative and lies between 0 and 100%. (If Q is less than df and the calculation would result in a negative value, then $I^2$ is defined as zero.) There are competing methods of calculating the confidence interval such as Hedges and Piggott (2001) and Higgins and Thompson (2002)."}, {"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Harold Lehmann, Joanne Dehnbostel, Muhammad Afzal, Khalid Shahin"}, {"code": "expert-comments", "valueString": "2024-05-20 comment:\n\"df, the degrees of freedom.\" Note punctuation needs.\n\"(If calculation results in a negative value, Q is less than df, \n\ud835\udc3c2 is defined as zero.)\" Is that supposed or be \"if Q is less than df\" or, \"and Q is less than df\" or \"because\"?\n\n2024-05-28 comment:\nIs the most commonly used name I square or I squared?  [[[so added as an alternative term]]]"}, {"code": "approval", "valueString": "2024-05-28 vote 7-0 by Lenny Vasanthan, Carlos Alva-Diaz, Saphia Mokrane, Homa Keshavarz, Sheyu Li, Brian S. Alper, Eric Harvey"}]}, {"code": "STATO:0000421", "display": "tau squared", "definition": "A measure of heterogeneity that estimates the variance of the distribution of true effect sizes.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "tau\u00b2"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "\u03c42"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "\u03c4\u00b2"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "tau square"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "tau2"}], "property": [{"code": "external-definitions", "valueString": "STATO: Tau-squared is an estimate of the between-study variance in a random-effects meta-analysis. The square root of this number (i.e. tau) is the estimated standard deviation of underlying effects across studies. (STATO:0000421)"}, {"code": "comment", "valueString": "A measure of heterogeneity is defined as a statistic that represents the variation or spread among values in the set of estimates across studies. The tau squared estimates the between-study variance in a random-effects meta-analysis or hierarchical multilevel model meta-analysis."}, {"code": "editors", "valueString": "Kenneth Wilkins, Brian S. Alper"}, {"code": "approval", "valueString": "2024-05-28 vote 6-0 by Lenny Vasanthan, Carlos Alva-Diaz, Saphia Mokrane, Homa Keshavarz, Sheyu Li, Eric Harvey"}]}]}], "display": "measure of dispersion", "property": [{"code": "external-definitions", "valueString": "STATO: measure of variation (measure of dispersion) = measure of variation or statistical dispersion is a data item which describes how much a theoritical distribution or dataset is spread.\n\nNCIt: \"Statistical dispersion-\t\nThe variation between data values in a sample.\"\nUMLS: \"Dispersion (C0332624)\nDefinition: The variation between data values in a sample.\nSemantic Types: Spatial Concept\""}, {"code": "comment", "valueString": "This categorical (parent) term can be used for a statistic that is a measure of dispersion and is not found in the child terms."}, {"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Yuan Gao, Joanne Dehnbostel"}, {"code": "approval", "valueString": "2023-02-07 vote 5-0 by Cau\u00ea Monaco, Harold Lehmann, Janice Tufte, Jesus Lopez-Alcalde, Eric Harvey"}], "definition": "A statistic that represents the variation or spread among data values in a dataset or data distribution.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "measure of variation"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "dispersion"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "statistical dispersion"}]}, {"code": "STATO:0000209", "display": "area under the curve", "definition": "A statistic that summarizes the variation of a quantity of interest across a domain interval of interest.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "AUC"}], "property": [{"code": "external-definitions", "valueString": "STATO: area under curve is a measurement datum which corresponds to the surface define by the x-axis and bound by the line graph represented in a 2 dimensional plot resulting from an integration or integrative calculus. The interpretation of this measurement datum depends on the variables plotted in the graph"}, {"code": "comment", "valueString": "As examples, in classification tasks, the quantity of interest is the true positive rate and the domain interval of interest is the false positive rate; in pharmacodynamic studies, the quantity of interest is the concentration of a drug and the domain interval of interest is time; and in assessment of lung barotrauma in intensive care, the quantity of interest is pressure and the domain interval of interest is time. \n\nIn general, the average quantity is calculated as the area under the curve divided by the range of the domain interval of interest."}, {"code": "editors", "valueString": "Harold Lehmann, Kenneth Wilkins, Joanne Dehnbostel, Muhammad Afzal, Khalid Shahin"}, {"code": "approval", "valueString": "2024-03-11 vote 5-0 by Eric Harvey, Xing Song, Lenny Vasanthan, Harold Lehmann, Homa Keshavarz"}], "concept": [{"code": "STATO:0000608", "display": "area under the ROC curve", "definition": "An area under the curve where the curve is the true positive rate and the range of interest is the false positive rate.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "AUC"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "AUROC"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "area under the receiver operating characteristic curve"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "c-statistic"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "C-statistic"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "Harrell's C"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "concordance index"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "concordance statistic"}], "property": [{"code": "external-definitions", "valueString": "One of the earliest descriptions of this concept is found in \"The area above the ordinal dominance graph and the area below the receiver operating characteristic graph\" (https://doi.org/10.1016/0022-2496(75)90001-2)"}, {"code": "comment", "valueString": "ROC stands for Receiver Operating Characteristic. The area under the ROC curve is used to assess the performance of a classifier used to distinguish between two or more groups. Another term for true positive rate is sensitivity and another term for false positive rate is 1-specificity. \n\nThe c-statistic is the area under the ROC curve calculated with the full range of possible values for true positive rate and false positive rate. Another interpretation of the c-statistic is similar without explicitly referencing the ROC curve: \"The C statistic is the probability that, given 2 individuals (one who experiences the outcome of interest and the other who does not or who experiences it later), the model will yield a higher risk for the first patient than for the second. It is a measure of concordance (hence, the name \u201cC statistic\u201d) between model-based risk estimates and observed events. C statistics measure the ability of a model to rank patients from high to low risk but do not assess the ability of a model to assign accurate probabilities of an event occurring (that is measured by the model\u2019s calibration). C statistics generally range from 0.5 (random concordance) to 1 (perfect concordance).\" (JAMA. 2015;314(10):1063-1064. doi:10.1001/jama.2015.11082)"}, {"code": "editors", "valueString": "Harold Lehmann, Kenneth Wilkins, Muhammad Afzal, Joanne Dehnbostel, Khalid Shahin"}, {"code": "approval", "valueString": "2024-04-22 vote 6-0 by Cau\u00ea Monaco, Harold Lehmann, Eric Harvey, Homa Keshavarz, Lenny Vasanthan, Sheyu Li"}, {"code": "negative-vote", "valueString": "area under the ROC curve was approved 2024-03-18 vote 6-0 by Cau\u00ea Monaco, Homa Keshavarz, Elma OMERAGIC, Xing Song, Lenny Vasanthan, Eric Harvey BUT then ...\nc-statistic had 2024-04-01 vote 4-2 by Philippe Rocca-Serra, Sheyu Li, Harold Lehmann, Lenny Vasanthan, Eric Harvey, Homa Keshavarz"}, {"code": "expert-comments", "valueString": "2024-03-18 comment: Can we consider having the statement on \"ROC stands for Receiver Operating Characteristic\" in the first line followed by the area under the ROC curve?\n\n 2024-04-01 comments for c-statistic:\n1) isn't this a synonym for AUROC ? (with the assumption that AUROC refers to the totality of the space located below the curve.\n2) Is it c-statistic or C statistic (capitaled)? \nQuote: The C statistic is the probability that, given 2 individuals (one who experiences the outcome of interest and the other who does not or who experiences it later), the model will yield a higher risk for the first patient than for the second. It is a measure of concordance (hence, the name \u201cC statistic\u201d) between model-based risk estimates and observed events. C statistics measure the ability of a model to rank patients from high to low risk but do not assess the ability of a model to assign accurate probabilities of an event occurring (that is measured by the model\u2019s calibration). C statistics generally range from 0.5 (random concordance) to 1 (perfect concordance).I would use discrimination rather than distinguish for the purpose of C-statistic. (JAMA. 2015;314(10):1063-1064. doi:10.1001/jama.2015.11082)\nI am also worried about the definition is highly relied on the definition of ROC. A link of ROC may be better for users. Discrimination rather than distinguish could be a better word to describe C statistic. \nC statistic also refers to concordance statistic."}]}, {"code": "STATO:0000689", "display": "partial area under the ROC curve", "definition": "An area under the curve where the curve is the true positive rate and the range of interest is a specified portion of the range of possible values for the false positive rate and/or range of possible values for the true positive rate.", "property": [{"code": "comment", "valueString": "Area under the ROC curve is defined as an area under the curve where the curve is the true positive rate and the range of interest is the false positive rate. ROC stands for Receiver Operating Characteristic. The area under the ROC curve is used to assess the performance of a classifier used to distinguish between two or more groups. Another term for true positive rate is sensitivity and another term for false positive rate is 1-specificity."}, {"code": "editors", "valueString": "Kenneth Wilkins, Brian S. Alper, Muhammad Afzal, Harold Lehmann"}, {"code": "negative-vote", "valueString": "2024-04-01 vote 4-2 by Philippe Rocca-Serra, Sheyu Li, Harold Lehmann, Lenny Vasanthan, Eric Harvey, Homa Keshavarz\n2024-04-15 vote 3-1 by Harold Lehmann, Eric Harvey, Lenny Vasanthan, Homa Keshavarz"}, {"code": "expert-comments", "valueString": "2024-04-01 comments:\n1) i assume 'area under the curve' to equate the entire area located under the curve, so 'a part' can not be a subtype of the whole.\n2) Similar concerns with the definition of C statistic. \n\n2024-04-15 comment:\nI think we have to add, to the definition, \"and/or range of possible values for the true positive rate\" as well. My apologies, but I didn't catch this during our dicussions."}, {"code": "approval", "valueString": "2024-04-22 vote 5-0 by Lenny Vasanthan, Homa Keshavarz, Eric Harvey, Harold Lehmann, Sheyu Li"}]}, {"code": "STATO:0000691", "display": "area under the precision-recall curve", "definition": "An area under the curve where the curve is the precision and the domain of interest is the recall.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "AUPRC"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "AUCPR"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "AUC-PR"}], "property": [{"code": "comment", "valueString": "In information retrieval, recall is a synonym for sensitivity and precision is a synonym for positive predictive value."}, {"code": "editors", "valueString": "Kenneth Wilkins, Harold Lehmann, Brian S. Alper"}, {"code": "approval", "valueString": "2024-04-01 vote 6-0 by Homa Keshavarz, Philippe Rocca-Serra, Sheyu Li, Harold Lehmann, Lenny Vasanthan, Eric Harvey"}]}, {"code": "STATO:0000690", "display": "area under the value-time curve", "definition": "An area under the curve where the curve is the repeated measures of a variable over time and the domain of interest is time.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "area under the value-by-time curve"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "area under the value vs. time curve"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "area under the value versus time curve"}], "property": [{"code": "comment", "valueString": "The area under the value-by-time curve is used for pharmacokinetics, pharmacodynamics, and physiological monitoring."}, {"code": "editors", "valueString": "Kenneth Wilkins, Harold Lehmann"}, {"code": "expert-comments", "valueString": "2024-04-01 comment: Is it value-time curve?"}, {"code": "negative-vote", "valueString": "2024-04-01 vote 5-1 by Homa Keshavarz, Philippe Rocca-Serra, Sheyu Li, Harold Lehmann, Lenny Vasanthan, Eric Harvey"}, {"code": "approval", "valueString": "2024-04-29 vote 7-0 by Lenny Vasanthan, Harold Lehmann, Eric Harvey, Homa Keshavarz, Sean Grant, Philippe Rocca-Serra, Sheyu Li"}]}]}, {"code": "STATO:0000633", "display": "threshold", "definition": "A statistic that represents the boundary at which something changes.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "cutoff"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "threshold value"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "cutoff value"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "cutoff threshold"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "limit"}], "property": [{"code": "comment", "valueString": "The thing that changes at the threshold value may be relevant for function, application, classification, or detection."}, {"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Muhammad Afzal, Janice Tufte, Bhagvan Kommadi, Kenneth Wilkins, Khalid Shahin"}, {"code": "approval", "valueString": "5/5 as of 10/11/2021: Janice Tufte, Joanne Dehnbostel, Louis Leff, Vignesh Subbian, Robin Ann Yurk"}]}, {"code": "STATO:0000069", "display": "degrees of freedom", "definition": "A statistic that represents the number of independent values used to calculate a statistical estimate. The number of degrees of freedom \u03bd is equal to the number of independent units of information given the model.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "number of degrees of freedom"}], "property": [{"code": "comment", "valueString": "The formula to calculate degrees of freedom will depend on the model. For example, the degrees of freedom for a sample standard deviation, given the sample mean, is N-1, because the Nth observation is no longer independent, given the N-1 other observations and the sample mean."}, {"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Muhammad Afzal, Janice Tufte, Bhagvan Kommadi, Kenneth Wilkins, Khalid Shahin, Harold Lehmann"}, {"code": "approval", "valueString": "6/6 as of 10/27/2021: Janice Tufte, Louis Leff, Vignesh Subbian, Robin Ann Yurk, Harold Lehmann, Muhammad Afzal, Pentti Nieminen"}, {"code": "expert-comments", "valueString": "Include * in P = x1 * x2...to clarify this is a product."}]}, {"code": "STATO:0000609", "display": "hypothesis testing measure", "definition": "A statistic that represents the relative support for competing hypotheses, based on the observed data under an assumed modeling framework.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "hypothesis testing statistic"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "hypothesis test statistic"}], "property": [{"code": "comment", "valueString": "A hypothesis testing measure may be used within the frequentist framework (Neyman-Pearson framework) or the Bayesian framework. Within the frequentist framework, the criterion for rejecting the null hypothesis is typically expressed as a [p-value](https://fevir.net/resources/CodeSystem/27270#TBD:0000076) that is less than an [alpha setting](https://fevir.net/resources/CodeSystem/27270#TBD:0000081). Within the Bayesian framework, the approach for rejecting the null hypothesis is typically based on a Bayes factor."}, {"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Harold Lehmann, Joanne Dehnbostel, Muhammad Afzal"}, {"code": "negative-vote", "valueString": "2024-06-10 vote 4-1 by Harold Lehmann, Lenny Vasanthan, Sean Grant, Eric Harvey, Sheyu Li\n2024-06-17 vote 7-0 by Harold Lehmann, Sean Grant, Carlos Alva-Diaz, Lenny Vasanthan, Eric Harvey, Yaowaluk Ngoenwiwatkul, Homa Keshavarz BUT ALTERNATIVE TERMS AND COMMENT MODIFIED\n2024-06-24 vote 7-1 by Sean Grant, Philippe Rocca-Serra, Sheyu Li, Saphia Mokrane, Cau\u00ea Monaco, Eric Harvey, Lenny Vasanthan, Homa Keshavarz"}, {"code": "expert-comments", "valueString": "2024-06-10 comments re: \"hypothesis testing measure\" = \"A statistic that represents the result of evaluating the congruence between a hypothesis and the statistics derived from the observed data.\"1) I guess we'll add \"hypothesis\" to our emerging glossary.\n2N) Would Bayesians say that they are \"testing\" a hypothesis?\n3) The definition looks fine but the comment seems confusing and unnecessary. \n\n\n2024-06-17 comment re: \"hypothesis testing measure\" = \"A statistic that represents the result of evaluating the congruence between a hypothesis and the statistics derived from the observed data.\"\"Hypothesis testing statistic\" as an alternative term?\n\n2024-06-24 comment re: \"hypothesis testing measure\" = \"A statistic that represents the result of evaluating the congruence between a hypothesis and the statistics derived from the observed data.\"The definition seems wordy. Why not: A statistic that represents the strength (or value?) of a statistical test (or: between the hypothesis and the observation)."}, {"code": "approval", "valueString": "2024-07-08 vote 6-0 by Saphia Mokrane, C P Ooi, Harold Lehmann, Eric Harvey, Lenny Vasanthan, Homa Keshavarz"}], "concept": [{"code": "STATO:0000700", "display": "p-value", "definition": "A hypothesis testing measure that represents the probability of obtaining a result at least as far from the value actually obtained as the value expected, assuming the null hypothesis is true.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "p value"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "P value"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "P-value"}], "property": [{"code": "external-definitions", "valueString": "STATO: A quantitative confidence value that represents the probability of obtaining a result at least as extreme as that actually obtained, assuming that the actual value was the result of chance alone. (OBI:0000175)\n\n\"You may summarize this comparison using a Bayesian p-value (Gelman et al., 1996, 2004), the predictive probability that a statistic is equal to or more extreme than that observed under the assumptions of the model.\" -- https://www.fda.gov/regulatory-information/search-fda-guidance-documents/guidance-use-bayesian-statistics-medical-device-clinical-trials"}, {"code": "comment", "valueString": "[Hypothesis testing measure](https://fevir.net/resources/CodeSystem/27270#TBD:0000073) is defined as a statistic that represents the result of evaluating the congruence between a hypothesis and the statistics derived from the observed data.\n\nWithin the frequentist framework, a p-value is typically a [p-value for two-sided test](https://fevir.net/resources/CodeSystem/27270#TBD:p-value-two-sided) and the criterion for rejecting the null hypothesis is typically expressed as a p-value that is less than an [alpha setting](https://fevir.net/resources/CodeSystem/27270#TBD:0000081) divided by 2. In some cases, the p-value is a [p-value for one-sided test](https://fevir.net/resources/CodeSystem/27270#TBD:p-value-one-sided), and the criterion for rejecting the null hypothesis is typically expressed as a p-value that is less than an [alpha setting](https://fevir.net/resources/CodeSystem/27270#TBD:0000081). A p-value is preferably coded more precisely as a [p-value for two-sided test](https://fevir.net/resources/CodeSystem/27270#TBD:p-value-two-sided) or a [p-value for one-sided test](https://fevir.net/resources/CodeSystem/27270#TBD:p-value-one-sided) rather than using the code for p-value without specification. The code for p-value (without specification) may be used in contexts where the p-value reported is ambiguous.\n\nWithin the Bayesian framework, use the [posterior predictive p-value](https://fevir.net/resources/CodeSystem/27270#TBD:Bayesianp)."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Muhammad Afzal, Kenneth Wilkins"}, {"code": "negative-vote", "valueString": "2024-06-17 vote 7-1 by Harold Lehmann, Sean Grant, Khalid Shahin, Carlos Alva-Diaz, Lenny Vasanthan, Eric Harvey, Yaowaluk Ngoenwiwatkul, Homa Keshavarz\n2024-07-01 vote 8-1 by Harold Lehmann, Sean Grant, Philippe Rocca-Serra, Sheyu Li, Saphia Mokrane, Cau\u00ea Monaco, Eric Harvey, Lenny Vasanthan, Homa Keshavarz\n2024-07-08 vote 3-0 by Saphia Mokrane, Eric Harvey, C P Ooi BUT THEN THE DEFINITION CHANGED\n2024-07-15 vote 4-2 by Homa Keshavarz, Cau\u00ea Monaco, Sheyu Li, Eric Harvey, Philippe Rocca-Serra, Lenny Vasanthan"}, {"code": "expert-comments", "valueString": "2024-06-17 comments re: \"p value\" = \"A hypothesis testing measure that represents the probability of obtaining a result at least as extreme as that actually obtained, assuming that the actual value was the result of chance alone.\"1) \"Within the frequentist framework...\"2N) The threshold is the alpha-level, not the p-value\n3) I personally prefer p-value, but I'm fine with \"p value\"\n2024-07-01 comments re: \"p-value\" = \"A hypothesis testing measure that represents the probability of obtaining a result at least as extreme as that actually obtained, assuming the null hypothesis is true.\"1) suggestion: add a sentence to also cover Bayesian framework\n2N) The hypothesis can be null or not null (non-inferior test for example). \n\n\n2024-07-15 comments re: \"p-value\" = \"A hypothesis testing measure that represents the probability of obtaining a result at least as far from the value actually obtained as the value expected, assuming the null hypothesis is true.\"1N)\nwith the distinction with posterior predictive p-value, one-sided pvalue and two-sided pvalue, is pvalue still needed?\nwhen should the term be used? if used to annotate data, is it imprecise as one would not know if both hypotheses have been tested. The introduction of more specific terms may render this type moot.\nAlso in the 'comment for application', if pvalue is parent term, the statement 'typically expressed as a p-value lesss than an alpha setting ' would not be true for 'two-sided pvalue'.\n2N)\nI am wondering if it might be helpful to add a statement on how 'p' value can help to identify if the desired effect is due to 'chance' or if there is an actual difference"}, {"code": "approval", "valueString": "2024-07-22 vote 7-0 by Saphia Mokrane, Carlos Alva-Diaz, Lenny Vasanthan, Sheyu Li, Airton Tetelbom Stein, Harold Lehmann, Eric Harvey"}], "concept": [{"code": "STATO:0000661", "display": "p-value for one-sided test", "definition": "A p-value which represents the probability of obtaining a result at least as far, in one direction, from the value actually obtained as the value expected, assuming the null hypothesis is true. A p-value for one-sided test interprets 'at least as far from' with only one of two directions, either the direction of 'greater than' or the direction of 'less than'.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "p-value for one-tailed test"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "one-sided p-value"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "one-tailed p-value"}], "property": [{"code": "comment", "valueString": "[P-value](https://fevir.net/resources/CodeSystem/27270#TBD:0000076) is defined as a hypothesis testing measure that represents the probability of obtaining a result at least as far from the value actually obtained as the value expected, assuming the null hypothesis is true. For p-value for one-sided test, the criterion for rejecting the null hypothesis is typically expressed as a p-value that is less than an [alpha setting](https://fevir.net/resources/CodeSystem/27270#TBD:0000081)."}, {"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Muhammad Afzal, Harold Lehmann, Kenneth Wilkins"}, {"code": "negative-vote", "valueString": "2024-07-08 vote 8-1 by C P Ooi, Harold Lehmann, Sean Grant, Philippe Rocca-Serra, Sheyu Li, Saphia Mokrane, Eric Harvey, Lenny Vasanthan, Homa Keshavarz\n2024-07-15 vote 5-1 by Homa Keshavarz, Cau\u00ea Monaco, Sheyu Li, Eric Harvey, Philippe Rocca-Serra, Lenny Vasanthan"}, {"code": "expert-comments", "valueString": "2024-07-08 comment re: \"p-value for one-sided test\" = \"A p-value which represents the probability of obtaining a result at least as extreme, in one direction, as that actually obtained.\"1N) The word 'one direction' did not explain 'one sided'. \n\n2024-07-15 comment re: \"p-value for one-sided test\" = \"A p-value which represents the probability of obtaining a result at least as far, in one direction, from the value actually obtained as the value expected, assuming the null hypothesis is true.\"1N) from an end user perspective, i feel that the definition should included the last statement found in the 'comment for application' = \" A p-value for two-sided test interprets 'at least as far from' with both the direction of 'greater than' and the direction of 'less than'. For hypothesis test interpretation, the one-tailed p-value is compared to the alpha setting\""}, {"code": "approval", "valueString": "2024-07-22 vote 6-0 by Carlos Alva-Diaz, Lenny Vasanthan, Sheyu Li, Airton Tetelbom Stein, Harold Lehmann, Eric Harvey"}]}, {"code": "STATO:0000662", "display": "p value for two-sided test", "definition": "A p-value which represents the probability of obtaining a result at least as far, in either direction, from the value actually obtained as the value expected, assuming the null hypothesis is true. A p-value for two-sided test interprets 'at least as far from' with both the direction of 'greater than' and the direction of 'less than'.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "p-value for two-tailed test"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "two-sided p-value"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "two-tailed p-value"}], "property": [{"code": "comment", "valueString": "[P-value](https://fevir.net/resources/CodeSystem/27270#TBD:0000076) is defined as a hypothesis testing measure that represents the probability of obtaining a result at least as  far from the value actually obtained as the value expected, assuming the null hypothesis is true. For hypothesis test interpretation, the two-tailed p-value is compared to the [alpha setting](https://fevir.net/resources/CodeSystem/27270#TBD:0000081) divided by 2."}, {"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Muhammad Afzal, Harold Lehmann, Kenneth Wilkins"}, {"code": "expert-comments", "valueString": "2024-07-15 comment re: \"p value for two-sided test\" = \"A p-value which represents the probability of obtaining a result at least as far, in either direction, from the value actually obtained as the value expected, assuming the null hypothesis is true.\"1N) from an end user perspective, i feel that the definition should included the last statement found in the 'comment for application' = \" A p-value for two-sided test interprets 'at least as far from' with both the direction of 'greater than' and the direction of 'less than'. For hypothesis test interpretation, the two-tailed p-value is compared to the alpha setting divided by 2\""}, {"code": "negative-vote", "valueString": "2024-07-15 vote 5-1 by Homa Keshavarz, Cau\u00ea Monaco, Sheyu Li, Eric Harvey, Philippe Rocca-Serra, Lenny Vasanthan"}, {"code": "approval", "valueString": "2024-07-22 vote 6-0 by Carlos Alva-Diaz, Lenny Vasanthan, Sheyu Li, Airton Tetelbom Stein, Harold Lehmann, Eric Harvey"}]}]}, {"code": "STATO:0000030", "display": "chi-square statistic", "definition": "A hypothesis testing measure that is assumed to follow a chi-square distribution.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "chi-squared statistic"}], "property": [{"code": "external-definitions", "valueString": "STATO: Chi-squared statistic is a statistic computed from observations and used to produce a p-value in statistical test when compared to a Chi-Squared distribution. (STATO:0000030)"}, {"code": "comment", "valueString": "A hypothesis testing measure is defined as a statistic that represents the relative support for competing hypotheses, based on the observed data under an assumed modeling framework."}, {"code": "editors", "valueString": "Kenneth Wilkins, Harold Lehmann, Brian S. Alper, Joanne Dehnbostel"}, {"code": "approval", "valueString": "2024-10-28 vote 6-0 by Saphia Mokrane, Eric Harvey, Harold Lehmann, Homa Keshavarz, Airton Tetelbom Stein, Lenny Vasanthan"}], "concept": [{"code": "STATO:0000081", "display": "chi-square statistic for independence", "definition": "A chi-square statistic used to test whether two categorical or nominal variables are associated.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "chi-squared statistic for independence"}], "property": [{"code": "external-definitions", "valueString": "STATO: Chi-squared statistic is a statistic computed from observations and used to produce a p-value in statistical test when compared to a Chi-Squared distribution. (STATO:0000030)"}, {"code": "comment", "valueString": "Types of chi-square statistic for independence include the Pearson's chi-square statistic for independence and the Yate's corrected chi-square statistic. The chi-square statistic for independence is a chi-square statistic used for testing for an association."}, {"code": "editors", "valueString": "Kenneth Wilkins, Harold Lehmann, Brian S. Alper, Joanne Dehnbostel"}, {"code": "approval", "valueString": "2024-11-04 vote 6-0 by Lara Kahaleh, Bhagvan Kommadi, Harold Lehmann, Eric Harvey, Homa Keshavarz, Airton Tetelbom Stein"}, {"code": "expert-comments", "valueString": "2024-10-28 comment re: \"chi-square statistic for independence\" = \"A chi-square statistic used to determine whether two categorical or nominal variables are likely to be related.\"1Yes)\nCan we consider adding in \"chi-squared statistic for association\" along with this."}, {"code": "negative-vote", "valueString": "2024-10-28 vote 6-0 by Saphia Mokrane, Eric Harvey, Harold Lehmann, Homa Keshavarz, Airton Tetelbom Stein, Lenny Vasanthan BUT THEN COMMENT CHANGED DEFINITION AND COMMENT FOR APPLICATION"}]}, {"code": "STATO:0000148", "display": "Cochran-Armitage chi-square statistic for trend", "definition": "A chi-square statistic used to test whether a dichotomous variable and an ordinal variable are related.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "Cochran-Armitage chi-squared statistic for trend"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "Cochran-Armitage chi-square statistic"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "Cochran-Armitage statistic"}], "property": [{"code": "comment", "valueString": "There are types of chi-square statistic for trend other than the Cochran-Armitage statistic."}, {"code": "editors", "valueString": "Kenneth Wilkins, Brian S. Alper, Joanne Dehnbostel"}, {"code": "approval", "valueString": "2024-11-04 vote 6-0 by Lara Kahaleh, Bhagvan Kommadi, Harold Lehmann, Eric Harvey, Homa Keshavarz, Airton Tetelbom Stein"}]}, {"code": "STATO:0000698", "display": "chi-square statistic for homogeneity", "definition": "A chi-square statistic used to test whether observed data from two or more groups follow the same distribution.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "chi-squared statistic for homogeneity"}], "property": [{"code": "comment", "valueString": "In meta-analysis, a chi-square statistic for homogeneity is often used to determine the appropriateness of combining the statistics to represent a common population."}, {"code": "editors", "valueString": "Kenneth Wilkins, Brian S. Alper, Joanne Dehnbostel, Harold Lehmann"}, {"code": "negative-vote", "valueString": "2024-11-04 vote 5-1 by Lara Kahaleh, Bhagvan Kommadi, Harold Lehmann, Eric Harvey, Homa Keshavarz, Airton Tetelbom Stein"}, {"code": "expert-comments", "valueString": "2024-11-04 comment re: \"chi-square statistic for homogeneity\" = \"A chi-square statistic used to test whether observed data from two or more groups follow the same distribution.\"1No)\nI recall that there used to be considerable controversy about the value of statistical tests applied to baseline characteristics, the recommendation being to avoid such tests. If this remains the case, shouldn't we note that here?"}, {"code": "approval", "valueString": "2024-11-11 vote 7-0 by Lenny Vasanthan, Yaowaluk Ngoenwiwatkul, Cau\u00ea Monaco, Saphia Mokrane, Eric Harvey, Airton Tetelbom Stein, Homa Keshavarz"}]}, {"code": "STATO_0000309", "display": "chi-square statistic for goodness of fit", "definition": "A chi-square statistic used to test whether observed data follows a specified distribution.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "chi-squared statistic for goodness of fit"}], "property": [{"code": "comment", "valueString": "There are types of chi-square statistic for goodness of fit with named tests based on the specified distribution, such as the Hosmer\u2013Lemeshow test for a given logistic regression model and the Shapiro\u2013Wilk test for a normal (Gaussian) distribution."}, {"code": "editors", "valueString": "Kenneth Wilkins, Brian S. Alper, Joanne Dehnbostel"}, {"code": "approval", "valueString": "2024-11-04 vote 6-0 by Lara Kahaleh, Bhagvan Kommadi, Harold Lehmann, Eric Harvey, Homa Keshavarz, Airton Tetelbom Stein"}]}]}, {"code": "STATO:0000376", "display": "z-statistic", "definition": "A hypothesis testing measure that is a z-score where the specified mean is based on the null hypothesis and the standard deviation is based on the observed data.", "property": [{"code": "external-definitions", "valueString": "STATO: A z-score (also known as z-value, standard score, or normal score) is a measure of the divergence of an individual experimental result from the most probable result, the mean. Z is expressed in terms of the number of standard deviations from the mean value. (STATO:0000104)   Z-statistic is a statistic computed from observations and used to produce a p-value when compared to a Standard Normal Distribution in a statistical test called the Z-test. (STATO:0000376)"}, {"code": "editors", "valueString": "Kenneth Wilkins, Joanne Dehnbostel, Harold Lehmann, Brian S. Alper"}, {"code": "comment", "valueString": "A [z-score](#STATO:0000104) is defined as a statistic that represents a measure of the divergence of an individual experimental result from a specified mean, expressed in terms of the number of standard deviations from the mean value.\nA z-statistic is a z-score of a sample in the conduct of a Z-test."}, {"code": "approval", "valueString": "2024-08-12 vote 7-0 by Harold Lehmann, Homa Keshavarz, Eric Harvey, Lenny Vasanthan, Sheyu Li, Airton Tetelbom Stein, Sean Grant"}]}, {"code": "STATO:0000176", "display": "t-statistic", "definition": "A hypothesis testing measure that is a t-score where the specified mean is based on the null hypothesis, the standard error is based on the observed data, and the degrees of freedom is based on the sample size.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "Student's t"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "Student's t statistic"}], "property": [{"code": "external-definitions", "valueString": "STATO: t-statistic is a statistic computed from observations and used to produce a p-value in statistical test when compared to a Student's t distribution. (STATO:0000176)"}, {"code": "comment", "valueString": "A t-score is defined as a statistic that represents a measure of the divergence of an individual experimental result from a specified mean, expressed in terms of the number of standard deviations from the mean value.\nA t-statistic is a t-score of a sample in the conduct of a t-test."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Muhammad Afzal"}, {"code": "approval", "valueString": "2024-10-14 vote 5-0 by Lenny Vasanthan, Harold Lehmann, Eric Harvey, Airton Tetelbom Stein, Homa Keshavarz"}]}, {"code": "STATO:0000266", "display": "Bayes factor", "definition": "A hypothesis testing measure that is a ratio of the probability of the observed data under one hypothesis divided by the probability of the same observed data under a different hypothesis.", "property": [{"code": "external-definitions", "valueString": "STATO: Bayes factor is a ratio between 2 probabilities of observing data according 2 distinct models. It is used in Bayes model selection to evaluate which model best explains the data. if K<0, the model used in the denominator term is supported, if K>1, the model used in the numerator term is supported. The Bayes factor is about the plausibility of 2 different models\n\nNCI Code         CDISC Submission Value      CDISC Synonym          NCI Preferred Term    CDISC Definition\n\nC142403          Bayesian approaches             _                                           Bayesian Approach        \n\nApproaches to data analysis that provide a posterior probability distribution for some parameter (e.g., treatment effect), derived from the observed data and a prior probability distribution for the parameter. The posterior distribution is then used as the basis for statistical inference. [ICH E9 Glossary]\n\nC142404          Bayesian statistics                   _                                           Bayesian Statistics        \n\nStatistical approach named for Thomas Bayes (1701-1761) that has among its features giving a subjective interpretation to probability, accepting the idea that it is possible to talk about the probability of hypotheses being true and of parameters having particular values."}, {"code": "comment", "valueString": "The Bayes factor numerator and denominator take into account the prior probabilities of each hypothesis. The Bayes factor represents the relative plausibility between competing hypotheses, taking the prior probabilities into account."}, {"code": "editors", "valueString": "Harold Lehmann, Brian S. Alper, Joanne Dehnbostel"}, {"code": "approval", "valueString": "2024-11-11 vote 7-0 by Lenny Vasanthan, Yaowaluk Ngoenwiwatkul, Cau\u00ea Monaco, Saphia Mokrane, Eric Harvey, Airton Tetelbom Stein, Homa Keshavarz"}]}, {"code": "STATO:0000660", "display": "posterior predictive p-value", "definition": "A hypothesis testing measure that is the probability that a statistic value derived from a posterior predictive distribution under the assumptions of the model is equal to or more extreme than the observed posterior value of the statistic.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "Bayesian p-value"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "Bayes p-value"}], "property": [{"code": "comment", "valueString": "[Hypothesis testing measure](https://fevir.net/resources/CodeSystem/27270#TBD:0000073) is defined as a statistic that represents the result of evaluating the congruence between a hypothesis and the statistics derived from the observed data.\n\nA posterior predictive p-value includes assumptions of prior probability of the hypothesis or parameters in the model.\n\nThe term 'posterior predictive p-value' is used within the Bayesian framework. Within the frequentist framework, use [p-value for two-sided test](https://fevir.net/resources/CodeSystem/27270#TBD:p-value-two-sided) or [p-value for one-sided test](https://fevir.net/resources/CodeSystem/27270#TBD:p-value-one-sided).\n\nNote that in the Bayesian case, one generally focuses on the posterior probability distribution of the parameter of interest, not on this posterior probability of a statistic."}, {"code": "external-definitions", "valueString": "\"You may summarize this comparison using a Bayesian p-value (Gelman et al., 1996, 2004), the predictive probability that a statistic is equal to or more extreme than that observed under the assumptions of the model.\" -- https://www.fda.gov/regulatory-information/search-fda-guidance-documents/guidance-use-bayesian-statistics-medical-device-clinical-trials"}, {"code": "editors", "valueString": "Kenneth Wilkins, Harold Lehmann, Philippe Rocca-Sera, Brian S. Alper"}, {"code": "negative-vote", "valueString": "2024-07-08 vote 3-1 by C P Ooi, Sheyu Li, Eric Harvey, Harold Lehmann\n2024-07-15 vote 5-1 by Homa Keshavarz, Cau\u00ea Monaco, Sheyu Li, Eric Harvey, Philippe Rocca-Serra, Lenny Vasanthan\n2024-07-22 vote 6-0 by Carlos Alva-Diaz, Lenny Vasanthan, Sheyu Li, Airton Tetelbom Stein, Harold Lehmann, Eric Harvey (Comment led us to reopen this term for voting)"}, {"code": "expert-comments", "valueString": "2024-07-08 comment re: \"posterior predictive p-value\" = \"A hypothesis testing measure that is the predictive probability that a statistic is equal to or more extreme than that observed under the assumptions of the model.\"1N) I think \"Bayesian\" should be the primary name, and something about priors and data should be included in the comment for application, since this is an atypical measure. (Sorry not having pointed this out during the session.)\n\n2024-07-15 comment re: \"posterior predictive p-value\" = \"A hypothesis testing measure that is the predictive probability that a statistic is equal to or more extreme than that observed under the assumptions of the model.\"1N) add \"Within the frequentist framework, use 'one-sided or two sided pvalue\" (or pvalue if kept) to the 'comment for application' for consistency and reciprocity\n\n2024-07-22 comment re: \"posterior predictive p-value\" = \"A hypothesis testing measure that is the probability that a statistic value derived from a posterior predictive distribution under the assumptions of the model is equal to or more extreme than the observed posterior value of the statistic.\"1Y) Because most \"posteriors\" in Bayesian statistics are about the parameter we really care about, let me suggest saying something like: \"Note that in the Bayesian case, one generally focuses on the posterior probability distribution of the parameter of interest, not on this posterior probability of a statistic.\"  And we will need a SEVCO term for \"posterior probability,\" to go under Bayes factor (not a child)."}, {"code": "approval", "valueString": "2024-07-29 vote 5-0 by Lenny Vasanthan, Airton Tetelbom Stein, Eric Harvey, Harold Lehmann, Homa Keshavarz"}]}]}, {"code": "TBD:0000065", "display": "DEPRECATED: measure of discrimination", "definition": "A statistic that quantifies the degree to which a classifier can distinguish among two or more groups.", "property": [{"code": "comment", "valueString": "A classifier is a rule, formula, algorithm, or procedure used to label an instance based on its attributes."}, {"code": "editors", "valueString": "Harold Lehmann, Kenneth Wilkins, Joanne Dehnbostel, Khalid Shahin"}, {"code": "deprecated", "valueString": "DEPRECATED 2024-02-05"}, {"code": "expert-comments", "valueString": "2024-02-05 in response to comment questioning placing other terms as types of measure of discrimination, the Working Group decided to remove this term from the hierarchy and simply make 'area under the curve' a type of statistic wtihout an additional hierarchical layer"}]}, {"code": "STATO:0000104", "display": "z-score", "definition": "A statistic that represents a measure of the divergence of an individual experimental result from a specified mean, expressed in terms of the number of standard deviations from the mean value.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "Z-score"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "z score"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "Z score"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "z-value"}], "property": [{"code": "external-definitions", "valueString": "STATO: A z-score (also known as z-value, standard score, or normal score) is a measure of the divergence of an individual experimental result from the most probable result, the mean. Z is expressed in terms of the number of standard deviations from the mean value. (STATO:0000104)"}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Muhammad Afzal"}, {"code": "negative-vote", "valueString": "2024-08-12 vote 7-1 by Harold Lehmann, Homa Keshavarz, Eric Harvey, Lenny Vasanthan, Sheyu Li, Elma OMERAGIC, Airton Tetelbom Stein, Sean Grant\n2024-08-19 vote 6-1 by Philippe Rocca-Serra, Sean Grant, Airton Tetelbom Stein, Homa Keshavarz, Cau\u00ea Monaco, Eric Harvey, Brian S. Alper"}, {"code": "expert-comments", "valueString": "2024-08-12\nComment for application maybe should include: \"A z-score can be calculated for a statistic for a sample z-statistic or may be calculated for an individual, using a reference mean and standard deviation, as in an IQ score.\"\n2024-08-19 comment re: \"z-score\" = \"A statistic that represents a measure of the divergence of an individual experimental result from a specified mean, expressed in terms of the number of standard deviations from the mean value.\"1N)\nDoes 'calculated for a statistic for a sample z-statistic' mean that you calculate the z-score from the z-statistic and they are 2 different values, or does it mean that z-statistic is the term for z-score when it is calculated for a sample?  This ambiguity can be avoided by making the comment for application 2 separate sentences, one clearly describing \"for a sample\" and the other clearly describing \"for an individual observation\" -- note individual needs to be an adjective and not a noun in the second sentence.  An individual person can be the population for a sample of observations about the individual.\nre: \"z-score\" = \"A statistic that represents a measure of the divergence of an individual experimental result from a specified mean, expressed in terms of the number of standard deviations from the mean value.\"\n2024-08-26 comment re: \"z-score\" = \"A statistic that represents a measure of the divergence of an individual experimental result from a specified mean, expressed in terms of the number of standard deviations from the mean value.\"1Y)\nOnly a petit change in comment for application...\"A z-score can also be calculated for a statistic for a sample, such as a z-statistic, which is a hypothesis testing measure. The z-score for the sample is based on the null hypothesis mean, and the standard deviation is based on the observed data.\""}, {"code": "comment", "valueString": "A z-score can be calculated for an individual observation, using a reference mean and standard deviation, such as in an IQ score or a weight-for-age-and-sex value in a pediatric growth chart.\nA z-score can also be calculated for a statistic for a sample, such as a [z-statistic](https://fevir.net/resources/CodeSystem/27270#STATO:0000376), which is a hypothesis testing measure. The z-score for the sample is based on the null hypothesis mean, and the standard deviation is based on the observed data."}, {"code": "approval", "valueString": "2024-08-26 vote 7-0 by Carlos Alva-Diaz, Elma OMERAGIC, Lenny Vasanthan, Eric Harvey, Homa Keshavarz, Airton Tetelbom Stein, Harold Lehmann"}]}, {"code": "STATO:0000699", "display": "t-score", "definition": "A statistic that represents a measure of the divergence of an individual experimental result from a specified mean, taking sample size into account and expressed in terms of the number of standard errors from the mean value.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "T-score"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "t score"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "T score"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "t-value"}], "property": [{"code": "comment", "valueString": "A t-score can be calculated for an individual observation, using a reference mean and standard error, such as in a bone mineral density value with a reference mean and standard error for young adult men.\nA t-score can also be calculated for a statistic for a sample, such as a t-statistic, which is a hypothesis testing measure. The t-score for the sample is based on the null hypothesis mean, and the standard error is based on the observed data.\nA t-score is used preferentially to a z-score when the sample size is low (e.g. < 30 for a unimodal symmetric distribution), the population standard deviation is unknown, or when the sample distribution cannot be assumed to follow a normal distribution."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Joanne Dehnbostel, Muhammad Afzal, Kenneth Wilkins"}, {"code": "approval", "valueString": "2024-10-14 vote 5-0 by Lenny Vasanthan, Harold Lehmann, Eric Harvey, Airton Tetelbom Stein, Homa Keshavarz"}]}, {"code": "STATO:0000702", "display": "prior probability", "definition": "A statistic that represents the likelihood of a parameter of interest, before accounting for the observed data from the study.", "property": [{"code": "comment", "valueString": "This term is core to Bayesian statistics, where the focus is on estimation of the parameter of interest (unlike frequentist statistics, where the focus is on the likelihood of producing an estimate given a specific value of the parameter).\nThe prior probability may be constructed in several ways: from prior research, from raw data in a database, from expert opinion, or specified as \"non-informative\" (meaning pure ignorance).\nThe likelihood of the parameter is usually represented as a distribution over all possible values of the parameter."}, {"code": "editors", "valueString": "Harold Lehmann, Brian S. Alper, Joanne Dehnbostel, Muhammad Afzal"}, {"code": "expert-comments", "valueString": "2024-08-12  comments:\n1N)\nI would suggest including Bayersian analysis as a context in the definition but not only in the comments. \n2Y)\nJust a comment for us: Note that this may be the first time that \"statistic\" is used NOT to mean a function of the observed data, but is still covered by our SEVCO definition for \"statistic.\"\n\n2024-08-19 comment re: \"prior probability\" = \"A statistic that represents the uncertainty of a parameter of interest, before accounting for the observed data from the study.\"1N)\nUncertainty and likelihood are not synonymous.  The word 'uncertainty' does in the proposed definition of prior probability does not match the parallel definition of posterior probability (using 'likelihood') and does not match the comment in posterior probability which states 'The prior probability is the likelihood of a parameter of interest'"}, {"code": "negative-vote", "valueString": "2024-08-12 vote 6-1 by Harold Lehmann, Homa Keshavarz, Eric Harvey, Lenny Vasanthan, Sheyu Li, Airton Tetelbom Stein, Sean Grant\n2024-08-19 vote 6-1 by Philippe Rocca-Serra, Sean Grant, Airton Tetelbom Stein, Homa Keshavarz, Cau\u00ea Monaco, Eric Harvey, Brian S. Alper"}, {"code": "external-definitions", "valueString": "NCI Code         CDISC Submission Value      CDISC Synonym          NCI Preferred Term    CDISC Definition\n\nC142403          Bayesian approaches             _                                           Bayesian Approach        \n\nApproaches to data analysis that provide a posterior probability distribution for some parameter (e.g., treatment effect), derived from the observed data and a prior probability distribution for the parameter. The posterior distribution is then used as the basis for statistical inference. [ICH E9 Glossary]\n\nC142404          Bayesian statistics                   _                                           Bayesian Statistics        \n\nStatistical approach named for Thomas Bayes (1701-1761) that has among its features giving a subjective interpretation to probability, accepting the idea that it is possible to talk about the probability of hypotheses being true and of parameters having particular values."}, {"code": "approval", "valueString": "2024-11-11 vote 7-0 by Lenny Vasanthan, Yaowaluk Ngoenwiwatkul, Cau\u00ea Monaco, Saphia Mokrane, Eric Harvey, Airton Tetelbom Stein, Homa Keshavarz"}]}, {"code": "STATO:0000703", "display": "posterior probability", "definition": "A statistic that represents the likelihood of a parameter of interest, after updating its prior probability with the observed data from the study.", "property": [{"code": "comment", "valueString": "This term is core to Bayesian statistics, where the focus is on estimation of the parameter of interest (unlike frequentist statistics, where the focus is on the likelihood of producing an estimate given a specific value of the parameter). The [prior probability](#TBD:priorprobability) is the likelihood of a parameter of interest from before the study. For calculating the posterior probability of a parameter, the  [prior probability](#TBD:priorprobability) is updated using Bayes' Theorem' and the likelihood function."}, {"code": "editors", "valueString": "Harold Lehmann, Brian S. Alper, Joanne Dehnbostel, Muhammad Afzal"}, {"code": "negative-vote", "valueString": "2024-08-12 vote 6-1 by Harold Lehmann, Homa Keshavarz, Eric Harvey, Lenny Vasanthan, Sheyu Li, Airton Tetelbom Stein, Sean Grant"}, {"code": "expert-comments", "valueString": "2024-08-12\n1N)\nI would suggest including Bayersian analysis as a context in the definition but not only in the comments. \n2Y)\nI would amend the last sentence of the Comment for application as, \"For calculating the posterior probability of a parameter, the prior probabilty is updated using Bayes' Theorem' \""}, {"code": "approval", "valueString": "2024-08-19 vote 7-0 by Philippe Rocca-Serra, Brian S. Alper, Sean Grant, Airton Tetelbom Stein, Homa Keshavarz, Cau\u00ea Monaco, Eric Harvey"}]}]}, {"code": "TBD:0000080", "display": "hypothesis test attribute", "definition": "An aspect, characteristic, or feature of a statistical hypothesis test.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Kenneth Wilkins, Philippe Rocca-Serra"}, {"code": "approval", "valueString": "2024-07-08 vote 5-0 by Joanne Dehnbostel, C P Ooi, Sheyu Li, Eric Harvey, Harold Lehmann"}], "concept": [{"code": "TBD:beta", "display": "beta"}, {"code": "STATO:0000200", "display": "power", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "statistical test power"}], "property": [{"code": "external-definitions", "valueString": "from STATO:\nthe statistical test power is data item which is about a statistical test and is obtained by subtracting the false negative rate (type II error rate) to 1. The power of a statistical test is the probability that it will correctly lead to the rejection of a false null hypothesis (Greene 2000). The statistical power is the ability of a test to detect an effect, if the effect actually exists (High 2000)."}]}, {"code": "TBD:0000081", "concept": [{"code": "TBD:0000084", "display": "alpha setting with subtype unspecified"}, {"code": "TBD:0000085", "display": "individual test alpha without multiple testing adjustment"}, {"code": "TBD:0000086", "display": "overall alpha with multiple testing"}, {"code": "TBD:0000087", "display": "individual test alpha with multiple testing adjustment"}], "display": "alpha setting"}, {"code": "STATO:0000286", "display": "one-tailed test", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "one threshold for hypothesis testing"}], "property": [{"code": "external-definitions", "valueString": "STATO: one tailed test (one sided test) = a one-tailed test is a statistical test which, assuming an unskewed probability distribution, allocates all of the significance level to evaluate only one hypothesis to explain a difference.\nThe one-tailed test provides more power to detect an effect in one direction by not testing the effect in the other direction.\none-tailed test should be preceded by two-tailed test in order to avoid missing out on detecting alternate effect explaining an observed difference."}]}, {"code": "STATO:0000287", "display": "two-tailed test", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "two thresholds for hypothesis testing"}], "property": [{"code": "external-definitions", "valueString": "STATO: two tailed test (two sided test) = a two tailed test is a statistical test which assess the null hypothesis of absence of difference assuming a symmetric (not skewed) underlying probability distribution by allocating half of the significance level selected to each of the direction of change which could explain a difference (for example, a difference can be an excess or a loss)."}]}, {"code": "TBD:checkIfInSTATOtesting-margin", "display": "hypothesis testing margin"}, {"code": "STATO:0000057", "display": "null hypothesis", "property": [{"code": "external-definitions", "valueString": "from STATO: A null hypothesis is a statistical hypothesis that is tested for possible rejection under the assumption that it is true (usually that observations are the result of chance). The concept was introduced by R. A. Fisher. The hypothesis contrary to the null hypothesis, usually that the observations are the result of a real effect, is known as the alternative hypothesis.[wolfram alpha -- from http://mathworld.wolfram.com/NullHypothesis.html]"}]}, {"code": "STATO:0000208", "display": "alternative hypothesis", "property": [{"code": "external-definitions", "valueString": "from STATO: \t\nAn alternative hypothesis is an hypothesis defined in a statistical test that is the opposite of the null hypothesis.\n\nfrom Wolfram Alpha (https://mathworld.wolfram.com/AlternativeHypothesis.html):\nThe alternative hypothesis is the hypothesis used in hypothesis testing that is contrary to the null hypothesis. It is usually taken to be that the observations are the result of a real effect (with some amount of chance variation superposed)."}]}]}, {"code": "STATO:0000107", "display": "statistical model", "definition": "A set of mathematical relationships that express assumptions related to the generation of the observed data and that sets constraints for the analysis of the data.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "generative model"}], "property": [{"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Kenneth Wilkins, Muhammad Afzal, Harold Lehmann"}, {"code": "comment", "valueString": "A statistical model describes how one or more random variables are related to one or more other variables. A statistical model often relates to the generation of sample data from a larger population. \"Generative model\" is a term used by the machine learning community."}, {"code": "negative-vote", "valueString": "2023-05-22 vote 3-1 by Jesus Lopez-Alcalde, Sunu Alice Cherian, Janice Tufte, Harold Lehmann\n2023-06-05 vote 5-1 by Cau\u00ea Monaco, Eric Harvey, Paul Whaley, Jesus Lopez-Alcalde, Sunu Alice Cherian, Harold Lehmann"}, {"code": "expert-comments", "valueString": "2023-05-22 comments:\nDefinition: A mathematical model that reflects a set of statistical assumptions with regards to the process governing the generation of sample data from a larger population. \n\nSince we now have Statistical Model Characteristics as a separate hierarchy, might we want to refer to that hierarchy in the Comment for Application. (\"There are many potential components to a statistical model. Those components are represented by the SEVCO hierarchy beginning with...\")\n\n2023-06-05 comment: The comment for application needs to be improved - it is difficult to read and the sentences are not grammatically correct."}, {"code": "approval", "valueString": "2023-06-12 vote 5-0 by Brian S. Alper, Sunu Alice Cherian, Harold Lehmann, Paola Rosati, Eric Harvey"}], "concept": [{"code": "TBD:0000090", "display": "fixed-effect model", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "common-effect model"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "one true effect size"}]}, {"code": "TBD:0000091", "display": "random-effects model", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "random effects"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "true effect sizes are distributed"}]}, {"code": "STATO:0000464", "display": "generalized linear mixed model", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "GLMM"}], "concept": [{"code": "TBD:0000093", "display": "GLMM with probit link"}, {"code": "TBD:0000094", "display": "GLMM with logit link"}, {"code": "TBD:0000095", "display": "GLMM with identity link"}, {"code": "TBD:0000096", "display": "GLMM with log link"}, {"code": "TBD:0000097", "display": "GLMM with generalized logit link"}, {"code": "TBD:0000098", "display": "GLMM with subtype unspecified"}], "property": [{"code": "external-definitions", "valueString": "STATO: linear mixed model (LMM) = \"A lnear mixed model is a mixed model containing both fixed effects and random effects and in which factors and covariates are assumed to have a linear relationship to the dependent variable. These models are useful in a wide variety of disciplines in the physical, biological and social sciences. They are particularly useful in settings where repeated measurements are made on the same statistical units (longitudinal study), or where measurements are made on clusters of related statistical units. Because of their advantage in dealing with missing values, mixed effects models are often preferred over more traditional approaches such as repeated measures ANOVA.\n\nFixed-effects factors are generally considered to be the variables whose values of interest are all represented in the data file.\n\nRandom-effects factors are variables whose values correspond to unwanted variation. They are useful when trying to understand variability in the dependent variable which was not anticipated and exceeds what was expected.\n\nLinear mixed models also allow to specify specific interactions between factors, and allow the evaluation of the various linear effect that a particular combination of factor levels may have on a response variable.\n\nFinally, linear mixed models allow to specify variance components in order to describe the relation between various random effects levels.\""}]}, {"code": "TBD:0000099", "display": "GLM", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "generalized linear model"}], "concept": [{"code": "TBD:0000100", "display": "GLM with probit link"}, {"code": "TBD:0000101", "display": "GLM with logit link", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "logistic regression"}], "property": [{"code": "multiple-parents", "valueString": "TBD:0000099 and TBD:0000106"}]}, {"code": "TBD:0000102", "display": "GLM with identity link", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "linear regression"}], "property": [{"code": "multiple-parents", "valueString": "TBD:0000099 and TBD:0000106"}]}, {"code": "TBD:0000103", "display": "GLM with log link"}, {"code": "TBD:0000104", "display": "GLM with generalized logit link"}, {"code": "TBD:0000105", "display": "GLM with subtype unspecified"}]}]}, {"code": "TBD:0000121", "display": "data transformation", "concept": [{"code": "TBD:0000122", "display": "data imputation", "concept": [{"code": "TBD:0000125", "display": "zero-cell adjustment with constant"}, {"code": "TBD:0000126", "display": "zero-cell adjustment with continuity correction"}]}, {"code": "TBD:0000123", "display": "meta-analysis", "concept": [{"code": "TBD:0000127", "display": "meta-analysis with fixed-effect model", "concept": [{"code": "TBD:0000129", "display": "meta-analysis using inverse variance method"}, {"code": "TBD:0000130", "display": "meta-analysis using Mantel-Haenszel method"}, {"code": "TBD:0000131", "display": "meta-analysis using Peto method"}], "property": [{"code": "external-definitions", "valueString": "STATO: STATO_0000082: fixed effect model = a fixed effect model is a statistical model which represents the observed quantities in terms of explanatory variables that are treated as if the quantities were non-random."}]}, {"code": "TBD:0000128", "display": "meta-analysis with random-effects model", "concept": [{"code": "TBD:0000132", "display": "meta-analysis using DerSimonian-Laird method", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "meta analysis by DerSimonian and Laird method"}], "property": [{"code": "external-definitions", "valueString": "STATO: STATO_0000429: DerSimonian-Laird estimator is a data item computed to estimate heterogeneity parameter (estimate of between-study variance) in a random effect model for meta analysis.  The estimator is used in simple noniterative procedure for characterizing the distribution of treatment effects in a series of studies"}]}, {"code": "TBD:0000133", "display": "meta-analysis using Paule-Mandel method"}, {"code": "TBD:0000134", "display": "meta-analysis using restricted maximum likelihood method", "property": [{"code": "external-definitions", "valueString": "STATO: STATO_0000427: restricted maximum likelihood estimation (REML) = restricted maximum likelihood estimation is a kind of maximum likelihood estimation data transformation which estimates the variance components of random-effects in univariate and multivariate meta-analysis. in contrast to 'maximum likelihood estimation', reml can produce unbiased estimates of variance and covariance parameters."}]}, {"code": "TBD:0000135", "display": "meta-analysis using maximum likelihood method", "property": [{"code": "external-definitions", "valueString": "STATO: STATO_0000428: maximum likelihood estimation = \"maximum likelihood estimation (MLE) is a method of estimating the parameters of a statistical model, given observations. MLE attempts to find the parameter values that maximize the likelihood function, given the observations.\n\nThe method of maximum likelihood is based on the likelihood function, {displaystyle {\\mathcal {L}}(\\theta \\,;x)} {\\displaystyle {\\mathcal {L}}(\\theta \\,;x)}. We are given a statistical model, i.e. a family of distributions {\\displaystyle \\{f(\\cdot \\,;\\theta )\\mid \\theta \\in \\Theta \\}} {\\displaystyle \\{f(\\cdot \\,;\\theta )\\mid \\theta \\in \\Theta \\}}, where {\\displaystyle \\theta } \\theta  denotes the (possibly multi-dimensional) parameter for the model. The method of maximum likelihood finds the values of the model parameter, {\\displaystyle \\theta } \\theta , that maximize the likelihood function, {\\displaystyle {\\mathcal {L}}(\\theta \\,;x)} {\\displaystyle {\\mathcal {L}}(\\theta \\,;x)}. I\""}]}, {"code": "TBD:0000136", "display": "meta-analysis using empirical Bayes method", "property": [{"code": "external-definitions", "valueString": "NCI Code         CDISC Submission Value      CDISC Synonym          NCI Preferred Term    CDISC Definition\n\nC142403          Bayesian approaches             _                                           Bayesian Approach        \n\nApproaches to data analysis that provide a posterior probability distribution for some parameter (e.g., treatment effect), derived from the observed data and a prior probability distribution for the parameter. The posterior distribution is then used as the basis for statistical inference. [ICH E9 Glossary]\n\nC142404          Bayesian statistics                   _                                           Bayesian Statistics        \n\nStatistical approach named for Thomas Bayes (1701-1761) that has among its features giving a subjective interpretation to probability, accepting the idea that it is possible to talk about the probability of hypotheses being true and of parameters having particular values."}]}, {"code": "TBD:0000137", "display": "meta-analysis using Hunter-Schmidt method", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "meta analysis by Hunter-Schmidt method"}], "property": [{"code": "external-definitions", "valueString": "STATO: STATO_0000426: Hunter-Schmidt estimator = Hunter-Schmidt estimator is a data item computed to estimate heterogeneity parameter (estimate of between-study variance) in a random effect model for meta analysis."}]}, {"code": "STATO:0000430", "display": "meta-analysis using Hartung-Knapp-Sidik-Jonkman method", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "may need to add synonyms of HKSJ method, Hartung-Knapp method, Sidik-Jonkman method"}], "property": [{"code": "external-definitions", "valueString": "STATO: a random effect meta analysis procedure defined by Hartung and Knapp and by Sidik and Jonkman which performs better than DerSimonian and Laird approach, especially when there is heterogeneity and the number of studies in the meta-analysis is small.\nalso STATO_0000425 Sidik-Jonkman estimator = Sidik-Jonkman estimator is a data item computed to estimate heterogeneity parameter (estimate of between-study variance) in a random effect model for meta analysis."}]}, {"code": "TBD:0000139", "display": "meta-analysis using modified Knapp-Hartung method", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "meta-analysis using mKH method"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "meta-analysis using modified Hartung-Knapp method"}]}, {"code": "TBD:0000140", "display": "meta-analysis using Hedges method"}], "property": [{"code": "external-definitions", "valueString": "STATO: STATO_0000099: random effect model (variance components model) = a random effect(s) model, also called a variance components model, is a kind of hierarchical linear model. It assumes that the dataset being analysed consists of a hierarchy of different populations whose differences relate to that hierarchy."}]}]}, {"code": "TBD:0000124", "display": "statistical hypothesis test", "concept": [{"code": "TBD:0000141", "display": "between group comparison statistical test", "concept": [{"code": "TBD:0000146", "display": "ANOVA", "concept": [{"code": "TBD:0000150", "display": "multivariate ANOVA", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "MANOVA"}]}, {"code": "STATO:0000048", "display": "multiway ANOVA", "definition": "child term ?? 3-way ANOVA", "property": [{"code": "external-definitions", "valueString": "STATO: Multi-way ANOVA is an analysis of variance where the difference groups being compared are associated to the factor levels of more than 2 independent variables. The null hypothesis is an absence of difference between the means calculated for each of the groups. The test assumes normality and equivariance of the data."}]}, {"code": "STATO:0000044", "display": "one-way ANOVA", "property": [{"code": "external-definitions", "valueString": "STATO: one-way ANOVA (one factor ANOVA) = one-way ANOVA is an analysis of variance where the different groups being compared are associated with the factor levels of only one independent variable. The null hypothesis is an absence of difference between the means calculated for each of the groups. The test assumes normality and equivariance of the data."}]}, {"code": "TBD:0000153", "display": "repeated measure ANOVA"}, {"code": "STATO:0000045", "display": "two-way ANOVA", "definition": "child terms ?? 2-way ANOVA without replication ?? 2-way ANOVA with replication", "property": [{"code": "external-definitions", "valueString": "STATO: two-way ANOVA (two factor ANOVA) = two-way ANOVA is an analysis of variance where the different groups being compared are associated the factor levels of exatly 2 independent variables. The null hypothesis is an absence of difference between the means calculated for each of the groups. The test assumes normality and equivariance of the data."}]}], "property": [{"code": "external-definitions", "valueString": "STATO: uses OBI_0200201: ANOVA or analysis of variance is a data transformation in which a statistical test of whether the means of several groups are all equal."}]}, {"code": "TBD:0000147", "display": "non-parametric test", "concept": [{"code": "STATO:0000094", "display": "Kruskal-Wallis test", "property": [{"code": "external-definitions", "valueString": "STATO: Kruskal Wallis test (rank-sum test for the comparison of multiple (more than 2) samples.; H test) = \"The Kruskal\u2013Wallis test is a null hypothesis statistical testing objective which  allows multiple (n>=2) groups (or conditions or treatments) to be compared, without making the assumption that values are normally distributed. The Kruskal\u2013Wallis test is the non-parametric equivalent of the independent samples ANOVA.\nThe Kruskal\u2013Wallis test is most commonly used when there is one nominal variable and one measurement variable, and the measurement variable does not meet the normality assumption of an ANOVA.\""}]}, {"code": "TBD:0000156", "display": "log rank test"}, {"code": "STATO:0000076", "display": "Mann-Whitney U-test", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "Wilcoxon rank-sum test"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "U test"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "Wilcoxon rank-sum test"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "rank-sum test for the comparison of two samples"}], "property": [{"code": "external-definitions", "valueString": "STATO: \"The Mann-Whitney U-test is a null hypothesis statistical testing procedure which allows two groups (or conditions or treatments) to be compared without making the assumption that values are normally distributed. \nThe Mann-Whitney test is the non-parametric equivalent of the t-test for independent samples\""}]}, {"code": "STATO:0000433", "display": "McNemar test", "property": [{"code": "external-definitions", "valueString": "STATO: McNemar test (McNemar's Chi-squared Test for Count Data; test of the marginal homogeneity of a contingency table; within-subjects chi-squared test) = \"McNemar's test is a statistical test used on paired nominal data. It is applied to 2 \u00d7 2 contingency tables with a dichotomous trait, with matched pairs of subjects, to determine whether the row and column marginal frequencies are equal (that is, whether there is \"\"marginal homogeneity\"\"). It is named after Quinn McNemar, who introduced it in 1947.\nAn application of the test in genetics is the transmission disequilibrium test for detecting linkage disequilibrium\""}]}, {"code": "TBD:0000159", "display": "sign test"}, {"code": "TBD:0000160", "display": "Friedman test"}]}, {"code": "TBD:0000148", "display": "two sample t-test", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "2-sample t-test, independent"}], "concept": [{"code": "STATO:0000303", "display": "two sample t-test with equal variance", "property": [{"code": "external-definitions", "valueString": "STATO: two sample t-test with equal variance (t-test for independent means assuming equal variance; two sample t-test) = two sample t-test is a null hypothesis statistical test which is used to reject or accept the hypothesis of absence of difference between the means over 2 randomly sampled populations.\nIt uses a t-distribution for the test and assumes that the variables in the population are normally distributed and with equal variances."}]}, {"code": "STATO:0000304", "display": "two sample t-test with unequal variance", "property": [{"code": "external-definitions", "valueString": "STATO: two sample t-test with unequal variance (t-test for independent means assuming unequal variance; Welsh t-test) = Welch t-test is a two sample t-test used when the variances of the 2 populations/samples are thought to be unequal (homoskedasticity hypothesis not verified). In this version of the two-sample t-test, the denominator used to form the t-statistics, does not rely on a 'pooled variance' estimate."}]}]}, {"code": "STATO:0000052", "display": "z test for between group comparison", "property": [{"code": "external-definitions", "valueString": "STATO: Z-test is a statistical test which evaluate the null hypothesis that the means of 2 populations are equal and returns a p-value."}]}, {"code": "TBD:ANCOVA", "display": "ANCOVA", "definition": "analysis of covariance (ANCOVA)"}]}, {"code": "TBD:0000142", "display": "chi square test", "concept": [{"code": "TBD:0000163", "display": "chi square test for homogeneity"}, {"code": "STATO:0000074", "display": "Mantel-Haenszel method", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "Cochran-Mantel-Haenszel chi-squared test for count data"}], "property": [{"code": "external-definitions", "valueString": "STATO: Cochran-Mantel-Haenzel test for repeated tests of independence (CHM test; Mantel\u2013Haenszel test) = \"Cochran-Mantel-Haenzel test for repeated tests of independence is a statitiscal test which allows the comparison of two groups on a dichotomous/categorical response. It is used when the effect of the explanatory variable on the response variable is influenced by covariates that can be controlled. It is often used in observational studies where random assignment of subjects to different treatments cannot be controlled, but influencing covariates can.\nThe null hypothesis is that the two nominal variables that are tested within each repetition are independent of each other. So there are 3 variables to consider: two categorical variables to be tested for independence of each other, and the third variable identifies the repeats.\""}]}, {"code": "TBD:0000165", "display": "Pearson\u2019s chi square test of goodness of fit"}, {"code": "TBD:0000166", "display": "Pearson\u2019s chi square test of goodness of independence between categorical variables", "concept": [{"code": "TBD:0000167", "display": "Yate\u2019s corrected chi-squared test"}]}], "property": [{"code": "external-definitions", "valueString": "STATO: from OBI_0200200: The chi-square test is a data transformation with the objective of statistical hypothesis testing, in which the sampling distribution of the test statistic is a chi-square distribution when the null hypothesis is true, or any in which this is asymptotically true, meaning that the sampling distribution (if the null hypothesis is true) can be made to approximate a chi-square distribution as closely as desired by making the sample size large enough."}]}, {"code": "TBD:0000143", "display": "single-sample reference comparison statistical test", "concept": [{"code": "STATO:0000302", "display": "one sample t-test", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "1-sample t-test"}], "property": [{"code": "external-definitions", "valueString": "STATO: \"one sample t-test is a kind of Student's t-test which evaluates if a given sample can be reasonably assumed to be taken from the population.\nThe test compares the sample statistic (m) to the population parameter (M).\n\nThe one sample t-test is the small sample analog of the z test, which is suitable for large samples.\""}]}, {"code": "TBD:0000169", "display": "z test for single-sample"}]}, {"code": "TBD:0000144", "display": "test of association between categorical variables", "concept": [{"code": "STATO:0000148", "display": "Cochran-Armitage test for trend", "property": [{"code": "external-definitions", "valueString": "STATO: \"The Cochran-Armitage test (CATT) s a statistical test used in categorical data analysis when the aim is to assess for the presence of an association between a dichotomous variable (variable with two categories) and a polychotomous variable  (a variable with k categories).\n\nThe two-level variable represents the response, and the other represents an explanatory variable with ordered levels. The null hypothesis is the hypothesis of no trend, which means that the binomial proportion is the same for all levels of the explanatory variable\n\nFor example, doses of a treatment can be ordered as 'low', 'medium', and 'high', and we may suspect that the treatment benefit cannot become smaller as the dose increases. The trend test is often used as a genotype-based test for case-control genetic association studies.\""}]}, {"code": "STATO:0000073", "display": "Fisher\u2019s exact test", "property": [{"code": "external-definitions", "valueString": "STATO: Fisher's exact test is a statistical test used to determine if there are nonrandom associations between two categorical variables."}]}]}, {"code": "TBD:0000145", "display": "within subject comparison statistical test", "concept": [{"code": "STATO:0000095", "display": "paired t-test", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "2-sample t-test, dependent"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "matched pair t-test"}], "property": [{"code": "external-definitions", "valueString": "STATO: paired t-test (t-test for dependent means) = paired t-test is a statistical test which is specifically designed to analysis differences between paired observations in the case of studies realizing repeated measures design with only 2 repeated measurements per subject (before and after treatment for example)"}]}, {"code": "STATO:0000092", "display": "Wilcoxon signed rank test", "property": [{"code": "external-definitions", "valueString": "STATO: \"The Wilcoxon signed rank test is a statistical test which tests the null hypothesis that the median difference between pairs of observations is zero. This is the non-parametric analogue to the paired t-test, and should be used if the distribution of differences between pairs may be non-normally distributed.\n\nThe procedure involves a ranking, hence the name. The absolute value of the differences between observations are ranked from smallest to largest, with the smallest difference getting a rank of 1, then next larger difference getting a rank of 2, etc. Ties are given average ranks. The ranks of all differences in one direction are summed, and the ranks of all differences in the other direction are summed. The smaller of these two sums is the test statistic, W (sometimes symbolized Ts). Unlike most test statistics, smaller values of W are less likely under the null hypothesis.\""}]}]}, {"code": "TBD:permutation-test", "display": "permutation test", "concept": [{"code": "TBD:prospective-sample-permutation-testing", "display": "prospective sample permutation testing"}, {"code": "TBD:retrospective-sample-permutation-testing", "display": "retrospective sample permutation testing"}]}]}, {"code": "TBD:0000Log", "display": "logarithm"}]}, {"code": "TBD:model-characteristics", "display": "statistical model characteristic", "definition": "An aspect, attribute, or feature of a statistical model.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "statistical model attribute"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "generative model characteristic"}], "property": [{"code": "comment", "valueString": "A statistical model is defined as a set of mathematical relationships that express assumptions related to the generation of the observed data and that sets constraints for the analysis of the data."}, {"code": "editors", "valueString": "Brian S. Alper, Joanne Dehnbostel, Kenneth Wilkins, Muhammad Afzal"}, {"code": "approval", "valueString": "2023-06-05 vote 6-0 by Cau\u00ea Monaco, Eric Harvey, Paul Whaley, Jesus Lopez-Alcalde, Sunu Alice Cherian, Harold Lehmann"}], "concept": [{"code": "TBD:0000118", "display": "statistical model goal", "concept": [{"code": "TBD:0000119", "display": "adjustment for clustering"}, {"code": "TBD:0000120", "display": "adjustment for covariates"}, {"code": "TBD:participant-inclusion-criteria-for-analysis", "display": "participant inclusion criteria for analysis", "concept": [{"code": "TBD:ITTA", "display": "intention-to-treat analysis"}, {"code": "TBD:PPA", "display": "per-protocol analysis"}, {"code": "TBD:participant-inclusion-criteria-for-secondary-analysis", "display": "participant inclusion criteria for secondary analysis"}]}, {"code": "TBD:data-inclusion-criteria-for-analysis", "display": "data inclusion criteria for analysis", "concept": [{"code": "TBD:data-inclusion-criteria-for-secondary-analysis", "display": "data inclusion criteria for secondary analysis"}]}, {"code": "TBD:handling-of-missing-endpoint-data", "display": "handling of missing endpoint data", "concept": [{"code": "TBD:single-imputation-by-LOCF", "display": "single imputation by last-observation-carried-forward (LOCF)"}]}, {"code": "TBD:sample-size", "display": "sample size estimation", "property": [{"code": "comment", "valueString": "The term 'sample size estimation' may be applied to hypothesis testing-based sample size calculation."}], "concept": [{"code": "TBD:sample-size-per-group", "display": "sample size per group"}, {"code": "TBD:number-of-permutations-sampled", "display": "number of permutations sampled"}]}, {"code": "TBD:net-effect-analysis", "display": "net effect analysis", "concept": [{"code": "TBD:OutcomeSetNetEffect", "display": "set of outcomes (for a net effect analysis)"}]}, {"code": "TBD:primary-analytic-method", "display": "primary analytic method"}, {"code": "TBD:identify-source-of-interaction", "display": "identify source(s) of significant interaction"}, {"code": "TBD:rank-based-analytic-method", "display": "rank-based analytic method"}]}, {"code": "TBD:statistical-model-assumption", "display": "statistical model assumption", "concept": [{"code": "TBD:assumption001", "display": "data distribution assumption of normal distribution", "definition": "Assumption that the observed data in each comparison group follows a normal distribution."}, {"code": "TBD:assumption002", "display": "data distribution assumption of equal standard deviations", "definition": "Assumption that the observed data across comparison groups have the same standard deviation."}, {"code": "TBD:assumption003", "display": "data distribution assumption of asymptotic approximation", "definition": "Assumption that there is sufficient data across the distribution to permit using an approximation that is [asymptotic]."}]}, {"code": "TBD:statistical-model-assumption-assessment", "display": "statistical model assumption assessment", "concept": [{"code": "TBD:assumption-assessment-001", "display": "all the expected counts in the cells of the contingency table  meet or exceed a threshold"}]}, {"code": "TBD:statistical-software-package", "display": "statistical software package"}, {"code": "TBD:predicted", "display": "predicted value", "definition": "TBD after example modeling"}, {"code": "STATO:0000299", "display": "statistical inference paradigm", "definition": "A set of fundamental assumptions underlying the quantitative process of using data analysis to deduce properties of a probability distribution.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "statistical inference approach"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "approach to statistical inference"}], "property": [{"code": "editors", "valueString": "Harold Lehmann, Brian S. Alper, Janice Tufte"}, {"code": "negative-vote", "valueString": "2024-09-16 vote 9-1 by C P Ooi, Bhagvan Kommadi, Carlos Alva-Diaz, Cau\u00ea Monaco, Javier Bracchiglione, Sheyu Li, Airton Tetelbom Stein, Lenny Vasanthan, Eric Harvey, Janice Tufte"}, {"code": "expert-comments", "valueString": "2024-09-16 comment re: \"statistical inference paradigm\" = \"A set of fundamental assumptions underlying the quantitative process of using data analysis to deduce properties of a probability distribution.\"1N)\nThe definition confuses me. It is unclear why this paradigm is a fixed set or a contextualised set. A comment here may be necessary."}, {"code": "comment", "valueString": "In this definition, the phrase \"fundamental assumptions\" refers to the foundational framework underlying specific statistical analyses, such as the Bayesian approach or the frequentist approach. Other less commonly used statistical inference paradigms include resampling methods, fiducial inference, pragmatic inference, and likelihoodist paradigm."}, {"code": "approval", "valueString": "2024-09-30 vote 6-0 by Eric Harvey, Arnav Agarwal, Airton Tetelbom Stein, Homa Keshavarz, Carlos Alva-Diaz, Javier Bracchiglione"}], "concept": [{"code": "TBD:Bayesian", "display": "Bayesian inference", "definition": "A statistical inference paradigm in which the assumptions are that parameters are random variables with probability distributions, that prior knowledge can be represented with such distributions, and that one learns from data by updating those prior distributions using Bayes' Rule.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "Bayesian approach"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "Bayesian statistical inference paradigm"}], "property": [{"code": "external-definitions", "valueString": "NCI Code         CDISC Submission Value      CDISC Synonym          NCI Preferred Term    CDISC Definition\n\nC142403          Bayesian approaches             _                                           Bayesian Approach        \n\nApproaches to data analysis that provide a posterior probability distribution for some parameter (e.g., treatment effect), derived from the observed data and a prior probability distribution for the parameter. The posterior distribution is then used as the basis for statistical inference. [ICH E9 Glossary]\n\nC142404          Bayesian statistics                   _                                           Bayesian Statistics        \n\nStatistical approach named for Thomas Bayes (1701-1761) that has among its features giving a subjective interpretation to probability, accepting the idea that it is possible to talk about the probability of hypotheses being true and of parameters having particular values."}, {"code": "editors", "valueString": "Harold Lehmann, Kenneth Wilkins"}, {"code": "comment", "valueString": "Regarding random variables with probability distribution: These random variables are often used to represent population parameters, but there are other types of random variables, e.g., representing typical methodological concerns, where the typical notion of \u201cpopulation\u201d does not apply.\n\nRegarding prior knowledge: The notion of representing prior knowledge as a probability distribution is the core of disagreement among statisticians around Bayesian inference. For those interpreting \u201cprobability\u201d as \u201cmeasure of belief\u201d, prior probability distributions encodes belief about the parameters (\u201csubjectivist Bayes\u201d), and ignorance is represented as a \u201cnon-informative\u201d prior. For those with a more frequentist interpretation of probability, such priors summarizes frequency knowledge seen in the past (\u201cempirical Bayes\u201d).\n\nRegarding Bayes\u2019 Rule: Probability theory, with no assumptions beyond regular probability, says that P(A|B) = P(B|A) P(A). Bayes Rule says that one can (should) use this formula to update knowledge from data: P(parameter value | data) = P(data | parameter value) P(Data), with P(data | parameter value) being called the \u201clikelihood function,\u201d communicating how likely data are, given parameter values (and what type of distribution the parameter(s) connote), and could be use to reflect sampling, if relevant."}, {"code": "approval", "valueString": "2024-09-30 vote 6-0 by Carlos Alva-Diaz, Eric Harvey, Arnav Agarwal, Airton Tetelbom Stein, Homa Keshavarz, Javier Bracchiglione"}]}, {"code": "TBD:frequentist", "display": "frequentist inference", "definition": "A statistical inference paradigm in which the assumptions are that probabilities reflect relative frequencies of events and that the probability of observing data are governed by fixed yet unknown population parameters.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "frequentist approach"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "frequentist statistical inference paradigm"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "classical statistical approach"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "classical inference"}], "property": [{"code": "comment", "valueString": "The frequentist inference is based on hypothetical repeated sampling and the resulting relative frequencies in the long run. Inferences are based on point and interval estimates. For hypothesis testing, the inference is based on the probability of obtaining values equal to or more extreme than the observed data."}, {"code": "editors", "valueString": "Harold Lehmann, Kenneth Wilkins, Muhammad Afzal, Joanne Dehnbostel"}, {"code": "approval", "valueString": "2024-09-30 vote 6-0 by Eric Harvey, Arnav Agarwal, Airton Tetelbom Stein, Homa Keshavarz, Carlos Alva-Diaz, Javier Bracchiglione"}]}]}]}, {"code": "TBD:model-component", "display": "statistical model component", "definition": "A part of a statistical model.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Muhammad Afzal, Joanne Dehnbostel, Harold Lehmann"}, {"code": "comment", "valueString": "A statistical model is defined as a set of mathematical relationships that express assumptions related to the generation of the observed data and that sets constraints for the analysis of the data.\nStatistical model components include graphical structures (e.g. directed acyclic graph), equations (e.g. regression model form), components of equations (e.g. covariate term), and distributional assumptions (e.g. regression error distribution)."}, {"code": "approval", "valueString": "2023-06-05 vote 6-0 by Cau\u00ea Monaco, Eric Harvey, Paul Whaley, Jesus Lopez-Alcalde, Sunu Alice Cherian, Harold Lehmann"}], "concept": [{"code": "TBD:0000088", "display": "covariate term"}, {"code": "STATO:0000469", "display": "interaction term", "property": [{"code": "external-definitions", "valueString": "STATO: model interaction effect term = a model interaction effect term is a model term which accounts for variation explained by the combined effects of the factor levels of more than one (usually 2) independent variables."}]}, {"code": "TBD:likelihoodfunction", "display": "likelihood function"}, {"code": "TBD:0000106", "display": "regression model form", "concept": [{"code": "TBD:0000102", "display": "linear regression", "definition": "see GLM with identity link (same term IS-A GLM)", "property": [{"code": "multiple-parents", "valueString": "true"}, {"code": "external-definitions", "valueString": "STATO: STATO_0000108: linear regression for analysis of continuous dependent variable = \"linear regression model is a model which attempts to explain data distribution associated with response/dependent variable in terms of values assumed by the independent variable uses a linear function or linear combination of the regression parameters and the predictor/independent variable(s).\nlinear regression modeling makes a number of assumptions, which includes homoskedasticity (constance of variance)\""}]}, {"code": "TBD:0000101", "display": "logistic regression", "definition": "see GLM with logit link (same term IS-A GLM)", "property": [{"code": "multiple-parents", "valueString": "true"}]}, {"code": "TBD:0000107", "display": "log linear regression"}, {"code": "TBD:0000108", "display": "polynomial regression"}, {"code": "TBD:0000109", "display": "Cox proportional hazards"}]}]}, {"code": "TBD:PDA", "display": "probability distribution attribute", "definition": "An aspect, characteristic, or feature of a probability distribution.", "property": [{"code": "comment", "valueString": "A probability distribution is represented by a combination of probability distribution attributes."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Muhammad Afzal"}, {"code": "approval", "valueString": "2023-10-09 vote 5-0 by Louis Leff, Jesus Lopez-Alcalde, Harold Lehmann,: Eric Harvey, Mario Tristan"}], "concept": [{"code": "TBD:0000110", "display": "probability distribution class", "definition": "A probability distribution attribute that communicates how the likelihood of a specified outcome is calculated.", "property": [{"code": "comment", "valueString": "The probability distribution class defines the assumed model. Parametric probability distribution classes are determined by parameters."}, {"code": "editors", "valueString": "Harold Lehmann, Kenneth Wilkins, Brian S. Alper, Muhammad Afzal, Joanne Dehnbostel"}, {"code": "approval", "valueString": "2023-10-09 vote 5-0 by Louis Leff, Jesus Lopez-Alcalde, Harold Lehmann, Eric Harvey, Mario Tristan"}], "concept": [{"code": "TBD:0000111", "display": "normal distribution", "definition": "A probability distribution class in which instances are unimodal, symmetric, and defined by two parameters, mean and standard deviation.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "Gaussian distribution"}], "property": [{"code": "external-definitions", "valueString": "Term IRI: http://purl.obolibrary.org/obo/STATO_0000227\nDefinition: A normal distribution is a continuous probability distribution described by a probability distribution function described here: http://mathworld.wolfram.com/NormalDistribution.html"}, {"code": "comment", "valueString": "Normal distribution is commonly used to approximate the sampling distribution of quantities estimated from samples.\nVariance is the square of standard deviation. Variance is sometimes used instead of standard deviation as a parameter for defining a normal distribution.\nStandard normal distribution is a special case of normal distribution with a mean = 0, variance = 1, and kurtosis = 3.\nAll normal distributions have skewness = 0."}, {"code": "editors", "valueString": "Philippe Rocca-Serra, Ken Wilkins, Joanne Dehnbostel, Khalid Shahin, Brian S. Alper, Harold Lehmann"}, {"code": "approval", "valueString": "2023-08-07 vote 5-0 by Joanne Dehnbostel, Mario Tristan, Philippe Rocca-Serra, Eric Harvey, Harold Lehmann"}]}, {"code": "STATO:0000438", "display": "log normal distribution", "definition": "A probability distribution class in which the logarithm transformed values of a variable follow a normal distribution. Instances of the log normal distribution class are unimodal and skewed. Variables can only be non-negative real values.", "property": [{"code": "comment", "valueString": "Log normal distribution is commonly used to approximate the distribution of times and costs.\nThe mean of a log normal distribution is the geometric mean of the log transformed values.\nLog transformed means the natural log of values replace those values.\n\nNormal distribution is defined as a probability distribution class in which instances are unimodal, symmetric, and defined by two parameters, mean and standard deviation."}, {"code": "editors", "valueString": "Harold Lehmann, Kenneth Wilkins, Joanne Dehnbostel, Brian S. Alper, Khalid Shahin"}, {"code": "negative-vote", "valueString": "2023-08-07 vote 4-1 by Joanne Dehnbostel, Mario Tristan, Philippe Rocca-Serra, Eric Harvey, Harold Lehmann"}, {"code": "expert-comments", "valueString": "2023-08-07 comment: (tweak to the definition):\nA probability distribution class in which the logarithm transformed values of a variable follow a normal distribution. Instances of the log normal distribution class are unimodal and skewed. \n\nSTATO_0000438"}, {"code": "approval", "valueString": "2023-10-09 vote 5-0 by Louis Leff, Jesus Lopez-Alcalde, Harold Lehmann, Eric Harvey, Mario Tristan"}]}, {"code": "STATO:0000160", "display": "exponential distribution", "definition": "A probability distribution class defined by a single parameter, rate. Instances of the exponential distribution class are unimodal and skewed. Variables can only be non-negative real values.", "property": [{"code": "comment", "valueString": "Exponential distribution is commonly used to represent the distribution of independent events occurring at the same rate over time.\n\nThe mean and standard deviation of an exponential distribution are each the reciprocal of the rate."}, {"code": "editors", "valueString": "Harold Lehmann, Kenneth Wilkins, Joanne Dehnbostel, Brian S. Alper, Khalid Shahin"}, {"code": "negative-vote", "valueString": "2023-08-07 vote 4-1 by Joanne Dehnbostel, Mario Tristan, Philippe Rocca-Serra, Eric Harvey, Harold Lehmann"}, {"code": "expert-comments", "valueString": "2023-08-07 comment: (tweak to the definition):\nA probability distribution class defined by a single parameter, rate and commonly used to represent the distribution of independent events occurring at the same rate over time. Instances of the exponential distribution class are unimodal, skewed, \n\nSTATO_0000160"}, {"code": "approval", "valueString": "2023-10-09 vote 5-0 by Louis Leff, Jesus Lopez-Alcalde, Harold Lehmann, Eric Harvey, Mario Tristan"}]}, {"code": "STATO:0000149", "display": "binomial distribution", "definition": "A probability distribution class defined by two parameters: the number of independent trials, n, and the probability of success, p.  Variables can only be dichotomous values.", "property": [{"code": "external-definitions", "valueString": "STATO: binomial logistic regression for analysis of dichotomous dependent variable = binomial logistic regression model is a model which attempts to explain data distribution associated with *dichotomous* response/dependent variable in terms of values assumed by the independent variable uses a function of predictor/independent variable(s): the function used in this instance of regression modeling is logistic function.\n\nalso STATO_0000276: binomial distribution = The binomial distribution is a discrete probability distribution which describes the probability of k successes in n draws with replacement from a finite population of size N.\n\nThe binomial distribution is frequently used to model the number of successes in a sample of size n drawn with replacement from a population of size N.\n\nThe binomial distribution gives the discrete probability distribution  of obtaining exactly n successes out of N Bernoulli trials (where the result of each Bernoulli trial is true with probability p and false with probability q=1-p )\n\nnotation: B(n,p)\n\nThe mean is N*p\n\nThe variance is N*p*q"}, {"code": "comment", "valueString": "Binomial distribution is commonly used to approximate the probability of a dichotomous state (presence/absence, success/failure, true/false).\n\nThe mean of a binomial distribution is the number of independent trials, n, multiplied by the probability of success, p.  n * p\n\nThe variance of a binomial distribution is the number of independent trials, n, multiplied by the probability of success, p, multiplied by the probability of failure, 1-p.  n * p * q where q = 1 - p"}, {"code": "editors", "valueString": "Joanne Dehnbostel, Kenneth Wilkins, Muhammad Afzal, Brian S. Alper"}, {"code": "approval", "valueString": "2023-10-09 vote 5-0 by Louis Leff, Jesus Lopez-Alcalde, Harold Lehmann, Eric Harvey, Mario Tristan"}]}, {"code": "STATO:0000109", "display": "multinomial distribution", "definition": "A probability distribution class defined by multiple parameters: the number of independent trials, n, the number of categories, k, and k-1 probabilities of success.  Variables can only be polychotomous values.", "property": [{"code": "external-definitions", "valueString": "STATO: multinomial logistic regression for analysis of dichotomous dependent variable = multinomial logistic regression model is a model which attempts to explain data distribution associated with *polychotomous* response/dependent variable in terms of values assumed by the independent variable uses a function of predictor/independent variable(s): the function used in this instance of regression modeling is logistic function.\n\nalso multinomial distribution (STATO_0000103) = the multinomial distribution is a probability distribution which gives the probability of any particular combination of numbers of successes for various categories defined in the context of  n independent trials each of which leads to a success for exactly one of k categories, with each category having a given fixed success probability."}, {"code": "comment", "valueString": "Multinomial distribution is commonly used to approximate the probability of a categorical outcome across a discrete number of mutually exclusive possible categories. A classic example is rolling a six-sided die.\n\nFor *n* independent trials, the expected (mean) number of times category *i* will appear is *n* multiplied by the probability of success, *p<sub>i</sub>*.  *n* * *p<sub>i</sub>*\nThe variance of that expectation is *n* multiplied by *p<sub>i</sub>* multiplied by the probability of failure, 1-*p<sub>i</sub>*"}, {"code": "editors", "valueString": "Harold Lehmann, Joanne Dehnbostel, Brian S. Alper"}, {"code": "approval", "valueString": "2023-10-09 vote 5-0 by Louis Leff, Jesus Lopez-Alcalde, Harold Lehmann, Eric Harvey, Mario Tristan"}]}, {"code": "STATO:0000051", "display": "Poisson distribution", "definition": "A probability distribution class defined by one parameter: a non-negative real number, ?. Random variables following a Poisson distribution can only have non-negative integer values.", "property": [{"code": "external-definitions", "valueString": "STATO: STATO_0000051 is Poisson distribution = \"Poisson distribution is a probability distribution used to model the number of events occurring within a given time interval. It is defined by a real number (?) and an integer k representing the number of events and a function.\nThe expected value of a Poisson-distributed random variable is equal to ? and so is its variance.\""}, {"code": "comment", "valueString": "Poisson distribution is commonly used to approximate the number (count) of events occurring within a given time interval or given spatial region.\nThe expected value of a Poisson-distributed random variable is equal to ? and so is its variance."}, {"code": "editors", "valueString": "Harold Lehmann, Joanne Dehnbostel, Brian S. Alper, Muhammad Afzal"}, {"code": "expert-comments", "valueString": "2023-10-02 comment: The other definitions include something about what is called the \"support\" (binary, polychotomous). Here, we should say, to be consistent, \"Variables can take on only non-negative integral values.\""}, {"code": "approval", "valueString": "2023-11-20 vote 5-0 by Brian S. Alper, Jesus Lopez-Alcalde, Harold Lehmann, Muhammad Afzal, Eric Harvey"}, {"code": "negative-vote", "valueString": "2023-10-09 vote 5-0 by Louis Leff, Jesus Lopez-Alcalde, Harold Lehmann, Eric Harvey, Mario Tristan BUT definition changed based on comment"}]}, {"code": "STATO:0000283", "display": "negative binomial distribution", "definition": "A probability distribution class for discrete data of the number of successes in a sequence of Bernoulli trials before a specified number (denoted r) of failures occur.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "Pascal distribution"}], "property": [{"code": "external-definitions", "valueString": "STATO: STATO_0000283: negative binomial distribution (Pascal distribution; P\u00f3lya distribution) = negative binomial probability distribution is a discrete probability distribution of the number of successes in a sequence of Bernoulli trials before a specified (non-random) number of failures (denoted r) occur. The negative binomial distribution, also known as the Pascal distribution or P\u00f3lya distribution, gives the probability of  r-1 successes and x  failures in x+r-1 trials, and success on the (x+r)th trial."}, {"code": "comment", "valueString": "The negative binomial distribution, also known as the Pascal distribution, gives the probability of  r-1 successes and x  failures in x+r-1 trials, and success on the (x+r)th trial. P\u00f3lya distribution is a variation of negative binomial distribution used for all real numbers, not just non-negative integers."}, {"code": "editors", "valueString": "Harold Lehmann, Kenneth Wilkins, Muhammad Afzal, Joanne Dehnbostel, Brian S. Alper"}, {"code": "approval", "valueString": "2023-10-09 vote 5-0 by Louis Leff, Jesus Lopez-Alcalde, Harold Lehmann, Eric Harvey, Mario Tristan"}]}]}, {"code": "TBD:mu", "display": "distribution mean", "definition": "A probability distribution attribute that represents the expected value of a variable that has that distribution.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Kenneth Wilkins, Joanne Dehnbostel, Muhammad Afzal"}, {"code": "comment", "valueString": "For a normal distribution, the distribution parameter mean (also called \u00b5 or mu) coincides with the mean of the distribution."}, {"code": "expert-comments", "valueString": "2023-06-12 comments: mu represents population mean. It is a measure of central tendency that represents the average value of a variable within an entire population.\n\nTo avoid any ambiguity, rather than mu I would use the Alternative term \u00b5.\nAs reported by Wikipedia:\nIn Ancient Greek, the name of the letter was written \u00b5? and pronounced [my?], but in Modern Greek, the letter is spelled \u00b5? and pronounced [mi]. In polytonic orthography, it is written with an acute accent: \u00b5?."}, {"code": "negative-vote", "valueString": "2023-06-12 vote 2-2 by Sunu Alice Cherian, Harold Lehmann, Paola Rosati, Eric Harvey"}, {"code": "approval", "valueString": "2023-10-09 vote 5-0 by Louis Leff, Jesus Lopez-Alcalde, Harold Lehmann, Eric Harvey, Mario Tristan"}]}, {"code": "STATO:0000694", "display": "distribution standard deviation", "definition": "A probability distribution attribute that is the square root of the distribution variance.", "property": [{"code": "statistical-purpose", "valueString": "Measure of Dispersion"}, {"code": "comment", "valueString": "A distribution variance is defined as a probability distribution attribute that is the expected value of the square of the difference of the value of a variable that has that distribution from its expected value.\n\nFor a normal distribution, the distribution parameter standard deviation (also called s or sigma) coincides with the standard deviation of the distribution. Standard deviation is defined as a measure of dispersion that represents the average of the distances from the mean of the dataset to each data point in the dataset."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Kenneth Wilkins"}, {"code": "negative-vote", "valueString": "2023-06-12 vote 3-1 by Sunu Alice Cherian, Harold Lehmann, Paola Rosati, Eric Harvey"}, {"code": "expert-comments", "valueString": "2023-06-12 comment: sigma represents population standard deviation, It is a measure of the dispersion or spread of data points within an entire population."}, {"code": "approval", "valueString": "2023-10-16 vote 5-0 by Harold Lehmann, Eric Harvey,: Muhammad Afzal, Louis Leff, Jesus Lopez-Alcalde"}]}, {"code": "TBD:model-parameter", "display": "probability distribution parameter", "definition": "A member of a set of quantities that unambiguously defines a probability distribution function.", "property": [{"code": "comment", "valueString": "Parameters serve different roles in defining distributions. Location parameters define the position along the range of possible values. Shape and scale parameters define the dispersion around the expected value.\n\nWhen the probability distribution parameters have values, the set of values defines a particular probability distribution function.\n\nWhen a statistic applies to a specific set of data, the specific set of data is called a sample and the statistic is called the sample statistic.  Likewise, when a probability distribution parameter applies to the group from which a sample may be derived, the group is called a population and the probability distribution parameter is called a population parameter."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Kenneth Wilkins, Joanne Dehnbostel"}, {"code": "approval", "valueString": "2023-11-20 vote 5-0 by Brian S. Alper, Jesus Lopez-Alcalde, Harold Lehmann, Muhammad Afzal, Eric Harvey"}, {"code": "negative-vote", "valueString": "2023-06-12 vote 5-0 by Brian S. Alper, Sunu Alice Cherian, Harold Lehmann, Paola Rosati, Eric Harvey BUT the term then changed in committee to grapple with sub-terms"}], "concept": [{"code": "TBD:mean-normal", "display": "mean as normal-distribution parameter", "definition": "A probability distribution parameter for a normal distribution that provides the location of the distribution.", "property": [{"code": "editors", "valueString": "Harold Lehmann, Brian S. Alper, Kenneth Wilkins"}, {"code": "comment", "valueString": "This parameter is generally denoted as \u00b5 or mu."}, {"code": "approval", "valueString": "2023-10-16 vote 5-0 by Harold Lehmann, Eric Harvey,: Muhammad Afzal, Louis Leff, Jesus Lopez-Alcalde"}]}, {"code": "TBD:variance-normal", "display": "variance as normal-distribution parameter", "definition": "A probability distribution parameter for a normal distribution that provides the dispersion of the distribution.", "property": [{"code": "editors", "valueString": "Harold Lehmann, Brian S. Alper, Kenneth Wilkins"}, {"code": "comment", "valueString": "This parameter is generally denoted as s<sup>2</sup> or sigma-squared."}, {"code": "approval", "valueString": "2023-10-16 vote 5-0 by Harold Lehmann, Eric Harvey,: Muhammad Afzal, Louis Leff, Jesus Lopez-Alcalde"}]}, {"code": "TBD:population-parameter", "display": "DEPRECATED: population parameter", "definition": "A statistical distribution parameter that is used to define a probability distribution function of the population.", "property": [{"code": "comment", "valueString": "A [statistical distribution parameter](https://fevir.net/resources/CodeSystem/27270#TBD:model-parameter) is defined as a member of a set of quantities that unambiguously defines a probability distribution function.\nWhen a statistic applies to a specific set of data, the specific set of data is called a sample and the statistic is called the sample statistic.  Likewise, when a statistical distribution parameter applies to the group from which a sample may be derived, the group is called a population and the statistical distribution parameter is called a population parameter."}, {"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Kenneth Wilkins, Muhammad Afzal, Joanne Dehnbostel"}, {"code": "deprecated", "valueString": "2023-07-10 with reorganization of the SEVCO section"}]}]}, {"code": "STATO:0000693", "display": "distribution variance", "definition": "A probability distribution attribute that is the expected value of the square of the difference of the value of a variable that has that distribution from its expected value.", "property": [{"code": "editors", "valueString": "Brian S. Alper, Harold Lehmann, Kenneth Wilkins"}, {"code": "comment", "valueString": "For a normal distribution, the distribution parameter variance (also called s<sup>2</sup> or sigma-squared) coincides with the variance of the distribution."}, {"code": "approval", "valueString": "2023-10-16 vote 5-0 by Harold Lehmann, Eric Harvey,: Muhammad Afzal, Louis Leff, Jesus Lopez-Alcalde"}], "concept": [{"code": "TBD:0000056", "display": "variance of the sampling distribution", "definition": "A distribution variance in which the distribution is a sampling distribution of a given statistic.", "designation": [{"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "sampling variance"}, {"use": {"system": "http://snomed.info/sct", "code": "900000000000013009", "display": "Synonym (core metadata concept)"}, "value": "variance of the empirical distribution"}], "property": [{"code": "statistical-purpose", "valueString": "Measure of Dispersion"}, {"code": "comment", "valueString": "Distribution variance is defined as a probability distribution attribute that is the expected value of the square of the difference of the value of a variable that has that distribution from its expected value.\n\nA sampling distribution is a distribution of values for the given statistic derived from a set of random independent samples from the same population. The samples may be theoretical or actual."}, {"code": "editors", "valueString": "Brian S. Alper, Kenneth Wilkins, Harold Lehmann"}, {"code": "approval", "valueString": "2023-11-20 vote 5-0 by Brian S. Alper, Jesus Lopez-Alcalde, Harold Lehmann, Muhammad Afzal, Eric Harvey"}]}]}]}, {"code": "TBD:PD", "display": "probability distribution"}], "contact": [{"name": "Brian S. Alper", "telecom": [{"value": "balper@computablepublishing.com", "system": "email"}]}], "content": "complete", "version": "2.0.0-ballot", "property": [{"code": "comment", "description": "Comment for application", "type": "string"}, {"code": "editors", "description": "Term/Definition Editors", "type": "string"}, {"code": "approval", "description": "Expert Working Group Agreement", "type": "string"}, {"code": "negative-vote", "description": "Expert Working Group Disagreement", "type": "string"}, {"code": "expert-comments", "description": "Expert Working Group Comments", "type": "string"}, {"code": "external-definitions", "description": "Externally Mapped Definitions", "type": "string"}, {"code": "open-for-voting", "description": "Open for Voting", "type": "dateTime"}, {"code": "change-for-vote", "description": "Proposed Change for Future Vote", "type": "string"}, {"code": "multiple-parents", "description": "Has more than one parent term (IS-A relationship)", "type": "string"}, {"code": "statistical-purpose", "description": "Statistical purpose", "type": "string"}], "copyright": "https://creativecommons.org/licenses/by-sa/4.0/ copyright holder is Scientific Knowledge Accelerator Foundation", "publisher": "Computable Publishing LLC", "description": "This code system was copied as a snapshot from the version being used for active development of the Scientific Evidence Code System (SEVCO). This code system is not yet released for expected use and may not be stable. This resource may be used for supporting the examples in the EBMonFHIR Implementation Guide, and published versions of the code system (when ready) will be published as separate resources with stable identifiers.", "experimental": false, "resourceType": "CodeSystem", "caseSensitive": false, "versionNeeded": true, "hierarchyMeaning": "is-a", "relatedArtifact": [{"type": "cite-as", "citation": "Scientific Evidence Code System (SEVCO) -- EXAMPLE VERSION for EBMonFHIR Implementation Guide [Database Entry: FHIR CodeSystem Resource]. Contributors: Brian S. Alper, Joanne Dehnbostel, Khalid Shahin [Authors/Creators]. In: Fast Evidence Interoperability Resources (FEvIR) Platform, FOI 181513. Revised 2024-12-13. Available at: https://fevir.net/resources/CodeSystem/181513. Computable resource at: https://fevir.net/resources/CodeSystem/181513#json."}], "identifier": [{"type": {"text": "FEvIR Object Identifier", "coding": [{"system": "http://terminology.hl7.org/CodeSystem/v2-0203", "code": "ACSN", "display": "Accession ID"}]}, "system": "urn:ietf:rfc:3986", "value": "https://fevir.net/FOI/181513", "assigner": {"display": "Computable Publishing LLC"}}], "author": [{"name": "Brian S. Alper"}, {"name": "Joanne Dehnbostel"}, {"name": "Khalid Shahin"}], "compositional": false, "purpose": "Support of examples in the EBMonFHIR Implementation Guide, prior to final publication of the EBMonFHIR Implementation Guide"}